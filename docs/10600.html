<html>
<head>
<title>Spark Structured Streaming: Multiple Sinks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Spark 结构化流:多个接收器</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/spark-structured-streaming-multiple-sinks-writes-5dea139d4920?source=collection_archive---------0-----------------------#2022-11-15">https://blog.devgenius.io/spark-structured-streaming-multiple-sinks-writes-5dea139d4920?source=collection_archive---------0-----------------------#2022-11-15</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><figure class="gl gn jl jm jn jo gh gi paragraph-image"><div class="gh gi jk"><img src="../Images/721f29f0aec83e0d4ee88c43a26fadf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*TcAv29jE_IRcuOHJa8Y_Kw.png"/></div><figcaption class="jr js gj gh gi jt ju bd b be z dk translated">ref:<a class="ae jv" href="https://qimia.io/en/blog/developing-streaming-applications-spark-structured-streaming/" rel="noopener ugc nofollow" target="_blank">https://qimia . io/en/blog/developing-streaming-applications-spark-structured-streaming/</a></figcaption></figure><p id="6574" class="pw-post-body-paragraph jw jx in jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ig bi translated">在创建接近实时执行的数据管道时，有一个有趣的场景，我在读取源时遇到过，转换复杂的数据，直到将数据写入多个接收器/写入。在寻找解决方案的同时，我阅读了许多解释管道创建和执行的概念的文章，我相信这是大多数开发人员在实时执行期间与流的约束进行斗争的场景。</p><p id="f77b" class="pw-post-body-paragraph jw jx in jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ig bi translated">在本文中，我将介绍 spark 结构在单输入和多输出场景中的行为，并深入探讨它的执行。</p><h1 id="3caf" class="ku kv in bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">问题陈述</h1><p id="ecbb" class="pw-post-body-paragraph jw jx in jy b jz ls kb kc kd lt kf kg kh lu kj kk kl lv kn ko kp lw kr ks kt ig bi translated">当我们从单个源读取数据到多个接收器/写入时，会创建多个作业，这导致从源多次读取相同的数据。</p><figure class="ly lz ma mb gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi lx"><img src="../Images/cccb282f3b36f1571c15acc4d65a9bcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*V1fswmaJQFtxP4ah"/></div></div><figcaption class="jr js gj gh gi jt ju bd b be z dk translated">参赛:https://www.scnsoft.com/services/big-data/spark<a class="ae jv" href="https://www.scnsoft.com/services/big-data/spark" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><h1 id="83f7" class="ku kv in bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">火花行为:当将流分成多个接收器时</h1><p id="7370" class="pw-post-body-paragraph jw jx in jy b jz ls kb kc kd lt kf kg kh lu kj kk kl lv kn ko kp lw kr ks kt ig bi translated">为了生成可能的场景，我们使用结构化流从 Kafka 消费数据，并将处理后的数据集写入 s3，同时在单个作业中使用多个写入器。</p><figure class="ly lz ma mb gt jo gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/e6aad14e45678cb4bc9f33552615db7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/0*RfurzUbDmj26xi7c.png"/></div><figcaption class="jr js gj gh gi jt ju bd b be z dk translated">ref:<a class="ae jv" href="https://jaceklaskowski.gitbooks.io/spark-structured-streaming/content/spark-sql-streaming-MicroBatchExecution.html" rel="noopener ugc nofollow" target="_blank">https://jaceklaskowski . git books . io/spark-structured-streaming/content/spark-SQL-streaming-microbatchexecution . html</a></figcaption></figure><p id="2856" class="pw-post-body-paragraph jw jx in jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ig bi translated">当编写从 Kafka 输入源创建的数据集时，根据执行中的基本理解，我们应该让单个作业包含单个输入和多个输出，但是当我检查 spark-UI 时，为每个输出创建了多个作业。</p><p id="46b2" class="pw-post-body-paragraph jw jx in jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ig bi translated">因为我们将输出分支到多个接收器，所以我们必须为每个接收器/写入提供检查点。因为我们正在分叉输出，这会导致创建多个流查询(作业)。</p><p id="d137" class="pw-post-body-paragraph jw jx in jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ig bi translated">由于 spark 并行性，这些作业可以独立调度，并可以维护其自己的检查点位置，由于这种行为，数据从输入源独立读取(根据接收器/写入的数量多次读取)，同样的事情也反映在 spark-UI 中。</p><p id="f13c" class="pw-post-body-paragraph jw jx in jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ig bi translated">总之，即使从输入主题创建了相同的数据集，并且将数据写入多个接收器/写入，也应该从输入主题多次读取数据。</p><figure class="ly lz ma mb gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi mh"><img src="../Images/f94075a0b8eb6d420b5993de71bd9496.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-mv-5fMgIum6sA1Z1spbAQ.png"/></div></div><figcaption class="jr js gj gh gi jt ju bd b be z dk translated">下面是观察截图，让我们更好地了解在单次读取上执行多个写入器时，spark 结构化流在内部是如何工作的。</figcaption></figure><p id="b2d1" class="pw-post-body-paragraph jw jx in jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ig bi translated">在上面的图像中，时间线部分准确地显示了相同的响应，其中每个接收器都有自己的作业 ID，它将开始从源重复读取数据。</p><p id="197f" class="pw-post-body-paragraph jw jx in jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ig bi translated">对于同一个批处理，它使用相同的查询计划创建多个作业，因此显示在写入多个接收器时发生了多个读取尝试。</p><p id="fa63" class="pw-post-body-paragraph jw jx in jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ig bi translated">如果我们有 N 个接收器，这意味着您有 N 个查询。每个查询都有自己的检查点，并独立地从数据源获取数据。</p><p id="4e43" class="pw-post-body-paragraph jw jx in jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ig bi translated">每个接收/写入创建新的流，它们独立运行，并且从它们自己的检查点位置选取偏移量。为每个流创建不同的组 ID，就好像您正在运行不同的读+写流一样</p><p id="0e86" class="pw-post-body-paragraph jw jx in jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ig bi translated"><strong class="jy io">缺点:</strong>当我们处理源/输入中的巨大数据集时，这会导致性能下降。上述用例在 Kafka 主题中测试了超过 51K 条消息，显示单个写流花费了 4 秒。</p><p id="9198" class="pw-post-body-paragraph jw jx in jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ig bi translated">下面是多重接收/写入的实现。</p><figure class="ly lz ma mb gt jo"><div class="bz fp l di"><div class="mi mj l"/></div></figure><h1 id="baee" class="ku kv in bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">解决方案:使用 forEachBatch writer 实现对多个接收器的写入</h1><p id="c3a2" class="pw-post-body-paragraph jw jx in jy b jz ls kb kc kd lt kf kg kh lu kj kk kl lv kn ko kp lw kr ks kt ig bi translated">可以使用 forEachBatch writer 处理上述场景。</p><p id="dd5b" class="pw-post-body-paragraph jw jx in jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ig bi translated">在执行过程中，我们使用结构化流从 Kafka 消费数据，并将处理后的数据集写入 s3，同时使用 forEachBatch writer 在单个作业中使用多个 writer。</p><figure class="ly lz ma mb gt jo gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/efba79db7422f3447e6ec9acd3d51422.png" data-original-src="https://miro.medium.com/v2/resize:fit:902/format:webp/0*7AyKA6r8sMoRj5B5.png"/></div><figcaption class="jr js gj gh gi jt ju bd b be z dk translated">ref:<a class="ae jv" href="https://jaceklaskowski.gitbooks.io/spark-structured-streaming/content/spark-sql-streaming-MicroBatchExecution.html" rel="noopener ugc nofollow" target="_blank">https://jaceklaskowski . git books . io/spark-structured-streaming/content/spark-SQL-streaming-microbatchexecution . html</a></figcaption></figure><p id="41db" class="pw-post-body-paragraph jw jx in jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ig bi translated">正常数据执行与 forEachBatch 的区别在于，在 forEachBatch 单流查询执行期间，直到 forEachBatch 流程执行。</p><p id="1c3b" class="pw-post-body-paragraph jw jx in jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ig bi translated">在 forEachBatch 中，我们将获得流的批处理数据帧行为，在这里我们可以写入多个目的地。</p><p id="ae50" class="pw-post-body-paragraph jw jx in jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ig bi translated">由于单一流查询，我们维护单一检查点位置。</p><p id="7689" class="pw-post-body-paragraph jw jx in jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ig bi translated">使用 forEachBatch writer，我们有机会缓存数据帧。</p><p id="69ab" class="pw-post-body-paragraph jw jx in jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ig bi translated">下面是我们对相同数量的记录(51K)运行后得到的性能观察结果:</p><figure class="ly lz ma mb gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi ml"><img src="../Images/d9cdec4128f2efd3e8398ea9cfb34e95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9S4GaBrpri79PnpoA34IIw.png"/></div></div></figure><p id="58a0" class="pw-post-body-paragraph jw jx in jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ig bi translated"><strong class="jy io">缺点:</strong>这只支持顺序执行。虽然我们导致了最大计算消耗问题。</p><p id="a634" class="pw-post-body-paragraph jw jx in jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ig bi translated">下面是使用 forEachBatch write 的代码实现。</p><figure class="ly lz ma mb gt jo"><div class="bz fp l di"><div class="mi mj l"/></div></figure><p id="b763" class="pw-post-body-paragraph jw jx in jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ig bi translated">在 spark-UI 中，我们看到了可以使用多线程并行执行的顺序执行……..但这将是另一篇文章了。</p><p id="bc9a" class="pw-post-body-paragraph jw jx in jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ig bi translated">感谢阅读。</p><p id="b853" class="pw-post-body-paragraph jw jx in jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ig bi translated">欢迎在 LinkedIn 上关注我，获取更多文章。</p><p id="9d65" class="pw-post-body-paragraph jw jx in jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ig bi translated">参考资料:<a class="ae jv" href="https://stackoverflow.com/questions/45642904/spark-structured-streaming-multiple-sinks?rq=1" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/45642904/spark-structured-streaming-multiple-sinks？rq=1 </a></p></div></div>    
</body>
</html>