<html>
<head>
<title>How to Install Hadoop on Ubuntu</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在 Ubuntu 上安装 Hadoop</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/how-to-install-hadoop-on-ubuntu-c357b983428c?source=collection_archive---------8-----------------------#2022-08-29">https://blog.devgenius.io/how-to-install-hadoop-on-ubuntu-c357b983428c?source=collection_archive---------8-----------------------#2022-08-29</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><h1 id="0cbb" class="jk jl in bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak">简介</strong></h1><p id="3e15" class="pw-post-body-paragraph ki kj in kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ig bi translated">每个主要行业都在实施 Apache Hadoop 作为处理和存储大数据的标准框架。Hadoop 旨在部署在由数百台甚至数千台专用服务器组成的网络中。所有这些机器一起工作来处理大量和各种各样的输入数据集。</p><p id="ae20" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">在单个节点上部署 Hadoop 服务是熟悉基本 Hadoop 命令和概念的好方法。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi ll"><img src="../Images/deefa9cb50ddf8c334678da8b9702436.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/0*DbnJmy_URBySiHr_.png"/></div></figure><p id="2d65" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated"><strong class="kk io">这本简单易懂的指南帮助你在 Ubuntu 上安装 Hadoop。</strong></p><p id="e0da" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">先决条件:</p><p id="73fb" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">基本上有两个先决条件:</p><ul class=""><li id="8f17" class="lt lu in kk b kl lg kp lh kt lv kx lw lb lx lf ly lz ma mb bi translated">本地/远程机器上的<strong class="kk io"> Sudo </strong>或<strong class="kk io"> root </strong>权限</li><li id="8b8a" class="lt lu in kk b kl mc kp md kt me kx mf lb mg lf ly lz ma mb bi translated">访问终端窗口/命令行</li></ul><h1 id="ce33" class="jk jl in bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">第一步:在 Ubuntu 上安装 OpenJDK</h1><p id="93d6" class="pw-post-body-paragraph ki kj in kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ig bi translated">Hadoop 框架是用 Java 编写的，其服务需要兼容的 Java 运行时环境(JRE)和 Java 开发工具包(JDK)。在开始新的安装之前，使用以下命令更新您的系统:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/e6a6127bad7c12f7cb0a64503791164c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*evGUF4v9T8887PM7h3vtbA.png"/></div></figure><p id="8478" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">目前，<strong class="kk io"> Apache Hadoop 3.x 全面支持 Java 8 </strong>。Ubuntu 中的 OpenJDK 8 包包含运行时环境和开发工具包。</p><p id="c29e" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">在终端中键入以下命令来安装 OpenJDK 8:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/ad7b759d97de1156af52ebfb6dedbbd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*rWt0QvUV29qZmG07-ElgEw.png"/></div></figure><p id="bac9" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">安装过程完成后，验证当前的 Java 版本:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/c3866522b63ac522ffc5255cec5753f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*JyfI2H-qjcOvJbuXMb6-Uw.png"/></div></figure><h1 id="6839" class="jk jl in bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">步骤 2:为 Hadoop 环境设置一个非根用户</h1><p id="8a0c" class="pw-post-body-paragraph ki kj in kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ig bi translated">建议创建一个非 root 用户，特别是对于 Hadoop 环境。独特的用户可以提高安全性，并帮助您更高效地管理集群。</p><p id="2279" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">为了确保 Hadoop 服务的顺利运行，用户应该能够与本地主机建立无密码的 SSH 连接。</p><p id="e53e" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">使用以下命令安装 OpenSSH 服务器和客户机:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/0c4a274e693cbf2c4ef7a01b443c6962.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*cEojuC2lSJtzQRatKopisA.png"/></div></figure><p id="8c54" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">现在我们将创建一个 Hadoop 用户，</p><p id="6f04" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">我们将利用<code class="fe mi mj mk ml b"><strong class="kk io">adduser</strong></code>命令创建一个新的 Hadoop 用户:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/0780bf2b510ea500597f4e4a5fa45bd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*h3SVR_SaGNRRrX5kG7LbQg.png"/></div></figure><p id="09df" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">在这个例子中，用户名是<strong class="kk io"> hadoop </strong>。你可以随意使用任何你认为合适的用户名和密码。切换到新创建的用户，并输入相应的密码:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/0ef733a0a260e21337fa947b1028220a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*YcqPc_FUOXDHFpzUZJUjdw.png"/></div></figure><p id="695b" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">用户现在需要能够在不提示输入密码的情况下 SSH 到本地主机。</p><p id="51e7" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">现在，我们将为 hadoop 用户启用无密码 SSH。用户现在需要能够在不提示输入密码的情况下 SSH 到本地主机。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/581bb74eefc146e264e0ff741416c23c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*KgBeBjV8zK_N8bxTnK3C2Q.png"/></div></figure><p id="9e16" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">使用<code class="fe mi mj mk ml b"><strong class="kk io">cat</strong></code>命令将公钥作为<strong class="kk io"> authorized_keys </strong>存储在 SSH 目录中:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/1234998a7621dfef03296bbe6dea08be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*URzqEQ_U-HHGDeJVAB4yBQ.png"/></div></figure><p id="9042" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">使用<code class="fe mi mj mk ml b"><strong class="kk io">chmod</strong></code>命令为您的用户设置权限:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/4c511d558d5f5d071faa527e2eb2c24e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*TtWRC6QlcUOrESqW8dOu2Q.png"/></div></figure><p id="7f56" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">新用户现在可以使用 SSH，而不需要每次都输入密码。通过使用<strong class="kk io"> hadoop </strong>用户 SSH 到本地主机，验证所有设置是否正确:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/eff4568ee1c09ccee8c08dbba16c6583.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*KYbt-VX1a26PgP5KVW9rsg.png"/></div></figure><p id="9ab1" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">在初始提示之后，Hadoop 用户现在能够无缝地建立到本地主机的 SSH 连接。</p><h1 id="7087" class="jk jl in bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">第三步:在 Ubuntu 上下载并安装 Hadoop</h1><p id="e33d" class="pw-post-body-paragraph ki kj in kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ig bi translated">访问<a class="ae mm" href="https://downloads.apache.org/hadoop/common/" rel="noopener ugc nofollow" target="_blank">官方 Apache Hadoop 项目页面</a>，选择想要实现的 Hadoop 版本。</p><p id="b548" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">选择您喜欢的选项，您会看到一个镜像链接，允许您下载<strong class="kk io"> Hadoop tar 包</strong>。</p><p id="a673" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">运筹学</p><p id="b64a" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">使用提供的镜像链接，并使用<code class="fe mi mj mk ml b"><strong class="kk io">wget</strong></code>命令下载 Hadoop 包(对于此安装，我们将使用 Hadoop 3.3.3，相应地更改链接):</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/4a56bb7b67ee3f34bf3a023ce0492afe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*6l7GyQgpPSFS9qLJc5io0A.png"/></div></figure><p id="d726" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">下载完成后，解压缩文件以启动 Hadoop 安装:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/a13abf924b44e7a4b41ae6429ff9a8ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*Mp9GNQgEY8uZFRur___-Xg.png"/></div></figure><p id="216e" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">Hadoop 在一个大型网络服务器集群<em class="mn">上以<strong class="kk io">完全分布式模式</strong>部署时表现出色。</em>但是，如果您是 Hadoop 新手，并且想要探索基本命令或测试应用程序，您可以在单个节点上配置 Hadoop。</p><h1 id="3e34" class="jk jl in bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">步骤 4:设置单节点 Hadoop 部署(伪分布式模式)</h1><p id="5867" class="pw-post-body-paragraph ki kj in kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ig bi translated">这种设置也称为<strong class="kk io">伪分布式模式</strong>，允许每个 Hadoop 守护进程作为单个 Java 进程运行。Hadoop 环境通过编辑一组配置文件来配置:</p><ul class=""><li id="53eb" class="lt lu in kk b kl lg kp lh kt lv kx lw lb lx lf ly lz ma mb bi translated">bashrc</li><li id="17bd" class="lt lu in kk b kl mc kp md kt me kx mf lb mg lf ly lz ma mb bi translated">hadoop-env.sh</li><li id="bff2" class="lt lu in kk b kl mc kp md kt me kx mf lb mg lf ly lz ma mb bi translated">核心网站. xml</li><li id="51ca" class="lt lu in kk b kl mc kp md kt me kx mf lb mg lf ly lz ma mb bi translated">hdfs-site.xml</li><li id="d6c6" class="lt lu in kk b kl mc kp md kt me kx mf lb mg lf ly lz ma mb bi translated">mapred-site-xml</li><li id="d1a5" class="lt lu in kk b kl mc kp md kt me kx mf lb mg lf ly lz ma mb bi translated">yarn-site.xml</li></ul><p id="9157" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">编辑<em class="mn">。使用您选择的文本编辑器的 bashrc </em> shell 配置文件(我们将使用 nano):</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/1ad30ba813283030c0decb9fc08967cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*rZbvqa9sEpOVcJRXpwFBSw.png"/></div></figure><p id="b341" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">现在，通过将以下内容添加到文件末尾来定义 Hadoop 环境变量(请检查文件路径并做出相应的更改) :</p><figure class="lm ln lo lp gt lq"><div class="bz fp l di"><div class="mo mp l"/></div></figure><p id="ae99" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">添加变量后，保存并退出<em class="mn">。bashrc </em>文件。要保存并退出，请按 CTRL+X，然后按 Enter。</p><p id="6b36" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">使用以下命令将更改应用到当前运行环境是至关重要的:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/c1a75969c41053ffd6458cffbb85046d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*NDYIGf0s904Ec00kd3kPjg.png"/></div></figure><p id="640f" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated"><em class="mn"> hadoop-env.sh </em>文件用作配置 YARN、HDFS、MapReduce 和 hadoop 相关项目设置的主文件。</p><p id="509e" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">使用以下命令编辑<em class="mn"> hadoop-env.sh </em>文件:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/ebf3f3e48b70cd8f6819200c9ba5e516.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*0Pv6TTqOwvAshe_3DFd--Q.png"/></div></figure><p id="0c7a" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">在<em class="mn"> hadoop-env.sh </em>文件中添加下面一行:</p><pre class="lm ln lo lp gt mq ml mr ms aw mt bi"><span id="da69" class="mu jl in ml b gy mv mw l mx my">export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64</span></pre><p id="cae6" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">如果您需要帮助来定位正确的 Java 路径，请在您的终端窗口中运行以下命令:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/6620aa6ddd3dce873648c08475ce92a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*UF0t9WrMCnWSPSwcHHOD8w.png"/></div></figure><p id="49cf" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">使用以下命令，使用提供的路径查找 OpenJDK 目录:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/d0a22478d19a76c791be826f86666d64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*pB3OnN7wleE4JBtDmbxXCA.png"/></div></figure><p id="c355" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">就在<em class="mn"> /bin/javac </em>目录之前的那部分路径需要分配给<code class="fe mi mj mk ml b"><strong class="kk io">$JAVA_HOME</strong></code>变量。</p><p id="7460" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">文件定义了 HDFS 和 Hadoop 的核心属性。</p><p id="6ca8" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">在文本编辑器中打开<em class="mn"> core-site.xml </em>文件:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/42773c76a2f38a662aa8bddb5ef91462.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*0KcPV2IP7BcHAa9pkgc38g.png"/></div></figure><p id="fcff" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">添加以下配置以覆盖临时目录的默认值，并添加您的 HDFS URL 以替换默认的本地文件系统设置:</p><figure class="lm ln lo lp gt lq"><div class="bz fp l di"><div class="mo mp l"/></div></figure><p id="7d3f" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated"><em class="mn"> hdfs-site.xml </em>文件中的属性控制存储节点元数据、fsimage 文件和编辑日志文件的位置。通过定义<strong class="kk io"> NameNode </strong>和<strong class="kk io"> DataNode 存储目录</strong>来配置文件。</p><p id="6acc" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">此外，<code class="fe mi mj mk ml b"><strong class="kk io">3</strong></code>的默认<code class="fe mi mj mk ml b"><strong class="kk io">dfs.replication</strong></code>值需要更改为<code class="fe mi mj mk ml b"><strong class="kk io">1</strong></code>，以匹配单节点设置。</p><p id="73a8" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">使用以下命令打开<em class="mn"> hdfs-site.xml </em>文件进行编辑:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi mz"><img src="../Images/3d94d88ee405ca2a6342ee383ce3451c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0m-dvcntr3LSUi-y-Ru1TQ.png"/></div></div></figure><p id="ea89" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">将以下配置添加到文件中，如果需要，将 NameNode 和 DataNode 目录调整到您的自定义位置:</p><figure class="lm ln lo lp gt lq"><div class="bz fp l di"><div class="mo mp l"/></div></figure><p id="b3e1" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">要保存文件，请按 CTRL+X，然后按 Enter。</p><p id="c0ad" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">使用以下命令访问<em class="mn"> mapred-site.xml </em>文件，并<strong class="kk io">定义 MapReduce 值</strong>:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi mz"><img src="../Images/346bee1daddc21f31a0b1443e0e96b53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5132kAth2jLcuaIzJ_cjfA.png"/></div></div></figure><p id="1f7a" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">添加以下配置，将默认 MapReduce 框架名称值更改为<code class="fe mi mj mk ml b"><strong class="kk io">yarn</strong></code>:</p><figure class="lm ln lo lp gt lq"><div class="bz fp l di"><div class="mo mp l"/></div></figure><p id="98a5" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated"><em class="mn"> yarn-site.xml </em>文件用于定义<strong class="kk io"> YARN </strong>的相关设置。它包含<strong class="kk io">节点管理器、资源管理器、容器、</strong>和<strong class="kk io">应用主机</strong>的配置。</p><p id="0a25" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">在文本编辑器中打开<em class="mn"> yarn-site.xml </em>文件:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi mz"><img src="../Images/ec6a6df72c2c8ca017018d477c04b8ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zI-61gUMx2c0P07Qzy0B2w.png"/></div></div></figure><p id="7be0" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">将以下配置附加到文件中:</p><figure class="lm ln lo lp gt lq"><div class="bz fp l di"><div class="mo mp l"/></div></figure><h1 id="dd40" class="jk jl in bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">步骤 5:格式化 HDFS 命名节点</h1><p id="773c" class="pw-post-body-paragraph ki kj in kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ig bi translated">第一次启动 Hadoop 服务之前，<strong class="kk io">格式化 NameNode </strong>很重要:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi mz"><img src="../Images/5fff95513d3d06b99cc724679a41c9e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ifU6K8Kd0QBQKw4-7WoHDA.png"/></div></div></figure><p id="e05e" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">关闭通知表示 NameNode 格式化过程的结束。</p><h1 id="6b39" class="jk jl in bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">步骤 6:启动 Hadoop 集群</h1><p id="99b8" class="pw-post-body-paragraph ki kj in kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ig bi translated">执行以下命令来启动 NameNode 和 DataNode。系统需要一些时间来启动必要的节点。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi mz"><img src="../Images/12cd20c91248bf5df28dbba8ea5a2e96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vf78dGq3vCpt5TfPuA5NHg.png"/></div></div></figure><p id="bd29" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">一旦 namenode、datanodes 和辅助 namenode 启动并运行，通过键入以下命令启动 YARN 资源和节点管理器:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi mz"><img src="../Images/90d53304262420cc4717436658f2ee81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cj9Av2Tg69oSKMu1hkG0Wg.png"/></div></div></figure><p id="6509" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">键入这个简单的命令来检查是否所有的守护进程都是活动的，并且作为 Java 进程运行:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi mz"><img src="../Images/e30001e42ce9cdef4686ba77749f42c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vFzpo1qNHUj8ZvHEj-wvTg.png"/></div></div></figure><h1 id="8316" class="jk jl in bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">步骤 7:从浏览器访问 Hadoop UI</h1><p id="1463" class="pw-post-body-paragraph ki kj in kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ig bi translated">使用您首选的浏览器并导航到您的本地主机 URL 或 IP。默认端口号<strong class="kk io"> 9870 </strong>允许您访问 Hadoop NameNode UI:</p><pre class="lm ln lo lp gt mq ml mr ms aw mt bi"><span id="e7f2" class="mu jl in ml b gy mv mw l mx my">http://localhost:9870</span></pre><p id="9367" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">NameNode 用户界面提供了整个集群的全面概述。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi ne"><img src="../Images/f5c42dcb01b9c73075f691f1facca198.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_kA_RKSNr1I_a4BDyiTjrQ.png"/></div></div></figure><p id="6a6e" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">默认端口<strong class="kk io"> 9864 </strong>用于直接从浏览器访问各个数据节点:</p><pre class="lm ln lo lp gt mq ml mr ms aw mt bi"><span id="d647" class="mu jl in ml b gy mv mw l mx my">http://localhost:9864</span></pre><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi ne"><img src="../Images/56dce24b54895d8a8bab3996bb423dd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b-BnULq5va9kBc50XEoYWw.png"/></div></div></figure><p id="4ccb" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">纱线资源管理器可通过端口<strong class="kk io"> 8088 </strong>访问:</p><pre class="lm ln lo lp gt mq ml mr ms aw mt bi"><span id="1d2c" class="mu jl in ml b gy mv mw l mx my">http://localhost:8088</span></pre><p id="fc74" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">资源管理器是一个非常有价值的工具，它允许您监控 Hadoop 集群中所有正在运行的进程。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi ne"><img src="../Images/080ab807af15d3547d3fa9ffe8b972fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MlH6dujxcsFB8VxZfYD2Aw.png"/></div></div></figure><p id="76a2" class="pw-post-body-paragraph ki kj in kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf ig bi translated">您已经在 Ubuntu 上成功安装了 Hadoop，并以伪分布式模式部署。单节点 Hadoop 部署是探索基本 HDFS 命令和获取设计完全分布式 Hadoop 集群所需经验的绝佳起点。</p><h1 id="d714" class="jk jl in bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">结论:</h1><p id="c140" class="pw-post-body-paragraph ki kj in kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ig bi translated">在这篇文章中，如果你正在阅读这篇文章，那么请喜欢，评论并与你的朋友分享这篇文章。我已经描述了安装 Hadoop 3 的一步一步的方法。我希望你喜欢阅读这篇文章，我已经能够做出一些贡献。谢谢你们。这是 Abhijit 结束。祝你有愉快的一天。</p></div></div>    
</body>
</html>