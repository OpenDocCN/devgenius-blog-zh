<html>
<head>
<title>How I scraped IPL Auction data using Beautiful Soup</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我是如何用美汤刮出 IPL 拍卖数据的</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/how-i-scraped-ipl-auction-data-using-beautiful-soup-b5f94f0fd300?source=collection_archive---------7-----------------------#2020-06-04">https://blog.devgenius.io/how-i-scraped-ipl-auction-data-using-beautiful-soup-b5f94f0fd300?source=collection_archive---------7-----------------------#2020-06-04</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><div class=""><h2 id="ace8" class="pw-subtitle-paragraph jk im in bd b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb dk translated">IPL 2020 数据从零开始报废！</h2></div><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi kc"><img src="../Images/1dfbd1d3b35bab56da1bc0a8b6a3b693.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6K1kiU-ghWRoUOr4p-r_eA.jpeg"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">samarth shirke 在<a class="ae ks" href="https://unsplash.com/s/photos/cricket?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="7988" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi lp translated"><span class="l lq lr ls bm lt lu lv lw lx di"> P </span> ython 几乎无所不能——从数据分析、构建 web 框架、处理后端，或者从 web 上抓取数据。当人们阅读代码的时候，抓取看起来非常混乱。但是，不是的！你读到的那些胡言乱语通常是我们从中提取数据的 web 元素。除此之外，一切都很简单。</p><p id="d007" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">我用美汤刮过 IPL 拍卖 2019–2020 赛季数据。看看刮任何网站都需要什么？大多数情况下，鹰眼捕捉网页元素和图书馆的知识。所以，我们刮吧！</p><p id="4c5d" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated"><strong class="kv io">包含的库</strong></p><p id="d6f9" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">我已经包括美丽的汤，熊猫，并要求图书馆。Requests 库将发送 HTTP 请求，BeautifulSoup 将获取 web 元素，Pandas 将分析数据。</p><pre class="kd ke kf kg gt ly lz ma mb aw mc bi"><span id="2325" class="md me in lz b gy mf mg l mh mi">from bs4 import BeautifulSoup<br/>import pandas as pd<br/>import requests as rq</span></pre><p id="d3eb" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated"><strong class="kv io">请求并解析 URL </strong></p><p id="437c" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">我使用了“请求”库来调用 URL。调用成功后，我用“美汤”解析网站的 web 元素。</p><pre class="kd ke kf kg gt ly lz ma mb aw mc bi"><span id="98fa" class="md me in lz b gy mf mg l mh mi">url="https://www.cricbuzz.com/cricket-series/ipl-2020/auction/completed"<br/>get_url=rq.get(url)<br/>soup=BeautifulSoup(get_url.text,"html.parser")</span></pre><h2 id="4327" class="md me in bd mj mk ml dn mm mn mo dp mp lc mq mr ms lg mt mu mv lk mw mx my mz bi translated"><strong class="ak">获取网页元素</strong></h2><p id="aef7" class="pw-post-body-paragraph kt ku in kv b kw na jo ky kz nb jr lb lc nc le lf lg nd li lj lk ne lm ln lo ig bi translated">我使用“findAll”方法，通过列表理解将每个名字和状态放入列表中。findAll 用于查找使用特定标签的每个 web 元素。并且，您可以使用循环来遍历它们。此外，从每次迭代中提取值，并将其添加到一个列表中，就像我在下面的场景中所做的那样。</p><pre class="kd ke kf kg gt ly lz ma mb aw mc bi"><span id="8de6" class="md me in lz b gy mf mg l mh mi">Name= [i.text for i in soup.findAll('div',{'class':'cb-font-18'})]</span><span id="fe33" class="md me in lz b gy nf mg l mh mi">Sold_Unsold= [i.text for i in soup.findAll('div',{'class':'cb-col cb-col-20 cb-lst-itm-sm'})]</span></pre><p id="770f" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">只是在这里和那里做了一点调整，比如在 Price 列和 Sold_To 列中用空白替换' \xa0\xa0 '。</p><pre class="kd ke kf kg gt ly lz ma mb aw mc bi"><span id="168b" class="md me in lz b gy mf mg l mh mi">Base_Price= [i.text for i in soup.findAll('div',{'class':'cb-col cb-col-33 cb-lst-itm-sm text-left','class':'cb-font-16'})]</span><span id="db8d" class="md me in lz b gy nf mg l mh mi">Base_Price=Base_Price[0:len(Base_Price)-3:3]<br/>Base_Price=[i.replace('\xa0\xa0',' ') for i in Base_Price]</span><span id="bf3f" class="md me in lz b gy nf mg l mh mi">Final_Price= [i.text for i in soup.findAll('div',{'class':'cb-col cb-col-33 cb-lst-itm-sm text-left','class':'cb-font-16'})]</span><span id="bf60" class="md me in lz b gy nf mg l mh mi">Final_Price=Final_Price[1:len(Final_Price)-3:3]<br/>Final_Price=[i.replace('\xa0\xa0',' ') for i in Final_Price]</span><span id="81ab" class="md me in lz b gy nf mg l mh mi">Sold_To= [i.text for i in soup.findAll('div',{'class':'cb-col cb-col-33 cb-lst-itm-sm text-left','class':'cb-font-16'})]</span><span id="6076" class="md me in lz b gy nf mg l mh mi">Sold_To=Sold_To[2:len(Sold_To)-3:3]<br/>Sold_To=[i.replace('\xa0\xa0',' ') for i in Sold_To]</span><span id="d959" class="md me in lz b gy nf mg l mh mi">Role= [i.text for i in soup.findAll('div',{'class':'cb-col cb-col-80','class':'cb-font-12 text-gray'})]</span><span id="eac6" class="md me in lz b gy nf mg l mh mi">Role=Role[0::4]<br/>Role=[i.split(' • ')[0] for i in Role]</span></pre><p id="6d79" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">我包含了一个 split 函数来从表中获取每个板球运动员的角色。我的输出如下所示:</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi ng"><img src="../Images/a9e52fd1eba1eac345349b4884ea9b4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S0QbCxHfC0oBDaT1IRwL4g.png"/></div></div></figure><p id="1463" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">所以，我只在我的角色列表中添加了第 0 个索引。</p><p id="6a43" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated"><strong class="kv io">最终触摸</strong></p><p id="400e" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">最后，将每一列都放入数据报。使用 pandas 的<em class="nh"> to_csv </em>方法将数据帧转换为 CSV 文件。你完了！</p><pre class="kd ke kf kg gt ly lz ma mb aw mc bi"><span id="2a51" class="md me in lz b gy mf mg l mh mi">Table=pd.DataFrame({<br/>    "Name":Name,<br/>    "Role": Role,<br/>    "Status":Sold_Unsold,<br/>    "Base Price": Base_Price,<br/>    "Final Price": Final_Price,<br/>    "Team": Sold_To })</span><span id="aad5" class="md me in lz b gy nf mg l mh mi">Table.replace("-","",inplace=True)</span><span id="f843" class="md me in lz b gy nf mg l mh mi">Table.to_csv("IPLAuction2019.csv")</span></pre><p id="c25c" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">只需 10-20 分钟就能刮出这样的东西。而且，你可以得到一个很好的数据集，你可以用它来获得洞察力和进行探索性分析。</p><p id="b913" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated"><strong class="kv io">平安！</strong></p></div></div>    
</body>
</html>