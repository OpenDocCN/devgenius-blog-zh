# èŠå¤©æœºå™¨äººé©±åŠ¨çš„å¼€å‘

> åŸæ–‡ï¼š<https://blog.devgenius.io/chatbot-driven-development-fbb4392ff5b4?source=collection_archive---------10----------------------->

## ç”¨ OpenAI çš„ ChatGPT åˆ†äº«æˆ‘çš„ç¼–ç å®éªŒ

ä½ å¯èƒ½å¬è¯´è¿‡ [ChatGPT](https://openai.com/blog/chatgpt/) ï¼Œå®ƒè‡ªå‘å¸ƒä»¥æ¥äººæ°”é£™å‡ï¼Œå·²ç»[çªç ´ä¸€ç™¾ä¸‡ç”¨æˆ·](https://twitter.com/sama/status/1599668808285028353?s=20&t=i1HtKPGeYadE397wB6bX9Q)ã€‚äººä»¬ç”¨è¿™ä¸ªå·¥å…·åšä¸€äº›ç»å¯¹ä»¤äººæƒŠè®¶çš„äº‹æƒ…ï¼Œæ¯”å¦‚åœ¨é‡Œé¢å»ºä¸€ä¸ª[è™šæ‹Ÿæœº](https://twitter.com/317070/status/1599152176344928256?s=20&t=yW4LjC4-7IY8RyiQ_FYtaA)æˆ–è€…[å†™å­¦æœ¯è®ºæ–‡](https://www.theguardian.com/technology/2022/dec/04/ai-bot-chatgpt-stuns-academics-with-essay-writing-skills-and-usability)ã€‚

æˆ‘ä¹Ÿä¸èƒ½é”™è¿‡å°è¯•çš„æœºä¼šã€‚ç›®å‰ï¼Œæˆ‘æ­£åœ¨å­¦ä¹  Rust ç¼–ç¨‹è¯­è¨€(è€Œä¸”è§‰å¾—å¾ˆç¥å¥‡ï¼)ï¼Œå¹¶æ„å»ºå°é¡¹ç›®æ¥å®è·µã€‚å¦‚æœæˆ‘ç”¨äººå·¥æ™ºèƒ½åŠ©æ‰‹æ¥ä¿ƒè¿›æˆ‘çš„å­¦ä¹ ä¼šæ€ä¹ˆæ ·ï¼Ÿæˆ‘ä»¬å·²ç»æœ‰äº†åƒ [Copilot](https://github.com/features/copilot) æˆ– [Ghostwriter](https://blog.replit.com/ai) è¿™æ ·çš„ä¸“ç”¨å·¥å…·æ¥å¸®åŠ©ç¼–å†™ä»£ç ã€‚ä½†æ˜¯ä¹Ÿè®¸æœ‰å¯èƒ½æ›´è¿›ä¸€æ­¥ï¼Œç”¨ä¸€ä¸ªé€šç”¨çš„èŠå¤©æœºå™¨äººæ¥æ„å»ºè½¯ä»¶ï¼Œå®ƒå¯ä»¥ç»™æˆ‘ä»¬åé¦ˆå¹¶å¸®åŠ©æˆ‘ä»¬æ”¹è¿›ã€‚

äº‹å®ä¸Šï¼Œä½¿ç”¨è‡ªç„¶è¯­è¨€æ¥æ„å»ºä»£ç å¹¶ä¸æ˜¯ä¸€ä¸ªæ–°çš„æƒ³æ³•ã€‚OpenAI ä¹‹å‰å‘å¸ƒäº†ä¸€ä¸ª [JavaScript playground](https://beta.openai.com/codex-javascript-sandbox) ï¼Œå…è®¸ç”¨æˆ·ä½¿ç”¨æ–‡æœ¬å‘½ä»¤æ„å»º web åº”ç”¨ã€‚ç„¶è€Œï¼Œç”±äºä½¿ç”¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ŒChatGPT å¹¶ä¸å±€é™äºä»»ä½•ç‰¹å®šçš„ç¼–ç¨‹è¯­è¨€ï¼Œè€Œä¸”åŠŸèƒ½æ›´åŠ å¼ºå¤§ã€‚

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†åˆ†äº«æˆ‘ä½¿ç”¨ ChatGPT æ„å»ºä¸€ä¸ªç®€å•çš„ Rust HTTP å®¢æˆ·ç«¯çš„ç»éªŒï¼Œè¯¥å®¢æˆ·ç«¯å‘â€¦ä¸€ä¸ª OpenAI æ¨¡å‹å‘é€è¯·æ±‚ï¼è¿™æ˜¯ä¸€ä¸ªéå¸¸åŸºæœ¬çš„æ¦‚å¿µéªŒè¯ï¼Œç”šè‡³ä¸æ˜¯ä¸€ä¸ª MVPã€‚ä½†æ˜¯å®ƒåº”è¯¥è®©æ‚¨å¯¹ ChatGPT çš„èƒ½åŠ›æœ‰æ‰€äº†è§£ã€‚æˆ‘ä»¬å¼€å§‹å§ï¼

> åœ¨è¿™é‡Œä½ å¯ä»¥æ‰¾åˆ°è¿™ç¯‡æ–‡ç« ä¸­åˆ›å»ºçš„ä»£ç ã€‚

![](img/a25be1ce439c2f1fe0fd0d91884ffe2f.png)

æˆ‘æƒ…ä¸è‡ªç¦åœ°ä¸ºè¿™ç¯‡æ–‡ç« ç”Ÿæˆäº†ä¸€å¼ å°é¢å›¾ç‰‡ï¼Œå¹¶ä¸”ä½¿ç”¨äº† [OpenAI æ¨¡å‹](https://openai.com/dall-e-2/)ã€‚

# 0.ä»‹ç»

æˆ‘ä½¿ç”¨ä»¥ä¸‹æ ¼å¼è§„åˆ™æ¥ç»„ç»‡æ–‡ç« ã€‚

*   æˆ‘å‘å¸ƒåˆ°èŠå¤©å®¤çš„æ‰€æœ‰æ–‡æœ¬ç‰‡æ®µéƒ½ä»¥ ***æˆ‘å¼€å§‹ã€‚***
*   åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæˆ‘ä¸ä»…å†™äº†çº¯æ–‡æœ¬ï¼Œè¿˜å†™äº†å°ä»£ç ç‰‡æ®µæ¥å¼•å¯¼å¯¹è¯ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ç”¨é™ä»·å¼çš„ä¸‰ä¸ªåå‹¾å·å°†ä»£ç æ®µåŒ…è£…èµ·æ¥ã€‚
*   ä»æ¨¡å‹æ¥æ”¶çš„å“åº”ä»¥ ***ChatGPT*** å¼€å§‹ã€‚
*   åœ¨æŸäº›(å¤§å¤šæ•°)æƒ…å†µä¸‹ï¼Œè¿™äº›å›ç­”è¢«ç¼–è¾‘ä»¥æ’é™¤ç”¨ç®€å•è‹±è¯­å†™çš„è¿‡äºå†—é•¿çš„ç‰‡æ®µæˆ–ç¼©çŸ­é‡å¤çš„ç‰‡æ®µï¼Œå¹¶ä¸”åªä¿ç•™æœ€ç›¸å…³çš„éƒ¨åˆ†ã€‚
*   æˆ‘å’Œ GPT çš„ä¿¡æ¯éƒ½æ˜¯ç”¨æ–œä½“å­—å†™çš„ã€‚æ–‡æœ¬çš„å…¶ä½™éƒ¨åˆ†ä»¥æ™®é€šå­—ä½“ä¹¦å†™(å°±åƒè¿™ä¸ªä»‹ç»ä¸€æ ·),ä»¥åŒ…å«é™„åŠ çš„æ³¨é‡Šã€‚
*   åœ¨æŸäº›åœ°æ–¹ï¼Œæˆ‘ä½¿ç”¨`[sentenses in square brackets]`æ¥æ·»åŠ â€œå†…åµŒâ€è¯„è®ºï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œå®ƒä¸æ˜¯æ¥è‡ªèŠå¤©çš„ä¸€å­—ä¸å·®çš„æ¶ˆæ¯ã€‚
*   æœ€åï¼Œå½“æˆ‘ä½¿ç”¨èŠå¤©æœºå™¨äººæ—¶ï¼Œå®ƒä¸æ˜¯å¾ˆç¨³å®šï¼Œæ‰€ä»¥ï¼Œæˆ‘ä¸å¾—ä¸ä»å¤´å¼€å§‹å¯¹è¯å‡ æ¬¡ï¼Œæˆ–è€…ä½¿ç”¨ä¹‹å‰åˆ›å»ºçš„ç‰‡æ®µé‡æ–°ç”Ÿæˆç­”æ¡ˆã€‚

# I .ç¼–å†™ API å®¢æˆ·ç«¯

***æˆ‘:*** *æˆ‘éœ€è¦ä½ å¸®æˆ‘å†™ä¸€ä¸ª Rust ç¨‹åºã€‚å‚è§è¦æ±‚:*

1.  è¯¥ç¨‹åºæ˜¯ä¸€ä¸ªç®€å•çš„ CLI å®¢æˆ·ç«¯ï¼Œç”¨äºæ‰“å¼€åŸºäº AI GPT çš„æ¨¡å‹ã€‚
2.  *ç¨‹åºå°†ä¸€ä¸ªå­—ç¬¦ä¸²ä½œä¸ºæç¤ºï¼Œå‘ API å‘å‡ºè¯·æ±‚ã€‚*
3.  *å®ƒä» env å˜é‡æˆ–ã€‚env æ–‡ä»¶(å¦‚æœå­˜åœ¨)ã€‚*
4.  *å¦‚æœæ²¡æœ‰æä¾› API å¯†é’¥/ä»¤ç‰Œï¼Œå®ƒä¼šè¦æ±‚éªŒè¯ã€‚*
5.  ç¨‹åºå¯ä»¥ä½¿ç”¨ä»»ä½•ä½ è®¤ä¸ºæœ‰åŠ©äºè¾¾åˆ°è¦æ±‚ç»“æœçš„æ¿æ¡ç®±ã€‚

***ChatGPT:*** `[phrases in plain English are omitted]`

```
use std::env;

// Import the OpenAI API client crate
use openai::Client;

// Read the API credentials from environment variables
let api_key = env::var("OPENAI_API_KEY").expect("OPENAI_API_KEY must be set");

// Create a new client with the API key
let client = Client::new(api_key);

// Prompt the user for input
println!("Enter a prompt:");
let mut prompt = String::new();
stdin().read_line(&mut prompt)?;

// Use the client to make a request to the API
let response = client.completions(prompt, None, None, None)?;

// Print the response
println!("{:?}", response);
```

***æˆ‘:*** *å¥½å§ï¼Œå°±è¯´æˆ‘æ²¡æœ‰* `*openai*` *æ¿æ¡ç®±å§ã€‚ä¸ºæˆ‘å†™ä¸€ä¸ªç®€å•çš„å®ç°ï¼Œç”¨* `*reqwest*` *æ¿æ¡ç®±ä»£æ›¿ã€‚*

***ChatGPT:***

```
use std::env;

// Import the reqwest crate
use reqwest;

// Read the API credentials from environment variables
let api_key = env::var("OPENAI_API_KEY").expect("OPENAI_API_KEY must be set");

// Prompt the user for input
println!("Enter a prompt:");
let mut prompt = String::new();
stdin().read_line(&mut prompt)?;

// Build the request URL with the prompt and API key
let url = format!("https://api.openai.com/v1/completions/models/davinci/versions/1?prompt={}&api_key={}", prompt, api_key);

// Send the request and parse the JSON response
let response: serde_json::Value = reqwest::get(url)?.json()?;

// Print the response
println!("{:?}", response);
```

***Me:*** *è¯·å°†åˆ›å»ºå¥½çš„çº¿æ¡éšè—åœ¨ä¸“ç”¨å®¢æˆ·ç«¯å¯¹è±¡åé¢ã€‚å®ƒå¯èƒ½çœ‹èµ·æ¥å¦‚ä¸‹:*

```
pub struct Client {
    /// add any fields you deem necessary
}
impl Client {
    pub fn authenticate(&mut self) {
        /// does API authentication if not authenticated yet
    }
    pub fn prompt(&self, message: &String) -> OpenAIResult {
        /// implement the request and return result as a dedicated result structure
    }
    /// any other methods you might need
}
```

***ChatGPT:***

```
use std::env;
use std::error::Error;

// Import the reqwest crate
use reqwest;

// Import the serde_json crate
use serde_json;

// Define a result type for the API response
type OpenAIResult = Result<serde_json::Value, Box<dyn Error>>;

// Define the Client struct
pub struct Client {
    api_key: String,
    authenticated: bool,
}

impl Client {
    // Implement the authenticate method
    pub fn authenticate(&mut self) {
        if !self.authenticated {
            // Read the API key from environment variables
            self.api_key = env::var("OPENAI_API_KEY").expect("OPENAI_API_KEY must be set");
            self.authenticated = true;
        }
    }

    // Implement the prompt method
    pub fn prompt(&self, message: &String) -> OpenAIResult {
        // Build the request URL with the prompt and API key
        let url = format!("https://api.openai.com/v1/completions/models/davinci/versions/1?prompt={}&api_key={}", message, self.api_key);

        // Send the request and parse the JSON response
        let response: serde_json::Value = reqwest::get(url)?.json()?;

        // Return the response
        Ok(response)
    }
}
```

***æˆ‘:*** *ç¼–è¾‘ä¸€ä¸‹ä½ çš„è§£å†³æ–¹æ¡ˆã€‚ä¸è¦ä½¿ç”¨ä»»ä½•ç¡¬ç¼–ç çš„å­—ç¬¦ä¸²ï¼Œè€Œæ˜¯å°†å®ƒä»¬æ”¾å…¥å…¨å±€å˜é‡å’Œ/æˆ–åŠ¨æ€æ„é€ ã€‚*

***ChatGPT:***

```
use std::env;
use std::error::Error;

// Import the reqwest crate
use reqwest;

// Import the serde_json crate
use serde_json;

// Define a result type for the API response
type OpenAIResult = Result<serde_json::Value, Box<dyn Error>>;

// Define global variables for the API endpoint and model
const API_ENDPOINT: &str = "https://api.openai.com/v1/completions/models/";
const MODEL: &str = "davinci";
const MODEL_VERSION: &str = "1";

// Define the Client struct
pub struct Client {
    api_key: String,
    authenticated: bool,
}

impl Client {
    // Implement the authenticate method
    pub fn authenticate(&mut self) {
        if !self.authenticated {
            // Read the API key from environment variables
            self.api_key = env::var("OPENAI_API_KEY").expect("OPENAI_API_KEY must be set");
            self.authenticated = true;
        }
    }

    // Implement the prompt method
    pub fn prompt(&self, message: &String) -> OpenAIResult {
        // Build the request URL with the prompt, model, and API key
        let url = format!("{}{}/versions/{}?prompt={}&api_key={}", API_ENDPOINT, MODEL, MODEL_VERSION, message, self.api_key);

        // Send the request and parse the JSON response
        let response: serde_json::Value = reqwest::get(url)?.json()?;

        // Return the response
        Ok(response)
    }
}
```

***æˆ‘:*** *å†™ä¸€ç³»åˆ—å‘½ä»¤ï¼Œæˆ‘éœ€è¦æ‰§è¡Œè¿™äº›å‘½ä»¤æ¥è®¾ç½®ä½ ä¸Šé¢åˆ›å»ºçš„é¡¹ç›®ã€‚*

***ChatGPT:*** `[returns a response with lots of text between commands]`

***æˆ‘:*** *å¯¹äºä¸Šé¢ä½ ç»™æˆ‘çš„ç­”æ¡ˆï¼Œå»æ‰æ‰€æœ‰ç”¨è‹±æ–‡å†™çš„â€œçº¯æ–‡æœ¬â€ï¼Œåˆ›å»ºä¸€ä¸ªå•ç‹¬çš„ä»£ç ç‰‡æ®µï¼Œä½œä¸º bash å‘½ä»¤çš„åºåˆ—ï¼Œæ¥å®ç°ç»“æœã€‚*

ä¸‹é¢æ˜¯ä¸€ç³»åˆ— bash å‘½ä»¤ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨å®ƒä»¬åœ¨ Rust ä¸­ä¸ºåŸºäº OpenAI GPT çš„æ¨¡å‹å»ºç«‹ä¸€ä¸ªç®€å•çš„ CLI å®¢æˆ·ç«¯é¡¹ç›®ã€‚

```
# Install the Rust programming language
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# Create a new project directory and navigate to it
mkdir openai-client
cd openai-client

# Initialize a new Rust project with cargo
cargo init

# Edit the Cargo.toml file and add the reqwest and serde_json crates as dependencies
echo '[dependencies]' >> Cargo.toml
echo 'reqwest = "0.10"' >> Cargo.toml
echo 'serde_json = "1.0"' >> Cargo.toml

# Create a new file named src/main.rs
touch src/main.rs

# Copy the code for the Client struct into src/main.rs
echo 'use std::env;
use std::error::Error;

// Import the reqwest crate
use reqwest;

// Import the serde_json crate
use serde_json;

// Define a result type for the API response
type OpenAIResult = Result<serde_json::Value, Box<dyn Error>>;

// Define global variables for the API endpoint and model
const API_ENDPOINT: &str = "https://api.openai.com/v1/completions/models/";
const MODEL: &str = "davinci";
const MODEL_VERSION: &str = "1";

// Define the Client struct
pub struct Client {
    api_key: String,
    authenticated: bool,
}

impl Client {
    // Implement the authenticate method
    pub fn authenticate(&mut self) {
        if !self.authenticated {
            // Read the API key from environment variables
            self.api_key = env::var("OPENAI_API_KEY").expect("OPENAI_API_KEY must be set");
            self.authenticated = true;
        }
    }

    // Implement the prompt method
    pub fn prompt(&self, message: &String) -> OpenAIResult {
        // Build the request URL with the prompt, model, and API key
        let url = format!("{}{}/versions/{}?prompt={}&api_key={}", API_ENDPOINT, MODEL, MODEL_VERSION, message, self.api_key);

        // Send the request and parse the JSON response
        let response: serde_json::Value = reqwest::get(url)?.json()?;

        // Return the response
        Ok(response)
    }
}' >> src/main.rs

# Build and run the project
cargo run
```

***æˆ‘:*** *å·®ä¸å¤šäº†ï¼ä½†æ˜¯ï¼Œæ‚¨åˆ›å»ºçš„* `*main.rs*` *æ–‡ä»¶æ— æ•ˆã€‚å®ƒä¸å…·å¤‡* `*main*` *åŠŸèƒ½ã€‚è¯·ç¼–è¾‘æ‚¨åˆ›å»ºçš„ä»£ç ç‰‡æ®µï¼Œä½¿å…¶åŒ…å«ä¸€ä¸ªåŸºæœ¬çš„ main å‡½æ•°ï¼Œè¯¥å‡½æ•°ä» args è·å–ç”¨æˆ·æç¤ºï¼Œå¹¶å‘ API å‘é€è¯·æ±‚ã€‚*

***ChatGPT:*** `[updates the script adding main function; showing the updated part only]`

```
... // [the rest of the code goes above]

// Define the main function
fn main() {
    // Create a new client
    let mut client = Client {
        api_key: "".to_string(),
        authenticated: false,
    };

    // Authenticate the client
    client.authenticate();

    // Read the prompt from command-line arguments
    let args: Vec<String> = env::args().collect();
    if args.len() < 2 {
        eprintln!("Usage: openai-client <prompt>");
        process::exit(1);
    }
    let prompt = &args[1];

    // Use the client to make a request to the API
    let response = client.prompt(prompt).unwrap();

    // Print the response
    println!("{:?}", response);
}
```

***æˆ‘:*** *ç°åœ¨ï¼Œè¿˜æœ‰ä¸€ä»¶äº‹ã€‚è¯·åˆ›å»ºä¸€ä¸ª* `*Client::new*` *æ¥åˆ›å»ºä¸€ä¸ªå®¢æˆ·ç«¯ï¼Œå…¶* `*api_key*` *å­—ç¬¦ä¸²ä¸ºç©ºï¼Œå¹¶ä¸”* `*false*` *å­—æ®µçš„å€¼ä¸º* `*authenticated*` *å­—æ®µï¼Œå¹¶ä½¿ç”¨å®ƒæ¥ä»£æ›¿åˆ›å»ºå®¢æˆ·ç«¯çš„å®ä¾‹ã€‚å› æ­¤ï¼Œæ›´æ–°åçš„è¡Œåº”è¯¥å¦‚ä¸‹æ‰€ç¤º:*

```
let mut client = Client::new();
```

***ChatGPT:*** `[unfortunately, this time, the conversation stopped abruptly; the snippet was trimmed half-way, and the model was thinking indefinitely without any further outout; so, I left the snippet as is]`

å“¦ï¼ŒçœŸä»¤äººå°è±¡æ·±åˆ»ï¼è¯¥æ¨¡å‹å‡†ç¡®åœ°è·Ÿè¸ªå¯¹è¯ï¼Œå¹¶æ ¹æ®è¯·æ±‚å¯¹ä»£ç è¿›è¡Œé€‚å½“çš„ä¿®æ”¹ã€‚å…³é”®æ—¶åˆ»:åœ¨æœ¬åœ°å¤åˆ¶ç²˜è´´ä»£ç ï¼Œæ·»åŠ ä¸€ä¸ªç¼ºå°‘çš„ä¸»å‡½æ•°ï¼Œå¹¶å°è¯•è¿è¡Œå®ƒï¼

```
chmod +x create_client.sh
./create_client.sh
```

> æˆ‘ä»¬åˆ°äº†å—ï¼Ÿå—¯ï¼Œä¸å®Œå…¨æ˜¯â€¦

```
error[E0433]: failed to resolve: use of undeclared crate or module `process`
  --> src/main.rs:62:9
   |
62 |         process::exit(1);
   |         ^^^^^^^ use of undeclared crate or module `process`

error[E0277]: the trait bound `std::string::String: IntoUrl` is not satisfied
   --> src/main.rs:40:56
    |
40  |         let response: serde_json::Value = reqwest::get(url)?.json()?;
    |                                           ------------ ^^^ expected an implementor of trait `IntoUrl`
    |                                           |
    |                                           required by a bound introduced by this call
    |
    = note: required because of the requirements on the impl of `IntoUrl` for `std::string::String`
note: required by a bound in `reqwest::get`
   --> [...].cargo/registry/src/github.com-1ecc6299db9ec823/reqwest-0.10.10/src/lib.rs:256:21
    |
256 | pub async fn get<T: IntoUrl>(url: T) -> crate::Result<Response> {
    |                     ^^^^^^^ required by this bound in `reqwest::get`
help: consider borrowing here
    |
40  |         let response: serde_json::Value = reqwest::get(&url)?.json()?;
    |                                                        +

error[E0277]: the `?` operator can only be applied to values that implement `Try`
  --> src/main.rs:40:43
   |
40 |         let response: serde_json::Value = reqwest::get(url)?.json()?;
   |                                           ^^^^^^^^^^^^^^^^^^ the `?` operator cannot be applied to type `impl Future<Output = Result<Response, reqwest::Error>>`
   |
   = help: the trait `Try` is not implemented for `impl Future<Output = Result<Response, reqwest::Error>>`

Some errors have detailed explanations: E0277, E0433.
For more information about an error, try `rustc --explain E0277`.
error: could not compile `openai-client` due to 3 previous errors
```

ä½ å¯èƒ½å·²ç»æ³¨æ„åˆ°äº†ï¼Œè¿™ä¸ªç‰‡æ®µä¸å¤ªæ­£ç¡®ã€‚

1.  ç”Ÿæˆçš„ bash è„šæœ¬ä½¿ç”¨`>>`æ“ä½œç¬¦å°†åˆ›å»ºçš„ä»£ç é™„åŠ åˆ°`main.rs`ä¸­ï¼Œè€Œä¸æ˜¯ä½¿ç”¨`>`ä»å¤´å¼€å§‹åˆ›å»ºæ–‡ä»¶ã€‚(æ‰€ä»¥ï¼Œä½ æœ€åå¾—åˆ°äº†*ä¸¤ä¸ª*ä¸»å‡½æ•°ã€‚)
2.  å®ƒè¿˜å‘æˆ‘æ‰‹åŠ¨ä¿®å¤çš„ TOML æ–‡ä»¶ä¸­å†™å…¥äº†ä¸€ä¸ªé¢å¤–çš„`[dependencies]`è¡Œï¼Œä»¥ä¾¿è®©`cargo run`å·¥ä½œã€‚
3.  æ¼æ‰äº†åŒ…æ‹¬`std::process`ã€‚
4.  ä¾èµ–ç‰ˆæœ¬å¾ˆé‡è¦:`reqwest=0.10`é»˜è®¤ä½¿ç”¨å¼‚æ­¥ APIï¼Œå› æ­¤ä¸èƒ½ä¸ ChatGPT ç”Ÿæˆçš„ä»£ç ä¸€èµ·å·¥ä½œã€‚å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:ç”¨`#[tokio::main]`ä¿®é¥°ä¸»å‡½æ•°ï¼Œä½¿å…¶å¼‚æ­¥ï¼Œæˆ–è€…é™çº§ç‰ˆæœ¬ä½¿ç”¨åŒæ­¥ APIã€‚
5.  æœ€åï¼Œå®ƒåº”è¯¥ä½¿ç”¨`&url`è€Œä¸ä»…ä»…æ˜¯`url`ã€‚

æˆ‘åœ¨å°è¯•è¿è¡Œç”Ÿæˆçš„è„šæœ¬å’Œç›‘å¬ç¼–è¯‘å™¨æ—¶å‘ç°äº†è¿™äº›é”™è¯¯ï¼Œå¹¶åœ¨ç¼–è¾‘å™¨ä¸­ä¸€ä¸ªæ¥ä¸€ä¸ªåœ°ä¿®å¤å®ƒä»¬ã€‚ä½†é™¤æ­¤ä¹‹å¤–ï¼Œå®ƒçœ‹èµ·æ¥å¾ˆæœ‰é“ç†ï¼å¹¶ä¸”ï¼Œå‡†ç¡®åœ°éµå¾ªè¯´æ˜ã€‚

å¦‚æœæˆ‘ä»¬èƒ½è®©æœºå™¨äººå¸®æˆ‘ä»¬ä¿®å¤ bug å‘¢ï¼Ÿæˆ‘ä»¬æ¥è¯•è¯•å§ï¼

# äºŒã€‚ä¿®å¤ bug

***æˆ‘:*** *æˆ‘æœ‰ä¸€ä¸ªé”ˆç¨‹åºï¼Œä¸èƒ½ç¼–è¯‘ã€‚æˆ‘ä¼šç»™ä½ çœ‹æˆ‘ç¨‹åºçš„å†…å®¹ï¼Œè¿˜æœ‰é”™è¯¯ã€‚è¯·å‘Šè¯‰æˆ‘å“ªé‡Œæœ‰é”™è¯¯ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªæ–°çš„æ–‡ä»¶(æˆ–æ–‡ä»¶)ä¸æ›´æ–°çš„å†…å®¹ï¼Œæˆ‘å¯ä»¥ç”¨æ¥æˆåŠŸåœ°ç¼–è¯‘ä»£ç ã€‚*

*ä¸‹é¢æ˜¯æˆ‘çš„æºä»£ç :* `[copy-pasted main.rs script that doesn't compile]`

*ä¸‹é¢æ˜¯æˆ‘çš„é”™è¯¯:* `[copy-pasted error output coming from the Rust compiler]`

***ChatGPT:****ä»£ç ä¸­æ²¡æœ‰å®šä¹‰* `*process*` *æ¨¡å—ã€‚* `*process*` *æ¨¡å—æ˜¯* `*std::process*` *æœºç®±çš„ä¸€éƒ¨åˆ†ï¼Œéœ€è¦åœ¨æ–‡ä»¶å¼€å¤´å¯¼å…¥ã€‚å¦å¤–ï¼Œç¬¬ 40 è¡Œçš„* `*url*` *å˜é‡æ˜¯ä¸€ä¸ª* `*String*` *ï¼Œéœ€è¦å°†å…¶è½¬æ¢ä¸º* `*Url*` *ç±»å‹ï¼Œä»¥ä¾¿ä½œä¸ºå‚æ•°ä¼ é€’ç»™* `*reqwest::get*` *æ–¹æ³•ã€‚*

*ä¸‹é¢æ˜¯ä»£ç çš„æ›´æ–°ç‰ˆæœ¬ï¼Œç¼–è¯‘æ—¶ä¸ä¼šå‡ºé”™:*

```
use std::env;
use std::error::Error;
use std::process;

// [same as before]

impl Client {
    // Implement the authenticate method
    pub fn authenticate(&mut self) { ... }

    // Implement the prompt method
    pub fn prompt(&self, message: &String) -> OpenAIResult {
        // Build the request URL with the prompt, model, and API key
        let url = format!("{}{}/versions/{}?prompt={}&api_key={}", API_ENDPOINT, MODEL, MODEL_VERSION, message, self.api_key);

        // Convert the URL to a `Url` type and send the request
        let url: reqwest::Url = url.parse()?;
        let response: serde_json::Value = reqwest::get(url)?.json()?;

        // Return the response
        Ok(response)
    }
}

// [same as before]
```

å®ƒæ•æ‰åˆ°äº†`std::process`çš„é—®é¢˜ï¼Œä¹Ÿå¯¹`url`å˜é‡åšäº†ä¸€äº›ä¿®æ”¹ã€‚æœ‰ç”¨å—ï¼Ÿ

```
 Compiling openai-client v0.1.0 (...)
error[E0277]: the `?` operator can only be applied to values that implement `Try`
  --> src/main.rs:42:43
   |
42 |         let response: serde_json::Value = reqwest::get(url)?.json()?;
   |                                           ^^^^^^^^^^^^^^^^^^ the `?` operator cannot be applied to type `impl Future<Output = Result<Response, reqwest::Error>>`
   |
   = help: the trait `Try` is not implemented for `impl Future<Output = Result<Response, reqwest::Error>>`

For more information about this error, try `rustc --explain E0277`.
error: could not compile `openai-client` due to previous error
```

è¿˜æ²¡æœ‰ï¼è®©æˆ‘ä»¬è¦æ±‚ä¸€ä¸ªè§£å†³æ–¹æ¡ˆâ€¦

***æˆ‘:*** *å—¯ï¼Œç‰‡æ®µè¿˜æ˜¯å¤±è´¥ã€‚è¿™ä¸€æ¬¡ï¼Œé”™è¯¯æ˜¯:[å¤åˆ¶ç²˜è´´ä¸Šé¢çš„é”™è¯¯]*

***ChatGPT:****è¯¥é”™è¯¯æ¶ˆæ¯è¡¨æ˜* `*?*` *è¿ç®—ç¬¦ä¸èƒ½ä¸* `*impl Future<Output = Result<Response, reqwest::Error>>*` *ç±»å‹çš„å€¼ä¸€èµ·ä½¿ç”¨ã€‚åœ¨ Rust ä¸­ï¼Œ* `*?*` *è¿ç®—ç¬¦åªèƒ½åº”ç”¨äºå®ç°* `*Try*` *ç‰¹å¾çš„å€¼ã€‚*

*`*reqwest::get*`*æ–¹æ³•è¿”å›ä¸€ä¸ª* `*Future*` *ï¼Œå®ƒæ˜¯ä¸€ä¸ªå¯¹è±¡ï¼Œè¡¨ç¤ºä¸€ä¸ªå¯èƒ½è¿˜ä¸å¯ç”¨çš„å€¼ã€‚ä¸ºäº†å°†* `*?*` *è¿ç®—ç¬¦ä¸* `*reqwest::get*` *æ–¹æ³•çš„ç»“æœä¸€èµ·ä½¿ç”¨ï¼Œå¿…é¡»ä½¿ç”¨* `*await*` *å…³é”®å­—å°†* `*Future*` *è½¬æ¢ä¸º* `*Result*` *ã€‚**

**ä¸‹é¢æ˜¯ä»£ç çš„æ›´æ–°ç‰ˆæœ¬ï¼Œç¼–è¯‘æ—¶ä¸ä¼šå‡ºé”™:**

```
*use std::env;
use std::error::Error;
use std::process;

// Import the reqwest crate
use reqwest;

// Import the serde_json crate
use serde_json;

// Define a result type for the API response
type OpenAIResult = Result<serde_json::Value, Box<dyn Error>>;

// Define global variables for the API endpoint and model
const API_ENDPOINT: &str = "https://api.openai.com/v1/completions/models/";
const MODEL: &str = "davinci";
const MODEL_VERSION: &str = "1";

// Define the Client struct
pub struct Client {
    api_key: String,
    authenticated: bool,
}

impl Client {
    // Implement the authenticate method
    pub fn authenticate(&mut self) {
        if !self.authenticated {
            // Read the API key from environment variables
            self.api_key = env::var("OPENAI_API_KEY").expect("OPENAI_API_KEY must be set");
            self.authenticated = true;
        }
    }

    // Implement the prompt method
    pub async fn prompt(&self, message: &String) -> OpenAIResult {
        // Build the request URL with the prompt, model, and API key
        let url = format!("{}{}/versions/{}?prompt={}&api_key={}", API_ENDPOINT, MODEL, MODEL_VERSION, message, self.api_key);

        // Convert the URL to a `Url` type and send the request
        let url: reqwest::Url = url.parse()?;
        let response: serde_json::Value = reqwest::get(url).await?.json().await?;

        // Return the response
        Ok(response)
    }
}

// Define the main function
#[tokio::main]
async fn main() {
    // Create a new client
    let mut client = Client {
        api_key: "".to_string(),
        authenticated: false,
    };

    // Authenticate the client
    client.authenticate();

    // Read the prompt from command-line arguments
    let args: Vec<String> = env::args().collect();
    if args.len() < 2 {
        eprintln!("Usage: openai-client <prompt>");
        process::exit(1);
    }
    let prompt = &args[1];

    // Use the client to make a request to the API
    let response = client.prompt(prompt).await.unwrap();

    // Print the response
    println!("{:?}", response);
}*
```

**æ³¨* `[it is defintely wanted to add some comment, but stopped here.]`*

*è¿™æ˜¯å¾ˆå¥½çš„è¿›æ­¥ï¼è¿™ä¸€æ¬¡ï¼Œä»£ç ç‰‡æ®µä½¿ç”¨äº†å¼‚æ­¥ APIï¼Œç¼–è¯‘é”™è¯¯çš„æ•°é‡å‡å°‘äº†ã€‚ç„¶è€Œï¼Œä»£ç ä»ç„¶ä¸å·¥ä½œï¼Œå› ä¸ºæˆ‘ä»¬è¿˜éœ€è¦å¯¹ TOML æ–‡ä»¶æ·»åŠ ä¸€äº›ä¿®æ­£ã€‚(ä¹Ÿè®¸æˆ‘ä¹Ÿåº”è¯¥æŠŠæ–‡ä»¶çš„å†…å®¹ä¼ é€’ç»™æœºå™¨äººï¼Ÿ)*

```
*[dependencies]
tokio = { version = "0.2", features = ["full"] }
reqwest = { version = "0.10", features = ["json"] }*
```

*å¦åˆ™ï¼Œä»£ç ç‰‡æ®µè¿™æ¬¡æˆåŠŸç¼–è¯‘ï¼ä½†æ˜¯çœŸçš„ç®¡ç”¨å—ï¼Ÿ*

```
*Object {"error": Object {"code": Null, "message": String("Invalid URL (GET /v1/completions/models/davinci/versions/1)"), "param": Null, "type": String("invalid_request_error")}}*
```

*æ˜¾ç„¶ï¼Œç«¯ç‚¹å’Œ/æˆ–å‚æ•°æ˜¯é”™è¯¯çš„ã€‚è®©æˆ‘ä»¬å†ä¸€æ¬¡å¯»æ±‚å¸®åŠ©ï¼è¿™ä¸€æ¬¡ï¼Œæˆ‘ä»¬ä½¿ç”¨æ–‡æ¡£ä¸­[çš„ä¸€ä¸ªä¾‹å­æ¥æç¤ºè¿™ä¸ªæ¨¡å‹ã€‚](https://beta.openai.com/docs/api-reference/making-requests)*

# *ä¸‰ã€‚å‘é€è¯·æ±‚*

****Me*** *:æˆ‘ç”¨ä¸‹é¢çš„ä»£ç ç‰‡æ®µåšä¸€ä¸ªæ‰“å¼€ AI API çš„è¯·æ±‚ã€‚**

```
*const API_ENDPOINT: &str = "https://api.openai.com/v1/completions/models/";
const MODEL: &str = "davinci";
const MODEL_VERSION: &str = "1";

pub async fn prompt(&self, message: &String) -> OpenAIResult {
    // Build the request URL with the prompt, model, and API key
    let url = format!("{}{}/versions/{}?prompt={}&api_key={}", API_ENDPOINT, MODEL, MODEL_VERSION, message, self.api_key);

    // Convert the URL to a `Url` type and send the request
    let url: reqwest::Url = url.parse()?;
    let response: serde_json::Value = reqwest::get(url).await?.json().await?;

    // Return the response
    Ok(response)
}*
```

**ä½†æ˜¯ï¼Œå®ƒå¤±è´¥äº†ï¼Œå¹¶æ˜¾ç¤ºé”™è¯¯:**

```
*Object {"error": Object {"code": Null, "message": String("Invalid URL (GET /v1/completions/models/davinci/versions/1)"), "param": Null, "type": String("invalid_request_error")}}*
```

**æˆ‘çŒœæ˜¯å‚æ•°æˆ–è€…ç½‘å€ï¼Œæˆ–è€…ä¸¤è€…éƒ½æ˜¯é”™çš„ã€‚ä½ èƒ½ç»™æˆ‘çœ‹ä¸€ä¸‹æ­£ç¡®é…ç½®çš„ä»£ç ç‰‡æ®µå—ï¼Ÿè¿™æ˜¯ä¸€ä¸ªä½¿ç”¨* `*curl*` *æ¥æŸ¥è¯¢ API çš„ bash è„šæœ¬ï¼Œå¹¶ä¸”å·¥ä½œæ­£å¸¸ã€‚**

```
*curl https://api.openai.com/v1/completions \
-H "Content-Type: application/json" \
-H "Authorization: Bearer YOUR_API_KEY" \
-d '{"model": "text-davinci-003", "prompt": "Say this is a test", "temperature": 0, "max_tokens": 7}'*
```

**è¯·ä¿®æ”¹æˆ‘çš„ä»£ç ï¼Œä»¥å®ç°ä¸ä¸Šé¢æ˜¾ç¤ºçš„* `*curl*` *ç›¸åŒçš„è¯·æ±‚ã€‚**

****ChatGPT:****æ‚¨çš„ä»£ç è¯•å›¾ä½¿ç”¨* `*GET*` *HTTP æ–¹æ³•å‘ OpenAI API å‘å‡ºè¯·æ±‚ï¼Œè¿™æ˜¯ä¸æ­£ç¡®çš„ã€‚æ‚¨æä¾›çš„* `*curl*` *å‘½ä»¤ä½¿ç”¨äº†* `*POST*` *æ–¹æ³•ï¼Œè¿™æ˜¯å‘é€å¸¦æœ‰æ­£æ–‡çš„è¯·æ±‚æ—¶ä½¿ç”¨çš„æ­£ç¡®æ–¹æ³•ã€‚**

**è¦ä¿®å¤æ‚¨çš„ä»£ç ï¼Œæ‚¨éœ€è¦å°†* `*reqwest::get*` *è°ƒç”¨æ”¹ä¸º* `*reqwest::Client::post*` *ï¼Œå¹¶å°†è¯·æ±‚ä½“ä½œä¸ºå‚æ•°ä¼ é€’ç»™* `*post*` *æ–¹æ³•ã€‚æ‚¨è¿˜éœ€è¦åœ¨è¯·æ±‚ä¸­è®¾ç½®* `*Content-Type*` *å’Œ* `*Authorization*` *å¤´ï¼Œå¦‚* `*curl*` *å‘½ä»¤æ‰€ç¤ºã€‚**

**è¿™æ˜¯ä½ çš„ä»£ç çš„æ›´æ–°ç‰ˆæœ¬ï¼Œåº”è¯¥å¯ä»¥å·¥ä½œ:**

```
*const API_ENDPOINT: &str = "https://api.openai.com/v1/completions";
const MODEL: &str = "text-davinci-003";
const MODEL_VERSION: &str = "1";

pub async fn prompt(&self, message: &String) -> OpenAIResult {
    // Build the request body with the prompt, model, and temperature
    let request_body = json!({
        "prompt": message,
        "model": MODEL,
        "temperature": 0,
        "max_tokens": 7,
    });

    // Build the request URL with the model and version
    let url = format!("{}/models/{}/versions/{}", API_ENDPOINT, MODEL, MODEL_VERSION);

    // Convert the URL to a `Url` type and send the request
    let url: reqwest::Url = url.parse()?;
    let client = reqwest::Client::new();
    let response: serde_json::Value = client.post(url)
        .header("Content-Type", "application/json")
        .header("Authorization", format!("Bearer {}", self.api_key))
        .json(&request_body)
        .send()
        .await?
        .json()
        .await?;

    // Return the response
    Ok(response)
}*
```

*å¹²å¾—å¥½ï¼Œéå¸¸æ¥è¿‘ï¼å¯¹åº”è¯¥æ”¹å˜ä»€ä¹ˆçš„è§£é‡Šä¹Ÿå¾ˆæ£’ã€‚(è¿™æ˜¯ä¸€ä¸ªå°†å‘½ä»¤æˆ–ä»£ç ç‰‡æ®µä»ä¸€ç§è¯­è¨€æˆ–å·¥å…·æ˜ å°„åˆ°å¦ä¸€ç§è¯­è¨€æˆ–å·¥å…·çš„å¥½å·¥å…·ã€‚)è®©å®ƒå·¥ä½œçš„ä¸€ä¸ªç¼–è¾‘æ˜¯å®é™…æ›¿æ¢æ‰€è¯·æ±‚çš„ URLã€‚å› ä¸ºæ¨¡å‹ä»ç„¶åšæŒä½¿ç”¨é”™è¯¯çš„é“¾æ¥ã€‚æˆ‘ä»¬åº”è¯¥ä½¿ç”¨ä¸‹é¢çš„ URLã€‚*

```
*let url = String::from(API_ENDPOINT);*
```

*ä¿®å¤å¹¶é‡æ–°ç¼–è¯‘åï¼Œè¾“å‡ºå¦‚ä¸‹:*

```
*> OPENAI_API_KEY="<your-key>" cargo run -- "Hello, Davinci"

Object {"choices": 
    Array [Object {
        "finish_reason": String("length"), 
        "index": Number(0), 
        "logprobs": Null, 
        "text": String("\n\nHello! How can I")}
     ], 
     "created": Number(1670342922), 
     "id": String("cmpl-6KUmowybKJ9NVIboliVpD2yaPeIv7"), 
     "model": String("text-davinci-003"), 
     "object": String("text_completion"), 
     "usage": Object {
         "completion_tokens": Number(7), 
         "prompt_tokens": Number(5), 
         "total_tokens": Number(12)
     }
}*
```

> *æœ‰ç”¨ï¼ğŸ‰*

*ç°åœ¨ï¼Œæ˜¯æ—¶å€™åšä¸€äº›é‡æ„æ¥ä½¿ä»£ç æ›´å¹²å‡€ï¼Œå¹¶ç”¨ CLI é€‰é¡¹æ›¿æ¢ç¡¬ç¼–ç çš„å‚æ•°äº†ã€‚è€Œä¸”ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªåŠ©æ‰‹éšæ—¶å‡†å¤‡å¸®åŠ©æˆ‘ä»¬â€¦*

# *å››ã€‚æ¸…ç†*

****Me:*** *åœ¨ä¸‹é¢çš„ä»£ç ä¸­ï¼Œå»æ‰* `*Client::authenticate*` *æ–¹æ³•ã€‚åˆ›å»ºä¸€ä¸ªæ–°çš„é™æ€æ–¹æ³•* `*Client::new*` *ï¼Œè¯¥æ–¹æ³•å®ç°è®¤è¯é€»è¾‘å¹¶è¿”å›ä¸€ä¸ª* `*Result*` *å¯¹è±¡ï¼Œè¯¥å¯¹è±¡åŒ…å«ä¸€ä¸ªæ–°åˆ›å»ºçš„å®¢æˆ·ç«¯(å¦‚æœå¸¦æœ‰å¯†é’¥çš„ç¯å¢ƒå˜é‡å­˜åœ¨)ï¼Œå¦åˆ™è¿”å› errorã€‚åŒæ ·ï¼Œé‡æ„* `*prompt*` *æ–¹æ³•ä»¥æ¥å—* `*request_body*` *ä½œä¸ºå‚æ•°ã€‚è¯·ä¸è¦åœ¨å›ç­”ä¸­åŒ…å«ä»»ä½•æ–‡æœ¬ï¼ŒåªåŒ…å«æ›´æ–°åçš„ä»£ç ç‰‡æ®µã€‚**

*`[copy-pasted the so far created code as the previously started conversation was lost]`*

****ChatGPT:****

```
*pub struct Client {
    api_key: String,
}

impl Client {
    // Implement the new method
    pub fn new() -> Result<Client, Box<dyn std::error::Error>> {
        // Read the API key from environment variables
        let api_key = env::var("OPENAI_API_KEY")?;
        Ok(Client{ api_key })
    }

    // Implement the prompt method
    pub async fn prompt(&self, request_body: &serde_json::Value) -> OpenAIResult {
        // Build the request URL with the model and version
        let url = String::from(API_ENDPOINT);

        // Convert the URL to a `Url` type and send the request
        let url: reqwest::Url = url.parse()?;
        let client = reqwest::Client::new();
        let response: serde_json::Value = client.post(url)
            .header("Content-Type", "application/json")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .json(request_body)
            .send()
            .await?
            .json()
            .await?;

        // Return the response
        Ok(response)
    }
}*
```

****æˆ‘:*** *å¤ªæ£’äº†ï¼ç°åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„å¼‚æ­¥ main å‡½æ•°ï¼Œè¯¥å‡½æ•°ä» CLI è¯»å–è¯·æ±‚ä½“å€¼ï¼Œå¹¶ä½¿ç”¨å®¢æˆ·ç«¯å‘å‡ºè¯·æ±‚ã€‚å¦‚æœç¼ºå°‘ä»»ä½•å‚æ•°ï¼Œåˆ™ç»ˆæ­¢ç¨‹åºã€‚**

***ChatGPT:***

```
*use structopt::StructOpt;

#[derive(StructOpt, Debug)]
struct Cli {
    // The prompt to generate text for
    #[structopt(short = "p", long = "prompt")]
    prompt: String,

    // The model to use for text generation
    #[structopt(short = "m", long = "model")]
    model: String,

    // The temperature to use for text generation
    #[structopt(short = "t", long = "temperature")]
    temperature: f64,

    // The maximum number of tokens to generate
    #[structopt(short = "x", long = "max_tokens")]
    max_tokens: usize,
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Parse CLI arguments
    let args = Cli::from_args();

    // Create a new client instance
    let client = Client::new()?;

    // Build the request body
    let request_body = json!({
        "prompt": &args.prompt,
        "model": &args.model,
        "temperature": args.temperature,
        "max_tokens": args.max_tokens,
    });

    // Generate text using the prompt
    let response = client.prompt(&request_body).await?;

    // Print the response
    println!("{}", response);

    Ok(())
}*
```

****æˆ‘:*** *æˆ‘åº”è¯¥ç”¨ä»€ä¹ˆç‰ˆæœ¬çš„* `*structopt*` *æ¿æ¡ç®±æ‰èƒ½è®©ä¸Šé¢çš„ç‰‡æ®µå·¥ä½œï¼Ÿ**

****ChatGPT:****ä½ åº”è¯¥ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬çš„* `*structopt*` *æœºç®±ã€‚ä¸ºæ­¤ï¼Œæ‚¨éœ€è¦æ›´æ–°æ‚¨çš„* `*Cargo.toml*` *æ–‡ä»¶ä¸­çš„ç‰ˆæœ¬å·ï¼Œå¦‚ä¸‹æ‰€ç¤º:**

```
*[dependencies]
structopt = "^0.3.12"*
```

**è¿™å°†ä½¿ç”¨ä¸* `*0.3.12*` *ç‰ˆæœ¬å…¼å®¹çš„* `*structopt*` *æ¿æ¡ç®±çš„æœ€æ–°ç‰ˆæœ¬ã€‚**

**æˆ–è€…ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬çš„* `*structopt*` *æ¿æ¡ç®±ï¼Œæ— éœ€æŒ‡å®šç‰ˆæœ¬å·ï¼Œå¦‚ä¸‹:**

```
*[dependencies]
structopt = "*"*
```

**è¿™å°†ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬çš„* `*structopt*` *æ¿æ¡ç®±å¯ç”¨åœ¨* [*æ¿æ¡ç®±. io*](https://crates.io/) *ä¸Šã€‚ä½†æ˜¯ï¼Œå¦‚æœåœ¨æ–°ç‰ˆæœ¬ä¸­å¼•å…¥äº†é‡å¤§æ›´æ”¹ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´å…¼å®¹æ€§é—®é¢˜ã€‚**

*å¥½çš„ï¼Œè¿™ä¸ªçœ‹èµ·æ¥æ¯”ä¸Šä¸€ä¸ªç‰ˆæœ¬å¥½ä¸€ç‚¹ã€‚æˆ‘ç‰¹åˆ«å–œæ¬¢å…³äºä½¿ç”¨å“ªç§æ¿æ¡ç®±ä»¥åŠæœ‰å“ªäº›é€‰é¡¹çš„è§£é‡Šã€‚*

*ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ£€æŸ¥å®ƒæ˜¯å¦ä»ç„¶å·¥ä½œã€‚*

```
*> cargo run -- -p 'hello, openai!' -m text-davinci-003 -t 0 -x 12

{
    "choices": [{
        "finish_reason":"stop",
        "index":0,"logprobs":null,
        "text":"\n\nHi there!"
    }],
    "created":1670360311,
    "id":"cmpl-6KZJHJ8vW8CB5LyTE0C2hfMv7DY6z",
    "model":"text-davinci-003",
    "object":"text_completion",
    "usage":{"completion_tokens":5,"prompt_tokens":5,"total_tokens":10}
}*
```

*å¤ªæ£’äº†ã€‚*

# *åŠ¨è¯ ï¼ˆverb çš„ç¼©å†™ï¼‰ç»“å°¾éƒ¨åˆ†*

*äººå·¥æ™ºèƒ½é¢†åŸŸçš„å‘å±•é€Ÿåº¦ä»¤äººå°è±¡æ·±åˆ»ã€‚æ¯ä¸ªæœˆ(ç”šè‡³æ¯å‘¨ï¼)å¸¦æ¥äº†æ–°çš„å‘å±•ï¼Œæ¯”å¦‚å¼ºå¤§çš„æ–°æ¨¡å‹çš„å‘å¸ƒï¼Œè¿™äº›æ¨¡å‹å¯ä»¥æœ‰æ•ˆåœ°ç©[å¤æ‚çš„æ£‹ç›˜æ¸¸æˆ](https://techcrunch.com/2022/12/01/now-ai-can-outmaneuver-you-at-both-stratego-and-diplomacy/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAEZvoiFQiW6I3q77eFPrthoj02eDMH2xoPfD15tf8SyGBzLhkV0AOle55NqPyFZbliqVC0NI5N_LW8AB9LshgIaE6-8TFoONqA0Ze39TiWt5hxw0g6_IlrY3QGPNy2FFywXhS0o1-MxahhxGZ0383QiebjVt1jr7ylVG39XYrS0q)ï¼Œæˆ–è€…æ¨åŠ¨[æ–°ç®—æ³•](https://www.nature.com/articles/s41586-022-05172-4)çš„å‘ç°ã€‚è¿‘å¹´æ¥å–å¾—çš„è¿›å±•ç¡®å®ä»¤äººç©ç›®ï¼Œæƒ³åˆ°è¿™äº›è¿›å±•çš„æ½œåœ¨åº”ç”¨ä»¤äººå…´å¥‹ã€‚éšç€äººå·¥æ™ºèƒ½ç ”ç©¶çš„ä¸æ–­å‘å±•ï¼Œæˆ‘ä»¬å¯ä»¥æœŸå¾…åœ¨æœªæ¥çœ‹åˆ°æ›´å¤šä»¤äººå…´å¥‹çš„å‘å±•ã€‚*

*å½“ç„¶ï¼Œè¿™äº›è¿›æ­¥ä¹Ÿæœ‰å±€é™æ€§ã€‚ä¸€ä¸ªæœ€é‡è¦çš„é™åˆ¶æ˜¯ï¼Œæœ‰æ—¶è¿™äº›æ¨¡å‹äº§ç”Ÿçš„ç­”æ¡ˆéå¸¸*åˆç†*ï¼Œä½†ä¸å®Œå…¨æ­£ç¡®ã€‚å®ƒä»¬å¯èƒ½éœ€è¦å¯¹æç¤ºè¿›è¡Œ(å¾®å°çš„)ç¼–è¾‘æˆ–é‡æ–°æªè¾ã€‚æ­¤å¤–ï¼Œè™½ç„¶ Rust ç­‰è¯­è¨€æ‹¥æœ‰ç¼–è¯‘å™¨å’Œ linters ç­‰å·¥å…·ï¼Œå¯ä»¥éªŒè¯ä»£ç çš„æ­£ç¡®æ€§å¹¶æ£€æŸ¥æ¼æ´ï¼Œä½†å°†è¿™äº›æ£€æŸ¥åº”ç”¨äºå…¶ä»–ç”¨é€”å¹¶ä¸å®¹æ˜“ï¼Œå¦‚[è§£é‡Šç§‘å­¦](https://www.technologyreview.com/2022/11/18/1063487/meta-large-language-model-ai-only-survived-three-days-gpt-3-science/)æˆ–[å›ç­” StackOverflow ä¸Šçš„ç¼–ç é—®é¢˜](https://www.theverge.com/2022/12/5/23493932/chatgpt-ai-generated-answers-temporarily-banned-stack-overflow-llms-dangers)ã€‚æœ‰æ—¶ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹(LLM)å®¹æ˜“å˜å¾—[éå¸¸è‡ªä¿¡ï¼Œä½†è‡ªç›¸çŸ›ç›¾ï¼Œè€Œä¸”å¤§é”™ç‰¹é”™](https://twitter.com/itstimconnors/status/1599544717943123969?s=20&t=Hwc370nJT2eQH66Wrpwjkg)ã€‚*

*ç„¶è€Œï¼Œè¿™äº›å·¥å…·å’Œæ¨¡å‹åœ¨æ¯æ¬¡è¿­ä»£ä¸­éƒ½åœ¨ä¸æ–­æ”¹è¿›ã€‚å¾ˆéš¾ç›¸ä¿¡ï¼Œå°±åœ¨å‡ å¹´å‰ï¼Œåšæˆ‘ä»¬åœ¨è¿™ç¯‡æ–‡ç« ä¸­è®¨è®ºçš„äº‹æƒ…ä¼¼ä¹è¿˜æ˜¯çº¯ç²¹çš„ç§‘å¹»å°è¯´ã€‚çœ‹åˆ°äººå·¥æ™ºèƒ½ç ”ç©¶å°†åœ¨æœªæ¥æŠŠæˆ‘ä»¬å¸¦åˆ°å“ªé‡Œï¼Œä»¤äººå…´å¥‹ã€‚*

*`[Parts of this post were edited with ChatGPT's assistance ;)]`*

*ä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« å—ï¼Ÿä¸è¦çŠ¹è±«ï¼Œç»™å®ƒé¼“æŒï¼è¿˜æœ‰ï¼Œä½ å¯ä»¥åœ¨ [*Twitter*](https://twitter.com/devforfu) *æˆ–*[*LinkedIn*](https://www.linkedin.com/in/ilia-zaitsev)*ä¸Šæ‰¾åˆ°æˆ‘ï¼Œå¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜ï¼Œæˆ–è€…è®¿é—®* [*æˆ‘çš„ç½‘ç«™*](https://iliazaitsev.me/) *æŸ¥çœ‹æˆ‘åœ¨äº’è”ç½‘ä¸Šçš„å…¶ä»–å¸–å­ã€‚**