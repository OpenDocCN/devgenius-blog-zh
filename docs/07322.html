<html>
<head>
<title>I created a dumb virtual assistant in Go</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我在围棋中创造了一个愚蠢的虚拟助手</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/i-created-a-dumb-virtual-assistant-in-go-9557ec28f71f?source=collection_archive---------4-----------------------#2022-03-15">https://blog.devgenius.io/i-created-a-dumb-virtual-assistant-in-go-9557ec28f71f?source=collection_archive---------4-----------------------#2022-03-15</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><figure class="gl gn jl jm jn jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi jk"><img src="../Images/54fabe9b9ef93e99591fe5626d9089fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rIpcc13nzEzAvwRL20RMuA.jpeg"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk translated">只是为了美观</figcaption></figure><p id="fea4" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">最近，我在头脑风暴一个有趣的项目，我可以建立它来打发时间，也许还能从中学习到一两件事。我一直着迷的一个项目是虚拟助手，比如谷歌的 Android 和苹果的 Siri，所以我认为尝试构建一个简单的虚拟助手会很棒，嗯，只是一个概念验证。以下是我认为每个虚拟助理应该能够做到的基本事情</p><ol class=""><li id="6de5" class="kx ky in kb b kc kd kg kh kk kz ko la ks lb kw lc ld le lf bi translated">将声音或语音作为输入</li><li id="d038" class="kx ky in kb b kc lg kg lh kk li ko lj ks lk kw lc ld le lf bi translated">将语音转换为文本</li><li id="875c" class="kx ky in kb b kc lg kg lh kk li ko lj ks lk kw lc ld le lf bi translated">从转换后的文本中确定要执行的操作，这通常使用自然语言处理(NLP)来完成</li><li id="7cb8" class="kx ky in kb b kc lg kg lh kk li ko lj ks lk kw lc ld le lf bi translated">执行确定的操作。</li><li id="08fb" class="kx ky in kb b kc lg kg lh kk li ko lj ks lk kw lc ld le lf bi translated">向用户反馈</li></ol><p id="7383" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">为了实现上述功能，我必须在我的电脑上安装一些第三方服务和库。</p><h1 id="1be4" class="ll lm in bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated"><strong class="ak">预先对等</strong></h1><p id="4420" class="pw-post-body-paragraph jz ka in kb b kc mj ke kf kg mk ki kj kk ml km kn ko mm kq kr ks mn ku kv kw ig bi translated"><strong class="kb io"> PortAudio </strong> : PortAudio 是一个免费的、跨平台的、<a class="ae mo" href="http://www.portaudio.com/license.html" rel="noopener ugc nofollow" target="_blank">开源的</a>，音频 I/O 库。它可以让你用 C 或 C++编写简单的音频程序，这些程序可以在许多平台上编译和运行，包括 Windows、Macintosh OS X 和 Unix (OSS/ALSA)。为您的操作系统安装 portAudio 开发头文件和库。</p><p id="25ce" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io"> Ubuntu </strong></p><blockquote class="mp mq mr"><p id="52ba" class="jz ka ms kb b kc kd ke kf kg kh ki kj mt kl km kn mu kp kq kr mv kt ku kv kw ig bi translated">apt-get 安装门户 19-dev</p></blockquote><p id="3b77" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io"> Mac </strong></p><blockquote class="mp mq mr"><p id="a796" class="jz ka ms kb b kc kd ke kf kg kh ki kj mt kl km kn mu kp kq kr mv kt ku kv kw ig bi translated">brew 安装门户音频</p></blockquote><p id="bd22" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io"> Wit AI: </strong> Wit.ai 是一个开源聊天机器人框架，具有高级自然语言处理(NLP)功能。归脸书所有。要使用 Wit.ai，你需要在 other 中注册一个 API 密钥</p><p id="024e" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io"> Espeak: </strong>文本到语音软件语音合成器</p><p id="8ea0" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io"> Ubuntu </strong></p><blockquote class="mp mq mr"><p id="298d" class="jz ka ms kb b kc kd ke kf kg kh ki kj mt kl km kn mu kp kq kr mv kt ku kv kw ig bi translated">sudo apt-get 安装 espeak</p></blockquote><p id="3bd2" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io"> Mac </strong></p><blockquote class="mp mq mr"><p id="488f" class="jz ka ms kb b kc kd ke kf kg kh ki kj mt kl km kn mu kp kq kr mv kt ku kv kw ig bi translated">brew 安装扬声器</p></blockquote><p id="448c" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">在这个练习中，我们将只处理四个意图</p><ol class=""><li id="c501" class="kx ky in kb b kc kd kg kh kk kz ko la ks lb kw lc ld le lf bi translated">问候</li><li id="a653" class="kx ky in kb b kc lg kg lh kk li ko lj ks lk kw lc ld le lf bi translated">发动</li><li id="8e45" class="kx ky in kb b kc lg kg lh kk li ko lj ks lk kw lc ld le lf bi translated">播放音乐</li></ol><p id="f0a9" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">参见下面的教程，了解如何在 Wit.ai 上创建话语、意图和实体</p><figure class="mw mx my mz gt jo"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="e759" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">创建一个新的围棋模块，你可以给它取任何名字，但我决定给我的助手杰罗姆取个名字</p><blockquote class="mp mq mr"><p id="ad08" class="jz ka ms kb b kc kd ke kf kg kh ki kj mt kl km kn mu kp kq kr mv kt ku kv kw ig bi translated">市场总监助理-杰罗姆</p><p id="dd4f" class="jz ka ms kb b kc kd ke kf kg kh ki kj mt kl km kn mu kp kq kr mv kt ku kv kw ig bi translated">cd 助理-杰罗姆</p><p id="2d0c" class="jz ka ms kb b kc kd ke kf kg kh ki kj mt kl km kn mu kp kq kr mv kt ku kv kw ig bi translated">go mod 初始化助手-jerome</p></blockquote><p id="9959" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">将以下内容添加到 go.mod 文件中</p><pre class="mw mx my mz gt nc nd ne nf aw ng bi"><span id="a3e2" class="nh lm in nd b gy ni nj l nk nl">module assistant-jerome<br/><br/>go 1.17<br/><br/>require (<br/>   github.com/gordonklaus/portaudio v0.0.0-20200911161147-bb74aa485641<br/>   github.com/mjibson/go-dsp v0.0.0-20180508042940-11479a337f12<br/>)</span></pre><p id="6430" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">github.com/gordonklaus/portaudio 包提供了一个到<a class="ae mo" href="http://www.portaudio.com/" rel="noopener ugc nofollow" target="_blank"> PortAudio </a>音频 I/O 库的接口。</p><p id="e483" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">包 github.com/mjibson/go-dsp 是一个数字信号处理包的去，这是有益的实施语音活动检测(VAD)，这基本上是一种虚拟助理，以确定用户何时结束发言。</p><p id="d0eb" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">创建 3 包语音，文字和行动，你的项目结构应该像这样。</p><pre class="mw mx my mz gt nc nd ne nf aw ng bi"><span id="46ae" class="nh lm in nd b gy ni nj l nk nl">assistant-jerome<br/>- actions<br/>- text<br/>- voice<br/>- go.mod<br/>- main.go</span></pre><p id="e00e" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">接下来在文本包中创建一个新的脚本 speech_to_text.go，这将处理与 Wit AI 的集成。这是剧本应该有的样子。</p><p id="dfcd" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io"> N/B: </strong>以下脚本中的 API 密钥具有功能性，但仅限于此 POC，并且应该用于运行项目。</p><pre class="mw mx my mz gt nc nd ne nf aw ng bi"><span id="0cd0" class="nh lm in nd b gy ni nj l nk nl">package text<br/><br/>import (<br/>   "bytes"<br/>   "encoding/json"<br/>   "fmt"<br/>   "io/ioutil"<br/>   "log"<br/>   "net/http"<br/>)<br/><br/>const <em class="ms">ApiKey </em>= "UKHKHD37C43H4ZUU65WBZNMXVJKOO6RO"<br/><br/>type WitAiContact struct {<br/>   Confidence float32 `json:"confidence"`<br/>   Suggested  bool    `json:"suggested"`<br/>   Type       string  `json:"type"`<br/>   Value      string  `json:"value"`<br/>}<br/><br/>type WitAiIntent struct {<br/>   Confidence float32 `json:"confidence"`<br/>   Value      string  `json:"value"`<br/>}<br/><br/>type WitAiEntities struct {<br/>   Contact []WitAiContact    `json:"contact"`<br/>   Intent  []WitAiIntent     `json:"intent"`<br/>   SongTitle  []WitAiContact `json:"song_title"`<br/>}<br/><br/>type WitAiOutcome struct {<br/>   Text     string        `json:"text"`<br/>   Entities WitAiEntities `json:"entities"`<br/>   Intent   string        `json:"intent"`<br/>}<br/><br/>type WitAiResponse struct {<br/>   Text     string         `json:"text"`<br/>   Outcomes []WitAiOutcome `json:"outcomes"`<br/>}<br/><br/><br/>func ConvertAudioToWitAiResponse(speechByte *bytes.Buffer) *WitAiResponse {<br/><br/>   var response *WitAiResponse<br/><br/>   stringResponse := sendWitBuff(speechByte)<br/><br/>   fmt.Println(stringResponse)<br/><br/>   rawResponseByte := []byte(stringResponse)<br/>   err := json.Unmarshal(rawResponseByte, &amp;response)<br/><br/>   if err != nil {<br/>      log.Println(err)<br/>   }<br/><br/>   return response<br/>}<br/><br/>func sendWitBuff(buffer *bytes.Buffer) string {<br/>   url := "https://api.wit.ai/speech?v=20141022"<br/>   client := &amp;http.Client{}<br/>   req, err := http.NewRequest("POST", url, buffer)<br/><br/>   if err != nil {<br/>      log.Fatal(err)<br/>   }<br/>   req.Header.Set("Authorization", "Bearer "+<em class="ms">ApiKey</em>)<br/>   req.Header.Set("Content-Type", "audio/raw;encoding=signed-integer;bits=16;rate=20k;endian=little")<br/>   res, err := client.Do(req)<br/>   if err != nil {<br/>      log.Fatal(err)<br/>   }<br/>   body, err := ioutil.ReadAll(res.Body)<br/>   if err != nil {<br/>      log.Fatal(err)<br/>   }<br/>   return string(body)<br/>}</span></pre><p id="320f" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">在这里，我们使用 Wit.ai 提供的语音 API 发送音频缓冲区。API 确定并返回来自我们训练好的模型的意图和相应的实体。</p><p id="fbf4" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">接下来在语音包中创建 vad.go 并粘贴下面的内容</p><pre class="mw mx my mz gt nc nd ne nf aw ng bi"><span id="0745" class="nh lm in nd b gy ni nj l nk nl">package voice<br/><br/>import (<br/>   "math"<br/><br/>   "github.com/mjibson/go-dsp/fft"<br/>)<br/><br/>// Voice Activity Detection (that's what they call it when you detect<br/>// that someone has started (or stopped) talking).<br/><br/>type VAD struct {<br/>   samples      []complex128<br/>   fft          []complex128<br/>   spectrum     []float64<br/>   lastSpectrum []float64<br/>}<br/><br/>func NewVAD(width int) *VAD {<br/>   return &amp;VAD{<br/>      samples:      make([]complex128, width),<br/>      spectrum:     make([]float64, width/2+1),<br/>      lastSpectrum: make([]float64, width/2+1),<br/>   }<br/>}<br/><br/>// Flux Given the samples, return the spectral flux value as compared to the previous samples.<br/>func (v *VAD) Flux(samples []int16) float64 {<br/>   for i, s := range samples {<br/>      v.samples[i] = complex(float64(s), 0)<br/>   }<br/><br/>   v.fft = fft.FFT(v.samples)<br/>   copy(v.spectrum, v.lastSpectrum)<br/><br/>   for i, _ := range v.spectrum {<br/>      c := v.fft[i]<br/>      v.spectrum[i] = math.Sqrt(real(c)*real(c) + imag(c)*imag(c))<br/>   }<br/><br/>   var flux float64<br/><br/>   for i, s := range v.spectrum {<br/>      flux += s - v.lastSpectrum[i]<br/>   }<br/><br/>   return flux<br/>}<br/><br/>func (v *VAD) FFT() []complex128 {<br/>   return v.fft<br/>}</span></pre><p id="8524" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">我们将在后面看到它的用法。</p><p id="a167" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">在 actions 包中创建 talk.go 并粘贴以下内容</p><pre class="mw mx my mz gt nc nd ne nf aw ng bi"><span id="fe25" class="nh lm in nd b gy ni nj l nk nl">package actions<br/><br/>import (<br/>   "log"<br/>   "os/exec"<br/>)<br/><br/>func SpeakText(textToSpeak string) {<br/>   cmd := exec.Command("espeak", textToSpeak)<br/>   if err := cmd.Run(); err != nil {<br/>      log.Fatal(err)<br/>   }<br/>}</span></pre><p id="44a3" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io"> <em class="ms"> SpeakText </em> </strong>函数执行 espeak 命令，该命令将读出所传递的文本。</p><p id="c41c" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">在 actions 包中创建 action.go，内容如下</p><pre class="mw mx my mz gt nc nd ne nf aw ng bi"><span id="9552" class="nh lm in nd b gy ni nj l nk nl">package actions<br/><br/>import (<br/>   "fmt"<br/>)<br/><br/><br/>func Greet() {<br/>   SpeakText("Hi, how can I help?")<br/>}<br/><br/>func CommandUnknown() {<br/>   SpeakText("Sorry, I don't understand. Please take that again")<br/>}<br/><br/>func playMusic(songTitle string, artist string ) {<br/>   if artist == ""{<br/>      SpeakText(fmt.Sprintf("Playing %s",songTitle))<br/>      return<br/>   }<br/>   SpeakText(fmt.Sprintf("Playing %s by %s",songTitle,artist))<br/>}<br/><br/>func PlayMusic(songTitle string, artist string ) {<br/><br/>   if songTitle == ""{<br/>      SpeakText("Playing requested song")<br/>      return<br/>   }<br/><br/>   playMusic(songTitle, artist)<br/><br/><br/>}</span></pre><p id="c066" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io"> Greet </strong>，<strong class="kb io"> PlayMusic </strong>和<strong class="kb io"> CommandUnknown </strong>是 action.go 脚本中要处理的场景，当调用这些函数时，不会发生任何复杂的事情，我们只是让 espeak 读出一些文本。</p><p id="41b8" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">在语音包中创建一个新的 go 文件 hear.go，这是大部分逻辑发生的地方。</p><pre class="mw mx my mz gt nc nd ne nf aw ng bi"><span id="2d3e" class="nh lm in nd b gy ni nj l nk nl">package voice<br/><br/>import (<br/>   "assistant-jerome/actions"<br/>   "assistant-jerome/text"<br/>   "bytes"<br/>   "encoding/binary"<br/>   "fmt"<br/>   "github.com/gordonklaus/portaudio"<br/>   "log"<br/>   "time"<br/>)<br/><br/>var audioRunning bool<br/>var handling bool<br/><br/>func InitAudio() {<br/>   if !audioRunning {<br/>      portaudio.Initialize()<br/>      audioRunning = true<br/>   }<br/>}<br/><br/>func FreeAudio() {<br/>   if audioRunning {<br/>      portaudio.Terminate()<br/>   }<br/>}<br/><br/>const <em class="ms">DefaultQuietTime </em>= time.<em class="ms">Second<br/><br/></em>type State int<br/><br/>const (<br/>   <em class="ms">Waiting </em>State = iota<br/>   <em class="ms">Listening<br/></em>)<br/><br/>type ListenOpts struct {<br/>   State            func(State)<br/>   QuietDuration    time.Duration<br/>   AlreadyListening bool<br/>}<br/><br/>func ListenIntoBuffer(opts ListenOpts) (*bytes.Buffer, error) {<br/>   in := make([]int16, 8196)<br/>   stream, err := portaudio.OpenDefaultStream(1, 0, 16000, len(in), in)<br/>   if err != nil {<br/>      return nil, err<br/>   }<br/><br/>   defer stream.Close()<br/><br/>   err = stream.Start()<br/>   if err != nil {<br/>      return nil, err<br/>   }<br/><br/>   var (<br/>      buf            bytes.Buffer<br/>      heardSomething = opts.AlreadyListening<br/>      quiet          bool<br/>      quietTime      = opts.QuietDuration<br/>      quietStart     time.Time<br/>      lastFlux       float64<br/>   )<br/><br/>   vad := NewVAD(len(in))<br/><br/>   if quietTime == 0 {<br/>      quietTime = <em class="ms">DefaultQuietTime<br/>   </em>}<br/><br/>   if opts.State != nil {<br/>      if heardSomething {<br/>         opts.State(<em class="ms">Listening</em>)<br/>      } else {<br/>         opts.State(<em class="ms">Waiting</em>)<br/>      }<br/>   }<br/><br/>reader:<br/>   for {<br/>      err = stream.Read()<br/>      if err != nil {<br/>         return nil, err<br/>      }<br/><br/>      err = binary.Write(&amp;buf, binary.LittleEndian, in)<br/>      if err != nil {<br/>         return nil, err<br/>      }<br/><br/>      flux := vad.Flux(in)<br/><br/>      if lastFlux == 0 {<br/>         lastFlux = flux<br/>         continue<br/>      }<br/><br/>      if heardSomething {<br/>         if flux*1.75 &lt;= lastFlux {<br/>            if !quiet {<br/>               quietStart = time.Now()<br/>            } else {<br/>               diff := time.Since(quietStart)<br/><br/>               if diff &gt; quietTime {<br/>                  break reader<br/>               }<br/>            }<br/><br/>            quiet = true<br/>         } else {<br/>            quiet = false<br/>            lastFlux = flux<br/>         }<br/>      } else {<br/>         if flux &gt;= lastFlux*1.75 {<br/>            heardSomething = true<br/>            if opts.State != nil {<br/>               opts.State(<em class="ms">Listening</em>)<br/>            }<br/>         }<br/><br/>         lastFlux = flux<br/>      }<br/>   }<br/><br/>   err = stream.Stop()<br/>   if err != nil {<br/>      return nil, err<br/>   }<br/><br/>   return &amp;buf, nil<br/>}<br/><br/>func Listen() {<br/><br/>   InitAudio()<br/>   defer FreeAudio()<br/><br/>   opts := ListenOpts{<br/>      QuietDuration:    1 * time.<em class="ms">Second</em>,<br/>      AlreadyListening: true,<br/>   }<br/><br/>   fmt.Printf("speak now\n")<br/><br/>   buf, err := ListenIntoBuffer(opts)<br/>   if err != nil {<br/>      log.Fatal(err)<br/>   }<br/><br/>   fmt.Printf("recognizing...\n")<br/>   handling = true<br/><br/>   convertedResponse := text.ConvertAudioToWitAiResponse(buf)<br/><br/>   determineAction(convertedResponse)<br/><br/>   Listen()<br/>}<br/><br/>func determineAction(witAiResponse *text.WitAiResponse) {<br/><br/>   if len(witAiResponse.Outcomes) &lt; 1 {<br/>      return<br/>   }<br/><br/>   if len(witAiResponse.Outcomes[0].Entities.Intent) &lt; 1 {<br/>      return<br/>   }<br/><br/>   switch witAiResponse.Outcomes[0].Entities.Intent[0].Value {<br/><br/>   case "greetings":<br/>      actions.Greet()<br/>   case "play_music":<br/>      //actions.PlayMusic(witAiResponse.Outcomes[0].Entities.SongTitle[0].Value,witAiResponse.Outcomes[0].Entities.Contact[0].Value)<br/>      actions.PlayMusic("","")<br/>   default:<br/>      actions.CommandUnknown()<br/>   }<br/>}</span></pre><p id="75f7" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io"> Listen </strong>函数不断递归调用它来保持应用程序运行。首先我们调用<strong class="kb io"> InitAudio </strong>函数，该函数将音频运行状态设置为 true 并初始化 portaudio，然后我们调用<strong class="kb io">listeningobuffer</strong>函数启动 portAudio 音频流。我们读取音频流，同时将音频流写入缓冲区，一旦我们确定用户已经结束讲话，我们就关闭音频流并返回缓冲区。然后使用<strong class="kb io">文本将缓冲区传递给 Wit AI。ConvertAudioToWitAiResponse</strong>函数，最后我们使用<strong class="kb io"> determineAction </strong>函数基于来自 Wit AI 的响应来确定动作。</p><p id="4957" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">最后，在项目目录中创建 main.go 文件，内容如下。</p><pre class="mw mx my mz gt nc nd ne nf aw ng bi"><span id="1374" class="nh lm in nd b gy ni nj l nk nl">package main<br/><br/>import (<br/>   "assistant-jerome/voice"<br/>)<br/><br/>func main() {<br/><br/>   voice.Listen()<br/><br/>}</span></pre><p id="ab7f" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">运行项目，尝试一些命令，如“早上好”，“播放音乐”等。通常你可以在 Github<a class="ae mo" href="https://github.com/okemechris/assistant-jerome" rel="noopener ugc nofollow" target="_blank">https://github.com/okemechris/assistant-jerome</a>上找到完整的源代码</p></div></div>    
</body>
</html>