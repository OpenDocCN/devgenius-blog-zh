<html>
<head>
<title>Write your first Generative Adversarial Network Model on PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 PyTorch 上写下你的第一个生成性对抗网络模型</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/write-your-first-generative-adversarial-network-model-on-pytorch-7dc0c7c892c7?source=collection_archive---------2-----------------------#2020-08-16">https://blog.devgenius.io/write-your-first-generative-adversarial-network-model-on-pytorch-7dc0c7c892c7?source=collection_archive---------2-----------------------#2020-08-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="7d04" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用使用 PyTorch 深度学习框架实现的两个模型的示例来构建生成式对抗性神经网络(GANs)的详细说明。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/8742dd9a2f9c46aec4e3110447fe2c56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*L-Fk03MfTldBOL3d"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk translated">照片由<a class="ae lb" href="https://unsplash.com/@hayleykimdesign?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Hayley Kim 设计</a>在<a class="ae lb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="5356" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">生成对抗网络(缩写为 GAN)是<a class="ae lb" href="https://ru.wikipedia.org/wiki/%D0%9D%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D1%81%D0%B5%D1%82%D1%8C" rel="noopener ugc nofollow" target="_blank">神经网络</a>，可以生成类似于人类的图像、音乐、语音和文本。近年来，gan 已经成为一个活跃的研究课题。脸书人工智能实验室主任杨乐坤称对抗性学习是“过去 10 年中最令人兴奋的机器学习想法”下面我们将探索 gan 如何工作，并使用 PyTorch <a class="ae lb" href="https://proglib.io/p/dl-frameworks" rel="noopener ugc nofollow" target="_blank">深度学习</a>框架创建两个模型。</p><h1 id="d628" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">什么是生成性对抗网络？</h1><p id="a061" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated"><a class="ae lb" href="https://ru.wikipedia.org/wiki/%D0%93%D0%B5%D0%BD%D0%B5%D1%80%D0%B0%D1%82%D0%B8%D0%B2%D0%BD%D0%BE-%D1%81%D0%BE%D1%81%D1%82%D1%8F%D0%B7%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F_%D1%81%D0%B5%D1%82%D1%8C" rel="noopener ugc nofollow" target="_blank">生成式对抗网络</a> (GAN)是一种可以模拟给定数据分布的机器学习模型。该模型最初是由深度学习专家 Ian Goodfellow 及其同事在 2014 年的一篇论文中提出的。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mf"><img src="../Images/812fa3cbb1aa87d32d0652c6e0a40789.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zsJ526OzRqOQIPhK.gif"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk translated">甘学习过程</figcaption></figure><p id="5575" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">GANs 由两个神经网络组成，其中一个被训练来生成数据，另一个被训练来区分模拟数据和真实数据(因此模型具有“对抗性”的性质)。生成敌对网络在图像和视频生成方面显示出令人印象深刻的结果:</p><ul class=""><li id="d9c3" class="mg mh iq jp b jq jr ju jv jy mi kc mj kg mk kk ml mm mn mo bi translated">风格转换(<a class="ae lb" href="https://github.com/junyanz/CycleGAN/" rel="noopener ugc nofollow" target="_blank"> CycleGAN </a> ) —一个图像根据其他图像的风格进行转换(例如，一位著名艺术家的绘画)；</li><li id="d904" class="mg mh iq jp b jq mp ju mq jy mr kc ms kg mt kk ml mm mn mo bi translated">人脸生成(<a class="ae lb" href="https://en.wikipedia.org/wiki/StyleGAN" rel="noopener ugc nofollow" target="_blank"> StyleGAN </a>)，现实例子在<a class="ae lb" href="https://www.thispersondoesnotexist.com/" rel="noopener ugc nofollow" target="_blank">有，这个人不存在</a>。</li></ul><p id="e6c6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">GANs 和其他数据生成结构被称为生成模型，与更广泛研究的判别模型相对。在深入研究 GANs 之前，我们先来看看这两类模型的区别。</p><h1 id="d264" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">判别型和生成型机器学习模型的比较</h1><p id="9163" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">判别模型用于大多数监督的<a class="ae lb" href="https://ru.wikipedia.org/wiki/%D0%9E%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%D1%81_%D1%83%D1%87%D0%B8%D1%82%D0%B5%D0%BB%D0%B5%D0%BC" rel="noopener ugc nofollow" target="_blank">学习</a>问题，用于<a class="ae lb" href="https://ru.wikipedia.org/wiki/%D0%97%D0%B0%D0%B4%D0%B0%D1%87%D0%B0_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D0%B8" rel="noopener ugc nofollow" target="_blank">分类</a>或<a class="ae lb" href="https://ru.wikipedia.org/wiki/%D0%A0%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D0%BE%D0%BD%D0%BD%D1%8B%D0%B9_%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7" rel="noopener ugc nofollow" target="_blank">回归</a>。作为分类问题的一个例子，假设你想训练<a class="ae lb" href="https://proglib.io/p/neural-network-course" rel="noopener ugc nofollow" target="_blank">一个手写数字图像识别模型</a>。要做到这一点，我们可以使用一个标记数据集，其中包含手写数字的照片，这些照片与数字本身相关联。</p><p id="8a88" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">训练被简化为使用特殊算法设置模型的参数，该算法使损失函数最小化。损失函数是估计参数的真实值与其期望值之间的差异的标准。在学习阶段之后，我们可以使用该模型通过将最可能的数字与输入图像进行匹配来对新的(之前未考虑的)手写数字图像进行分类。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mu"><img src="../Images/77fe6c926756aba741659e35dae1ed3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*x82zPwvO5wy2HbmJ.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk translated">判别模型训练方案</figcaption></figure><p id="d61e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">判别模型使用训练数据来寻找类之间的边界。找到的边界用于区分新的输入并预测它们的类别。数学上，判别模型研究给定输入<strong class="jp ir"> <em class="mv"> x </em> </strong>的一个观测 y 的<a class="ae lb" href="https://ru.wikipedia.org/wiki/%D0%A3%D1%81%D0%BB%D0%BE%D0%B2%D0%BD%D0%B0%D1%8F_%D0%B2%D0%B5%D1%80%D0%BE%D1%8F%D1%82%D0%BD%D0%BE%D1%81%D1%82%D1%8C" rel="noopener ugc nofollow" target="_blank">条件概率</a> <strong class="jp ir"> <em class="mv"> P (y | x) </em> </strong>。</p><p id="4c1c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">判别模型不仅是神经网络，还有<a class="ae lb" href="https://ru.wikipedia.org/wiki/%D0%9B%D0%BE%D0%B3%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D1%8F" rel="noopener ugc nofollow" target="_blank">逻辑回归</a>和<a class="ae lb" href="https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BE%D0%BF%D0%BE%D1%80%D0%BD%D1%8B%D1%85_%D0%B2%D0%B5%D0%BA%D1%82%D0%BE%D1%80%D0%BE%D0%B2" rel="noopener ugc nofollow" target="_blank">支持向量机(SVM) </a>。</p><p id="7017" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">虽然判别模型用于监督学习，但生成模型通常使用原始数据集，也就是说，可以被视为一种形式的<a class="ae lb" href="https://ru.wikipedia.org/wiki/%D0%9E%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%D0%B1%D0%B5%D0%B7_%D1%83%D1%87%D0%B8%D1%82%D0%B5%D0%BB%D1%8F" rel="noopener ugc nofollow" target="_blank">无监督学习</a>。因此，使用手写数字的数据集，你可以训练一个生成模型来生成新的图像。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mu"><img src="../Images/5b5f9f3e126b44a53a35f2af21b52457.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*XuX0zwnw2NVA74PN.png"/></div></div></figure><p id="2f44" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">与判别模型相反，生成模型研究输入数据<strong class="jp ir"> <em class="mv"> 𝑥 </em> </strong>的概率函数 <strong class="jp ir"> <em class="mv"> P (x) </em> </strong>的性质。因此，它们不会生成预测，而是生成一个具有类似于训练数据集的属性的新对象。</p><p id="da4d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">除了 GAN，还有其他生成架构:</p><ul class=""><li id="bbf6" class="mg mh iq jp b jq jr ju jv jy mi kc mj kg mk kk ml mm mn mo bi translated"><a class="ae lb" href="https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%B0_%D0%91%D0%BE%D0%BB%D1%8C%D1%86%D0%BC%D0%B0%D0%BD%D0%B0" rel="noopener ugc nofollow" target="_blank">玻尔兹曼机</a></li><li id="6427" class="mg mh iq jp b jq mp ju mq jy mr kc ms kg mt kk ml mm mn mo bi translated"><a class="ae lb" href="https://ru.wikipedia.org/wiki/%D0%90%D0%B2%D1%82%D0%BE%D0%BA%D0%BE%D0%B4%D0%B8%D1%80%D0%BE%D0%B2%D1%89%D0%B8%D0%BA" rel="noopener ugc nofollow" target="_blank">自动编码器</a></li><li id="e8dc" class="mg mh iq jp b jq mp ju mq jy mr kc ms kg mt kk ml mm mn mo bi translated"><a class="ae lb" href="https://ru.wikipedia.org/wiki/%D0%A1%D0%BA%D1%80%D1%8B%D1%82%D0%B0%D1%8F_%D0%BC%D0%B0%D1%80%D0%BA%D0%BE%D0%B2%D1%81%D0%BA%D0%B0%D1%8F_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C" rel="noopener ugc nofollow" target="_blank">隐马尔可夫模型</a></li><li id="3c8c" class="mg mh iq jp b jq mp ju mq jy mr kc ms kg mt kk ml mm mn mo bi translated">预测序列中下一个单词的模型，如<a class="ae lb" href="https://en.wikipedia.org/wiki/OpenAI#GPT-2" rel="noopener ugc nofollow" target="_blank"> GPT-2 </a></li></ul><p id="436d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最近，GANs 因其在视觉内容生成方面令人印象深刻的成果而获得了很多关注。让我们更详细地讨论生成性对抗网络的装置。</p><h1 id="cf8a" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">生成对立神经网络的体系结构</h1><p id="43e2" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">正如我们已经理解的，生成性对抗网络不是一个网络，而是两个网络:一个生成器和一个鉴别器。生成器的作用是基于类似真实数据的真实样本生成数据集。鉴别器被训练来估计样本是从真实数据获得而不是由生成器提供的概率。两个神经网络玩猫捉老鼠:生成器试图欺骗鉴别器，鉴别器试图更好地识别生成的样本。</p><p id="cf73" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了理解 GAN 训练如何工作，考虑一个玩具示例，其数据集由二维样本<strong class="jp ir"> <em class="mv"> (x1，x2) </em> </strong>组成，其中<strong class="jp ir"> <em class="mv"> x1 </em> </strong>的范围从<strong class="jp ir"> <em class="mv"> 0 </em> </strong>到<strong class="jp ir"> <em class="mv"> 2π </em> </strong>和<strong class="jp ir"> <em class="mv"> x2=sin(x1) </em> </strong>。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/c7c0f42b5f551aa9d57319a6c40f5f11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/1*gMl4oAXRKXeo8powk0_0Uw.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk translated">x2 对 x1 的依赖性</figcaption></figure><p id="a5b2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">用于从数据集中生成<strong class="jp ir"> <em class="mv"> (x̃1，x̃2) </em> </strong>相似点对的 GAN 的一般结构如下图所示。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mx"><img src="../Images/b272d961b52631d89582623574c4cd02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sWmghgwfCs_9ZE74WqY70g.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk translated">通用 GAN 结构</figcaption></figure><p id="d98a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">生成器接收随机数对<strong class="jp ir"> <em class="mv"> (z1，z2) </em> </strong>作为输入，对其进行转换，使其类似于真实样本中的示例。神经网络的结构可以是任意的，例如，<a class="ae lb" href="https://ru.wikipedia.org/wiki/%D0%9C%D0%BD%D0%BE%D0%B3%D0%BE%D1%81%D0%BB%D0%BE%D0%B9%D0%BD%D1%8B%D0%B9_%D0%BF%D0%B5%D1%80%D1%86%D0%B5%D0%BF%D1%82%D1%80%D0%BE%D0%BD_%D0%A0%D1%83%D0%BC%D0%B5%D0%BB%D1%8C%D1%85%D0%B0%D1%80%D1%82%D0%B0" rel="noopener ugc nofollow" target="_blank">多层感知器</a>或<a class="ae lb" href="https://ru.wikipedia.org/wiki/%D0%A1%D0%B2%D1%91%D1%80%D1%82%D0%BE%D1%87%D0%BD%D0%B0%D1%8F_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D1%81%D0%B5%D1%82%D1%8C" rel="noopener ugc nofollow" target="_blank">卷积神经网络</a>。<code class="fe my mz na nb b">G</code> <code class="fe my mz na nb b">G</code></p><p id="8a53" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">鉴别器交替输入来自训练数据集的样本和由生成器提供的模拟样本。鉴别器的作用是评估输入数据属于真实数据集的可能性。也就是说，训练是以这样一种方式进行的，即它给出、接收真实样本，并且对于生成的样本。<code class="fe my mz na nb b">D</code>T3<code class="fe my mz na nb b">D</code>T5<code class="fe my mz na nb b">0</code></p><p id="b676" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">与生成器的情况一样，考虑到输入和输出数据的大小，您可以选择神经网络的任何结构。在这个例子中，输入是 2D，输出是范围从 0 到 1 的标量<a class="ae lb" href="https://ru.wikipedia.org/wiki/%D0%A1%D0%BA%D0%B0%D0%BB%D1%8F%D1%80%D0%BD%D0%B0%D1%8F_%D0%B2%D0%B5%D0%BB%D0%B8%D1%87%D0%B8%D0%BD%D0%B0" rel="noopener ugc nofollow" target="_blank">。<code class="fe my mz na nb b">D</code></a></p><p id="b925" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在数学上，GAN 学习过程由两个玩家的<a class="ae lb" href="https://ru.wikipedia.org/wiki/%D0%9C%D0%B8%D0%BD%D0%B8%D0%BC%D0%B0%D0%BA%D1%81" rel="noopener ugc nofollow" target="_blank">极小最大游戏组成，其中它适于最小化真实样本和生成样本之间的差异的误差，并且适于最大化出错的概率。<code class="fe my mz na nb b">D</code> <code class="fe my mz na nb b">G</code> <code class="fe my mz na nb b">D</code></a></p><p id="0f91" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在训练的每个阶段，模型和的参数被更新。为了训练，在每次迭代中，我们用 1 标记真实样本的样本，用 0 标记生成样本的样本。因此，可以使用正常的监督学习方法来更新参数，如图所示。<code class="fe my mz na nb b">D</code> <code class="fe my mz na nb b">G</code> <code class="fe my mz na nb b">D</code> <code class="fe my mz na nb b">G</code> <code class="fe my mz na nb b">D</code></p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi nc"><img src="../Images/c6e6e2cb6f93263f1f9d564498b792a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*QWCV4JtStsQQjJLa.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk translated">鉴别器训练过程</figcaption></figure><p id="e23d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于包含标记的真实样本和生成样本的每批训练数据，我们更新模型参数组<code class="fe my mz na nb b">D</code>，最小化损失函数。参数<code class="fe my mz na nb b">D</code>更新后，我们训练<code class="fe my mz na nb b">G</code>生成更好的样本。在发电机训练期间，该组参数被<code class="fe my mz na nb b">D</code>“冻结”。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi nc"><img src="../Images/0710051d1fd0153fe4c351073c82a571.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*i4tHghuLMnC04BM7.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk translated">发电机学习过程</figcaption></figure><p id="6812" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当它开始生成样本好到“被忽悠”的时候，输出概率趋向于 1——它认为所有样本都属于原始样本。<code class="fe my mz na nb b">G</code> <code class="fe my mz na nb b">D</code> <code class="fe my mz na nb b">D</code></p><p id="cd09" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们知道了 GAN 是如何工作的，我们准备使用 PyTorch 实现我们自己的神经网络。</p><h1 id="63e5" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">你的第一个生殖对抗网络</h1><p id="bcd2" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">作为对生成性对抗网络的第一个实验，我们将使用调和函数实现上面的例子。为了使用这个例子，我们将使用流行的 PyTorch 库，它可以使用<a class="ae lb" href="https://pytorch.org/get-started/locally/" rel="noopener ugc nofollow" target="_blank">指令</a>来安装。如果你对数据科学非常感兴趣，你可能已经使用过<a class="ae lb" href="https://www.anaconda.com/products/individual" rel="noopener ugc nofollow" target="_blank"> Anaconda </a>发行版和<a class="ae lb" href="https://docs.conda.io/projects/conda/en/latest/user-guide/getting-started.html" rel="noopener ugc nofollow" target="_blank"> conda </a>包和环境管理系统。请注意，该环境使安装过程更加容易。</p><p id="0f5a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用安装 PyTorch，首先创建一个环境并激活它:<code class="fe my mz na nb b">conda</code></p><pre class="km kn ko kp gt nd nb ne nf aw ng bi"><span id="77b9" class="nh ld iq nb b gy ni nj l nk nl">$ conda create --name gan<br/>$ conda activate gan</span></pre><p id="e2d1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这就创建了一个名为<code class="fe my mz na nb b">gan</code>的环境<code class="fe my mz na nb b">conda</code>。在创建的环境中，您可以安装必要的软件包:</p><pre class="km kn ko kp gt nd nb ne nf aw ng bi"><span id="265c" class="nh ld iq nb b gy ni nj l nk nl">$ conda install -c pytorch pytorch=1.4.0<br/>$ conda install matplotlib jupyter</span></pre><p id="ab1a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于 PyTorch 是一个活跃的开发环境，API 可能会在新版本中发生变化。1.4.0 版的代码示例已经过验证。</p><p id="2f50" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将使用<code class="fe my mz na nb b">matplotlib</code>来处理图形。</p><p id="40c6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用 Jupyter Notebook 时，需要注册环境，这样就可以使用这个环境作为内核来创建笔记本。为此，在激活的环境中，运行以下命令:<code class="fe my mz na nb b">conda gan</code> <code class="fe my mz na nb b">gan</code></p><pre class="km kn ko kp gt nd nb ne nf aw ng bi"><span id="6d52" class="nh ld iq nb b gy ni nj l nk nl">$ python -m ipykernel install --user --name gan</span></pre><p id="5606" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们从导入所需的库开始:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="b70c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里我们导入 PyTorch ( <code class="fe my mz na nb b">torc</code>)库。为了更简洁的处理，我们从库中单独导入组件。内置库只需要获取常量的值，上面提到的工具是用来构建依赖关系的。<code class="fe my mz na nb b">nn</code> <code class="fe my mz na nb b">math</code> <code class="fe my mz na nb b">pi</code> <code class="fe my mz na nb b">matplotlib</code></p><p id="3406" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">好的做法是暂时保护随机数生成器，以便可以在另一台机器上重复该实验。要在 PyTorch 中实现这一点，请运行以下代码:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="7b44" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们使用<code class="fe my mz na nb b">111</code>号来初始化随机数发生器。我们需要一个生成器来设置神经网络的初始权重。尽管实验具有随机性，但其过程将是可重复的。</p><h1 id="f2d9" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">为 GAN 训练准备数据</h1><p id="0bf4" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">训练集由数对<strong class="jp ir"> <em class="mv"> (x1，x2) </em> </strong> —使得<strong class="jp ir"> <em class="mv"> x2 </em> </strong>对应于<strong class="jp ir"> <em class="mv"> x1 </em> </strong>的<strong class="jp ir"> <em class="mv"> x1 </em>的正弦值，范围从<strong class="jp ir"><em class="mv">0</em><strong class="jp ir"><em class="mv">2π</em></strong>。训练数据可以通过以下方式获得:</strong></strong></p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="771d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里我们编译一个 1024 对<strong class="jp ir"> <em class="mv"> (x1，x2) </em> </strong>的训练数据集。然后我们用零初始化——一个 1024 行 2 列的矩阵。<code class="fe my mz na nb b">train_data</code></p><p id="b107" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第一列填充从<strong class="jp ir"> <em class="mv"> 0 </em> </strong>到<strong class="jp ir"> <em class="mv"> 2π </em> </strong>范围内的随机值。我们将第二列的值计算为第一列的正弦值。<code class="fe my mz na nb b">train_data</code></p><p id="5cef" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，我们正式需要一个标签数组，并将其传递给 PyTorch 数据加载器。由于 GAN 实现了无监督学习，标签可以是任何东西。<code class="fe my mz na nb b">train_labels</code></p><p id="85ee" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，我们从和中创建一个元组列表。<code class="fe my mz na nb b">train_data</code> <code class="fe my mz na nb b">train_labels</code> <code class="fe my mz na nb b">train_set</code></p><p id="2756" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们通过绘制每个点<strong class="jp ir"> <em class="mv"> (x1，x2) </em> </strong>来显示用于训练的数据:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nm nn l"/></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mf"><img src="../Images/bd8c1e0335c46455d7beb3f3f9da3330.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Kjb63gN4E-IWSBRd.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk translated">建设成果</figcaption></figure><p id="d8c7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们创建一个名为<code class="fe my mz na nb b">train_loader</code>的数据加载器，它将混洗来自<code class="fe my mz na nb b">train_set</code>的数据，返回用于训练神经网络的 32 个样本(<code class="fe my mz na nb b">batch_size</code>)的数据包:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="56f7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">数据准备好了，现在你需要创建鉴别器和 GAN 神经网络。</p><h1 id="c3d2" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">GAN 鉴频器实现</h1><p id="f292" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">在 PyTorch 中，神经网络模型由从类继承的类表示。如果你是面向对象编程的新手，文章<a class="ae lb" href="https://proglib.io/p/vvedenie-v-obektno-orientirovannoe-programmirovanie-oop-na-python-2020-07-23" rel="noopener ugc nofollow" target="_blank">“Python 中面向对象编程(OOP)的介绍”</a>将足以理解正在发生的事情。<code class="fe my mz na nb b">nn.Module</code></p><p id="2499" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">鉴别器是二维输入一维输出模型。它从真实数据或生成器中获取样本，并提供样本来自真实训练数据的概率。下面的代码显示了如何创建一个鉴别器类。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="ad3f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用标准的类方法来建立神经网络模型。在这个方法中，我们首先调用来运行继承类的相应方法。一个<a class="ae lb" href="https://ru.wikipedia.org/wiki/%D0%9C%D0%BD%D0%BE%D0%B3%D0%BE%D1%81%D0%BB%D0%BE%D0%B9%D0%BD%D1%8B%D0%B9_%D0%BF%D0%B5%D1%80%D1%86%D0%B5%D0%BF%D1%82%D1%80%D0%BE%D0%BD_%D0%A0%D1%83%D0%BC%D0%B5%D0%BB%D1%8C%D1%85%D0%B0%D1%80%D1%82%D0%B0" rel="noopener ugc nofollow" target="_blank">多层感知器被</a>用作神经网络的架构。它的结构是用。该模型有以下特点:<code class="fe my mz na nb b">__init__()</code> <code class="fe my mz na nb b">super().__init__()</code> <code class="fe my mz na nb b">__init__()</code> <code class="fe my mz na nb b">nn.Module</code> <code class="fe my mz na nb b">nn.Sequential()</code></p><ul class=""><li id="171f" class="mg mh iq jp b jq jr ju jv jy mi kc mj kg mk kk ml mm mn mo bi translated">二维入口；</li><li id="aff9" class="mg mh iq jp b jq mp ju mq jy mr kc ms kg mt kk ml mm mn mo bi translated">第一隐含层由 256 个神经元组成，具有<a class="ae lb" href="https://ru.wikipedia.org/wiki/%D0%A4%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F_%D0%B0%D0%BA%D1%82%D0%B8%D0%B2%D0%B0%D1%86%D0%B8%D0%B8" rel="noopener ugc nofollow" target="_blank">a</a>T14】ReLUT16】激活函数；</li><li id="1676" class="mg mh iq jp b jq mp ju mq jy mr kc ms kg mt kk ml mm mn mo bi translated">在随后的层中，神经元的数量减少到 128 和 64。输出具有 s 形激活函数，其特征是表示概率(<code class="fe my mz na nb b">Sigmoid</code>)；</li><li id="47b7" class="mg mh iq jp b jq mp ju mq jy mr kc ms kg mt kk ml mm mn mo bi translated">为了避免过拟合，在第一、第二和第三隐藏层之后，丢弃一部分神经元(<code class="fe my mz na nb b">Dropout</code>)。</li></ul><p id="2bbb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了方便推断，还在类中创建了一个方法。这里对应于模型的输入。在这个实现中，输出是通过将输入输入到我们定义的模型中而获得的，没有经过预处理。<code class="fe my mz na nb b">forward()</code> <code class="fe my mz na nb b">x</code> <code class="fe my mz na nb b">x</code></p><p id="c914" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">声明鉴别器类后，创建它的一个实例:</p><pre class="km kn ko kp gt nd nb ne nf aw ng bi"><span id="d41c" class="nh ld iq nb b gy ni nj l nk nl">discriminator = Discriminator()</span></pre><h1 id="667a" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">GAN 发生器实现</h1><p id="630d" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">在生成式对抗网络中，生成器是一种模型，它从隐藏变量的<a class="ae lb" href="https://ru.wikipedia.org/wiki/%D0%A1%D0%BA%D1%80%D1%8B%D1%82%D0%B0%D1%8F_%D0%BF%D0%B5%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%BD%D0%B0%D1%8F" rel="noopener ugc nofollow" target="_blank">空间中获取一些样本作为输入，这些样本类似于训练集中的数据。在我们的例子中，这是一个 2D 输入模型，它将接收随机点<strong class="jp ir"> <em class="mv"> (z1，z2) </em> </strong>，以及一个 2D 输出，它产生看起来像来自训练数据的点的点<strong class="jp ir"> <em class="mv"> (x̃1，x̃2) </em> </strong>。</a></p><p id="7245" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该实现类似于我们为鉴别器编写的内容。首先需要创建一个继承自的类，然后定义神经网络的架构，最后创建对象的实例:<code class="fe my mz na nb b">Generator</code> <code class="fe my mz na nb b">nn.Module</code> <code class="fe my mz na nb b">Generator</code></p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="19f2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该发生器包括具有 16 和 32 个神经元的两个隐藏层，具有 ReLU 激活函数，并且在输出处包括具有线性激活函数的两个神经元的层。因此，输出将由范围从<strong class="jp ir"><em class="mv">—∞</em></strong>到<strong class="jp ir"> <em class="mv"> + ∞ </em> </strong>的两个元素组成，它们将代表<strong class="jp ir"> <em class="mv"> (x̃1，x̃2) </em> </strong>。也就是说，最初我们不对生成器施加任何限制——它必须“自己学习一切”</p><p id="f991" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们已经定义了鉴别器和生成器的模型，我们准备开始训练。</p><h1 id="95ab" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">训练 GAN 模型</h1><p id="23fa" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">在训练模型之前，您需要配置将在训练过程中使用的参数:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="1722" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是怎么回事:</p><ol class=""><li id="3b93" class="mg mh iq jp b jq jr ju jv jy mi kc mj kg mk kk no mm mn mo bi translated">我们设置学习率，我们将使用它来调整网络权重。<code class="fe my mz na nb b">lr</code></li><li id="3c35" class="mg mh iq jp b jq mp ju mq jy mr kc ms kg mt kk no mm mn mo bi translated">我们设置历元的数量，这决定了使用整个数据集重复训练过程的次数。<code class="fe my mz na nb b">num_epochs</code></li><li id="027e" class="mg mh iq jp b jq mp ju mq jy mr kc ms kg mt kk no mm mn mo bi translated">对于变量，我们指定<a class="ae lb" href="https://ru.wikipedia.org/wiki/%D0%9F%D0%B5%D1%80%D0%B5%D0%BA%D1%80%D1%91%D1%81%D1%82%D0%BD%D0%B0%D1%8F_%D1%8D%D0%BD%D1%82%D1%80%D0%BE%D0%BF%D0%B8%D1%8F" rel="noopener ugc nofollow" target="_blank">逻辑损失函数</a>(二元交叉熵)的函数。这是我们将用来训练模型的损失函数。它既适用于训练鉴别器(其任务简化为二进制分类),也适用于生成器，因为它将其输出提供给鉴别器的输入。<code class="fe my mz na nb b">loss_function</code> <code class="fe my mz na nb b">BCELoss()</code></li></ol><p id="fe35" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">PyTorch 中更新权重(训练模型)的规则是在一个模块中实现的。我们将使用<a class="ae lb" href="https://ru.wikipedia.org/wiki/%D0%A1%D1%82%D0%BE%D1%85%D0%B0%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D0%B3%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82%D0%BD%D1%8B%D0%B9_%D1%81%D0%BF%D1%83%D1%81%D0%BA#Adam" rel="noopener ugc nofollow" target="_blank"> Adam 的</a>随机梯度下降算法来训练鉴别器和生成器模型。要创建优化器，运行下面的代码:<code class="fe my mz na nb b">torch.optim</code> <code class="fe my mz na nb b">torch.optim</code></p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="1320" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，有必要实现一个训练循环，其中训练样本的样本被馈送到模型输入，并且它们的权重被更新，从而最小化损失函数:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="bfc3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里，在每次训练迭代中，我们更新鉴别器和生成器参数。正如通常对神经网络所做的那样，训练过程由两个嵌套循环组成:外部循环用于训练时期，内部循环用于每个时期内的数据包。在内部循环中，一切都从准备用于训练鉴别器的数据开始:</p><ul class=""><li id="7f5a" class="mg mh iq jp b jq jr ju jv jy mi kc mj kg mk kk ml mm mn mo bi translated">我们从数据加载器中获取当前批次的真实样本，并将它们赋给一个变量。请注意，数组维度中的第一个维度的元素数量等于。这是 PyTorch 中组织数据的标准方式，其中每个张量行代表包中的一个样本。<code class="fe my mz na nb b">real_samples</code>T3】</li><li id="2d11" class="mg mh iq jp b jq mp ju mq jy mr kc ms kg mt kk ml mm mn mo bi translated">用于为真实样本创建值为 1 的标签，并将标签分配给变量。<code class="fe my mz na nb b">torch.ones()</code> <code class="fe my mz na nb b">real_samples_labels</code></li><li id="63bc" class="mg mh iq jp b jq mp ju mq jy mr kc ms kg mt kk ml mm mn mo bi translated">我们通过存储随机数据来生成样本，然后将这些数据传递给生成器进行接收。我们对生成的样本的标签使用零，这些样本存储在<code class="fe my mz na nb b">latent_space_samples</code> <code class="fe my mz na nb b">generate_samples</code> <code class="fe my mz na nb b">torch.zeros()</code> <code class="fe my mz na nb b">generate_samples_labels</code>中</li><li id="eaa9" class="mg mh iq jp b jq mp ju mq jy mr kc ms kg mt kk ml mm mn mo bi translated">仍然需要将真实的和生成的样本和标签合并，并分别保存在和<code class="fe my mz na nb b">all_samples</code> <code class="fe my mz na nb b">all_samples_labels</code>中</li></ul><p id="3a19" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在下一个模块中，我们训练鉴别器:</p><ul class=""><li id="d47b" class="mg mh iq jp b jq jr ju jv jy mi kc mj kg mk kk ml mm mn mo bi translated">在 PyTorch 中，在训练的每一步清除梯度值是很重要的。我们使用方法<code class="fe my mz na nb b">zero_grad()</code>来完成这项工作</li><li id="5ebf" class="mg mh iq jp b jq mp ju mq jy mr kc ms kg mt kk ml mm mn mo bi translated">我们使用训练数据<code class="fe my mz na nb b">all_samples</code>计算鉴频器的输出</li><li id="f263" class="mg mh iq jp b jq mp ju mq jy mr kc ms kg mt kk ml mm mn mo bi translated">使用输出和标签<code class="fe my mz na nb b">output_discriminator</code> <code class="fe my mz na nb b">all_samples_labels</code>计算损失函数值</li><li id="11f8" class="mg mh iq jp b jq mp ju mq jy mr kc ms kg mt kk ml mm mn mo bi translated">用<code class="fe my mz na nb b">loss_discriminator.backward()</code>计算梯度以更新权重</li><li id="8fee" class="mg mh iq jp b jq mp ju mq jy mr kc ms kg mt kk ml mm mn mo bi translated">通过调用<code class="fe my mz na nb b">optimizer_discriminator.step()</code>找到更新的鉴别器权重</li><li id="c701" class="mg mh iq jp b jq mp ju mq jy mr kc ms kg mt kk ml mm mn mo bi translated">我们为训练发电机准备数据。我们使用两列来匹配发生器输入端的 2D 数据。<code class="fe my mz na nb b">latent_space_samples</code> <code class="fe my mz na nb b">batch_size</code></li></ul><p id="8905" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们训练发电机:</p><ul class=""><li id="1fd0" class="mg mh iq jp b jq jr ju jv jy mi kc mj kg mk kk ml mm mn mo bi translated">我们使用该方法来清理梯度。<code class="fe my mz na nb b">zero_grad()</code></li><li id="dcbd" class="mg mh iq jp b jq mp ju mq jy mr kc ms kg mt kk ml mm mn mo bi translated">我们将其传递给生成器，并将其输出保存到<code class="fe my mz na nb b">latent_space_samples</code> <code class="fe my mz na nb b">generate_samples</code></li><li id="ca1e" class="mg mh iq jp b jq mp ju mq jy mr kc ms kg mt kk ml mm mn mo bi translated">我们将生成器输出传递给鉴别器并保存其输出，该输出将被用作整个模型的输出。<code class="fe my mz na nb b">output_discriminator_generated</code></li><li id="842a" class="mg mh iq jp b jq mp ju mq jy mr kc ms kg mt kk ml mm mn mo bi translated">使用存储在中的分类系统的输出和等于 1 的标签来计算损失函数。<code class="fe my mz na nb b">output_discriminator_generated</code> <code class="fe my mz na nb b">real_samples_labels</code></li><li id="76ef" class="mg mh iq jp b jq mp ju mq jy mr kc ms kg mt kk ml mm mn mo bi translated">计算梯度和更新生成器权重。记住，当我们训练发电机时，我们保持鉴别器重量不变。</li></ul><p id="4b45" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，在循环的最后几行中，在每第十个时期结束时输出鉴别器和发电机损耗函数值。</p><h1 id="59f0" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">检查 GAN 生成的样本</h1><p id="e153" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">生成性对抗网络被设计成生成数据。因此，在训练过程完成后，我们可以调用生成器来获取新数据:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="36e7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们绘制生成的数据，并检查它与训练数据有多相似。在为生成的样本绘制图表之前，您需要应用方法<code class="fe my mz na nb b">detach()</code>从 PyTorch 计算图表中获取必要的数据:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nm nn l"/></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mf"><img src="../Images/c8f3ab685615d80349b174e763f9ed58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*uuGXR98gsJGL8CkR.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk translated">构建生成的数据集的结果</figcaption></figure><p id="9f35" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">生成数据的分布与真实数据非常相似，即原始正弦。学习进化的动画可以<a class="ae lb" href="https://files.realpython.com/media/fig_gan_x1x2.69b1d6021da8.gif" rel="noopener ugc nofollow" target="_blank">看这里</a>。</p><p id="f73f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在训练过程的开始，生成数据的分布与真实数据有很大不同。但是随着它的学习，生成器学习真实的数据分布，就好像适应它一样。</p><p id="5bd8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">既然我们已经实现了生成性对抗网络的第一个模型，我们可以继续讨论一个更实际的生成图像的例子。</p><h1 id="5d92" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">GAN 手写数字发生器</h1><p id="8eda" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">在下面的例子中，我们将使用 GAN 来生成手写数字的图像。为此，我们将使用手写数字的<a class="ae lb" href="https://ru.wikipedia.org/wiki/MNIST_(%D0%B1%D0%B0%D0%B7%D0%B0_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85)" rel="noopener ugc nofollow" target="_blank"> MNIST 数据集</a>来训练模型。该标准数据集包含在包<code class="fe my mz na nb b">torchvision</code>中</p><p id="90c3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，在激活的环境中，需要安装:<code class="fe my mz na nb b">gan</code> <code class="fe my mz na nb b">torchvision</code></p><pre class="km kn ko kp gt nd nb ne nf aw ng bi"><span id="9168" class="nh ld iq nb b gy ni nj l nk nl">$ conda install -c pytorch torchvision=0.5.0</span></pre><p id="89fc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">同样，这里我们指定了特定的版本，就像我们对 PyTorch 所做的那样，以确保代码示例能够运行。<code class="fe my mz na nb b">torchvision</code></p><p id="9fa9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们从导入所需的库开始:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="542c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">除了我们之前导入的库之外，我们还需要转换存储在图像文件中的信息。<code class="fe my mz na nb b">torchvision</code> <code class="fe my mz na nb b">torchvision.transforms</code></p><p id="2e32" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因为在这个例子中训练集包括图像，所以模型将更复杂，训练将花费更长的时间。在中央处理器(<a class="ae lb" href="https://ru.wikipedia.org/wiki/%D0%A6%D0%B5%D0%BD%D1%82%D1%80%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9_%D0%BF%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81%D0%BE%D1%80" rel="noopener ugc nofollow" target="_blank"> CPU </a>)中训练时，一个历元大约需要两分钟。大约需要 50 个历元才能得到可接受的结果，因此使用处理器的总训练时间大约为 100 分钟。</p><p id="86ad" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">图形处理单元(<a class="ae lb" href="https://ru.wikipedia.org/wiki/%D0%93%D1%80%D0%B0%D1%84%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D0%BF%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81%D0%BE%D1%80" rel="noopener ugc nofollow" target="_blank"> GPU </a>)可用于减少训练时间。</p><p id="d46d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了使代码不管计算机的特征如何都能工作，让我们创建一个指向中央处理器或图形处理器(如果有的话)的对象:<code class="fe my mz na nb b">device</code></p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="09b3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">环境已配置好，让我们准备一个数据集进行训练。</p><h1 id="da4e" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">准备 MNIST 数据集</h1><p id="0cad" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">MNIST 数据集由手写数字 0 到 9 的图像组成。这些图像是灰度图像，尺寸为<strong class="jp ir"> 28 × 28 像素</strong>。要在 PyTorch 中使用它们，您需要做一些转换。为此，我们定义了加载数据时使用的函数:<code class="fe my mz na nb b">transform</code></p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="c061" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该功能有两个部分:</p><ol class=""><li id="b748" class="mg mh iq jp b jq jr ju jv jy mi kc mj kg mk kk no mm mn mo bi translated"><code class="fe my mz na nb b">transforms.ToTensor()</code>将数据转换成 PyTorch 张量。</li><li id="bc5e" class="mg mh iq jp b jq mp ju mq jy mr kc ms kg mt kk no mm mn mo bi translated"><code class="fe my mz na nb b">transforms.Normalize()</code>转换一系列张量系数。</li></ol><p id="9ad5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">原始系数由从 0 到 1 的函数范围给出。因为图像具有黑色背景，所以大多数系数是 0。<code class="fe my mz na nb b">transforms.ToTensor()</code></p><p id="fcf6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该函数将系数的取值范围改为<code class="fe my mz na nb b">transforms.Normalize()</code> <strong class="jp ir"> <em class="mv"> [ - 1，1]【1，1】</em></strong>，从原赔率中减去 0.5，结果除以 0.5。该变换将输入样本中的元素数量减少到零。这有助于训练模型。</p><p id="9cca" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们现在可以通过调用:<code class="fe my mz na nb b">torchvision.datasets.MNIST</code>来加载训练数据</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="2f5c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">参数可确保首次运行代码时，MNIST 数据集将被加载并保存在参数中指定的当前目录中。<code class="fe my mz na nb b">download = True</code> <code class="fe my mz na nb b">root</code></p><p id="de38" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们创建了，这样我们就可以像以前一样创建数据加载器:<code class="fe my mz na nb b">train_set</code></p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="1ff2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们使用<code class="fe my mz na nb b">matplotlib</code>对数据进行选择性绘图。非常适合作为调色板<code class="fe my mz na nb b">cmap = gray_r</code>。数字将以白底黑字显示:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="5b91" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如您所见，数据集包含不同笔迹的数字。随着 GAN 学习数据的分布，它也生成具有不同手写风格的数字。</p><p id="b491" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们已经准备好了训练数据，我们可以实现鉴别器和生成器模型。</p><h1 id="e1d8" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">鉴别器和生成器实现</h1><p id="7fb9" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">在这种情况下，鉴别器是一个多层感知器神经网络，它取一幅<strong class="jp ir"> 28 × 28 像素</strong>的图像，求出该图像属于真实训练数据的概率。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="2e76" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了将图像系数引入感知器神经网络，有必要对其进行矢量化，以便神经网络接收由 784 个系数组成的向量(<strong class="jp ir"> 28 × 28 = 784 </strong>)。</p><p id="c6c6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">矢量化发生在方法的第一行——调用转换输入张量的形式。初始张量形式<code class="fe my mz na nb b">forward()</code> <code class="fe my mz na nb b">x.view()</code> <strong class="jp ir"> 𝑥 </strong>，其中 32 为批量大小。变换后，形式<code class="fe my mz na nb b"><strong class="jp ir">32 × 1 × 28 × 28</strong></code> <strong class="jp ir"> </strong> 𝑥x 变得相等，每一行代表训练集的图像系数。<code class="fe my mz na nb b"><strong class="jp ir">32 × 784</strong></code></p><p id="02c7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要使用 GPU 运行鉴别器模型，您需要实例化它，并使用方法将它与设备对象相关联:<code class="fe my mz na nb b">to()</code></p><pre class="km kn ko kp gt nd nb ne nf aw ng bi"><span id="c472" class="nh ld iq nb b gy ni nj l nk nl">discriminator = Discriminator().to(device=device)</span></pre><p id="7108" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">生成器将创建比前一个示例更复杂的数据。因此，有必要增加用于初始化的输入数据的大小。这里我们使用一个 100 维的输入和输出，有 784 个系数。结果被组织成一个代表图像的<strong class="jp ir"> 28x28 张量</strong>。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="37da" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">输出系数必须在-1 到 1 的范围内。因此，在发生器的输出端，我们使用双曲线激活函数。在最后一行中，我们实例化了生成器，并将其与设备对象相关联。<code class="fe my mz na nb b">Tanh()</code></p><p id="755e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">剩下的只是训练模型。</p><h1 id="79c0" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">模特培训</h1><p id="3979" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">要训练模型，您需要定义训练参数和优化器:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="2729" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">与前面的例子相比，我们降低了学习率。要缩短训练时间，请将时期数设置为 50。</p><p id="6078" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">学习循环类似于我们在前面的例子中使用的循环:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nm nn l"/></div></figure><h1 id="1449" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">检查生成的 GAN 样本</h1><p id="7aa9" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">让我们生成一些“手写数字”的样本。为此，我们向生成器传递一组初始随机数:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="617a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要构建生成的样本，您需要将数据移回中央处理器，如果它是在 GPU 上处理的。为此，只需调用方法<code class="fe my mz na nb b">cpu()</code>。和以前一样，在绘制数据之前，您需要调用方法<code class="fe my mz na nb b">detach()</code>:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="a8f4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">输出应该是类似于训练数据的数字。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mf"><img src="../Images/0ba197e2967e1bd1e9a686cf7e80df64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KmERuapYQHyTO6uD.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk translated">生成图像的结果</figcaption></figure><p id="b9bb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">经过五十代的学习，有几个数字，好像是人手写的。训练时间越长(时期越多)，结果越好。与前面的例子一样，您可以通过使用输入的固定张量并在每个时期结束时将其馈送给生成器来可视化训练的演变(训练演变的<a class="ae lb" href="https://files.realpython.com/media/fig_gan_mnist.5d8784a85944.gif" rel="noopener ugc nofollow" target="_blank">动画</a>)。</p><p id="f18d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在训练过程的开始，生成的图像是完全随机的。随着它的学习，生成器学习真实数据的分布，并且在大约二十个时期之后，一些生成的数字图像已经类似于真实数据。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mf"><img src="../Images/812fa3cbb1aa87d32d0652c6e0a40789.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zsJ526OzRqOQIPhK.gif"/></div></div></figure><h1 id="0087" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">结论</h1><p id="cff9" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">恭喜你！你已经学会了如何实现你自己的生成性对抗网络。我们首先构建了一个玩具示例来理解 GAN 的结构，然后研究了一个从可用样本数据生成图像的网络。</p><p id="c242" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">尽管 GAN 主题很复杂，但像 PyTorch 这样的机器学习框架使实现变得非常容易。</p></div></div>    
</body>
</html>