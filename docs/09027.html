<html>
<head>
<title>Spark Structured Streaming — Outer Joins Caveats</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Spark 结构化流—外部连接警告</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/spark-structured-streaming-outer-joins-caveats-41971a1937cf?source=collection_archive---------10-----------------------#2022-07-25">https://blog.devgenius.io/spark-structured-streaming-outer-joins-caveats-41971a1937cf?source=collection_archive---------10-----------------------#2022-07-25</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><p id="acd0" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">在 Spark Streaming 中，我有机会处理的最棘手的主题之一是外部连接。当我开始使用 spark 和外部连接时，这种行为对我来说非常意外。有时行匹配，有时不匹配，有时行从不写入接收器，有时执行程序会用尽内存。</p><p id="4482" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">Spark 文档很清楚，但是您需要深入了解它的位和字节才能真正理解它的行为。</p><p id="bb87" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">我将使用<a class="ae ki" href="http://equalum.io" rel="noopener ugc nofollow" target="_blank"> Equalum </a> UI 来可视化演示，稍后将写下我们如何在<a class="ae ki" href="http://equalum.io" rel="noopener ugc nofollow" target="_blank"> Equalum </a>为我们的客户解决一些 Spark 警告。</p><p id="5570" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">所以让我们开始吧。假设我想在两个流之间做一个简单的左连接。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi kj"><img src="../Images/e1cbc3da9c61651d598c24b977c4fadf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T-rklrIpFKn0k3ll39oPwQ.png"/></div></div></figure><p id="aacf" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">要理解 join 配置，我们需要理解 Spark 中什么是<a class="ae ki" href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#outer-joins-with-watermarking" rel="noopener ugc nofollow" target="_blank"> <strong class="jm io">水印</strong> </a>和什么是<strong class="jm io">状态</strong>。</p><blockquote class="kv kw kx"><p id="8dfa" class="jk jl ky jm b jn jo jp jq jr js jt ju kz jw jx jy la ka kb kc lb ke kf kg kh ig bi translated"><strong class="jm io"> Spark 支持在存储中保存流状态的有状态操作。</strong></p><p id="88f0" class="jk jl ky jm b jn jo jp jq jr js jt ju kz jw jx jy la ka kb kc lb ke kf kg kh ig bi translated"><strong class="jm io">状态存储占用内存、磁盘空间等资源来存储状态。</strong></p><p id="7874" class="jk jl ky jm b jn jo jp jq jr js jt ju kz jw jx jy la ka kb kc lb ke kf kg kh ig bi translated"><strong class="jm io">有状态操作:连接&amp;聚合</strong></p></blockquote><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi lc"><img src="../Images/d6c56d70b2ea5b506984788d4113b4ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mdC75tVX-6CDaJwj"/></div></div></figure><blockquote class="kv kw kx"><p id="a584" class="jk jl ky jm b jn jo jp jq jr js jt ju kz jw jx jy la ka kb kc lb ke kf kg kh ig bi translated"><strong class="jm io">水印——让 spark 引擎自动跟踪数据中的当前事件时间，并尝试相应地清除旧状态。</strong></p><p id="2779" class="jk jl ky jm b jn jo jp jq jr js jt ju kz jw jx jy la ka kb kc lb ke kf kg kh ig bi translated">没有水印，状态将永远变得越来越大…</p><p id="448b" class="jk jl ky jm b jn jo jp jq jr js jt ju kz jw jx jy la ka kb kc lb ke kf kg kh ig bi translated"><strong class="jm io">水印基本上是指示何时丢弃“旧”数据</strong></p><p id="211c" class="jk jl ky jm b jn jo jp jq jr js jt ju kz jw jx jy la ka kb kc lb ke kf kg kh ig bi translated"><strong class="jm io">火花引擎将保持状态，并允许后期数据更新状态，直到(火花-后期阈值看到的最大事件时间&gt; T)。换句话说，在阈值范围内的晚数据将被加入，但是晚于阈值的数据将开始被丢弃</strong></p></blockquote><p id="cff3" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">我们将使用以下配置来配置连接:</p><p id="6317" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">水印字段将是该行进入 kafka 主题的时间。</p><p id="c8b7" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">1 分钟水印用于左侧和右侧，2 分钟延迟(右侧将等待 2 分钟以“延迟”左侧事件)。</p><p id="0d48" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">在<a class="ae ki" href="http://equalum.io" rel="noopener ugc nofollow" target="_blank"> Equalum </a> UI 上看起来是这样的:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi ld"><img src="../Images/7d001b50255b021da2cbe8665d9a3745.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bsNNX9PMA8N8J1vV5NQZOA.png"/></div></div></figure><p id="e839" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">在 Scala 中是这样的:</p><pre class="kk kl km kn gt le lf lg lh aw li bi"><span id="6f41" class="lj lk in lf b gy ll lm l ln lo">dfLeft.withWatermark("<strong class="lf io">TSLeft</strong>", "60 seconds")<br/>dfRight.withWatermark("<strong class="lf io">TSRight"</strong>, "60 seconds")</span></pre><p id="bc46" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">2 分钟的延迟是连接条件的一部分:</p><pre class="kk kl km kn gt le lf lg lh aw li bi"><span id="c5c3" class="lj lk in lf b gy ll lm l ln lo">val joinCondition = "ID=IDRight AND <strong class="lf io">TSLeft</strong> &gt;= <strong class="lf io">TSRight</strong> AND <strong class="lf io">TSLeft</strong> &lt;= <strong class="lf io">TSRight</strong> + interval <strong class="lf io">120</strong> seconds"</span><span id="e377" class="lj lk in lf b gy lp lm l ln lo">dfLeft<br/> .join(dfRight, <em class="ky">expr</em>(joinCondition), "left")</span></pre><p id="7278" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">让我们看看左边和右边的流数据:</p><p id="645e" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io">左:</strong></p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi lq"><img src="../Images/ecfc8056f3a5a240691d8076e6f95bd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wyRZo6BbUiVEPUaEH34gOg.png"/></div></div></figure><p id="a4fe" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io">右:</strong></p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi lr"><img src="../Images/47519ad1ee942a9462d49dec52f43503.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nuSWw0czEl5tX3JXOARxYw.png"/></div></div></figure><p id="5390" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">因此，如果我问你“左外部连接的预期输出是什么”,你可能会这样说:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi ls"><img src="../Images/3d88482098e1dfe0ad434c36451726c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*73s0J09zjcthviawOWX_ZA.png"/></div></div></figure><p id="5e9b" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">这只是 Equalum 预览版，它实际上以批处理模式运行 spark(不是流到流连接)</p><p id="fbf7" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">因此，让我们看看流式查询输出。在我们开始流式查询后，查看 Kafka(sink)中的数据:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi lt"><img src="../Images/2844f2502f5543e6082085429e6ef5b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WHbUqmaiXgrpDOC1HywoHw.png"/></div></div></figure><p id="99f0" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">什么？“YAIR”一行是在哪里消失的？！它在哪里，为什么不写到接收器？！</p><p id="2450" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">让我们看看 Spark UI，并尝试理解丢失的行在哪里:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/f3e529009713e6a7f825c6124ce1fc09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/format:webp/1*9F4qK79JatDZZj4Ce5GJJA.png"/></div></figure><p id="b358" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io"> <em class="ky">“更新状态行数:3”</em></strong>—到目前为止输入了 3 行(左边两行，右边一行)</p><p id="5917" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io"> <em class="ky">“输出行数:1”</em></strong>-&gt;这是我们在水槽里看到的。“阿米尔”加入了排写。</p><p id="37f5" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">因此，我们仍然有 1 行从左边保持在状态。</p><p id="ccef" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">您可能想知道:“那么让我们等 1 分钟，没有匹配的行将被写入接收器”，对吗？水印过期后。</p><p id="1a34" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">这并不简单，因为 Spark Streaming 有两个警告:</p><ol class=""><li id="5ed8" class="lv lw in jm b jn jo jr js jv lx jz ly kd lz kh ma mb mc md bi translated">如果您希望将数据从状态中推出，您需要一个微批处理来触发。这意味着你需要在 kafka 中有一个新的数据来触发新的微批处理。真扫兴。</li><li id="7b31" class="lv lw in jm b jn me jr mf jv mg jz mh kd mi kh ma mb mc md bi translated">您需要连接两端的数据，因此水印将被推进(与<em class="ky">spark . SQL . streaming . multiplewatermarkpolicy = min 相关)，我们将在稍后讨论。</em></li></ol><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi mj"><img src="../Images/f11de90e864a41d1955e5b577ea27e60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ee5uHFk2oVzCnWNeSx3xnQ.png"/></div></div></figure><p id="4d2a" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">因此，如果出于某种原因，您有一个流查询，其中的数据只来自右边(或左边)，您可能会丢失数据，并有可能在执行器上遇到 OOM，因为状态会变得越来越大…</p><p id="cc83" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">在 Equalum，我们为用户提供了克服 Spark 警告的能力，如果他们愿意的话(就像在简单的流执行中，当数据一直在流动时，没有真正的问题，除了在某些情况下可能会出现停滞的数据)</p><p id="be20" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">在运行查询之前，我们已经为用户添加了一个可选配置。用户可以选择查询中联接的前导端和/或非前导端的心跳(对于左联接，前导端是左侧)。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/0931960802a3458b1e5650d234456bc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*3Cq6sxfiHO73l6WkUUEv9A.png"/></div></figure><p id="6fc2" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">因此 heartbeat 实际上是一个虚拟事件(被过滤掉)，我们将它推送到查询中任何 join 的左侧和/或右侧的每个微批处理上。在这种情况下，在每个 spark 流微批次间隔中，即使 kafka 主题中没有新数据，也将有<strong class="jm io">成为微批次。我们基本上实现了一个 spark 数据源，它在每个触发器上生成虚拟事件(以 join 的右/左模式为例)。</strong></p><p id="6c33" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">这样，我们首先要确保:</p><ol class=""><li id="174f" class="lv lw in jm b jn jo jr js jv lx jz ly kd lz kh ma mb mc md bi translated">每隔一段时间就会创建一个新的微型计算机</li><li id="60f9" class="lv lw in jm b jn me jr mf jv mg jz mh kd mi kh ma mb mc md bi translated">数据正在进入连接的两端(如果选中了 lead + non lead)</li></ol><p id="666e" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">在 spark ui 中，它看起来像这样:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi ml"><img src="../Images/bf26fbd4f32d74310ad3b6a8c851c53e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XZmSn7FpKULMq26DspD08A.png"/></div></div></figure><p id="c41f" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">您可以看到两个额外的源，它们在连接之前与每个流合并。每个新源都生成 1 个事件“输出行数”。</p><p id="a222" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">这个特性非常棘手，用户应该知道他们在做什么:</p><ol class=""><li id="6ee2" class="lv lw in jm b jn jo jr js jv lx jz ly kd lz kh ma mb mc md bi translated">与以前相比，更多的微批次将在火花簇上被触发。</li><li id="4d6f" class="lv lw in jm b jn me jr mf jv mg jz mh kd mi kh ma mb mc md bi translated">如果只选择心跳的一侧— OOM 是一个潜在的风险，因为我们不断将数据推入状态(以防没有来自 kafka 源的新数据)</li><li id="8a2d" class="lv lw in jm b jn me jr mf jv mg jz mh kd mi kh ma mb mc md bi translated">水印——它仅适用于水印为“现在”的“真实”流处理，因为心跳将“现在”用于 ts 字段，它基本上将水印递增到当前时间。因此，如果处理旧数据—可能会导致行不等待“非前导端”的“延迟”时间。</li><li id="1646" class="lv lw in jm b jn me jr mf jv mg jz mh kd mi kh ma mb mc md bi translated">全局水印-如果在查询中有另一个 spark 操作，如 GroupBy with watermark 字段在过去，该解决方案将不起作用，因为 spark 默认将最小水印值作为全局水印，并且心跳将不起作用，迟早会导致 OOM。对于 equalum 客户，我们建议使用"<em class="ky">spark . SQL . streaming . multiplewatermarkpolicy = max "配置运行这些查询，这可以解决此问题，但在某些情况下可能会导致数据问题:)</em></li></ol></div></div>    
</body>
</html>