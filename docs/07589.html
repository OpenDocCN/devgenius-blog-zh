<html>
<head>
<title>Investigating Machine Learning Techniques to Improve Spec Tests — III</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">研究机器学习技术以改进规格测试(三)</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/investigating-machine-learning-techniques-to-improve-spec-tests-iii-7120d90a1ac5?source=collection_archive---------10-----------------------#2022-04-07">https://blog.devgenius.io/investigating-machine-learning-techniques-to-improve-spec-tests-iii-7120d90a1ac5?source=collection_archive---------10-----------------------#2022-04-07</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><figure class="gl gn jl jm jn jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi jk"><img src="../Images/b373c7822c8d404d00f315ea92dd48be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P1v2Vctv1Cm9iOWyw_fH5g.jpeg"/></div></div></figure><h1 id="bd0b" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">介绍</h1><p id="a08b" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">这是与人工智能实现相关的系列博文的一部分。如果你对故事的背景或情节感兴趣:</p><figure class="lr ls lt lu gt jo"><div class="bz fp l di"><div class="lv lw l"/></div></figure><p id="b4eb" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">本周我们将展示为一般测试目的实现机器学习模型的训练程序。我们将使用<a class="ae mc" href="https://serpapi.com/organic-results" rel="noopener ugc nofollow" target="_blank"> SerpApi 的 Google Organic Results Scraper API</a>进行数据收集。此外，您可以查看<a class="ae mc" href="https://serpapi.com/playground?q=Coffee&amp;location=Austin%2C+Texas%2C+United+States&amp;gl=us&amp;hl=en&amp;no_cache=true&amp;newPara=lr+async+as_qdr" rel="noopener ugc nofollow" target="_blank">游乐场</a>，了解我们将使用的数据的更多详细信息。</p><figure class="lr ls lt lu gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi md"><img src="../Images/6767f40afd71c36beb8d584280b0e59f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WDQwARa7hFeONBpOriUOOg.png"/></div></div></figure><p id="862b" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi">____</p><h1 id="f2e9" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">Ruby 中自定义加权 KNN 的分解</h1><p id="c2cf" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">让我们初始化一个培训班</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="e3a5" class="mj jw in mf b gy mk ml l mm mn">class Train<br/>  def initialize csv_path<br/>    @@csv_path = csv_path<br/>    @@vector_arr = []<br/>    @@word_arr = []<br/>    @@maximum_word_size = 100<br/>    @@weights = Vector[]<br/>    @@losses = []<br/>  end</span></pre><figure class="lr ls lt lu gt jo"><div class="bz fp l di"><div class="lv lw l"/></div></figure><p id="c761" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi">— —</p><p id="490b" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">让我们读取特定于密钥的 CSV 文件。</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="39f6" class="mj jw in mf b gy mk ml l mm mn">def self.read<br/> @@word_arr = CSV.read(@@csv_path)<br/> @@word_arr<br/>end<br/>```</span></pre><p id="6c14" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">举个例子，如果我们键入以下命令:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="5b7a" class="mj jw in mf b gy mk ml l mm mn">csv_path = “organic_results/organic_results__snippet.csv”<br/>Train.new csv_path<br/>key_array = Train.read</span></pre><p id="8464" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">输出将是:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="7abc" class="mj jw in mf b gy mk ml l mm mn">[[“0”, “McDonald’s: Burgers, Fries &amp; More. Quality Ingredients.”],<br/> [“0”, “<a class="ae mc" href="https://www.mcdonalds.com/us/en-us.html" rel="noopener ugc nofollow" target="_blank">https://www.mcdonalds.com/us/en-us.html</a>"],<br/> [“0”, “<a class="ae mc" href="https://www.mcdonalds.com" rel="noopener ugc nofollow" target="_blank">https://www.mcdonalds.com</a> › en-us”],<br/> [“1”, “McDonalds.com is your hub for everything McDonald’s. Find out more about our menu items and promotions today!”],<br/> [“0”, “Breakfast”],<br/> …</span></pre><p id="c065" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">该阵列是 csv 上内容的副本。它包含元素及其对应的二进制对应的关键问题。</p><p id="cdbd" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">——<br/>让我们在“Train”类中定义这些单词的矢量化版本。</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="3f28" class="mj jw in mf b gy mk ml l mm mn">def self.define_training_set vectors<br/> @@vector_arr = vectors<br/>end</span></pre><p id="0f36" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">为了建立这样一个“向量”数组，我们将使用如下词汇表:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="6116" class="mj jw in mf b gy mk ml l mm mn">{<br/> “&lt;unk&gt;”: 0,<br/> “&lt;pad&gt;”: 1,<br/> “1”: 2,<br/> “mcdonald”: 3,<br/> “‘“: 4,<br/> “s”: 5,<br/> “burgers,”: 6,<br/> “fries”: 7,<br/> …<br/>}</span></pre><p id="de3a" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">这些“标记”中的每一个都应该用以下命令行在向量中表示:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="d25b" class="mj jw in mf b gy mk ml l mm mn">vector_array = key_array.map { |word| Database.word_to_tensor word[1] }<br/>Train.define_training_set vector_array</span></pre><p id="22c5" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">` Database.word_to_tensor '是我们在上周的代码中定义的函数。它根据词汇来标记单词或句子。我们实际上在“Database”类中添加了以下函数来调用已经创建的词汇表:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="b3d7" class="mj jw in mf b gy mk ml l mm mn">def self.read_vocab vocab_path<br/>   vocab = File.read vocab_path<br/>   @@vocab = JSON.parse(vocab)<br/> end</span></pre><p id="f1b0" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">最终结果是一个可矢量化数组的数组:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="b443" class="mj jw in mf b gy mk ml l mm mn">[[2],<br/> [3, 4, 5, 6, 7, 8, 9, 10, 11, 12],<br/> [22, 23, 24, 10, 25],<br/> [22, 23, 24, 10, 30, 31, 32],<br/> [36, 10, 37, 38, 39, 40, 41, 42, 3, 4, 43, 44, 45, 9, 46, 47, 48, 49, 50, 51, 52, 53],<br/> [74],<br/> [22, 23, 24, 10, 75],<br/> [77, 78],<br/> [22, 23, 24, 10, 80],<br/> [82, 83],<br/> [22, 23, 24, 10, 85],<br/> …<br/>]</span></pre><p id="76a6" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi">— -</p><p id="ed4f" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">让我们定义一个函数来自动取最大的字长来确定填充模式。对于您想要训练的最终模型，建议不要这样做，因为该集合中的最大值可能会小于您将输入的实际示例。</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="8114" class="mj jw in mf b gy mk ml l mm mn">def self.auto_define_maximum_size<br/> @@maximum_word_size = @@vector_arr.map {|el| el.size}.max<br/>end</span></pre><p id="ccce" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">所以再举一个例子:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="1c80" class="mj jw in mf b gy mk ml l mm mn">Train.auto_define_maximum_size</span></pre><p id="76cf" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">输出:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="93cb" class="mj jw in mf b gy mk ml l mm mn">37</span></pre><p id="68d9" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">这是具有最大字符数的单词，所以它将被视为最大单词大小。其余的条目将用“<pad>”字符补全为 37 个字符，在词汇表中标记为“1”。</pad></p><p id="27b8" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">— <br/>让我们定义将单个向量扩展到最大字数的函数。</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="3d75" class="mj jw in mf b gy mk ml l mm mn">def self.extend_vector vector<br/>  vector_arr = vector.to_a<br/>  (@@maximum_word_size - vector.size).times { vector_arr &lt;&lt; 1 }<br/>  Vector.[](*vector_arr)<br/>end</span></pre><p id="a2f1" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">它获取向量，将其转换为数组，向其中输入足够的“1 ”,然后再次对其进行矢量化。<br/>要浏览整个数据集，我们需要:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="8d3c" class="mj jw in mf b gy mk ml l mm mn">def self.extend_vectors<br/>  @@vector_arr.each_with_index do |vector, index|<br/>    @@vector_arr[index] = extend_vector vector<br/>  end<br/>end</span></pre><p id="a02c" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">因此，如果我们应用以下命令:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="b826" class="mj jw in mf b gy mk ml l mm mn">[Vector[2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],<br/> Vector[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],<br/> Vector[22, 23, 24, 10, 25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],<br/> Vector[22, 23, 24, 10, 30, 31, 32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],<br/> …</span></pre><p id="a38b" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">迎接我们的是多个向量，每个向量的大小都是 37。这对于在下面的部分中保持带权重的矢量乘法是很重要的。</p><p id="85c1" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi">— -</p><p id="8d2b" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">现在我们需要初始化权重。它们将帮助我们将向量调整到它们相应分类的附近。</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="8c45" class="mj jw in mf b gy mk ml l mm mn">def self.initialize_weights<br/> weights = []<br/> @@maximum_word_size.times { weights &lt;&lt; 1.0 }<br/> @@weights = Vector.[](*weights)<br/>end</span></pre><p id="eb88" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">如果我们输入以下命令，我们可以看到输出将是一个大小为 37 的向量，由“1”组成:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="e97a" class="mj jw in mf b gy mk ml l mm mn">Train.initialize_weights</span></pre><p id="6392" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">输出:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="ab64" class="mj jw in mf b gy mk ml l mm mn">Vector[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]</span></pre><p id="35e7" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">— <br/>让我们也添加一些东西来控制变化的零件:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="42bf" class="mj jw in mf b gy mk ml l mm mn">def self.config k = 1, lr = 0.001<br/> [k, lr]<br/>end</span></pre><figure class="lr ls lt lu gt jo"><div class="bz fp l di"><div class="lv lw l"/></div></figure><p id="3334" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi">— —</p><p id="8eba" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">让我们定义我们的函数，在多个维度上倾斜向量，以获得我们想要的结果。</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="b5d0" class="mj jw in mf b gy mk ml l mm mn">def self.product vector<br/>  @@weights.each_with_index do |weight, index|<br/>    vector[index] = weight * vector[index]<br/>  end</span><span id="1509" class="mj jw in mf b gy mo ml l mm mn">  vector<br/>end</span></pre><p id="0dfe" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">权重向量中的每个元素乘以我们用于训练或预测的初始向量中的每个元素，以获得加权向量。因为我们的初始权重仅由‘1’组成，这个函数将返回我们在第一次迭代中输入的向量。</p><p id="25df" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">如果我们的初始向量仅由“2”组成</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="6f50" class="mj jw in mf b gy mk ml l mm mn">vector = Vector[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]</span><span id="a436" class="mj jw in mf b gy mo ml l mm mn">Train.product vector</span></pre><p id="141b" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">这些命令将为我们提供:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="2026" class="mj jw in mf b gy mk ml l mm mn">Vector[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]</span></pre><p id="5221" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">— <br/>多维空间中两点之间的欧几里德距离不应该吓到你，这很简单:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="c2c0" class="mj jw in mf b gy mk ml l mm mn">def self.euclidean_distance vector_1, vector_2<br/>  subtractions = (vector_1 - vector_2).to_a<br/>  subtractions.map! {|sub| sub = sub*sub }<br/>  Math.sqrt(subtractions.sum)<br/>end</span></pre><p id="4ea8" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">就像我们在之前的博文中提到的那样，取向量中每个值的减法，平方，求和，得到平方根。<br/>因此，如果我们给定“Vector[1，2]”和“Vector[2，3]”，它将计算点“x=1，y=2”和“x=2，y=3”之间的距离:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="3886" class="mj jw in mf b gy mk ml l mm mn">Train.euclidean_distance Vector[1,2], Vector[2,3]</span></pre><p id="8105" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">输出:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="d324" class="mj jw in mf b gy mk ml l mm mn">1.4142135623730951</span></pre><p id="39ef" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">——<br/>所以为了找到给定向量的“k”个最近向量，我们可以代入距离:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="4632" class="mj jw in mf b gy mk ml l mm mn">def self.k_neighbors distances, k<br/>  indexes = []<br/>  (k).times do<br/>    min = distances.index(distances.min)<br/>    indexes &lt;&lt; min<br/>    distances[min] = distances.max + 1<br/>  end</span><span id="6123" class="mj jw in mf b gy mo ml l mm mn">  indexes<br/>end</span></pre><p id="7725" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">还有另一个负责收集距离的命令:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="b430" class="mj jw in mf b gy mk ml l mm mn">distances = []<br/>    @@vector_arr.each_with_index do |comparison_vector, vector_index|<br/>      if vector_index == index<br/>        distances &lt;&lt; 100000000<br/>      else<br/>        distances &lt;&lt; euclidean_distance(comparison_vector, vector)<br/>      end<br/>    end</span><span id="af5d" class="mj jw in mf b gy mo ml l mm mn">    indexes = k_neighbors distances, k</span></pre><p id="fdf3" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">为了避免混淆，如果矢量本身就是距离，那么就给它一个大的值。<br/>如果我们插入第一个向量，例如“k=1 ”,输出将是:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="4b65" class="mj jw in mf b gy mk ml l mm mn">[22]</span></pre><p id="7ad4" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">它给出了离第一个向量最近的向量的索引。</p><p id="de2d" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">——<br/>让我们创建一个函数来检查指标的分类，并给出分类的含义。</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="0996" class="mj jw in mf b gy mk ml l mm mn">def self.make_prediction indexes<br/>  predictions = []<br/>  indexes.each do |index|<br/>    predictions &lt;&lt; @@word_arr[index][0].to_i<br/>  end</span><span id="5c4b" class="mj jw in mf b gy mo ml l mm mn">  predictions.sum/predictions.size<br/>end</span></pre><p id="b6b0" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">这种分类的输出可以是‘1’和‘0 ’,因为在这种情况下我们检查元素是否是‘snippet’。因此它们平均值将在“0”和“1”之间，包括两端。</p><p id="0159" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">如果我们插上 22 号:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="e882" class="mj jw in mf b gy mk ml l mm mn">0</span></pre><p id="ebfb" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">它向我们展示了这个向量并不像索引“22”处的向量那样是“片段”。</p><p id="e0cb" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi">— -</p><p id="69f6" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">让我们根据这个预测的有效性来实现一些改变权重的东西:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="5def" class="mj jw in mf b gy mk ml l mm mn">def self.update_weights result, indexes, vector, lr<br/>  indexes.each do |index|<br/>    subtractions = @@vector_arr[index] — vector<br/>    subtractions.each_with_index do |sub, sub_index|<br/>      if result == 0 &amp;&amp; sub &gt;= 0<br/>        @@weights[sub_index] = @@weights[sub_index] + lr<br/>      elsif result == 0 &amp;&amp; sub &lt; 0<br/>        @@weights[sub_index] = @@weights[sub_index] — lr<br/>      elsif result == 1 &amp;&amp; sub &gt;= 0<br/>        @@weights[sub_index] = @@weights[sub_index] — lr<br/>      elsif result == 1 &amp;&amp; sub &lt; 0<br/>        @@weights[sub_index] = @@weights[sub_index] + lr<br/>      end<br/>    end<br/>  end<br/>end</span></pre><p id="fccc" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">作为预测分类和真实分类之间的关系，这里的“结果”是“0”代表假，“1”代表真。我们使用“lr”来使向量更接近，或者通过在权重上加上或减去“lr”来使向量更接近。由于加权向量将用于训练，从概率上来说，如果预测是真的，它不会犯同样的错误，如果预测是假的，它会做得更好。<br/>结果将是重量的变化:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="2840" class="mj jw in mf b gy mk ml l mm mn">Vector[0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999]</span></pre><p id="5832" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">注意，并不是所有的权重都以负序变化，以最大化或最小化两个向量之间的距离。这是一个巧合。</p><p id="6900" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">— - <br/>平均绝对误差是一种非常常见的计算损失的技术:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="a589" class="mj jw in mf b gy mk ml l mm mn">def self.mean_absolute_error real, indexes<br/>  errors = []<br/>  indexes.each do |index|<br/>    errors &lt;&lt; (@@word_arr[index][0].to_i - real).abs<br/>  end</span><span id="5518" class="mj jw in mf b gy mo ml l mm mn">  (errors.sum/errors.size).to_f<br/>end</span></pre><p id="9745" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">计算损失会告诉我们健康的训练过程。我们可能需要调整配置，使其更好。请注意，它不会给出这是否是我们必须使用的流程的指示，而只是流程的健康状况。你可以在以前的博客文章中找到详细信息。</p><p id="1087" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">— - <br/>现在让我们来看看训练一个向量的整个函数:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="29e7" class="mj jw in mf b gy mk ml l mm mn">def self.train vector, index<br/>    k, lr = config<br/>    vector = extend_vector vector<br/>    vector = product vector<br/>    <br/>    distances = []<br/>    @@vector_arr.each_with_index do |comparison_vector, vector_index|<br/>      if vector_index == index<br/>        distances &lt;&lt; 100000000<br/>      else<br/>        distances &lt;&lt; euclidean_distance(comparison_vector, vector)<br/>      end<br/>    end</span><span id="a06c" class="mj jw in mf b gy mo ml l mm mn">    indexes = k_neighbors distances, k<br/>    real = @@word_arr[index][0].to_i<br/>    prob_prediction = make_prediction indexes<br/>    prediction = prob_prediction &gt; 0.5 ? 1 : 0<br/>    result = real == prediction ? 1 : 0</span><span id="8da8" class="mj jw in mf b gy mo ml l mm mn">    update_weights result, indexes, vector, lr<br/>    loss = mean_absolute_error real, indexes<br/>    @@losses &lt;&lt; loss<br/>    <br/>    puts "Result : #{real}, Prediction: #{prediction}"<br/>    puts "Loss: #{loss}"</span><span id="5b20" class="mj jw in mf b gy mo ml l mm mn">    prediction<br/>end</span></pre><p id="ab24" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">*我们从一个向量及其索引开始。然后我们从“配置”中调用“k”和“lr”值。<br/> *之后，我们把向量做成加权向量。<br/> *然后我们计算加权向量相对于训练集中所有其他向量的距离。<br/> *找到“k”个最近邻居的索引。<br/> *得到加权向量的真实分类。<br/> *使用最近邻获得它的预测。<br/> *比较它们以创建一个结果。<br/> *根据结果更新权重。<br/> *计算损失并将其追加到所有损失中。(为了以后图形化)<br/> *输出结果，返回预测。</p><p id="824a" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">如果我们迭代地执行这些步骤，我们将以一种适用于一般情况的方式训练权重。分类为‘1’向量将更接近分类为‘1’的向量，因此给我们一个好的预测。</p><h1 id="61d7" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">完整代码</h1><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="c1f6" class="mj jw in mf b gy mk ml l mm mn">class Database<br/>  def initialize json_data, vocab = { "&lt;unk&gt;" =&gt; 0, "&lt;pad&gt;" =&gt; 1 }<br/>    super()<br/>    @@pattern_data = []<br/>    @@vocab = vocab<br/>  end</span><span id="175b" class="mj jw in mf b gy mo ml l mm mn">  ## Related to creating main database<br/>  def self.add_new_data_to_database json_data, csv_path = nil<br/>    json_data.each do |result|<br/>      recursive_hash_pattern result, ""<br/>    end</span><span id="b4f6" class="mj jw in mf b gy mo ml l mm mn">    @@pattern_data = @@pattern_data.reject { |pattern| pattern.include? nil }.uniq.compact</span><span id="5a9d" class="mj jw in mf b gy mo ml l mm mn">    path = "#{csv_path}master_database.csv"<br/>    File.write(path, @@pattern_data.map(&amp;:to_csv).join)<br/>  end</span><span id="0734" class="mj jw in mf b gy mo ml l mm mn">  def self.element_pattern result, pattern<br/>    @@pattern_data.append([result, pattern].flatten)<br/>  end</span><span id="a5df" class="mj jw in mf b gy mo ml l mm mn">  def self.element_array_pattern result, pattern<br/>    result.each do |element|<br/>      element_pattern element, pattern<br/>    end<br/>  end</span><span id="d2db" class="mj jw in mf b gy mo ml l mm mn">  def self.assign hash, key, pattern<br/>    if hash[key].is_a?(Hash)<br/>      if pattern.present?<br/>        pattern = "#{pattern}__#{key}"<br/>      else<br/>        pattern = "#{key}"<br/>      end</span><span id="907b" class="mj jw in mf b gy mo ml l mm mn">      recursive_hash_pattern hash[key], pattern<br/>    elsif hash[key].present? &amp;&amp; hash[key].is_a?(Array) &amp;&amp; hash[key].first.is_a?(Hash)<br/>      if pattern.present?<br/>        pattern = "#{pattern}__#{key}__n"<br/>      else<br/>        pattern = "#{key}"<br/>      end</span><span id="5c4e" class="mj jw in mf b gy mo ml l mm mn">      hash[key].each do |hash_inside_array|<br/>        recursive_hash_pattern hash_inside_array, pattern<br/>      end<br/>    elsif hash[key].present? &amp;&amp; hash[key].is_a?(Array)<br/>      if pattern.present?<br/>        pattern = "#{pattern}__n"<br/>      else<br/>        pattern = "#{key}"<br/>      end</span><span id="1d67" class="mj jw in mf b gy mo ml l mm mn">      element_array_pattern hash[key], pattern<br/>    else<br/>      if pattern.present?<br/>        pattern = "#{pattern}__#{key}"<br/>      else<br/>        pattern = "#{key}"<br/>      end</span><span id="5fc4" class="mj jw in mf b gy mo ml l mm mn">      element_pattern hash[key], pattern<br/>    end<br/>  end<br/> <br/>  def self.recursive_hash_pattern hash, pattern<br/>    hash.keys.each do |key|<br/>      assign hash, key, pattern<br/>    end<br/>  end</span><span id="5823" class="mj jw in mf b gy mo ml l mm mn">  ## Related to tokenizing<br/>  def self.default_dictionary_hash<br/>    {<br/>      /\"/ =&gt; "",<br/>      /\'/ =&gt; " \'  ",<br/>      /\./ =&gt; " . ",<br/>      /,/ =&gt; ", ",<br/>      /\!/ =&gt; " ! ",<br/>      /\?/ =&gt; " ? ",<br/>      /\;/ =&gt; " ",<br/>      /\:/ =&gt; " ",<br/>      /\(/ =&gt; " ( ",<br/>      /\)/ =&gt; " ) ",<br/>      /\// =&gt; " / ",<br/>      /\s+/ =&gt; " ",<br/>      /&lt;br \/&gt;/ =&gt; " , ",<br/>      /http/ =&gt; "http",<br/>      /https/ =&gt; " https ",<br/>    }<br/>  end</span><span id="36cc" class="mj jw in mf b gy mo ml l mm mn">  def self.tokenizer word, dictionary_hash = default_dictionary_hash<br/>    word = word.downcase</span><span id="a069" class="mj jw in mf b gy mo ml l mm mn">    dictionary_hash.keys.each do |key|<br/>      word.sub!(key, dictionary_hash[key])<br/>    end</span><span id="c0cb" class="mj jw in mf b gy mo ml l mm mn">    word.split<br/>  end</span><span id="a7e8" class="mj jw in mf b gy mo ml l mm mn">  def self.iterate_ngrams token_list, ngrams = 1<br/>    token_list.each do |token|<br/>      1.upto(ngrams) do |n|<br/>        permutations = (token_list.size - n + 1).times.map { |i| token_list[i...(i + n)] }<br/>        <br/>        permutations.each do |perm|<br/>          key = perm.join(" ")</span><span id="ad09" class="mj jw in mf b gy mo ml l mm mn">          unless @@vocab.keys.include? key<br/>            @@vocab[key] = @@vocab.size<br/>          end<br/>        end<br/>      end<br/>    end<br/>  end</span><span id="8206" class="mj jw in mf b gy mo ml l mm mn">  def self.word_to_tensor word<br/>    token_list = tokenizer word<br/>    token_list.map {|token| @@vocab[token]}<br/>  end</span><span id="47ba" class="mj jw in mf b gy mo ml l mm mn">  ## Related to creating key-specific databases <br/>  def self.create_key_specific_databases result_type = "organic_results", csv_path = nil, dictionary = nil, ngrams = nil, vocab_path = nil<br/>    keys, examples = create_keys_and_examples</span><span id="d312" class="mj jw in mf b gy mo ml l mm mn">    keys.each do |key|<br/>      specific_pattern_data = []<br/>      @@pattern_data.each_with_index do |pattern, index|<br/>        word = pattern.first.to_s<br/>        <br/>        next if word.blank?</span><span id="3134" class="mj jw in mf b gy mo ml l mm mn">        if dictionary.present?<br/>          token_list = tokenizer word, dictionary<br/>        else<br/>          token_list = tokenizer word<br/>        end</span><span id="0a7c" class="mj jw in mf b gy mo ml l mm mn">        if ngrams.present?<br/>          iterate_ngrams token_list, ngrams<br/>        else<br/>          iterate_ngrams token_list<br/>        end</span><span id="a20d" class="mj jw in mf b gy mo ml l mm mn">        if key == pattern.second<br/>          specific_pattern_data &lt;&lt; [ 1, word ]<br/>        elsif (examples[key].to_s.to_i == examples[key]) &amp;&amp; word.to_i == word<br/>          next<br/>        elsif (examples[key].to_s.to_i == examples[key]) &amp;&amp; word.numeric?<br/>          specific_pattern_data &lt;&lt; [ 0, word ]<br/>        elsif examples[key].numeric? &amp;&amp; word.numeric?<br/>          next<br/>        elsif key.split("__").last == pattern.second.to_s.split("__").last<br/>          specific_pattern_data &lt;&lt; [ 1, word ]<br/>        else<br/>          specific_pattern_data &lt;&lt; [ 0, word ]<br/>        end<br/>      end</span><span id="ef27" class="mj jw in mf b gy mo ml l mm mn">      path = "#{csv_path}#{result_type}__#{key}.csv"<br/>      File.write(path, specific_pattern_data.map(&amp;:to_csv).join)<br/>    end</span><span id="6cc3" class="mj jw in mf b gy mo ml l mm mn">    if vocab_path.present?<br/>      save_vocab vocab_path<br/>    else<br/>      save_vocab<br/>    end<br/>  end</span><span id="5d10" class="mj jw in mf b gy mo ml l mm mn">  def self.create_keys_and_examples<br/>    keys = @@pattern_data.map { |pattern| pattern.second }.uniq</span><span id="46c4" class="mj jw in mf b gy mo ml l mm mn">    examples = {}<br/>    keys.each do |key|<br/>      examples[key] = @@pattern_data.find { |pattern| pattern.first.to_s if pattern.second == key }<br/>    end</span><span id="ce3b" class="mj jw in mf b gy mo ml l mm mn">    [keys, examples]<br/>  end</span><span id="940b" class="mj jw in mf b gy mo ml l mm mn">  def self.numeric?<br/>    return true if self =~ /\A\d+\Z/<br/>    true if Float(self) rescue false<br/>  end</span><span id="a8d6" class="mj jw in mf b gy mo ml l mm mn">  def self.save_vocab vocab_path = ""<br/>    path = "#{vocab_path}vocab.json"<br/>    vocab = JSON.parse(@@vocab.to_json)<br/>    File.write(path, JSON.pretty_generate(vocab))<br/>  end</span><span id="c1e8" class="mj jw in mf b gy mo ml l mm mn">  def self.read_vocab vocab_path<br/>    vocab = File.read vocab_path<br/>    @@vocab = JSON.parse(vocab)<br/>  end</span><span id="8ee6" class="mj jw in mf b gy mo ml l mm mn">  def self.return_vocab<br/>    @@vocab<br/>  end<br/>end</span><span id="0ea9" class="mj jw in mf b gy mo ml l mm mn">class Train<br/>  def initialize csv_path<br/>    @@csv_path = csv_path<br/>    @@vector_arr = []<br/>    @@word_arr = []<br/>    @@maximum_word_size = 100<br/>    @@weights = Vector[]<br/>    @@losses = []<br/>  end</span><span id="ccab" class="mj jw in mf b gy mo ml l mm mn">  def self.read<br/>    @@word_arr = CSV.read(@@csv_path)<br/>    @@word_arr<br/>  end</span><span id="3ac5" class="mj jw in mf b gy mo ml l mm mn">  def self.define_training_set vectors<br/>    @@vector_arr = vectors<br/>  end</span><span id="0e6c" class="mj jw in mf b gy mo ml l mm mn">  def self.auto_define_maximum_size<br/>    @@maximum_word_size = @@vector_arr.map {|el| el.size}.max<br/>  end</span><span id="5e00" class="mj jw in mf b gy mo ml l mm mn">  def self.extend_vector vector<br/>    vector_arr = vector.to_a<br/>    (@@maximum_word_size - vector.size).times { vector_arr &lt;&lt; 1 }<br/>    Vector.[](*vector_arr)<br/>  end</span><span id="b604" class="mj jw in mf b gy mo ml l mm mn">  def self.extend_vectors<br/>    @@vector_arr.each_with_index do |vector, index|<br/>      @@vector_arr[index] = extend_vector vector<br/>    end<br/>  end</span><span id="167c" class="mj jw in mf b gy mo ml l mm mn">  def self.initialize_weights<br/>    weights = []<br/>    @@maximum_word_size.times { weights &lt;&lt; 1.0 }<br/>    @@weights = Vector.[](*weights)<br/>  end</span><span id="1fd0" class="mj jw in mf b gy mo ml l mm mn">  def self.config k = 1, lr = 0.001<br/>    [k, lr]<br/>  end</span><span id="2b1a" class="mj jw in mf b gy mo ml l mm mn">  def self.product vector<br/>    @@weights.each_with_index do |weight, index|<br/>      vector[index] = weight * vector[index]<br/>    end</span><span id="6a72" class="mj jw in mf b gy mo ml l mm mn">    vector<br/>  end</span><span id="b4b9" class="mj jw in mf b gy mo ml l mm mn">  def self.euclidean_distance vector_1, vector_2<br/>    subtractions = (vector_1 - vector_2).to_a<br/>    subtractions.map! {|sub| sub = sub*sub }<br/>    Math.sqrt(subtractions.sum)<br/>  end</span><span id="322a" class="mj jw in mf b gy mo ml l mm mn">  def self.k_neighbors distances, k<br/>    indexes = []<br/>    (k).times do<br/>      min = distances.index(distances.min)<br/>      indexes &lt;&lt; min<br/>      distances[min] = distances.max + 1<br/>    end</span><span id="e352" class="mj jw in mf b gy mo ml l mm mn">    indexes<br/>  end</span><span id="7d68" class="mj jw in mf b gy mo ml l mm mn">  def self.make_prediction indexes<br/>    predictions = []<br/>    indexes.each do |index|<br/>      predictions &lt;&lt; @@word_arr[index][0].to_i<br/>    end</span><span id="d119" class="mj jw in mf b gy mo ml l mm mn">    predictions.sum/predictions.size<br/>  end</span><span id="7258" class="mj jw in mf b gy mo ml l mm mn">  def self.update_weights result, indexes, vector, lr<br/>    indexes.each do |index|<br/>      subtractions = @@vector_arr[index] - vector<br/>      subtractions.each_with_index do |sub, sub_index|<br/>        if result == 0 &amp;&amp; sub &gt;= 0<br/>          @@weights[sub_index] = @@weights[sub_index] + lr<br/>        elsif result == 0 &amp;&amp; sub &lt; 0<br/>          @@weights[sub_index] = @@weights[sub_index] - lr<br/>        elsif result == 1 &amp;&amp; sub &gt;= 0<br/>          @@weights[sub_index] = @@weights[sub_index] - lr<br/>        elsif result == 1 &amp;&amp; sub &lt; 0<br/>          @@weights[sub_index] = @@weights[sub_index] + lr<br/>        end<br/>      end<br/>    end<br/>  end</span><span id="db62" class="mj jw in mf b gy mo ml l mm mn">  def self.mean_absolute_error real, indexes<br/>    errors = []<br/>    indexes.each do |index|<br/>      errors &lt;&lt; (@@word_arr[index][0].to_i - real).abs<br/>    end</span><span id="e595" class="mj jw in mf b gy mo ml l mm mn">    (errors.sum/errors.size).to_f<br/>  end</span><span id="5e02" class="mj jw in mf b gy mo ml l mm mn">  def self.train vector, index<br/>    k, lr = config<br/>    vector = extend_vector vector<br/>    vector = product vector<br/>    <br/>    distances = []<br/>    @@vector_arr.each_with_index do |comparison_vector, vector_index|<br/>      if vector_index == index<br/>        distances &lt;&lt; 100000000<br/>      else<br/>        distances &lt;&lt; euclidean_distance(comparison_vector, vector)<br/>      end<br/>    end</span><span id="72ff" class="mj jw in mf b gy mo ml l mm mn">    indexes = k_neighbors distances, k<br/>    real = @@word_arr[index][0].to_i<br/>    prob_prediction = make_prediction indexes<br/>    prediction = prob_prediction &gt; 0.5 ? 1 : 0<br/>    result = real == prediction ? 1 : 0</span><span id="0db3" class="mj jw in mf b gy mo ml l mm mn">    update_weights result, indexes, vector, lr<br/>    loss = mean_absolute_error real, indexes<br/>    @@losses &lt;&lt; loss<br/>    <br/>    puts "Result : #{real}, Prediction: #{prediction}"<br/>    puts "Loss: #{loss}"</span><span id="a885" class="mj jw in mf b gy mo ml l mm mn">    prediction<br/>  end<br/>end<br/></span><span id="2e09" class="mj jw in mf b gy mo ml l mm mn">json_path = "organic_results/example.json"<br/>json_data = File.read(json_path)<br/>json_data = JSON.parse(json_data)</span><span id="376c" class="mj jw in mf b gy mo ml l mm mn">Database.new json_data<br/>## For training from scratch                     <br/>#Database.add_new_data_to_database json_data, csv_path = "organic_results/"<br/>#Database.create_key_specific_databases result_type = "organic_results", csv_path = "organic_results/", ngrams = 2<br/>##<br/>Database.read_vocab "vocab.json"</span><span id="df82" class="mj jw in mf b gy mo ml l mm mn">## We will use an iteration of csvs within a specific path in the end<br/>csv_path = "organic_results/organic_results__snippet.csv"</span><span id="9773" class="mj jw in mf b gy mo ml l mm mn">Train.new csv_path<br/>key_array = Train.read</span><span id="a765" class="mj jw in mf b gy mo ml l mm mn">vector_array = key_array.map { |word| Database.word_to_tensor word[1] }<br/>Train.define_training_set vector_array<br/>Train.auto_define_maximum_size<br/>Train.extend_vectors<br/>Train.initialize_weights<br/>Train.config k = 3</span><span id="a97f" class="mj jw in mf b gy mo ml l mm mn">vector_array.each_with_index do |vector, index|<br/>  Train.train vector, index<br/>end</span></pre><h1 id="d5d5" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">结论</h1><p id="7a86" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">从现在开始，这个博客系列将是“双周”的。两周后，我们将训练初始模型，并展示如何存储它们以供实现。</p><p id="f8af" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">这个项目的最终目标是创建一个“开源 gem ”,每个人都可以在代码中使用 JSON 数据结构来实现它。</p><p id="99af" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">我要感谢读者的关注，感谢才华横溢的塞尔帕皮人在艰难时刻创造奇迹，感谢他们的支持。</p><p id="b060" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated"><a class="ae mc" href="https://serpapi.com/blog/author/emirhan/" rel="noopener ugc nofollow" target="_blank">如果你觉得这篇博文有用，可以看看我的其他博文</a>。</p><p id="65e9" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">加入我们的|<a class="ae mc" href="https://twitter.com/serp_api" rel="noopener ugc nofollow" target="_blank">Twitter</a>|<a class="ae mc" href="https://www.youtube.com/channel/UCUgIHlYBOD3yA3yDIRhg_mg" rel="noopener ugc nofollow" target="_blank">YouTube</a>|<a class="ae mc" href="https://dev.to/serpapi/" rel="noopener ugc nofollow" target="_blank">dev . to</a>|<a class="ae mc" href="https://serpapi.hashnode.dev/" rel="noopener ugc nofollow" target="_blank">hash node</a>|<a class="ae mc" href="https://medium.com/serpapi" rel="noopener">ser papi Medium</a></p></div></div>    
</body>
</html>