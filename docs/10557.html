<html>
<head>
<title>Real-time data pipeline using Kafka and ClickHouse</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Kafka 和 ClickHouse 的实时数据管道</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/real-time-data-pipeline-using-kafka-and-clickhouse-c83134e6f5d9?source=collection_archive---------0-----------------------#2022-11-11">https://blog.devgenius.io/real-time-data-pipeline-using-kafka-and-clickhouse-c83134e6f5d9?source=collection_archive---------0-----------------------#2022-11-11</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><figure class="gl gn jl jm jn jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi jk"><img src="../Images/b859c6e9bb0fc80370cbe13de3f56423.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QNPSBjP5jXaOL2hC"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk translated">卢克·切瑟在<a class="ae jz" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="4932" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">在本文中，我们将构建一个数据管道，通过 Kafka 将数据接收到 ClickHouse 中，然后根据新数据自动进行聚合。我们将使用<a class="ae jz" href="https://www.kaggle.com/datasets/jboysen/global-food-prices" rel="noopener ugc nofollow" target="_blank">全球食品价格数据集</a>作为一个例子，但是，当然，这个例子对于 Kafka 来说不是很有代表性，因为它错过了<a class="ae jz" href="https://www.oracle.com/big-data/what-is-big-data/#three" rel="noopener ugc nofollow" target="_blank">速度标准</a>。</p><p id="d72a" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">让我们定义我们的计划——首先，我们将创建一个生成消息的 Python 脚本(消息是我们数据集的行)。接下来，我们将设置 ClickHouse 来接收和处理这些消息。最后，我们将修补实时视图和数据删除。</p><h2 id="e990" class="ky kz in bd la lb lc dn ld le lf dp lg kl lh li lj kp lk ll lm kt ln lo lp lq bi translated">0.要求</h2><ul class=""><li id="497f" class="lr ls in kc b kd lt kh lu kl lv kp lw kt lx kx ly lz ma mb bi translated">拥有一个卡夫卡集群。我个人使用这个<a class="ae jz" href="https://github.com/conduktor/kafka-stack-docker-compose" rel="noopener ugc nofollow" target="_blank"> GitHub 库</a>中的<code class="fe mc md me mf b">zk-single-kafka-single.yml</code> docker-compose 文件。一旦通过<code class="fe mc md me mf b">docker-compose -f &lt;file&gt; up</code>启动，就没什么可做的了。</li><li id="69cd" class="lr ls in kc b kd mg kh mh kl mi kp mj kt mk kx ly lz ma mb bi translated">安装 Python 3.x</li><li id="8189" class="lr ls in kc b kd mg kh mh kl mi kp mj kt mk kx ly lz ma mb bi translated">拥有一个 ClickHouse 服务器(只需使用官方的二进制文件)。</li></ul><h2 id="3fb6" class="ky kz in bd la lb lc dn ld le lf dp lg kl lh li lj kp lk ll lm kt ln lo lp lq bi translated">1.消息生产者</h2><p id="05bd" class="pw-post-body-paragraph ka kb in kc b kd lt kf kg kh lu kj kk kl ml kn ko kp mm kr ks kt mn kv kw kx ig bi translated">在我们的例子中，消息生产者非常简单。在生产环境中，我们可以想象获取多个源并发送给 Kafka，但是，在我们的例子中，我们只需读取一个 CSV 文件，将行转换成 JSON 并发送它们。ClickHouse 对格式解析非常严格，这就是为什么我们将使用 JSON 而不是 CSV(例如，双逗号可以阻止您的数据被使用)。</p><p id="3e9f" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">这是我们的 Python 制作人:</p><pre class="mo mp mq mr gt ms mf mt bn mu mv bi"><span id="04a4" class="mw kz in mf b be mx my l mz na">import csv<br/>import json<br/><br/>import kafka<br/><br/>producer = kafka.KafkaProducer()<br/><br/>with open('global_food_prices.csv', 'r', encoding='iso-8859-1') as f:<br/>  r = csv.DictReader(f)<br/><br/>  for row in r:<br/>    producer.send('food', json.dumps(row).encode('utf-8', 'replace'))<br/>    <br/>producer.close()</span></pre><p id="22d1" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">因此，我们正在读取<code class="fe mc md me mf b">global_food_prices.csv</code>，将缓冲区传递给一个<code class="fe mc md me mf b">csv.DictReader</code>，最后通过 JSON 发送每一行。请记住，这个例子过于简化了，我们可以通过 Python 驱动程序将数据插入 ClickHouse，但是 Kafka 有更多的优势。<br/> <em class="nb">(我在编码方面有问题，iso-8859–1 很好用)</em></p><h2 id="95af" class="ky kz in bd la lb lc dn ld le lf dp lg kl lh li lj kp lk ll lm kt ln lo lp lq bi translated">2.使用来自 ClickHouse 的消息</h2><p id="676e" class="pw-post-body-paragraph ka kb in kc b kd lt kf kg kh lu kj kk kl ml kn ko kp mm kr ks kt mn kv kw kx ig bi translated">启动 ClickHouse 和 Kafka 服务器后，进入 ClickHouse 控制台(通过 CLI 或使用 GUI，我喜欢使用 DataGrip)。</p><p id="19ff" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">我们将设置总共 3 张桌子:</p><ol class=""><li id="cbea" class="lr ls in kc b kd ke kh ki kl nc kp nd kt ne kx nf lz ma mb bi translated">一个<code class="fe mc md me mf b">queue</code>，这个表有我们所有的 CSV 列，并使用 Kafka 引擎从<code class="fe mc md me mf b">food</code>，我们上面定义的主题接收数据。</li><li id="5b33" class="lr ls in kc b kd mg kh mh kl mi kp mj kt mk kx nf lz ma mb bi translated">一个结果表，只包含我们想要保留的列，具有更好的名称和类型(如果您的数据具有不一致的数据类型，如 CSV，这不再是一个问题)。</li><li id="ded6" class="lr ls in kc b kd mg kh mh kl mi kp mj kt mk kx nf lz ma mb bi translated">一个物化视图将数据从队列转移到结果表，这个物化视图是 SQL 中的一个<code class="fe mc md me mf b">SELECT</code>语句，我们将把我们的类型转换放在那里。</li></ol><p id="16c1" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">让我们从第一张表开始:</p><pre class="mo mp mq mr gt ms mf mt bn mu mv bi"><span id="eedd" class="mw kz in mf b be mx my l mz na">CREATE TABLE queue (<br/>  adm0_id String,<br/>  adm0_name String,<br/>  adm1_id String,<br/>  adm1_name String,<br/>  mkt_id String,<br/>  mkt_name String,<br/>  cm_id String,<br/>  cm_name String,<br/>  cur_id String,<br/>  cur_name String,<br/>  pt_id String,<br/>  pt_name String,<br/>  um_id String,<br/>  um_name String,<br/>  mp_month String,<br/>  mp_year String,<br/>  mp_price String,<br/>  mp_commoditysource String<br/>) ENGINE = Kafka()<br/>SETTINGS<br/>    kafka_broker_list = 'localhost:9092',<br/>    kafka_topic_list = 'food',<br/>    kafka_group_name = 'clickhouse_reader',<br/>    kafka_format = 'JSONStringsEachRow';</span></pre><p id="2130" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">因为 CSV 没有类型，我们将在<code class="fe mc md me mf b">String</code>中设置所有的列，稍后我们将转换类型。<br/>这是结果表:</p><pre class="mo mp mq mr gt ms mf mt bn mu mv bi"><span id="11af" class="mw kz in mf b be mx my l mz na">CREATE TABLE food_data (<br/>  Country String, -- from: adm0_name<br/>  Market String, -- from: pt_name<br/>  Product String, -- from: cm_name<br/>  QuantityUnit String, -- from: um_name<br/>  Price Float32, -- from: mp_price<br/>  Date Date, -- computed from: mp_month, mp_year<br/>  CurrencyCode String -- from: cur_name<br/>) ENGINE = MergeTree()<br/>ORDER BY (Country, Product);</span></pre><p id="82c8" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">最后，我们可以创建处理表:</p><pre class="mo mp mq mr gt ms mf mt bn mu mv bi"><span id="2296" class="mw kz in mf b be mx my l mz na">CREATE MATERIALIZED VIEW food_processing TO food_data AS<br/>    SELECT<br/>        adm0_name as Country,<br/>        pt_name as Market,<br/>        cm_name as Product,<br/>        um_name as QuantityUnit,<br/>        toFloat32OrZero(mp_price) as Price,<br/>        toDate(format('{0}-{1}-01', mp_year, mp_month)) as Date,<br/>        cur_name as CurrencyCode<br/>    FROM queue</span></pre><p id="1164" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">一旦创建了物化视图，它将立即开始处理数据。如果您还没有执行 Python producer，现在可以执行了。</p><figure class="mo mp mq mr gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi ng"><img src="../Images/449acb6992a0d154c82f4854aa412dab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e_o7G-01Jpyws9Pr7M-IXg.png"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk translated">现在已经填充了 food_data 表！</figcaption></figure><h2 id="5bdf" class="ky kz in bd la lb lc dn ld le lf dp lg kl lh li lj kp lk ll lm kt ln lo lp lq bi translated">3.如果数据需要更新或删除怎么办？</h2><p id="7776" class="pw-post-body-paragraph ka kb in kc b kd lt kf kg kh lu kj kk kl ml kn ko kp mm kr ks kt mn kv kw kx ig bi translated">有时，数据可能不正确，需要更正，不幸的是，这对于 OLAP 数据库来说不太实用，因为它们针对读写进行了优化，但不适合覆盖和删除。</p><pre class="mo mp mq mr gt ms mf mt bn mu mv bi"><span id="605b" class="mw kz in mf b be mx my l mz na">SELECT Product,<br/>       avg(Price) as AveragePrice,<br/>       toYear(Date) as Year<br/>FROM food_data<br/>WHERE Country = 'Afghanistan'<br/>GROUP BY Product, Year<br/>ORDER BY Product, Year</span></pre><p id="8c93" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">该查询将计算阿富汗每年每种产品的平均价格。现在让我们考虑几个用例及问题。</p><h2 id="eeb8" class="ky kz in bd la lb lc dn ld le lf dp lg kl lh li lj kp lk ll lm kt ln lo lp lq bi translated">3.1.数据集很小</h2><p id="ff02" class="pw-post-body-paragraph ka kb in kc b kd lt kf kg kh lu kj kk kl ml kn ko kp mm kr ks kt mn kv kw kx ig bi translated">如果<code class="fe mc md me mf b">food_data</code>很小，那么你想直接查询或者使用一个<code class="fe mc md me mf b">VIEW</code>。<br/>如果我们从源表中删除行，使用<code class="fe mc md me mf b">VIEW</code>将只是重新执行查询，我们不会受到影响。</p><h2 id="4694" class="ky kz in bd la lb lc dn ld le lf dp lg kl lh li lj kp lk ll lm kt ln lo lp lq bi translated">3.2.数据集很大，但不可变</h2><p id="a625" class="pw-post-body-paragraph ka kb in kc b kd lt kf kg kh lu kj kk kl ml kn ko kp mm kr ks kt mn kv kw kx ig bi translated">如果您从不删除行，但是查询太慢，无法在最终用户端执行，您可以使用<code class="fe mc md me mf b">SummingMergeTree</code>，如下所示:</p><pre class="mo mp mq mr gt ms mf mt bn mu mv bi"><span id="d251" class="mw kz in mf b be mx my l mz na">CREATE TABLE afghanistan_products (<br/>  Product String,<br/>  AveragePrice Float32,<br/>  Year UInt16<br/>) ENGINE = SummingMergeTree([Product, Year]) <br/>-- Every row is unique on Product and Year.</span></pre><pre class="nh ms mf mt bn mu mv bi"><span id="caa6" class="mw kz in mf b be mx my l mz na">CREATE MATERIALIZED VIEW afghanistan_processing TO afghanistan_products AS<br/>  SELECT Product,<br/>         avg(Price) as AveragePrice,<br/>         toYear(Date) as Year<br/>  FROM food_data<br/>  WHERE Country = 'Afghanistan'<br/>  GROUP BY Product, Year<br/>  ORDER BY Product, Year</span></pre><p id="6058" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">当数据添加到<code class="fe mc md me mf b">food_data</code>时，<code class="fe mc md me mf b">afghanistan_processing</code>将被触发并执行查询。它不是仅仅将数据添加到<code class="fe mc md me mf b">afghanistan_products</code>中，而是比较产品和年份列来替换现有的内容。</p><p id="19c9" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">当您的数据可更新或可删除时，不应使用此解决方案，因为<code class="fe mc md me mf b">ALTER TABLE &lt;table&gt; [UPDATE/DELETE]</code>不会触发实体化视图的更新。</p><h2 id="39ff" class="ky kz in bd la lb lc dn ld le lf dp lg kl lh li lj kp lk ll lm kt ln lo lp lq bi translated">3.3.数据集很大并且是可变的</h2><p id="64eb" class="pw-post-body-paragraph ka kb in kc b kd lt kf kg kh lu kj kk kl ml kn ko kp mm kr ks kt mn kv kw kx ig bi translated">我们之前了解到物化视图不会随着变化而更新，不幸的是，似乎 ClickHouse 没有办法监听变化。我们将使用一种受批量数据处理启发的方法:cron jobs，这有点超出了本文的范围。</p><p id="e848" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">在批处理中，大多数情况下，数据每 N 个小时在一个 cron 之后聚集一次。<strong class="kc io"> ClickHouse 也有类似的东西:</strong> <a class="ae jz" href="https://clickhouse.com/docs/en/sql-reference/statements/create/view/#live-view-experimental" rel="noopener ugc nofollow" target="_blank"> <strong class="kc io">直播查看</strong> </a> <strong class="kc io">。</strong></p><pre class="mo mp mq mr gt ms mf mt bn mu mv bi"><span id="45fb" class="mw kz in mf b be mx my l mz na">CREATE LIVE VIEW afghanistan_products WITH REFRESH 120 AS (<br/>    SELECT<br/>        Product,<br/>        avg(Price) as AveragePrice,<br/>        toYear(Date) as Year<br/>    FROM food_data<br/>    WHERE Country = 'Afghanistan'<br/>    GROUP BY Product, Year<br/>    ORDER BY Product, Year<br/>)<br/>SETTINGS allow_experimental_live_view = 1</span></pre><p id="83b3" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">该查询将每 120 秒更新一次，<strong class="kc io">数据被写入内存</strong>，使得最终用户查询更快。请注意，这是 ClickHouse 的一个实验性功能，随时可能被删除。</p><figure class="mo mp mq mr gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi ni"><img src="../Images/ed57906b59713a6d1a17f033ce2030e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bp76x94km1JNbHoaEec_Iw.png"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk translated">结果表</figcaption></figure><p id="2a3c" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">数据写在内存中，考虑到这一点，如果查询结果很大，这仍然不是一个好主意。</p></div><div class="ab cl nj nk hr nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="ig ih ii ij ik"><p id="8a60" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">在 OLAP 场景中拥有可变数据可能是一种反模式，但有时，根据数据集，这是不可避免的，例如，计费数据可能经常受到价格修正的影响。然而，我希望您喜欢这三种方法的快速概述。在进入实时视图之前，我建议你检查一下你的数据集是否可以使用<a class="ae jz" href="https://clickhouse.com/docs/en/engines/table-engines/mergetree-family/collapsingmergetree" rel="noopener ugc nofollow" target="_blank"> CollapsingMergeTree </a>或<a class="ae jz" href="https://clickhouse.com/docs/en/engines/table-engines/mergetree-family/replacingmergetree" rel="noopener ugc nofollow" target="_blank"> ReplacingMergeTree </a>。</p><p id="5aa7" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">最后，我希望您喜欢这篇文章，我想我已经讨论了开始实时处理时的大部分问题，但是还有更多需要了解的内容(Kafka 安全和认证、优化 ClickHouse 模型等。)</p><p id="d4c4" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">感谢您的阅读:)</p></div></div>    
</body>
</html>