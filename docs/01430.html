<html>
<head>
<title>Creating a production-ready web crawler in Go</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 Go 中创建生产就绪的网络爬虫</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/creating-an-efficient-web-crawler-in-go-e4eec36bbf8c?source=collection_archive---------2-----------------------#2020-07-03">https://blog.devgenius.io/creating-an-efficient-web-crawler-in-go-e4eec36bbf8c?source=collection_archive---------2-----------------------#2020-07-03</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><h2 id="cd14" class="il im in bd b dl io ip iq ir is it dk iu translated" aria-label="kicker paragraph">去编程</h2><div class=""/><div class=""><h2 id="a54a" class="pw-subtitle-paragraph jt iw in bd b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk dk translated">使用 GoRoutines、通道和更多构造</h2></div><p id="fa42" class="pw-post-body-paragraph kl km in kn b ko kp jx kq kr ks ka kt ku kv kw kx ky kz la lb lc ld le lf lg ig bi translated">对于大多数程序员来说，网络爬虫是一个基本的工具。它允许你抓取和处理任何网站的内容。在我编程的最初几天，通过抓取一个网站，我可以从中获得关键的见解，而不需要太多的人工努力。从亚马逊搜索页面，我可以很容易地解析价格，平均。查看所有产品的评级和品牌，并以表格形式呈现。你问“为什么”吗？让我解释一下..对大多数程序员来说，最基本的要求是自动化日常流程。在我通常浏览多个网站来收集数据并做出决定的情况下，网络爬虫会自动完成部分工作。将它与其他数据分析工具相结合，它可以释放更多的功能。你也可以浏览“中等”网站，找出流行趋势或热门话题。你可以抓取多个新闻网站并整理结果，建立文字云等。这完全给了你一种错误的权力感！价格跟踪网站是使用网络爬虫建立的，在那里他们抓取各种网站产品页面并存储每天的产品价格，等等。应用是无限的。</p><figure class="li lj lk ll gt lm gh gi paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="gh gi lh"><img src="../Images/9c445d570b90930e1cae40c85c586ece.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*NQbPvPHW-glSyNat"/></div></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk translated">格伦·卡斯滕斯-彼得斯在<a class="ae lx" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h1 id="c6ef" class="ly lz in bd ma mb mc md me mf mg mh mi kc mj kd mk kf ml kg mm ki mn kj mo mp bi translated">爬行不同于刮擦！</h1><p id="a18d" class="pw-post-body-paragraph kl km in kn b ko mq jx kq kr mr ka kt ku ms kw kx ky mt la lb lc mu le lf lg ig bi translated">在了解如何创建一个网络爬虫之前，请检查一下爬虫和抓取器之间的区别。<strong class="kn ix">网络爬行</strong>是搜索引擎做的事情:浏览网页，寻找任何信息，点击每一个可用的链接。Web scraper 的主要目的是从网页中提取数据。现在你知道了区别，让我们看看如何建立一个有效的网络爬虫。</p></div><div class="ab cl mv mw hr mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="ig ih ii ij ik"><h1 id="4ed9" class="ly lz in bd ma mb nc md me mf nd mh mi kc ne kd mk kf nf kg mm ki ng kj mo mp bi translated">网络爬虫设计</h1><p id="bca8" class="pw-post-body-paragraph kl km in kn b ko mq jx kq kr mr ka kt ku ms kw kx ky mt la lb lc mu le lf lg ig bi translated">要构建一个用于生产的网络爬虫，你需要在设计上花时间。确保适应实现中的变化，使其可扩展，以便能够轻松添加新功能。这是我的系统的设计，但不要局限于此，根据你的需求和功能来设计。</p><p id="4321" class="pw-post-body-paragraph kl km in kn b ko kp jx kq kr ks ka kt ku kv kw kx ky kz la lb lc ld le lf lg ig bi translated">通过创建具有独立功能的方法来模块化代码总是更好。在这个例子中，我将创建多个方法，其中一个方法包含连接到网站的逻辑，并返回指针以提取内容。从网站提取链接的另一种方法和连接所有这些独立方法的另一种方法，本质上包含了程序的业务逻辑。</p><figure class="li lj lk ll gt lm gh gi paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="gh gi nh"><img src="../Images/9a50e7c88106e9dd3258d0192553dc4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TSXpiMtles7Sjbq5XmwApQ.png"/></div></div></figure><p id="2b93" class="pw-post-body-paragraph kl km in kn b ko kp jx kq kr ks ka kt ku kv kw kx ky kz la lb lc ld le lf lg ig bi translated">创建的组件是-</p><ol class=""><li id="0a16" class="ni nj in kn b ko kp kr ks ku nk ky nl lc nm lg nn no np nq bi translated">CrawlerMain:触发程序的主要方法。</li><li id="75a0" class="ni nj in kn b ko nr kr ns ku nt ky nu lc nv lg nn no np nq bi translated">CrawlerBO(业务对象) :包含网络爬虫的业务逻辑。协调其他组件之间的调用。</li><li id="6405" class="ni nj in kn b ko nr kr ns ku nt ky nu lc nv lg nn no np nq bi translated">WebpageReader:将网页 Url 作为输入，连接并提取内容。</li><li id="671d" class="ni nj in kn b ko nr kr ns ku nt ky nu lc nv lg nn no np nq bi translated">WebsiteConnector:包含创建 http 连接的逻辑，并返回到网站的连接，以提取内容。</li><li id="3b06" class="ni nj in kn b ko nr kr ns ku nt ky nu lc nv lg nn no np nq bi translated">LinksExtractor:将网站作为输入，包含从网站中提取超链接的逻辑。</li></ol><p id="51fe" class="pw-post-body-paragraph kl km in kn b ko kp jx kq kr ks ka kt ku kv kw kx ky kz la lb lc ld le lf lg ig bi translated">根据 web crawler 的功能，您可以添加更多提取器。如果你想计算单词的数量，创建一个提取器来返回单词图。通过这种方式，您可以轻松地添加更多提取器组件来扩展 web 爬虫的功能，而无需更新和复杂化代码库。</p><p id="710e" class="pw-post-body-paragraph kl km in kn b ko kp jx kq kr ks ka kt ku kv kw kx ky kz la lb lc ld le lf lg ig bi translated">在这个网络爬虫中，当它从一个网站提取链接时，我也想抓取这些链接。为了有效地执行这一点，我们需要使程序并发。然后，我可以增加线程的数量来并行抓取提取的链接。为此，我们将添加 3 个通道-</p><ol class=""><li id="0ce4" class="ni nj in kn b ko kp kr ks ku nk ky nl lc nm lg nn no np nq bi translated">Sites Channel:包含要抓取的网站 URL。</li><li id="2fd1" class="ni nj in kn b ko nr kr ns ku nt ky nu lc nv lg nn no np nq bi translated">CrawledLinks Channel:包含在已爬网网站上找到的链接。</li><li id="bb8b" class="ni nj in kn b ko nr kr ns ku nt ky nu lc nv lg nn no np nq bi translated">PendingNumSites Channel:包含要爬网的挂起网站的数量。</li></ol><p id="dd5f" class="pw-post-body-paragraph kl km in kn b ko kp jx kq kr ks ka kt ku kv kw kx ky kz la lb lc ld le lf lg ig bi translated">我们需要 CrawledLinksChannel，这样我们可以在提交它进行爬网之前过滤掉重复的链接。这样，它就不会进入循环。我们将维护一个内存映射来存储抓取的网站列表，以过滤重复的网站。要使它为生产做好准备，请使用分布式数据库，而不是内存映射。</p><p id="5673" class="pw-post-body-paragraph kl km in kn b ko kp jx kq kr ks ka kt ku kv kw kx ky kz la lb lc ld le lf lg ig bi translated">PendingNumSites 频道有助于了解是否有更多的网站要爬网。当一个链接被添加到 SitesChannel 时，它将为 PendingNumSites 添加+1，当被爬网时，它将为 pending numsites 添加-1。我们将设置一个监视器来维护当前计数，当计数达到 0 时，它将关闭所有通道，从而终止程序。</p><p id="2e50" class="pw-post-body-paragraph kl km in kn b ko kp jx kq kr ks ka kt ku kv kw kx ky kz la lb lc ld le lf lg ig bi translated">通过添加所有这些组件，设计看起来会像-</p><figure class="li lj lk ll gt lm gh gi paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="gh gi nw"><img src="../Images/01c7ec5cdfc5b4ce324828736c8ef3f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FN7CjEoVELkPNk0xZFl6cQ.png"/></div></div></figure></div><div class="ab cl mv mw hr mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="ig ih ii ij ik"><h1 id="29bf" class="ly lz in bd ma mb nc md me mf nd mh mi kc ne kd mk kf nf kg mm ki ng kj mo mp bi translated">网络爬虫实现</h1><h2 id="4a18" class="nx lz in bd ma ny nz dn me oa ob dp mi ku oc od mk ky oe of mm lc og oh mo it bi translated">使用 Goroutines、频道和等待组</h2><p id="453e" class="pw-post-body-paragraph kl km in kn b ko mq jx kq kr mr ka kt ku ms kw kx ky mt la lb lc mu le lf lg ig bi translated">WebCrawlerMain 为 web crawler 创建所有必需的组件，并通过添加要爬网的站点来触发爬网。在这里，我创建了 50 个<em class="oi"> goroutines </em>来抓取网站。<em class="oi"> WaitGroups </em>允许主程序等待，直到所有线程完成执行。如上所述，它创建了 3 个<em class="oi">频道</em>，并向 sitesChannel 添加了一个站点。</p><figure class="li lj lk ll gt lm"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="b384" class="pw-post-body-paragraph kl km in kn b ko kp jx kq kr ks ka kt ku kv kw kx ky kz la lb lc ld le lf lg ig bi translated">CrawlerBO 是包含网络爬虫业务逻辑的核心组件。</p><figure class="li lj lk ll gt lm"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="1465" class="pw-post-body-paragraph kl km in kn b ko kp jx kq kr ks ka kt ku kv kw kx ky kz la lb lc ld le lf lg ig bi translated">网页阅读器连接到网站，提取链接并添加到频道。</p><figure class="li lj lk ll gt lm"><div class="bz fp l di"><div class="oj ok l"/></div></figure><h2 id="7af6" class="nx lz in bd ma ny nz dn me oa ob dp mi ku oc od mk ky oe of mm lc og oh mo it bi translated">过滤重复网站</h2><p id="47c4" class="pw-post-body-paragraph kl km in kn b ko mq jx kq kr mr ka kt ku ms kw kx ky mt la lb lc mu le lf lg ig bi translated">这是防止程序进入无限循环的重要一步。</p><figure class="li lj lk ll gt lm"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="8f9d" class="pw-post-body-paragraph kl km in kn b ko kp jx kq kr ks ka kt ku kv kw kx ky kz la lb lc ld le lf lg ig bi translated">当 CrawlerBO 从 sitesChannel 中读取内容时，将该站点添加到其中会提交该站点进行爬网。</p><h2 id="31b8" class="nx lz in bd ma ny nz dn me oa ob dp mi ku oc od mk ky oe of mm lc og oh mo it bi translated">关闭频道</h2><p id="82ff" class="pw-post-body-paragraph kl km in kn b ko mq jx kq kr mr ka kt ku ms kw kx ky mt la lb lc mu le lf lg ig bi translated">所有网站抓取成功后，它要关闭所有频道。</p><figure class="li lj lk ll gt lm"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="eaf1" class="pw-post-body-paragraph kl km in kn b ko kp jx kq kr ks ka kt ku kv kw kx ky kz la lb lc ld le lf lg ig bi translated">你可以在这里找到完整的代码实现。</p><h1 id="ca9d" class="ly lz in bd ma mb mc md me mf mg mh mi kc mj kd mk kf ml kg mm ki mn kj mo mp bi translated">结论</h1><p id="ce3d" class="pw-post-body-paragraph kl km in kn b ko mq jx kq kr mr ka kt ku ms kw kx ky mt la lb lc mu le lf lg ig bi translated">正如我上面提到的，创建一个网络爬虫并不困难，它提供了许多可能性。此外，这对于学习编程语言的各个方面也是一个非常好的工具。生产就绪代码与其他代码的主要区别在于，能够轻松扩展或更新功能，以及代码的可读性和可维护性。我已经提供了一种构建代码的方法，但是还有许多方法可以有效地编写代码并将功能划分到不同的组件中。一定要创建自己的网络爬虫，尝试各种功能，并拥有一个创建自己的网络工具的平台。</p></div></div>    
</body>
</html>