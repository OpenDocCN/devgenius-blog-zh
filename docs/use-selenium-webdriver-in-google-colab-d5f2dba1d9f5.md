# 在 Google Colab 中运行 Selenium WebDriver

> 原文：<https://blog.devgenius.io/use-selenium-webdriver-in-google-colab-d5f2dba1d9f5?source=collection_archive---------1----------------------->

![](img/e3e4c3dfb08ff66e84fe0a57a9f5c63f.png)

克里斯里德在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

如果您需要在 Google Colab 中为您的分析项目收集数据，您可以在您的 Colab 笔记本中使用 web scraper 代码。

Google Colab 是一项免费托管 Jupyter 笔记本的服务，几乎不需要任何设置即可使用。Colab 在数据科学家中尤其有名，他们利用它来完成机器学习和数据分析任务。Google Colab 的一个特殊特性是它允许您执行 Bash 命令。如果您不熟悉 Bash，这是一种 shell 语言，一些 Linux 发行版在命令行界面(CLI)上使用它来完成许多任务，比如文件管理或程序安装。有了这些功能，我们可以安装以前在 Google Colab 中没有的包，比如 Selenium 和用于各自浏览器的 WebDriver。

# 使用 Colab 进行网页抓取的原因

如果您最近运行 Selenium，您可能会注意到运行 Selenium 需要大量内存。当然，如果您只运行 WebDriver 的一个实例，这完全没问题。但是，有些用例需要为 Selenium 程序分配更多的内存。以多线程运行[Selenium](/dbcfb0635e83)为例。

使用多线程运行 Selenium 意味着后台会有很多并发线程，每个线程本身都会占用大量内存。Selenium 需要的内存数量取决于分配给程序的线程数量。从我的经验来看，你可以用 8GB 的内存运行一些 Selenium 线程，没有任何问题。然而，当你需要更多的线程时，问题就出现了。在本文的[中，我能够在 36 分钟内用 4 个线程通过 1500 页数据运行 Selenium，同时自动解析链接。如果你有成千上万的网页要抓取，增加更多的线程会提高程序的速度，但需要更多的内存。如果有足够的空闲内存，您仍然可以在本地运行它，但是使用 Colab 可以释放您的本地资源来执行其他任务。](/dbcfb0635e83)

此外，要考虑到许多计算机一开始就没有很多内存。这不仅是老电脑的问题，也是许多新电脑的问题。例如，在印度尼西亚，许多新的笔记本电脑仍然配备 8GB 内存，有些甚至只配备 4GB 内存。这就是使用 Google Colab 来运行 Selenium 程序能给你很大帮助的地方。它帮助您完成手头的任务，同时释放您的本地资源来完成另一项任务。

Colab 还使用谷歌的互联网连接来运行请求和获取数据。这意味着你不必使用你自己的带宽来获取所有你要抓取的 HTML 页面、CSS 样式表和 JS 脚本。如果您没有非常可靠的互联网连接，这尤其有用。此外，谷歌的互联网依赖于谷歌云平台的速度，所以他们的连接可能比你的更快。因此，您现在可以在处理其他需要共享个人带宽的任务时，享受 web scraper 的可靠连接。

# 它是如何工作的

让我们从使用`apt` & PIP 安装 Selenium 和 WebDriver 开始，编写下面的代码。注意，这三个命令前面都有`!`，因为任何出现在`!`后面的命令都将由系统命令行执行。

在 Colab 中安装 Selenium 和 WebDriver 的代码。

安装好所有东西后，Colab 一切如常。就像在本地机器上一样编写 Selenium 代码。让我们通过抓取印尼最大的电子商务网站之一 Tokopedia.com 的页面源码来测试一下。

首先，让我们用正确的选项设置 WebDriver。下面的代码将 WebDriver 设置为 headless 模式，同时也使它不同于人工操作的浏览器。这些设置来自 webscraping.pro 的伊戈尔·萨维金的博客文章，他想出了一个绝妙的主意来测试人工操作和自动浏览器的参数和设置，看看指纹识别程序能否区分这两者。

Selenium 的驱动程序设置选项。

设置好 WebDriver 后，我们将编写一些代码来返回页面源代码:

返回页面源代码的小代码。

现在，如果我们尝试调用上面的方法，我们将得到我们期望的 HTML。

![](img/c01487c151e4f993f26c91ed7c385157.png)

Selenium 成功返回 Tokopedia 的 HTML。实际上没有必要像我一样美化源代码。

从这一点上来说，你可以根据你要抓取的网站来设计你的网页抓取器。

# 等等，我还是不能运行硒！:(

如果收到类似`WebDriverException: Message: unknown error: Chrome failed to start: exited abnormally`的消息，这意味着 Chrome 启动失败，因为 WebDriver 找不到 Chrome 的安装。

当你第一次运行 Selenium 时，你通常会看到 Selenium 在前台自动为你打开一个浏览器。在这种情况下，您可以看到 Selenium 在做什么；点击链接、滚动等。这是以**开头的**版本的浏览器。然而，我们不能以这种方式运行 Selenium，因为浏览器的安装本身并不存在于 Colab 实例中。相反，我们需要在打开**无头**模式的情况下使用 Selenium。如果您希望了解如何利用此功能，请参考驱动程序设置部分。

如果你收到另一个错误，请在评论中写下来。

# Colab 对资源有什么限制吗？

> “Colab 中可用的资源会随着时间的推移而变化，以适应需求的波动，以及适应整体增长和其他因素。”——Google

简而言之，**谷歌确实在运行中限制了 Colab** 的资源。存储、内存、处理器以及带宽。问题是，**资源在 Colab 实例上从来没有得到保证**，所以我们无法知道 Colab 在任何给定的时间里会为我们提供多少资源。执行时间也有限制。在免费版本中，最长可达 **12 小时**。如果您正确设置了 Selenium，您仍然可以在 12 小时内获得大量数据。您甚至可以设置您的 Selenium 在 12 小时标记完成后继续提取，但这是另一篇文章的主题。

也请记住，负责任地使用网页抓取工具，并为你的请求设定时间。不要试图搞垮互联网。**使用 Colab 进行 DoS 攻击是严格禁止的，也是非法的**。

如果你能走到这一步，谢谢。希望这个故事对你的旅途有所帮助。发现错误请随意评论，喜欢就鼓掌。谢谢你。