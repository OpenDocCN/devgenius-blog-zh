<html>
<head>
<title>I Finally Made a Neural Network that Learns Snake in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我终于用Python做了一个学习蛇的神经网络</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/i-finally-made-a-neural-network-that-learns-snake-in-python-4ba9f3975783?source=collection_archive---------3-----------------------#2022-01-04">https://blog.devgenius.io/i-finally-made-a-neural-network-that-learns-snake-in-python-4ba9f3975783?source=collection_archive---------3-----------------------#2022-01-04</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><div class=""><h2 id="9922" class="pw-subtitle-paragraph jk im in bd b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb dk translated">我的背景故事:</h2></div><p id="adb4" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">当我15岁的时候，我偶然在YouTube上看到一个视频，有人使用机器学习来训练一个人工智能玩蛇。受此启发，我立即加载了python，并尝试使用神经网络和遗传算法来学习snake。最终它失败了，因为它朝着第一个食物的方向跌跌撞撞，然后全心全意地撞向墙壁。</p><p id="4dd6" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">从那以后，每当我回来看这个项目时，它都会难倒我，有些东西就是不太管用。直到今天！</p><p id="85d4" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">(再补充一点，我是一个对计算机科学没什么背景的业余爱好者。我对这个项目的想法是从头开始构建一切，这样我就可以尽可能多地学习，所以这是我的“hello world”机器学习项目</p></div><div class="ab cl ky kz hr la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ig ih ii ij ik"><h2 id="77ad" class="lf lg in bd lh li lj dn lk ll lm dp ln kl lo lp lq kp lr ls lt kt lu lv lw lx bi translated">第1部分:定义成功</h2><p id="cc46" class="pw-post-body-paragraph kc kd in ke b kf ly jo kh ki lz jr kk kl ma kn ko kp mb kr ks kt mc kv kw kx ig bi translated">贪吃蛇是一个非常简单的游戏，所以让我们把成功的定义变得简单一些。吃1种食物只是运气，吃2种食物也可能只是运气，所以让我们一起来吃10种食物吧。</p></div><div class="ab cl ky kz hr la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ig ih ii ij ik"><h2 id="f8ca" class="lf lg in bd lh li lj dn lk ll lm dp ln kl lo lp lq kp lr ls lt kt lu lv lw lx bi translated">第二部分:计划</h2><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi md"><img src="../Images/8b91f48207062681b155e9cac20ffe49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*aqx888NFN_CUQbgpDsT-gQ.png"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">学习算法</figcaption></figure><p id="8aa1" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">正如我们可以从计划中看到的，我们将实现一个非常简单的遗传算法来提高代理。我在下面定义了评分函数:</p><p id="5f6f" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">体能= 1000*(进食次数)+ 1*(移动次数)</p><p id="67e8" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">这导致食物成为主要的刺激因素，但也促使自我保护成为次要的刺激因素。代理人也将有一个“能量”值，这是他们在筋疲力尽之前可以做的动作数量，这是通过吃食物来补充的。这个“能量”值是至关重要的，否则代理可能会学习无限循环，以最大化他们的健身分数。</p></div><div class="ab cl ky kz hr la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ig ih ii ij ik"><h2 id="20fd" class="lf lg in bd lh li lj dn lk ll lm dp ln kl lo lp lq kp lr ls lt kt lu lv lw lx bi translated">第3部分:代码</h2><p id="97a9" class="pw-post-body-paragraph kc kd in ke b kf ly jo kh ki lz jr kk kl ma kn ko kp mb kr ks kt mc kv kw kx ig bi translated">该代码由4个主要部分组成:</p><ul class=""><li id="2376" class="mp mq in ke b kf kg ki kj kl mr kp ms kt mt kx mu mv mw mx bi translated">游戏引擎</li><li id="b6f7" class="mp mq in ke b kf my ki mz kl na kp nb kt nc kx mu mv mw mx bi translated">神经网络</li><li id="0015" class="mp mq in ke b kf my ki mz kl na kp nb kt nc kx mu mv mw mx bi translated">学习算法</li><li id="0886" class="mp mq in ke b kf my ki mz kl na kp nb kt nc kx mu mv mw mx bi translated">分析</li></ul><p id="cbe5" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">游戏引擎是整个操作的核心，它必须很快。为了做到这一点，我使用了BitBoards，这是一种用4个整数来表示蛇的环境的方法，这4个整数分别代表食物位置、头部位置、身体位置和墙壁位置。这比用数组来表示游戏要快得多，因为我可以使用按位操作符来操作棋盘，而不是每次访问数组时都要搜索它。</p><p id="73c6" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">为了更好地理解BitBoards如何工作，我发现这个链接在象棋环境中非常有用(<a class="ae nd" href="https://www.chessprogramming.org/Efficient_Generation_of_Sliding_Piece_Attacks" rel="noopener ugc nofollow" target="_blank">滑动棋子攻击的有效生成——象棋编程维基</a>)。</p><p id="ce16" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">下面是我的游戏引擎代码。</p><pre class="me mf mg mh gt ne nf ng nh aw ni bi"><span id="4a6b" class="lf lg in nf b gy nj nk l nl nm">import math<br/>import random</span><span id="6fa1" class="lf lg in nf b gy nn nk l nl nm">#Converting binary number to index location<br/>def index(b):<br/>    return math.log(b)/math.log(2)</span><span id="98c6" class="lf lg in nf b gy nn nk l nl nm">#Converting index location to binary number<br/>def bini(index):<br/>    return 2 ** index<br/><br/><br/>class Board():<br/>    def __init__(self):<br/>        self.size = 15<br/>        self.full_size = self.size ** 2<br/><br/>        self.walls = 0<br/><br/>        for i in range(self.size):<br/>            self.walls += bini(i)<br/>            self.walls += bini(self.size*(self.size-1)+i)<br/><br/>        for i in range(self.size-2):<br/>            self.walls += bini(self.size + self.size * i)<br/>            self.walls += bini(self.size *2 -1 + self.size * i)<br/><br/>        self.food = 0<br/>        self.head = bini(round(self.full_size / 2)) &lt;&lt; self.size<br/>        self.body_list = [(self.head &gt;&gt; self.size*2) , (self.head &gt;&gt; self.size)]<br/><br/>        self.food_points = 0<br/>        self.move_points = 0<br/>        self.energy = 100<br/><br/>        self.end = False<br/><br/>        self.update()<br/><br/>        self.place_food()<br/><br/>    def __str__(self):<br/>        con = '{:'+str(self.full_size)+'b}'<br/>        walls = con.format(self.walls)<br/>        head = con.format(self.head)<br/>        food = con.format(self.food)<br/>        body = con.format(self.body)<br/><br/>        rows = []<br/>        r = ''<br/>        for i in range(self.full_size):<br/>            r += ' '<br/>            if walls[i] == '1':<br/>                r = r + 'X'<br/>            elif head[i] == '1':<br/>                r = r + 'H'<br/>            elif food[i] == '1':<br/>                r = r + 'F'<br/>            elif body[i] == '1':<br/>                r = r + 'B'<br/>            <br/>            else:<br/>                r = r + ' '<br/><br/>            if (i+1) % self.size == 0:<br/>                rows.append(r[::-1])<br/>                r = ''<br/><br/>        out = '\n'.join(rows)<br/><br/>        return out<br/>        <br/>    def update(self):<br/>        self.body = sum(self.body_list)<br/><br/>        self.all = self.walls | self.food | self.body | self.head<br/><br/>        if self.head &amp; self.body != 0:<br/>            self.end = True<br/>            #print('GAME OVER')<br/><br/>        if self.head &amp; self.walls != 0:<br/>            self.end = True<br/>            #print('GAME OVER')<br/><br/>        if self.energy &lt; self.move_points:<br/>            self.end = True<br/><br/>    def place_food(self):<br/>        choices = []<br/>        for i in range(self.full_size):<br/>            if bini(i) &amp; self.all == 0:<br/>                choices.append(i)<br/><br/>        loc = random.choice(choices)<br/>        self.food = bini(loc)<br/><br/>    def print(self,var):<br/>        con = '{:'+str(self.full_size)+'b}'<br/>        return con.format(var)<br/><br/>    def push(self,move):<br/>        # 0 - Left<br/>        # 1 - UP<br/>        # 2 - Right<br/>        # 3 - DOWN<br/><br/>        old_head = self.head<br/><br/>        if move == 0:<br/>            self.head = self.head &gt;&gt; 1<br/>        elif move == 1:<br/>            self.head = self.head &lt;&lt; self.size<br/>        elif move == 2:<br/>            self.head = self.head &lt;&lt; 1<br/>        elif move == 3:<br/>            self.head = self.head &gt;&gt; self.size<br/>        else:<br/>            self.end = True<br/>            print('wtf is this input')<br/><br/>        if self.head &amp; self.food == 0:#if not on a food<br/>            self.body_list.remove(self.body_list[0])<br/>            self.body_list.append(old_head)<br/><br/>        else:<br/>            self.food_points += 1000<br/>            self.energy += 100<br/>            self.body_list.append(old_head)<br/>            self.place_food()<br/><br/>        self.update()<br/>        self.move_points += 1</span></pre><p id="89c8" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated"><strong class="ke io">神经网络</strong>将由3层组成，一个输入层(大小24)，一个隐藏层(大小8)，和一个输出层(大小4)。</p><p id="1c28" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">输入层是蛇从头部获得的“视觉”。它能够在所有4个方向和4条以上的对角线上看到自己和物体之间的距离。它可以识别3种类型的对象，食物、墙壁和它的身体，因此这导致输入层的大小为24。</p><p id="5457" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">输入和隐藏层之间的激活函数是一个整流器函数，这只是一个花哨的词:f(x) = max(0，x)。</p><p id="1c66" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">隐藏层存在，大小为8，因为为什么不，我们希望蛇是聪明的，对不对？但也不用花太多时间去思考。(老实说，这是我所有的想法)。</p><p id="e9ad" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">隐藏层和输出层之间的激活函数是Softmax，它将输出中的值限制在0-1之间，所有输出的总和将为1。这就放弃了代理偏好哪种输出的概率概念。</p><p id="9438" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">输出层的大小为4，因为蛇可以选择4个方向移动。</p><p id="3acb" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">下面是我的神经网络代码，在这种情况下，代理是由类Brain定义的。(这很大程度上是受到了Sentdex在youtube上的精彩教程的启发<a class="ae nd" href="https://www.youtube.com/c/sentdex/featured" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/c/sentdex/featured</a></p><pre class="me mf mg mh gt ne nf ng nh aw ni bi"><span id="b7f6" class="lf lg in nf b gy nj nk l nl nm">import numpy as np</span><span id="b908" class="lf lg in nf b gy nn nk l nl nm">class Layer_Dense: #hidden layer<br/>    def __init__(self, n_inputs, n_neurons):<br/>        self.weights = 0.1 * np.random.randn(n_inputs, n_neurons)<br/>        self.biases = np.zeros((1, n_neurons))<br/>    def forward(self, inputs):<br/>        self.output = np.dot(inputs, self.weights) + self.biases<br/><br/>class Activation_ReLU:<br/>    def forward(self, inputs):<br/>        self.output = np.maximum(0, inputs)<br/><br/>class Activation_Softmax:<br/>    def forward(self, inputs):<br/><br/>        exp_values = np.exp(inputs - np.max(inputs,axis=1,keepdims=True))<br/>        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)<br/>        self.output = probabilities<br/><br/><br/>class Brain:<br/>    def __init__(self):<br/>        self.lay1 = Layer_Dense(24,8)<br/>        self.act1 = Activation_ReLU()<br/>        self.lay2 = Layer_Dense(8,4)<br/>        self.act2 = Activation_Softmax()<br/>    def forward(self, inputs):<br/>       <br/>        self.lay1.forward(inputs)<br/>        self.act1.forward(self.lay1.output)<br/>        <br/>        self.lay2.forward(self.act1.output)<br/>        self.act2.forward(self.lay2.output)<br/><br/>        self.output = self.act2.output</span><span id="cd58" class="lf lg in nf b gy nn nk l nl nm">def get_inputs(state):<br/>    out = np.array([[0,0,0,0,0,0,0,0,<br/>                     0,0,0,0,0,0,0,0,<br/>                     0,0,0,0,0,0,0,0]],dtype = float)<br/><br/>    # d / l / u / r<br/><br/>    head = index(state.head)<br/>    food = index(state.food)<br/>    <br/><br/>    head_loc = (int(head // state.size),int(head % state.size))<br/>    food_loc = (int(food // state.size),int(food % state.size))<br/><br/>    diff_x = head_loc[0] - food_loc[0]<br/>    diff_y = head_loc[1] - food_loc[1]<br/><br/>    #print(head_loc)<br/>    #print(food_loc)<br/><br/>    ouot = out[0]<br/><br/>    ouot[0] = head_loc[0]<br/>    ouot[1] = head_loc[1]<br/>    ouot[2] = state.size - ouot[0] - 1<br/>    ouot[3] = state.size - ouot[1] - 1<br/><br/>    ouot[4] = (ouot[0] + ouot[1] - 1) / 2<br/>    ouot[5] = (ouot[1] + ouot[2] - 1) / 2<br/>    ouot[6] = (ouot[2] + ouot[3] - 1) / 2<br/>    ouot[7] = (ouot[3] + ouot[0] - 1) / 2<br/><br/>    if head_loc[0] == food_loc[0]:<br/><br/>        if head_loc[1] &gt; food_loc[1]:<br/>            ouot[8] = head_loc[1] - food_loc[1]<br/>        else:<br/>            ouot[9] = food_loc[1] - head_loc[1]<br/><br/>    if head_loc[1] == food_loc[1]:<br/>        if head_loc[0] &gt; food_loc[0]:<br/>            ouot[10] = head_loc[0] - food_loc[0]<br/>        else:<br/>            ouot[11] = food_loc[0] - head_loc[0]<br/><br/>    <br/>    if diff_x == diff_y:<br/>        if diff_x &lt; 0:<br/>            ouot[12] = abs(diff_x)<br/>        else:<br/>            ouot[13] = abs(diff_x)<br/><br/>    if diff_x == -diff_y:<br/>        if diff_x &lt; 0:<br/>            ouot[14] = abs(diff_x)<br/>        else:<br/>            ouot[15] = abs(diff_x)<br/><br/><br/>    for body in state.body_list:<br/>        b = index(body)<br/>        loc = (int(b // state.size),int(b % state.size))<br/><br/>        diff_x = head_loc[0] - loc[0]<br/>        diff_y = head_loc[1] - loc[1]<br/><br/>        if loc[0] == head_loc[0]:<br/>            if loc[1] &gt; head_loc[1]:<br/>                if ouot[16] == 0:<br/>                    ouot[16] = loc[1] - head_loc[1]<br/>                else:<br/>                    ouot[16] = min(ouot[16],loc[1] - head_loc[1])<br/><br/>            else:<br/>                if ouot[17] == 0:<br/>                    ouot[17] = head_loc[1] - loc[1]<br/>                else:<br/>                    ouot[17] = min(ouot[17],head_loc[1] - loc[1])<br/><br/>        if loc[1] == head_loc[1]:<br/>            if loc[0] &gt; head_loc[0]:<br/>                if ouot[18] == 0:<br/>                    ouot[18] = loc[0] - head_loc[0]<br/>                else:<br/>                    ouot[18] = min(ouot[18],loc[0] - head_loc[0])<br/><br/>            else:<br/>                if ouot[19] == 0:<br/>                    ouot[19] = head_loc[0] - loc[0]<br/>                else:<br/>                    ouot[19] = min(ouot[19],head_loc[0] - loc[0])<br/><br/>        if diff_x == diff_y:<br/>            if diff_x &lt; 0:<br/>                if ouot[20] == 0:<br/>                    ouot[20] = abs(diff_x)<br/>                else:<br/>                    ouot[20] = min(ouot[20],abs(diff_x))<br/>            else:<br/>                if ouot[21] == 0:<br/>                    ouot[21] = abs(diff_x)<br/>                else:<br/>                    ouot[21] = min(ouot[20],abs(diff_x))<br/><br/>        if diff_x == -diff_y:<br/>            if diff_x &lt; 0:<br/>                if ouot[22] == 0:<br/>                    ouot[22] = abs(diff_x)<br/>                else:<br/>                    ouot[22] = min(ouot[22],abs(diff_x))<br/>            else:<br/>                if ouot[23] == 0:<br/>                    ouot[23] = abs(diff_x)<br/>                else:<br/>                    ouot[23] = min(ouot[23],abs(diff_x))<br/>                <br/><br/>    for i in range(len(ouot)):<br/>        if ouot[i] != 0:<br/>            ouot[i] = (state.size - ouot[i] - 1) / (state.size - 2)<br/><br/>    return out</span></pre><p id="8f1b" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated"><strong class="ke io">学习算法</strong>基于第2部分描述的简单进化算法。每一代的前10%的病原体传递到下一代，并与每种病原体的其他9种变异版本包含在一起。变异是通过向每个代理的权重和偏差添加小的随机值而发生的(由下面的multi_mutate函数定义)。</p><p id="5356" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">通过让每一代的最佳表现者延续到下一代，使我们不会因为不幸的突变而失去进步。</p><p id="0f94" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">下面是这个学习算法的代码。</p><pre class="me mf mg mh gt ne nf ng nh aw ni bi"><span id="a181" class="lf lg in nf b gy nj nk l nl nm">def multi_mutate(brains, x): #keeps the brains and makes x many children asexually<br/>    out = brains<br/><br/>    for i in range(len(brains)):<br/>        brain = brains[i]<br/>        for i in range(x):<br/>            new_brain = deepcopy(brain)<br/><br/>            new_brain.lay1.weights += np.random.randn(24, 8) * np.random.randn(24, 8)<br/>            new_brain.lay1.biases += 0.01 * np.random.randn(1,8)<br/>            new_brain.lay2.weights += np.random.randn(8, 4) * np.random.randn(8, 4)<br/>            new_brain.lay2.biases += 0.01 * np.random.randn(1,4)<br/>        <br/>            out.append(new_brain)<br/><br/>    return out<br/><br/>def learn(networks,gens):<br/><br/>    top_brains = int(networks/10) #top 10% stay alive in each gen<br/>    trial_brains = [Brain() for i in range(networks)]<br/>    output = []<br/><br/>    for i in range(gens):<br/>        scores = []<br/>        <br/>        for brain in trial_brains: <br/>            score = test(brain) #score each brain<br/>            scores.append(score)<br/><br/>        print('Gen :',i)<br/>        print('Best Score :',max(scores))<br/>        print('Avg Score :',sum(scores) / len(scores))<br/><br/>        max_index = scores.index(max(scores))<br/>        best_brain = trial_brains[max_index]<br/><br/>        output.append([scores,best_brain])<br/><br/>        scores_copy = scores.copy()<br/>        multi_best_brains = [] #list for best brains<br/>        for x in range(top_brains): #picks out top 10% brains<br/>                multi_best_brains.append(trial_brains[ scores_copy.index(max(scores_copy))])<br/><br/>            scores_copy.remove(max(scores_copy))<br/><br/><br/>        trial_brains = multi_mutate(multi_best_brains, 9) #mutate<br/><br/>        plot_data(output)<br/><br/>    return output</span></pre><p id="dcac" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated"><strong class="ke io">分析</strong>功能让我们可以跟踪进度。您可能已经注意到plot_data函数，它绘制了每一代的最大适应度、平均适应度和标准偏差的图形。</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi no"><img src="../Images/de91c1f2caa8c89fb4f53ef921a98312.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*C1cXmlzQSH1WxiB34X255Q.gif"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">健康与世代的进度图</figcaption></figure><p id="0602" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">我们还有一个函数来显示代理的动作，这是一个简单的窗口，使用Tkinter来显示正在玩的贪吃蛇游戏。</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi np"><img src="../Images/33737b5e3db78a8236a587568eb0bbd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:480/1*hh80aXdYOOPmp3mxqM_zPw.gif"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">简单的图形用户界面</figcaption></figure><pre class="me mf mg mh gt ne nf ng nh aw ni bi"><span id="c235" class="lf lg in nf b gy nj nk l nl nm">import matplotlib.pyplot as plt</span><span id="5bc1" class="lf lg in nf b gy nn nk l nl nm">def plot_data(data):<br/>    plt.clf()<br/><br/>    data = [d[0] for d in data]<br/><br/>    avg = [sum(d)/len(d) for d in data]<br/>    maxx = [max(d) for d in data]<br/>    std = [np.std(d) for d in data]<br/><br/>    low_var = [avg[i] - std[i] for i in range(len(avg))]<br/>    high_var = [avg[i] + std[i] for i in range(len(avg))]<br/><br/>    #print(low_var)<br/>    <br/><br/>    plt.plot(avg,'r',label = 'avg')<br/>    plt.plot(maxx,label = 'max')<br/>    plt.fill_between(range(len(avg)),low_var,high_var)<br/><br/>    plt.legend()<br/><br/>    plt.show(block=False)<br/>    plt.pause(0.1)</span><span id="6ad7" class="lf lg in nf b gy nn nk l nl nm">def display(brain):<br/><br/>    state = Board()<br/>    root = tk.Tk()<br/>    while state.end == False:<br/>        try:<br/>            T.destroy()<br/>        except:<br/>            pass<br/>        <br/>        show = state.__str__()<br/><br/>        T = tk.Text(root)<br/>        T.insert(tk.END,show)<br/>        T.pack()<br/>   <br/>        inputs = get_inputs(state)<br/>        brain.forward(inputs)<br/>        brain_out = brain.output<br/>        foo = 0<br/><br/>        for i in range(4):<br/>            prob = brain_out[0][i]<br/>            if prob &gt; foo:<br/>                foo = prob<br/>                move = i<br/><br/>        state.push(move)<br/>        root.update()<br/>    points = state.food_points + state.move_points<br/>    return points</span></pre></div><div class="ab cl ky kz hr la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ig ih ii ij ik"><h2 id="1fc4" class="lf lg in bd lh li lj dn lk ll lm dp ln kl lo lp lq kp lr ls lt kt lu lv lw lx bi translated">第4部分:总结+结果</h2><p id="bf28" class="pw-post-body-paragraph kc kd in ke b kf ly jo kh ki lz jr kk kl ma kn ko kp mb kr ks kt mc kv kw kx ig bi translated">所以我设置学习函数运行1000代，群体大小N = 1000。这花了大约一个半小时运行，这是结果！</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi nq"><img src="../Images/7e42d2ba122b975e341624a08b13491c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5NP2cp6adHyaeTMX5lSE_A.png"/></div></div></figure><p id="a43b" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">这些结果给我留下了非常深刻的印象，正如你所看到的，接近第1000代的最好的代理达到了超过40，000的分数。这意味着他们吃了40多种食物，远远超过了我10种食物的目标。</p><p id="7c6a" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">有趣的是，你可以看到大约从第0-400代开始，最大适应度的大致形状类似于一个sigmoid函数。这在直觉上是有意义的，因为最好的特工开始掌握避开墙壁、走向食物和不背叛自己的概念。</p><p id="f3b5" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">从大约第400-600代开始，除了种群的平均健康水平稳步提高之外，似乎没有什么进步。然而，由于突变的性质，这个值似乎将一直保持较低，并且具有较高的方差。</p><p id="5727" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">从大约第600个标记到最后，从30k到40k有一个小的跳跃，我认为代理在定位和移动食物方面变得更加有效。</p><p id="d2ae" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">下面是第1000代最佳特工的动画。</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi np"><img src="../Images/1dfa25375444c7699a0a8a948e08dc8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:480/1*ikHxKqx2OGBiCUsDEH9I5g.gif"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">第1000代最佳代理的演示</figcaption></figure><p id="6689" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">我们可以看到，代理人很好地掌握了避免墙壁，但坚持接近他们，我认为这是一个非常像人类的策略。它也能高效地走向食物。</p><p id="95a3" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">我认为它最后的失败是因为它可以看到自己的身体，而沿着底部的墙，这种输入改变了输出，以避免避开蛇下面的墙。</p><p id="3657" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">这可能是代理人最大的改进领域，这将是正确理解有关其身体的视觉的最后8个输入。然而，我认为代理人应该没有学到这一点，因为与食物和墙壁相比，他们看到自己身体的机会要少得多。</p><h2 id="6084" class="lf lg in bd lh li lj dn lk ll lm dp ln kl lo lp lq kp lr ls lt kt lu lv lw lx bi translated">第五部分:展望未来</h2><p id="91b1" class="pw-post-body-paragraph kc kd in ke b kf ly jo kh ki lz jr kk kl ma kn ko kp mb kr ks kt mc kv kw kx ig bi translated">显然，我可以对更多代或更大的人口规模运行学习算法，看看它们会产生什么结果。我认为其他一些改变可能会提高算法的准确性。</p><p id="2047" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">一个变化可以是让适应度函数是多次运行的平均值，因为在随机位置产卵的食物可能会淘汰好的代理，或者如果运气好的话，会包括坏的代理。</p><p id="0661" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">上述问题的另一个解决方案是为每一代设置一个随机种子，这样所有的代理在每一代都玩完全相同的贪吃蛇游戏。</p><p id="bf96" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">另一个变化可能是减少消耗食物的“能量”。考虑到13x13的游戏区域，每种食物移动100次似乎已经足够了。将它减少到50可能会缩短模拟时间，从而允许我们在相同的时间框架内运行更多的模拟。</p><p id="3d0f" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">我们也可以调整神经网络的结构，也许有另一个隐藏层或改变现有隐藏层的大小。然而，如果我真的尝试了，那很可能是通过反复试验，因为我对这个话题还没有足够好的理解。</p><p id="1e5c" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated"><strong class="ke io"> <em class="nv">非常感谢你坚持到我的文章结束！如果你有任何反馈，我很想听听。</em>T3】</strong></p></div></div>    
</body>
</html>