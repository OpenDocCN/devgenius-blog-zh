# 使用 Selenium 的多线程 Web 刮擦

> 原文：<https://blog.devgenius.io/multi-threaded-web-scraping-with-selenium-dbcfb0635e83?source=collection_archive---------0----------------------->

![](img/1360981d915eca69d0e68125b521ab4b.png)

vecteezy.com 的插图

最近，我在做一个兼职项目，需要对 pergikuliner.com 网站进行网络抓取，这是一个位于印尼的美食&餐厅探索网站。主要目标是从 1500 家餐馆的名称、电话号码、可用设施和评级中获取数据。为了从这 1500 家餐馆获得数据，诉诸网络搜集是一个合乎逻辑的选择。这是因为食品网站没有任何 API 可以用来查询数据，至少在撰写本文时是这样。

在这个项目中，我选择使用硒。Selenium 是一个广泛的框架，具有几个强大的特性，包括 WebDriver，它使程序员能够模拟真实世界的 web 使用，并通过编程控制浏览器来发送和接收信息。然而，我需要的所有信息只需要很少的 Selenium 模拟，只是 pergikuliner.com 的 HTML 注入了 JavaScript，所以我使用 Selenium 来检索 HTML，而不是 JavaScript 注入的脚本。

我将从描述我的程序的两次迭代开始这篇文章:第一次迭代的单线程版本和第二次迭代的多线程版本。本文假设您对 Python 有所了解，但是我会在适当的时候介绍一些基础知识。让我们开始吧。

# 第一次尝试:就地使用硒

我最初的工作流程是进入列出 pergikuliner 餐馆数据的页面，遍历每个餐馆的所有链接，然后从每个餐馆页面获取信息。

首先，我们将导入必要的库并设置 web 驱动程序。在这种情况下，我们在无头模式下使用 Chrome WebDrivers。

接下来，让我们构建获取所需信息的函数。该函数需要两个参数:一个是我们将要抓取的餐馆页面的 URL，另一个是驱动程序，它是将被分配来请求 URL 的 WebDriver 实例。

接下来，我们需要的是“爬虫”功能。这个函数生成我们需要的餐馆链接。该函数通过从列出餐馆的页面中抓取餐馆链接来实现这一点。然后，该函数将每个 URL 传递给我们之前定义的函数，以获取餐馆数据。

要运行这个脚本，我们只需运行函数，提供显示餐馆列表的站点的页码。网站中有 125 页的餐馆页面，所以我们连同驱动程序一起提供 125 页。

最后，我们可以将结果组合成一个熊猫数据框架。

为了我的项目，脚本已经成功地收集了我需要的数据集。然而，我认为有几件事可以改进。

首先，我想知道这一进程是否可以加快。使用这个工作流程，我能够在 3.5 小时内收集所有数据。那 3.5 个小时主要是因为我的网络连接不好，所以这个任务变成了 I/O 绑定。由于这个事实，我对使用多线程来加速这个过程很感兴趣，这样 CPU 就不会浪费时间等待连接的建立。更短的执行时间意味着我的资源释放得更快，我可以更快地获得数据。

在本地使用 Selenium 意味着我必须提供一部分计算机资源来抓取网站。我有 16GB 的内存，所以这不是问题。然而，正如我所说，我的互联网连接非常有限。在对餐馆页面的每个请求中，我的计算机花费大约 4-5 秒等待响应，有时长达 9 秒。所有 1500 个餐馆页面中的每一个页面 4-5 秒意味着增加 6000-7500 秒的执行时间，或者大约 2 个小时。看到这里，我想知道将这个程序部署到 Google Colab 是不是一个好主意。这是因为使用虚拟机(VM)可以加快这一过程，因为互联网连接速度更快。使用 VM 实例还意味着我不需要提供这么多本地资源，所以我可以将它用于其他任务。

# 第二次尝试:在启用多线程的 Google Colab 中部署 Selenium

我之前描述的工作流也可以在这个迭代中使用，只需稍作修改就可以实现多线程。首先要寻找的是 WebDriver 的每个实例都不是线程安全的。这并不是说我们不能用 Selenium 实现多线程。相反，它说 WebDriver 的每个实例只需要一个线程。因此，如果您尝试将 WebDriver 的一个实例用于多个线程，可能会导致意外的行为。解决这个问题的方法是序列化对每个 WebDriver 实例的访问。也就是说，每个线程都应该有自己的 WebDriver 实例，你可以用一个简单的 for 循环打开它。我将实例化 4 个线程，因此我也将实例化 4 个驱动程序。

序列化对 WebDrivers 的访问后，您需要为每个线程提供不同的餐馆链接，以便不同的线程可以处理不同的餐馆页面。为此，您可以将餐馆链接数据分成块，然后将不同的块提供给它们自己的线程。使用的块的数量与线程的数量相同，所以我将数据分成 4 个大小相等的链接列表。

最后要处理的事情是选择线程的数量。如果保留默认值，Python 会将工作线程的最大数量增加到 32 个。然而，在这次迭代中，我选择只使用 4 个线程，这意味着我需要 4 个 WebDriver 实例和 4 个数据块。使用完 WebDriver 实例后，不要忘记在使用后关闭所有实例。

接下来，我们将在 Google Colab 上部署这个脚本。Google Colab 的环境没有缺省安装 Selenium、浏览器和 WebDriver，所以它需要一些 pip 和 apt 安装。让我们看看这个脚本抓取网页需要多少时间。

在第二次迭代中，脚本在 Colab 上运行 36 分钟。这比我们花在本地资源上的 3.5 小时要好得多。

这个故事到此为止。希望这个故事对你的旅途有所帮助。发现错误请随意评论，喜欢就鼓掌。谢谢你。