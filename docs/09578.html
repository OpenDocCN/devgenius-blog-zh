<html>
<head>
<title>Scale Vision Transformers (ViT) Beyond Hugging Face | Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">超越拥抱脸的视觉变形金刚(ViT)|第 2 部分</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/scale-vision-transformers-vit-beyond-hugging-face-part-2-b7b296d548b7?source=collection_archive---------23-----------------------#2022-08-29">https://blog.devgenius.io/scale-vision-transformers-vit-beyond-hugging-face-part-2-b7b296d548b7?source=collection_archive---------23-----------------------#2022-08-29</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><div class=""><h2 id="3e91" class="pw-subtitle-paragraph jk im in bd b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb dk translated">加快拥抱脸最先进的维生素 t 模型🤗借助 Databricks、Nvidia 和 Spark NLP，速度提升高达 2300%(25 倍)🚀</h2></div><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi kc"><img src="../Images/c7572592ba711def70ee3e626385d598.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q7ZNzdLPjeBLF-04_tfp4A.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated"><strong class="bd ks">通过使用<strong class="bd ks">数据模块</strong>、<strong class="bd ks">英伟达</strong>和<strong class="bd ks"> Spark NLP </strong>扩展</strong>基于<strong class="bd ks">变压器</strong>的型号</figcaption></figure><p id="2488" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">《超越拥抱脸|第一部 》前情提要:</p><blockquote class="lq lr ls"><p id="ba2c" class="kt ku lt kv b kw kx jo ky kz la jr lb lu ld le lf lv lh li lj lw ll lm ln lo ig bi translated"><strong class="kv io">裸机戴尔服务器:Spark NLP </strong>在预测具有 3K 图像的样本数据集的图像类时，比 CPU<strong class="kv io">上的拥抱脸</strong>快<strong class="kv io"> 65%,在具有 34K 图像的较大数据集上快 47%。<strong class="kv io"> Spark NLP </strong>在单个<strong class="kv io"> GPU </strong>推理 34K 图像的较大数据集上比拥抱脸</strong>快<strong class="kv io"> 79%，在较小数据集上快 35%。</strong></p></blockquote><blockquote class="lx"><p id="dcfa" class="ly lz in bd ma mb mc md me mf mg lo dk translated">本文的目的是演示如何从 Hugging Face 向外扩展 Vision Transformer (ViT)模型，并将其部署到生产就绪环境中，以实现加速和高性能的推理。最后，我们将通过使用 Databricks、Nvidia 和 Spark NLP，将拥抱脸的 ViT 模型扩展 25 倍(2300%)。</p></blockquote><h2 id="f39e" class="mh mi in bd ks mj mk dn ml mm mn dp mo lc mp mq mr lg ms mt mu lk mv mw mx my bi translated">在本文的第 2 部分，我将:</h2><ul class=""><li id="2c55" class="mz na in kv b kw nb kz nc lc nd lg ne lk nf lo ng nh ni nj bi translated">CPU 和 GPU 上 Databricks 单节点内部的基准拥抱面</li><li id="cff2" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated">CPU 和 GPU 上 Databricks 单节点内部的基准 Spark NLP</li></ul><blockquote class="lq lr ls"><p id="74f9" class="kt ku lt kv b kw kx jo ky kz la jr lb lu ld le lf lv lh li lj lw ll lm ln lo ig bi translated"><em class="in">本着完全透明的精神，GitHub </em>  上的 <a class="ae lp" href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/tutorials/blogposts/medium/scale-vision-transformers-vit-beyond-hugging-face?ref=hackernoon.com" rel="noopener ugc nofollow" target="_blank"> <strong class="kv io"> <em class="in">提供了所有的笔记本及其日志、截图，甚至带有数字的 excel 表格</em></strong></a></p></blockquote><div class="np nq gp gr nr ns"><a rel="noopener  ugc nofollow" target="_blank" href="/scale-vision-transformers-vit-beyond-hugging-face-part-1-e09318cab588"><div class="nt ab fo"><div class="nu ab nv cl cj nw"><h2 class="bd io gy z fp nx fr fs ny fu fw im bi translated">超越拥抱脸的视觉变形金刚(ViT)|第 1 部分</h2><div class="nz l"><h3 class="bd b gy z fp nx fr fs ny fu fw dk translated">加快拥抱脸最先进的维生素 t 模型🤗使用 Databricks、Nvidia 和……最高可达 2300%(快 25 倍)</h3></div><div class="oa l"><p class="bd b dl z fp nx fr fs ny fu fw dk translated">blog.devgenius.io</p></div></div><div class="ob l"><div class="oc l od oe of ob og km ns"/></div></div></a></div><div class="np nq gp gr nr ns"><a rel="noopener  ugc nofollow" target="_blank" href="/scale-vision-transformers-vit-beyond-hugging-face-part-2-b7b296d548b7"><div class="nt ab fo"><div class="nu ab nv cl cj nw"><h2 class="bd io gy z fp nx fr fs ny fu fw im bi translated">超越拥抱脸的视觉变形金刚(ViT)|第 2 部分</h2><div class="nz l"><h3 class="bd b gy z fp nx fr fs ny fu fw dk translated">加速拥抱脸的最先进的维生素 t 模型🤗使用 Databricks、Nvidia 和……最高可达 2300%(快 25 倍)</h3></div><div class="oa l"><p class="bd b dl z fp nx fr fs ny fu fw dk translated">blog.devgenius.io</p></div></div><div class="ob l"><div class="oc l od oe of ob og km ns"/></div></div></a></div><div class="np nq gp gr nr ns"><a rel="noopener  ugc nofollow" target="_blank" href="/scale-vision-transformers-vit-beyond-hugging-face-part-3-5b8c13ef6477"><div class="nt ab fo"><div class="nu ab nv cl cj nw"><h2 class="bd io gy z fp nx fr fs ny fu fw im bi translated">超越拥抱脸的视觉变形金刚(ViT)|第 3 部分</h2><div class="nz l"><h3 class="bd b gy z fp nx fr fs ny fu fw dk translated">加速拥抱脸的最先进的维生素 t 模型🤗使用 Databricks、Nvidia 和……最高可达 2300%(快 25 倍)</h3></div><div class="oa l"><p class="bd b dl z fp nx fr fs ny fu fw dk translated">blog.devgenius.io</p></div></div><div class="ob l"><div class="oc l od oe of ob og km ns"/></div></div></a></div></div><div class="ab cl oh oi hr oj" role="separator"><span class="ok bw bk ol om on"/><span class="ok bw bk ol om on"/><span class="ok bw bk ol om"/></div><div class="ig ih ii ij ik"><h1 id="d084" class="oo mi in bd ks op oq or ml os ot ou mo jt ov ju mr jw ow jx mu jz ox ka mx oy bi translated">数据块上的火花 NLP 和拥抱脸</h1><p id="8918" class="pw-post-body-paragraph kt ku in kv b kw nb jo ky kz nc jr lb lc oz le lf lg pa li lj lk pb lm ln lo ig bi translated"><strong class="kv io">什么是数据块？</strong>您所有的数据、分析和人工智能都在一个平台上</p><p id="adff" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Databricks 是一个基于云的平台，拥有一套数据工程和数据科学工具，被许多公司广泛用于处理和转换大量数据。用户将数据块用于许多目的，从处理和转换大量数据到运行许多 ML/DL 管道来探索数据。</p><p id="44f1" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated"><strong class="kv io">免责声明:</strong>这是我对 Databricks 的解释，它的确有很多其他特性，你应该去看看:<a class="ae lp" href="https://www.databricks.com/product/data-lakehouse" rel="noopener ugc nofollow" target="_blank">https://www.databricks.com/product/data-lakehouse</a></p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi pc"><img src="../Images/e7b028820dd8c12b660b8dede2656be3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OdPgF1kW-5GdAL1choxvAQ.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">Databricks 支持 AWS、Azure 和 GCP 云:<a class="ae lp" href="https://www.databricks.com/product/data-lakehouse" rel="noopener ugc nofollow" target="_blank">https://www.databricks.com/product/data-lakehouse</a></figcaption></figure><p id="3550" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated"><strong class="kv io">AWS 上带 CPU 的 Databricks 单节点中的拥抱面</strong></p><p id="5dcc" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">当您创建一个集群时，Databricks 提供了一个<strong class="kv io"> "Single Node" </strong>集群类型，它适合于那些希望仅在一台机器上使用 Apache Spark 或者使用非 Spark 应用程序的人，尤其是基于 ML 和 DL 的 Python 库。当您选择 Datanricks <code class="fe pd pe pf pg b">11.1 ML</code>运行时，拥抱脸已经安装。在我们开始基准测试之前，下面是我的单节点数据块(仅 CPU)的集群配置:</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi ph"><img src="../Images/84363371db8de971855528f77e87e858.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pJbSbFuDc7E88i11RlFDww.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">数据块单节点集群— CPU 运行时</figcaption></figure><p id="0f32" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">这个在<strong class="kv io"> AWS </strong>上使用<strong class="kv io"> m5n.8xlarge </strong>实例的集群的总结是:有 1 个驱动(只有 1 个节点)，128 GB 内存，<strong class="kv io"> 32 核</strong>CPU，每小时花费<strong class="kv io"> 5.71 DBU </strong>。你可以在 AWS 上阅读关于“DBU”的内容:https://www.databricks.com/product/aws-pricing<a class="ae lp" href="https://www.databricks.com/product/aws-pricing" rel="noopener ugc nofollow" target="_blank"/></p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi pi"><img src="../Images/d8f3d21e3b053d5e0f1f7cf5df8926b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QtpFfcewHQQY0__6JULfpA.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">Databricks 单集群— AWS 实例配置文件</figcaption></figure><p id="0473" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">让我们在单节点数据块(仅限 CPU)上复制上一节(裸机戴尔服务器)中的基准测试。我们从拥抱脸和 ImageNet 的样本大小的数据集开始，找出什么样的批量大小是好的，这样我们就可以将它用于更大的数据集，因为这在以前的基准测试中恰好是一个经过验证的实践:</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi pj"><img src="../Images/03453bc6011c4e54487e8712d49a2e60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3ojhdVcw1mCu_IkZjRAmBQ.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">Databricks 单节点 CPU 上的拥抱人脸图像分类流水线—预测 3544 幅图像</figcaption></figure><p id="e56b" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">在一个仅使用<strong class="kv io">CPU</strong>的单节点数据块上，我们花了大约 2 分半钟(<strong class="kv io"> 149 秒</strong>)完成了对来自样本数据集的大约<strong class="kv io"> 3544 幅图像</strong>的处理。这台机器上仅使用 CPU 的最佳批量是<strong class="kv io"> 8 </strong>，因此我将使用它在更大的数据集上运行基准测试:</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi pk"><img src="../Images/6e877ab3acfb6db62ea7f5ce8a95ba2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dzixGMmOxzvmXxPzHAHf2A.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">Databricks 单节点 CPU 上的拥抱人脸图像分类流水线—预测 34745 幅图像</figcaption></figure><p id="3dec" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">在超过 34K 图像的较大数据集上，完成这些图像的分类预测大约需要 20 分半钟(<strong class="kv io"> 1233 秒</strong>)。对于我们的下一个基准测试，我们需要一个单节点 Databricks 集群，但这次我们需要一个基于 GPU 的运行时，并选择一个基于 GPU 的 AWS 实例。</p><p id="bed0" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated"><strong class="kv io">AWS 上带有 GPU 的 Databricks 单节点中的拥抱脸</strong></p><p id="256a" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">让我们创建一个新的集群，这一次我们将选择一个带有 GPU 的运行时，在这种情况下称为<code class="fe pd pe pf pg b">11.1 ML (includes Apache Spark 3.3.0, GPU, Scala 2.12)</code>，它安装了所有必需的 CUDA 和 NVIDIA 软件。接下来我们需要选择一个拥有 GPU 的 AWS 实例，我选择了<strong class="kv io"> g4dn.8xlarge </strong>，它拥有 1 个 GPU 和与另一个集群相似数量的内核/内存。这个 GPU 实例带有一个<strong class="kv io">特斯拉 T4 </strong>和<strong class="kv io"> 16 GB 内存(</strong> 15 GB <strong class="kv io"> </strong>可用 GPU 内存)。</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi pl"><img src="../Images/c898ac5c182130bb941ef7f77e54193b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xGvjXNF6e-bE2Lu-k7xq2w.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">Databricks 单节点集群— GPU 运行时</figcaption></figure><p id="72cc" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">这是我们的单节点集群的总结，就核心数量和内存容量而言，与上一个集群相同，但它配有一个特斯拉 T4 GPU:</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi pm"><img src="../Images/6d32827b6c23d08bb0f36bae3f47fb9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iofC7ECNBv6wZFhMTVRhvQ.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">Databricks 单节点集群— AWS 实例配置文件</figcaption></figure><p id="4f23" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">现在我们有了一个带 GPU 的单节点集群，我们可以继续我们的基准测试，看看 Hugging Face 在 Databricks 中的性能如何。我将在较小的数据集上运行基准测试，看看哪种批量更适合我们基于 GPU 的机器:</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi pj"><img src="../Images/3057abeb31d42e5659320d7ad8e9f4df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2G5c4bX-kU5sVTw6LqCpmQ.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">Databricks 单节点 CPU 上的拥抱人脸图像分类流水线—预测 3544 幅图像</figcaption></figure><p id="2420" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">在我们使用 GPU 设备的单节点 Databricks 集群上，大约花了一分钟(<strong class="kv io"> 64 秒</strong>)完成了对来自样本数据集的大约<strong class="kv io"> 3544 张图像的处理。如果我们查看批量大小为 1 的结果，批处理提高了速度，但是，在批量大小为 8 之后，结果几乎保持不变。虽然在批量大小为 8 之后结果是相同的，但我还是为我的更大的基准选择了批量大小为<strong class="kv io"> 256 </strong>，以便利用更多的 GPU 内存。(说实话，8 和 256 的表现都差不多)</strong></p><p id="2a4e" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">让我们在更大的数据集上运行基准测试，看看批量大小为 256 时会发生什么:</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi pn"><img src="../Images/7cbab7a09a7a506492ef7a6d08ff8230.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r0uysYipVcaVMqkAE3Tf1g.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">Databricks 单节点 CPU 上的拥抱人脸图像分类流水线—预测 34745 幅图像</figcaption></figure><p id="40dc" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">在一个更大的数据集上，对超过 34K 的图像完成分类预测需要将近 11 分钟(<strong class="kv io"> 659 秒</strong>)。如果我们将基准测试的结果在带有 CPU 的单个节点和带有 1 个 GPU 的单个节点上进行比较，我们可以看到 GPU 节点胜出:</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi po"><img src="../Images/cd377970ad3a8cc5a4d5b6946e87df17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ojClDZP-rzXIdv4HlGzC6A.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">拥抱脸(PyTorch)在 GPU 上比 CPU 快 2.3 倍</figcaption></figure><blockquote class="lq lr ls"><p id="fce5" class="kt ku lt kv b kw kx jo ky kz la jr lb lu ld le lf lv lh li lj lw ll lm ln lo ig bi translated">与在 Databricks 单节点上的 Hugging Face 中的 CPU 上运行相同的流水线相比，<strong class="kv io"> GPU </strong>的速度快了<strong class="kv io">到 2.3 倍</strong></p></blockquote><p id="511e" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">现在，我们将通过在相同的集群和相同的数据集上使用 Spark NLP 来运行相同的基准，以将其与拥抱脸进行比较。</p><h2 id="2129" class="mh mi in bd ks mj pp dn ml mm pq dp mo lc pr mq mr lg ps mt mu lk pt mw mx my bi translated">在单节点数据块上对 Spark NLP 进行基准测试</h2><p id="0b6b" class="pw-post-body-paragraph kt ku in kv b kw nb jo ky kz nc jr lb lc oz le lf lg pa li lj lk pb lm ln lo ig bi translated">首先，让我们在您的单节点数据块 CPU 中安装 Spark NLP:</p><ul class=""><li id="621f" class="mz na in kv b kw kx kz la lc pu lg pv lk pw lo ng nh ni nj bi translated">在您的集群中的<strong class="kv io">库</strong>选项卡中，您需要执行以下步骤:<br/> —安装新的-&gt;PyPI-&gt;<strong class="kv io">Spark-NLP = = 4 . 1 . 0</strong>-&gt;安装<br/> —安装新的- &gt; Maven - &gt;坐标-&gt;<strong class="kv io">com . johnsnowlabs . NLP:Spark-NLP _ 2.12:4 . 1 . 0</strong>-&gt;安装【T12</li></ul><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi px"><img src="../Images/4fb93232c5c89cba2f5e25d8d6d50a99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BeHyZZYDT-OHEbrmxrzAPA.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">如何在 Python、Scala 和 Java 的 CPU 上的 Databricks 中安装 Spark NLP</figcaption></figure><p id="ffa1" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated"><strong class="kv io">AWS 上带 CPU 的 Databricks 单节点中的 Spark NLP</strong></p><p id="12a2" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">现在，我们已经在 Databricks 单节点集群上安装了 Spark NLP，我们可以在 CPU 和 GPU 上对样本和完整数据集重复基准测试。让我们先从样本数据集上的 CPU 性能指标评测开始:</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi py"><img src="../Images/fc83345c931d718b0fb69e8c33403294.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ihFgKzxXzQS3OHmFGMD9pA.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">Databricks 单节点 CPU(one dnn)上的 Spark NLP 图像分类流水线—预测 3544 幅图像</figcaption></figure><p id="5ada" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">用了大约 2 分钟(<strong class="kv io"> 111 秒</strong>)完成了对<strong class="kv io"> 3544 张图像</strong>的处理，并在同一个单节点 Databricks 集群上预测了它们的类别，该集群使用了我们用于拥抱脸的 CPU。我们可以看到，批量大小为 16 具有最佳结果，因此我将在下一个更大数据集的基准测试中使用它:</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi pz"><img src="../Images/7411e107aabf3ce1b6d167fdccfbe41a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cBNtHmj2x7ukisDhgj42XA.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">Databricks 单节点 CPU(one dnn)上的 Spark NLP 图像分类流水线—预测 34742 幅图像</figcaption></figure><p id="be20" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">在拥有超过<strong class="kv io"> 34K 张图像</strong>的大型数据集上，完成这些图像的分类预测大约需要 18 分钟(<strong class="kv io"> 1072 秒</strong>)。接下来，我将在使用 GPU 的集群上重复相同的基准测试。</p><p id="980a" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated"><strong class="kv io">AWS 上带 GPU 的数据块单节点</strong></p><p id="5d95" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">首先，在您的单节点数据块<strong class="kv io"> GPU </strong>中安装 Spark NLP(唯一的区别是使用了 Maven 的"<strong class="kv io"> spark-nlp-gpu" </strong>):</p><ul class=""><li id="6c21" class="mz na in kv b kw kx kz la lc pu lg pv lk pw lo ng nh ni nj bi translated">在你的<strong class="kv io">数据块集群</strong> <br/>中安装<strong class="kv io">Spark NLP</strong>——在集群内的<strong class="kv io">库</strong>标签中你需要遵循这些步骤:<br/> —安装新的-&gt;PyPI-&gt;<strong class="kv io">Spark-NLP = = 4 . 1 . 0</strong>-&gt;安装<br/> —安装新的- &gt; Maven - &gt;坐标-&gt;<strong class="kv io">com . johnsnow</strong></li></ul><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi px"><img src="../Images/261e2e52951d8db503e803b23e8a2f61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KdLyOI3B9bBWKBKSwARyhA.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">如何在用于 Python、Scala 和 Java 的 GPU 上的 Databricks 中安装 Spark NLP</figcaption></figure><p id="95e9" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">我将在较小的数据集上运行基准测试，看看哪种批量更适合我们基于 GPU 的机器:</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi qa"><img src="../Images/3adbff5094def6ea971fd156e0731801.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gB_mAqAH2zHKS6paetf-lw.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">Databricks 单节点 GPU 上的 Spark NLP 图像分类流水线—预测 3544 幅图像</figcaption></figure><p id="2316" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">用了不到一分钟(<strong class="kv io"> 47 秒</strong>)的时间，我们用 GPU 设备在单节点数据块上完成了对来自样本数据集的<strong class="kv io"> 3544 张图像</strong>的处理。我们可以看到<strong class="kv io">批量 8 </strong>在这个特定用例中表现最佳，因此我将在更大的数据集上运行基准测试:</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi qb"><img src="../Images/e877cdd0a9296b188a98d19d3adcddd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SGB17-xyZORbT3jte8D4cg.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">Databricks 单节点 GPU 上的 Spark NLP 图像分类流水线—预测 34742 幅图像</figcaption></figure><p id="719d" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">在一个更大的数据集上，花了将近 7 分半钟(<strong class="kv io"> 435 秒</strong>)来完成对超过<strong class="kv io"> 34K 图像的分类预测</strong>。如果我们将基准测试的结果在带有 CPU 的单个节点和带有 1 个 GPU 的单个节点上进行比较，我们可以看到 GPU 节点胜出:</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi qc"><img src="../Images/6f58721ce0470e6edf4bab7556d05f7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*73Ad0brwvQBrZbCXREQjgQ.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">在 Databricks 单节点中，Spark NLP 在 GPU 上的速度是 CPU 的 2.5 倍</figcaption></figure><blockquote class="lq lr ls"><p id="a23a" class="kt ku lt kv b kw kx jo ky kz la jr lb lu ld le lf lv lh li lj lw ll lm ln lo ig bi translated">这太棒了！我们可以看到，即使启用了 oneDNN，GPU 上的 Spark NLP 也比 CPU 快 2.5 倍(oneDNN 将 CPU 的性能提高了 10%至 20%)。</p></blockquote><p id="a2d4" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">让我们来看看这些结果如何与相同 Databricks 单节点集群中的拥抱脸基准进行比较:</p><div class="kd ke kf kg gt ab cb"><figure class="qd kh qe qf qg qh qi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><img src="../Images/62b802536b5976c88f59c91a6ef7713a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*PrEqyCMAz0E12DeRoTnhTg.png"/></div></figure><figure class="qd kh qj qf qg qh qi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><img src="../Images/63cfc22a75372f97486f2e658c1640e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*MK_KwU0F7mnMkUup7VkS-Q.png"/></div></figure></div><blockquote class="lq lr ls"><p id="f10b" class="kt ku lt kv b kw kx jo ky kz la jr lb lu ld le lf lv lh li lj lw ll lm ln lo ig bi translated"><strong class="kv io"> Spark NLP </strong>在预测具有 3K 图像的样本数据集的图像类别时，在<strong class="kv io">CPU 上比拥抱脸</strong>快达<strong class="kv io"> 15% </strong>，在具有 34K 图像的较大数据集上快达<strong class="kv io"> 34% </strong>。<strong class="kv io"> Spark NLP </strong>在单个<strong class="kv io"> GPU 上比拥抱脸</strong>快<strong class="kv io"> 51%,对于具有 34K 图像的较大数据集，在具有 3K 图像的较小数据集上快<strong class="kv io">36%</strong><strong class="kv io"/>。</strong></p></blockquote><div class="kd ke kf kg gt ab cb"><figure class="qd kh qk qf qg qh qi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><img src="../Images/6c02402ab4873845f8be0c77f4058a58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*StuxKGsOi0PUUmTo6SDvLw.png"/></div></figure><figure class="qd kh qk qf qg qh qi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><img src="../Images/1dbb0c2a62ec9e28d28b6646c8ef0895.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*pIi7Cf1_NRSua-M5dIkc1w.png"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk ql di qm qn translated"><strong class="bd ks"> Spark NLP </strong>在<strong class="bd ks">CPU</strong>和<strong class="bd ks">GPU</strong>上比在 Databricks 单节点中的<strong class="bd ks">拥抱面</strong>更快</figcaption></figure></div><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi qo"><img src="../Images/8451e4b37be84241d8c1cf6e16eade92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PboaEOwMcTHdBpBGgLujNQ.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated"><strong class="bd ks"> Spark NLP </strong>在数据块单节点中的<strong class="bd ks">CPU</strong>和<strong class="bd ks">GPU</strong>与<strong class="bd ks">拥抱面</strong>上都更快</figcaption></figure></div><div class="ab cl oh oi hr oj" role="separator"><span class="ok bw bk ol om on"/><span class="ok bw bk ol om on"/><span class="ok bw bk ol om"/></div><div class="ig ih ii ij ik"><p id="38bf" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">在<a class="ae lp" href="https://medium.com/@maziyar/scale-vision-transformers-vit-beyond-hugging-face-part-3-5b8c13ef6477" rel="noopener"> <strong class="kv io">第 3 部分</strong> </a>中，我将在 Databricks 多节点(CPU &amp; GPU)上运行相同的基准测试，以比较 Spark NLP 与 Hugging Face。</p><h1 id="6502" class="oo mi in bd ks op qp or ml os qq ou mo jt qr ju mr jw qs jx mu jz qt ka mx oy bi translated">参考</h1><p id="cedc" class="pw-post-body-paragraph kt ku in kv b kw nb jo ky kz nc jr lb lc oz le lf lg pa li lj lk pb lm ln lo ig bi translated"><strong class="kv io"> ViT </strong></p><ul class=""><li id="7d2c" class="mz na in kv b kw kx kz la lc pu lg pv lk pw lo ng nh ni nj bi translated"><a class="ae lp" href="https://arxiv.org/pdf/2010.11929.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2010.11929.pdf</a></li><li id="b56a" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://github.com/google-research/vision_transformer" rel="noopener ugc nofollow" target="_blank">https://github.com/google-research/vision_transformer</a></li><li id="0d5a" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://viso.ai/deep-learning/vision-transformer-vit/" rel="noopener ugc nofollow" target="_blank">图像识别中的视觉变压器(ViT)——2022 指南</a></li><li id="71aa" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated">【https://github.com/lucidrains/vit-pytorch T4】</li><li id="f236" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://medium.com/mlearning-ai/an-image-is-worth-16x16-words-transformers-for-image-recognition-at-scale-51f3561a9f96" rel="noopener">https://medium . com/mlearning-ai/an-image-is-worth-16x 16-words-transformers-for-image-recognition-at-scale-51f 3561 a9f 96</a></li><li id="3efb" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://medium.com/nerd-for-tech/an-image-is-worth-16x16-words-transformers-for-image-recognition-at-scale-paper-summary-3a387e71880a" rel="noopener">https://medium . com/nerd-for-tech/an-image-worth-16x 16-words-transformers-for-image-recognition-at-scale-paper-summary-3a 387 e 71880 a</a></li><li id="df17" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://gareemadhingra11.medium.com/summary-of-paper-an-image-is-worth-16x16-words-3f7f3aca941" rel="noopener">https://gareemadhingra 11 . medium . com/summary-of-paper-an-image-worth-16x 16-words-3f 7 F3 ACA 941</a></li><li id="8176" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://medium.com/analytics-vidhya/vision-transformers-bye-bye-convolutions-e929d022e4ab" rel="noopener">https://medium . com/analytics-vid hya/vision-transformers-bye-bye-convolutions-e 929d 022 E4 ab</a></li><li id="f68c" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://medium.com/syncedreview/google-brain-uncovers-representation-structure-differences-between-cnns-and-vision-transformers-83b6835dbbac" rel="noopener">https://medium . com/synced review/Google-brain-uncovers-re presentation-structure-differences-between-CNN-and-vision-transformers-83b 6835 db BAC</a></li></ul><p id="37a4" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated"><strong class="kv io">抱紧脸</strong></p><ul class=""><li id="734b" class="mz na in kv b kw kx kz la lc pu lg pv lk pw lo ng nh ni nj bi translated"><a class="ae lp" href="https://huggingface.co/docs/transformers/main_classes/pipelines" rel="noopener ugc nofollow" target="_blank">https://hugging face . co/docs/transformers/main _ classes/pipelines</a></li><li id="a212" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://huggingface.co/blog/fine-tune-vit" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/blog/fine-tune-vit</a></li><li id="6a7a" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://huggingface.co/blog/vision-transformers" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/blog/vision-transformers</a></li><li id="5b51" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://huggingface.co/blog/tf-serving-vision" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/blog/tf-serving-vision</a></li><li id="a69b" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://huggingface.co/blog/deploy-tfserving-kubernetes" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/blog/deploy-tfserving-kubernetes</a></li><li id="eb7f" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://huggingface.co/google/vit-base-patch16-224" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/google/vit-base-patch16-224</a></li><li id="398e" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://huggingface.co/blog/deploy-vertex-ai" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/blog/deploy-vertex-ai</a></li><li id="decb" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated">https://huggingface.co/models?other=vit<a class="ae lp" href="https://huggingface.co/models?other=vit" rel="noopener ugc nofollow" target="_blank"/></li></ul><p id="c6e2" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated"><strong class="kv io">数据砖块</strong></p><ul class=""><li id="7cda" class="mz na in kv b kw kx kz la lc pu lg pv lk pw lo ng nh ni nj bi translated"><a class="ae lp" href="https://www.databricks.com/spark/getting-started-with-apache-spark" rel="noopener ugc nofollow" target="_blank">https://www . data bricks . com/spark/getting-started-with-Apache-spark</a></li><li id="7f24" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://docs.databricks.com/getting-started/index.html" rel="noopener ugc nofollow" target="_blank">https://docs.databricks.com/getting-started/index.html</a></li><li id="53ad" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://docs.databricks.com/getting-started/quick-start.html" rel="noopener ugc nofollow" target="_blank">https://docs . databricks . com/getting-started/quick-start . html</a></li><li id="5d01" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated">看最好的<a class="ae lp" href="https://www.databricks.com/dataaisummit/" rel="noopener ugc nofollow" target="_blank">数据+AI 峰会 2022 </a></li><li id="b422" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://www.databricks.com/blog/2020/05/15/shrink-training-time-and-cost-using-nvidia-gpu-accelerated-xgboost-and-apache-spark-on-databricks.html" rel="noopener ugc nofollow" target="_blank">https://www . data bricks . com/blog/2020/05/15/shrink-training-time-and-cost-using-NVIDIA-GPU-accelerated-xgboost-and-Apache-spark-on-data bricks . html</a></li></ul><p id="1950" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated"><strong class="kv io">火花 NLP </strong></p><ul class=""><li id="2e9c" class="mz na in kv b kw kx kz la lc pu lg pv lk pw lo ng nh ni nj bi translated"><a class="ae lp" href="https://github.com/JohnSnowLabs/spark-nlp" rel="noopener ugc nofollow" target="_blank"> Spark NLP GitHub </a></li><li id="c1bc" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://github.com/JohnSnowLabs/spark-nlp-workshop" rel="noopener ugc nofollow" target="_blank"> Spark NLP 研讨会</a> (Spark NLP 示例)</li><li id="a4af" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://nlp.johnsnowlabs.com/docs/en/transformers" rel="noopener ugc nofollow" target="_blank">火花 NLP 变压器</a></li><li id="ec4d" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://nlp.johnsnowlabs.com/models?edition=Spark+NLP" rel="noopener ugc nofollow" target="_blank"> Spark NLP 车型轮毂</a></li><li id="62f1" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://www.johnsnowlabs.com/watch-webinar-speed-optimization-benchmarks-in-spark-nlp-3-making-the-most-of-modern-hardware/" rel="noopener ugc nofollow" target="_blank">Spark NLP 3 中的速度优化&amp;基准测试:充分利用现代硬件</a></li><li id="e1a8" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://nlp.johnsnowlabs.com/docs/en/hardware_acceleration" rel="noopener ugc nofollow" target="_blank">Spark NLP 中的硬件加速</a></li><li id="0469" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://medium.com/spark-nlp/serving-spark-nlp-via-api-spring-and-lightpipelines-64d2e6413327" rel="noopener">通过 API 服务 Spark NLP:Spring 和 LightPipelines </a></li><li id="27bb" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://medium.com/spark-nlp/serving-spark-nlp-via-api-1-3-microsoft-synapse-ml-2c77a3f61f9d" rel="noopener">通过 API 服务 Spark NLP(1/3):微软的 Synapse ML </a></li><li id="eb33" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://medium.com/spark-nlp/serving-spark-nlp-via-api-2-3-fastapi-and-lightpipelines-218d1980c9fc" rel="noopener">通过 API (2/3)服务 Spark NLP:FastAPI 和 LightPipelines </a></li><li id="13c6" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://medium.com/spark-nlp/serving-spark-nlp-via-api-3-3-databricks-and-mlflow-serve-apis-4ef113e7fac4" rel="noopener">通过 API 服务 Spark NLP(3/3):数据块作业和 MLFlow 服务 API</a></li><li id="31d7" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://aws.amazon.com/blogs/opensource/leverage-deep-learning-in-scala-with-gpu-on-spark-3-0/" rel="noopener ugc nofollow" target="_blank">利用 Scala 中的深度学习和 Spark 3.0 上的 GPU</a></li><li id="0ea4" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://www.nvidia.com/en-us/ai-data-science/spark-ebook/getting-started-spark-3/" rel="noopener ugc nofollow" target="_blank">开始使用 GPU 加速的 Apache Spark 3 </a></li><li id="9039" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated"><a class="ae lp" href="https://spark.apache.org/docs/latest/sql-performance-tuning.html" rel="noopener ugc nofollow" target="_blank"> Apache Spark 性能调优</a></li><li id="5d7f" class="mz na in kv b kw nk kz nl lc nm lg nn lk no lo ng nh ni nj bi translated">GPU 上可能的额外优化:<a class="ae lp" href="https://nvidia.github.io/spark-rapids/docs/configs.html" rel="noopener ugc nofollow" target="_blank">Apache Spark 配置的 RAPIDS 加速器</a></li></ul></div></div>    
</body>
</html>