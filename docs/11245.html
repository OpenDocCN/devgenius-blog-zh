<html>
<head>
<title>Programming with RDDs in PySpark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PySpark 中的 RDDs 编程</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/programming-with-rdds-in-pyspark-5889ff90da91?source=collection_archive---------10-----------------------#2022-12-27">https://blog.devgenius.io/programming-with-rdds-in-pyspark-5889ff90da91?source=collection_archive---------10-----------------------#2022-12-27</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><figure class="gl gn jl jm jn jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi jk"><img src="../Images/60bd032c92811dc24a7f3469aa3ad2bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RUzjm7RAJlj8mUpZErcKFw.jpeg"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk translated">Matthew Jungling 在<a class="ae jz" href="https://unsplash.com/photos/xBhVNtslEuE?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h1 id="9593" class="ka kb in bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">PySpark 中的 RDDs 编程</h1><figure class="kz la lb lc gt jo gh gi paragraph-image"><div class="gh gi ky"><img src="../Images/86b9903db2b11e8f6fac5231404713bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/0*iDF0TjY1yzRr7VYT"/></div></figure><p id="aa56" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">当处理大数据时，这是当今时代数据科学家的一种需要，执行是在 Apache spark 上进行的。spark 最初构建于 Scala 之上，现在可以使用 PySpark 在 Python 之上运行。</p><p id="447e" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">在高层次上，每个 Spark 应用程序都由一个驱动程序组成，该程序运行用户的主要功能，并在集群上执行各种并行操作。Spark 提供的主要抽象是一个弹性分布式数据集(RDD ),这是一个跨集群节点划分的元素集合，可以并行操作。</p><p id="c405" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">这篇博客主要是使用 PySpark 对 RDD 进行一个温和的介绍。</p><p id="db92" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">Spark 中的 RDD(弹性分布式数据集)只是一个<strong class="lf io">不可变的分布式对象集合</strong>。每个 RDD 被分成多个分区，这些分区可以在集群的不同节点上进行计算。rdd 是 PySpark 中的基本数据类型。</p><h2 id="92cc" class="mb kb in bd kc mc md dn kg me mf dp kk lo mg mh ko ls mi mj ks lw mk ml kw mm bi translated">先决条件:</h2><ol class=""><li id="2696" class="mn mo in lf b lg mp lk mq lo mr ls ms lw mt ma mu mv mw mx bi translated">大数据基础</li><li id="50bd" class="mn mo in lf b lg my lk mz lo na ls nb lw nc ma mu mv mw mx bi translated">Pyspark 工作原理和基本原理</li><li id="b4a4" class="mn mo in lf b lg my lk mz lo na ls nb lw nc ma mu mv mw mx bi translated">Python 知识</li></ol><h2 id="71a2" class="mb kb in bd kc mc md dn kg me mf dp kk lo mg mh ko ls mi mj ks lw mk ml kw mm bi translated">配置平台</h2><p id="4c7b" class="pw-post-body-paragraph ld le in lf b lg mp li lj lk mq lm ln lo nd lq lr ls ne lu lv lw nf ly lz ma ig bi translated">我们将使用 Google collaboratory 来运行 PySpark 命令，所以首先让我们配置 Colab。</p><figure class="kz la lb lc gt jo"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="ce64" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">现在让我们初始化一个 Spark 会话</p><figure class="kz la lb lc gt jo"><div class="bz fp l di"><div class="ng nh l"/></div></figure><figure class="kz la lb lc gt jo"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="1590" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">太好了！</p><p id="1392" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">我们安装了 PySpark，并在 colab 中用一个命令启动了一个 Spark 会话。现在让我们创建 rdd。</p><h1 id="03a1" class="ka kb in bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">在火花中创造 RDD</h1><p id="ec00" class="pw-post-body-paragraph ld le in lf b lg mp li lj lk mq lm ln lo nd lq lr ls ne lu lv lw nf ly lz ma ig bi translated">创建数据框有两种方式:</p><ol class=""><li id="bad8" class="mn mo in lf b lg lh lk ll lo ni ls nj lw nk ma mu mv mw mx bi translated">通过加载外部数据集</li><li id="d9c0" class="mn mo in lf b lg my lk mz lo na ls nb lw nc ma mu mv mw mx bi translated">分发一组对象集合</li></ol><p id="8dac" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">让我们首先使用<code class="fe nl nm nn no b">parallelize()</code>方法从程序中已经存在的对象集合中创建 RDD。</p><figure class="kz la lb lc gt jo"><div class="bz fp l di"><div class="ng nh l"/></div></figure><figure class="kz la lb lc gt jo"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="cd6f" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated"><code class="fe nl nm nn no b">show()</code> —打印数据帧中的前 20 行</p><figure class="kz la lb lc gt jo"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="50ea" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated"><code class="fe nl nm nn no b">collect()</code> —以数组形式返回 RDD 的所有元素</p><figure class="kz la lb lc gt jo"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="326a" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">我们还可以使用<code class="fe nl nm nn no b">read.csv()</code>从 CSV 文件创建 RDD，首先创建一个数据帧，然后使用<code class="fe nl nm nn no b">.rdd</code>将其转换为 RDD</p><figure class="kz la lb lc gt jo"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="bd6a" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated"><code class="fe nl nm nn no b">first()</code>命令从 RDD 中检索第一条记录</p><p id="a76a" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">使用<code class="fe nl nm nn no b">textFile()</code>从文本文件创建 RDD</p><figure class="kz la lb lc gt jo"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="b9c2" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">使用<code class="fe nl nm nn no b">read.json()</code>从一个 JSON 文件创建一个 RDD，这会创建一个数据框，我们使用<code class="fe nl nm nn no b">.rdd</code>将它转换成 RDD</p><figure class="kz la lb lc gt jo"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="1064" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated"><code class="fe nl nm nn no b">take(n)</code>返回包含数据集前 n 个元素的数组</p><p id="f3e4" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">注意:rdd 也可以从以下位置创建</p><ol class=""><li id="6f27" class="mn mo in lf b lg lh lk ll lo ni ls nj lw nk ma mu mv mw mx bi translated">通过从数据库中读取数据集</li></ol><p id="dfc5" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">语法-</p><pre class="kz la lb lc gt np no nq bn nr ns bi"><span id="c372" class="nt kb in no b be nu nv l nw nx">df = spark.read.jdbc(url=url, table=table_name,properties=properties)</span></pre><ol class=""><li id="a909" class="mn mo in lf b lg lh lk ll lo ni ls nj lw nk ma mu mv mw mx bi translated">被一个 HDFS 人</li></ol><p id="3ad0" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">语法-</p><pre class="kz la lb lc gt np no nq bn nr ns bi"><span id="7973" class="nt kb in no b be nu nv l nw nx">from pyspark.sql import HiveContext<br/>hc = HiveContext(sc)<br/>tf1 = sc.textFile("hdfs://.../demo.CSV")<br/>hc.sql("use intg_cme_w")<br/>spf = hc.sql("SELECT * FROM spf LIMIT 100")</span></pre><h1 id="5c5b" class="ka kb in bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">火花操作</h1><p id="4c98" class="pw-post-body-paragraph ld le in lf b lg mp li lj lk mq lm ln lo nd lq lr ls ne lu lv lw nf ly lz ma ig bi translated">有两种主要类型的火花操作:</p><ol class=""><li id="fe8a" class="mn mo in lf b lg lh lk ll lo ni ls nj lw nk ma mu mv mw mx bi translated">转型——在原有的基础上建设新的 RDD</li><li id="2d25" class="mn mo in lf b lg my lk mz lo na ls nb lw nc ma mu mv mw mx bi translated">操作-对 RDD 执行计算并返回值</li></ol><h2 id="2d69" class="mb kb in bd kc mc md dn kg me mf dp kk lo mg mh ko ls mi mj ks lw mk ml kw mm bi translated">转换</h2><p id="4d66" class="pw-post-body-paragraph ld le in lf b lg mp li lj lk mq lm ln lo nd lq lr ls ne lu lv lw nf ly lz ma ig bi translated">PySpark RDD 转换是惰性评估，这意味着 Spark 会根据您在 RDD 上执行的所有操作创建一个图，并且只有在 RDD 上执行操作时才会开始执行图，简单地说，操作只有在被操作调用时才会执行。它用于从一个 RDD 转换/更新到另一个。在 RDD 上执行时，它会产生一个或多个新 RDD。</p><p id="da7e" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">由于 RDD 本质上是不可变的，转换总是创建新的 RDD 而不更新现有的，因此，RDD 转换链创建了 RDD 谱系(也称为 RDD 算子图或 RDD 依赖图)。</p><h2 id="d70c" class="mb kb in bd kc mc md dn kg me mf dp kk lo mg mh ko ls mi mj ks lw mk ml kw mm bi translated">行动</h2><p id="d117" class="pw-post-body-paragraph ld le in lf b lg mp li lj lk mq lm ln lo nd lq lr ls ne lu lv lw nf ly lz ma ig bi translated">另一方面，动作基于 RDD 计算结果，并将其返回给驱动程序或保存到外部存储系统(例如，HDFS)。</p><p id="d2ab" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated"><a class="ae jz" href="https://spark.apache.org/docs/latest/rdd-programming-guide.html#transformations" rel="noopener ugc nofollow" target="_blank">在这里查看所有转换及其描述的官方文档</a></p><p id="1693" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">现在让我们采取一种实用的方法，一步一步地熟悉 RDDs 编程。</p><h1 id="158d" class="ka kb in bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">示例 1</h1><p id="96cd" class="pw-post-body-paragraph ld le in lf b lg mp li lj lk mq lm ln lo nd lq lr ls ne lu lv lw nf ly lz ma ig bi translated">我们将做以下事情-</p><ol class=""><li id="c87c" class="mn mo in lf b lg lh lk ll lo ni ls nj lw nk ma mu mv mw mx bi translated">从 python 列表创建 RDD</li><li id="2dd7" class="mn mo in lf b lg my lk mz lo na ls nb lw nc ma mu mv mw mx bi translated">获取第一个元素</li><li id="9821" class="mn mo in lf b lg my lk mz lo na ls nb lw nc ma mu mv mw mx bi translated">获取前两个元素</li><li id="6456" class="mn mo in lf b lg my lk mz lo na ls nb lw nc ma mu mv mw mx bi translated">获取 RDD 中的分区数量</li></ol><p id="dcdc" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">我们将使用<code class="fe nl nm nn no b">parallelize()</code>方法从列表中创建一个 RDD。</p><p id="b7e8" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">对于大数据，甚至是表格数据，一个表可能有 1000 多列。有时，分析人员想看看那些数据列是什么样子。该函数定义在 RDD 上，将返回 RDD 的第一个元素。</p><p id="7442" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">要从列表中获取多个元素，我们可以使用<code class="fe nl nm nn no b">take()</code>。</p><p id="cfde" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">使用<code class="fe nl nm nn no b">getNumPartitions()</code>可以获取集合的分区数量。</p><figure class="kz la lb lc gt jo"><div class="bz fp l di"><div class="ng nh l"/></div></figure><figure class="kz la lb lc gt jo"><div class="bz fp l di"><div class="ng nh l"/></div></figure><figure class="kz la lb lc gt jo"><div class="bz fp l di"><div class="ng nh l"/></div></figure><h1 id="eda0" class="ka kb in bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">示例 2</h1><p id="b480" class="pw-post-body-paragraph ld le in lf b lg mp li lj lk mq lm ln lo nd lq lr ls ne lu lv lw nf ly lz ma ig bi translated">我们将做以下事情-</p><ol class=""><li id="5486" class="mn mo in lf b lg lh lk ll lo ni ls nj lw nk ma mu mv mw mx bi translated">从 python 列表创建 RDD</li><li id="6bfa" class="mn mo in lf b lg my lk mz lo na ls nb lw nc ma mu mv mw mx bi translated">将每个值增加 1.1 倍</li><li id="5f5e" class="mn mo in lf b lg my lk mz lo na ls nb lw nc ma mu mv mw mx bi translated">过滤掉大于特定值的值</li></ol><div class="ny nz gp gr oa ob"><a href="https://carbon.now.sh/?bg=rgba%2528171%252C+184%252C+195%252C+1%2529&amp;t=night-owl&amp;wt=none&amp;l=markdown&amp;width=500&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=false&amp;pv=10px&amp;ph=9px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14.5px&amp;lh=133%2525&amp;si=false&amp;es=1x&amp;wm=false&amp;code=%252523%252520create%252520an%252520RDD%252520from%252520a%252520python%252520list%25250A%252523%252520this%252520list%252520contains%252520prices%252520of%252520productX%252520in%252520year%2525202021%252520each%252520month%25250AtempData%252520%25253D%252520%25255B59%25252C57.2%25252C53.6%25252C55.4%25252C51.8%25252C53.6%25252C55.4%25252C57%25252C59.2%25252C56.8%25252C53.9%25252C55.5%25255D%25250Ardd%252520%25253D%252520sc.parallelize%2528tempData%2529%25250Ardd.collect%2528%2529%25250A%252520%252520%252520%252520%252520%25250A%25255B59%25252C%25252057.2%25252C%25252053.6%25252C%25252055.4%25252C%25252051.8%25252C%25252053.6%25252C%25252055.4%25252C%25252057%25252C%25252059.2%25252C%25252056.8%25252C%25252053.9%25252C%25252055.5%25255D" rel="noopener  ugc nofollow" target="_blank"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd io gy z fp og fr fs oh fu fw im bi translated">碳</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">Carbon 是创建和共享源代码美丽图像的最简单方式。</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">碳. now.sh</p></div></div><div class="ok l"><div class="ol l om on oo ok op jt ob"/></div></div></a></div><figure class="kz la lb lc gt jo"><div class="bz fp l di"><div class="ng nh l"/></div></figure><figure class="kz la lb lc gt jo"><div class="bz fp l di"><div class="ng nh l"/></div></figure><figure class="kz la lb lc gt jo"><div class="bz fp l di"><div class="ng nh l"/></div></figure><figure class="kz la lb lc gt jo"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="9687" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">我们最终有四个元素指示温度大于或等于 13。现在您已经了解了使用 PySpark 对数据进行基本分析的方法。</p><h1 id="adf2" class="ka kb in bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">示例 3:基本数据操作</h1><p id="16f8" class="pw-post-body-paragraph ld le in lf b lg mp li lj lk mq lm ln lo nd lq lr ls ne lu lv lw nf ly lz ma ig bi translated">我们将做以下工作:</p><ol class=""><li id="d752" class="mn mo in lf b lg lh lk ll lo ni ls nj lw nk ma mu mv mw mx bi translated">从表格中列出清单</li><li id="a0d8" class="mn mo in lf b lg my lk mz lo na ls nb lw nc ma mu mv mw mx bi translated">并行化数据</li><li id="ccbb" class="mn mo in lf b lg my lk mz lo na ls nb lw nc ma mu mv mw mx bi translated">计算平均值</li><li id="4f53" class="mn mo in lf b lg my lk mz lo na ls nb lw nc ma mu mv mw mx bi translated">过滤平均值</li><li id="2152" class="mn mo in lf b lg my lk mz lo na ls nb lw nc ma mu mv mw mx bi translated">查找最佳结果</li><li id="133d" class="mn mo in lf b lg my lk mz lo na ls nb lw nc ma mu mv mw mx bi translated">寻找底部结果</li><li id="c120" class="mn mo in lf b lg my lk mz lo na ls nb lw nc ma mu mv mw mx bi translated">基于一个值获取所有结果</li></ol><p id="326c" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">每个学生每年每学期的平均成绩</p><p id="ce46" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">第二年平均成绩最高的前三名学生</p><p id="ae91" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">第二年平均成绩最低的前三名学生</p><p id="1ee4" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">第二年第二学期平均成绩超过 80%的所有学生</p><p id="ca95" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">使用 map()函数通常很有帮助。在本例中，可以使用 map()计算每年每学期的平均成绩。获得前 k 个元素，例如前 k 个高性能债券，是一个一般的数据科学问题。PySpark takeOrdered()函数将从我们的 RDD 中获取顶部 k 或顶部底部元素。可以使用 filter()函数筛选第二年平均成绩超过 80%的学生。</p><figure class="kz la lb lc gt jo"><div class="bz fp l di"><div class="ng nh l"/></div></figure><figure class="kz la lb lc gt jo"><div class="bz fp l di"><div class="ng nh l"/></div></figure><figure class="kz la lb lc gt jo"><div class="bz fp l di"><div class="ng nh l"/></div></figure><figure class="kz la lb lc gt jo"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="f573" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">takeOrdered()函数是一个动作。为了打印结果，我们没有使用 collect()函数来获取数据。记住，转换创建了另一个 RDD，所以我们需要 collect()函数来收集数据。但是一个动作将直接获取数据到驱动程序，而 collect()不是必需的。</p><figure class="kz la lb lc gt jo"><div class="bz fp l di"><div class="ng nh l"/></div></figure><h1 id="22be" class="ka kb in bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">参考文献—</h1><ol class=""><li id="a739" class="mn mo in lf b lg mp lk mq lo mr ls ms lw mt ma mu mv mw mx bi translated">GitHub 查看代码—<a class="ae jz" href="https://github.com/RaghuMadhavTiwari/PySpark-practice/blob/main/Programming_with_RDDs_in_PySpark.ipynb" rel="noopener ugc nofollow" target="_blank">https://GitHub . com/RaghuMadhavTiwari/py spark-practice/blob/main/Programming _ with _ RDDs _ in _ py spark . ipynb</a></li><li id="91ce" class="mn mo in lf b lg my lk mz lo na ls nb lw nc ma mu mv mw mx bi translated">PySpark 食谱 _ 用 PySpark2 解决问题的方法</li></ol><h1 id="cb54" class="ka kb in bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">祝你好运！</h1><p id="4707" class="pw-post-body-paragraph ld le in lf b lg mp li lj lk mq lm ln lo nd lq lr ls ne lu lv lw nf ly lz ma ig bi translated">如果你想进一步讨论这个问题，请通过 LinkedIn 联系我，地址:<a class="ae jz" href="https://www.linkedin.com/in/raghumadhavtiwari/" rel="noopener ugc nofollow" target="_blank"> Raghu Madhav Tiwari </a>！<strong class="lf io">在下面留下掌声和评论支持博客吧！关注更多。</strong></p><p id="0df4" class="pw-post-body-paragraph ld le in lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma ig bi translated">PS:与我进行一对一的会谈(此处为新生或模拟面试提供指导—<a class="ae jz" href="http://topmate.io/raghu_tiwari?utm_source=topmate&amp;utm_medium=popup&amp;utm_campaign=SocialProfile" rel="noopener ugc nofollow" target="_blank">topmate.io/raghu_tiwari?utm_source=topmate&amp;UTM _ medium = popup&amp;UTM _ campaign = social profile</a></p></div></div>    
</body>
</html>