# 数据科学工作流简介

> 原文：<https://blog.devgenius.io/an-introduction-to-the-data-science-workflow-3d165803ed09?source=collection_archive---------12----------------------->

2022 年，数据科学是一个在大多数 STEM 领域都处于领先地位的行业。为了确保您作为数据科学家的成功，保持行业最佳实践以支持您的分析非常重要。每个优秀数据科学家的基础都是高效的数据管道和有效的开发环境，因此在本指南中，我们将讨论优化数据科学家技能的所有最新手段和方法。

## 优化您的开发环境

讨论的第一个创新是关于云笔记本。对于那些不熟悉的人来说，笔记本本质上是一个分隔的计算表，允许你的分析分段。与完整运行传统的 Python 脚本不同，这些笔记本允许用户将代码和计算分成几个部分，而无需在多个文件之间跳转。直到最近，这些笔记本电脑主要托管在云中，允许多个用户随心所欲地访问和编辑代码。然而，这些云实例笔记本的缺点是，即使在最好的情况下，它们也可能是喜怒无常和死板的。如果有一种方法可以用 Git 这样的版本管理工具复制经过测试的本地开发环境，那该多好啊…

欢迎上台，VS 代码。VS Code 最近发布了一个被微软称为 Jupyter 的 VS Code 扩展。这为用户提供了传统云笔记本的所有优势，而没有可变包管理、云认证和网络要求的限制。安装扩展后，Python 代码可以使用`# %%`字符分割成“单元”,并通过单击与“运行”命令相关的单元或选择键盘上的`shift + enter`键来运行。

![](img/122f466a3e0f83b17c3a37f11d7dacc6.png)

左边是我们的本地笔记本，右边是运行前两个代码分段(单元)的输出。

我个人喜欢跟随我的`# %%`角色，给他们起一个适合特定细胞的名字。您可能还注意到，我正在一个虚拟的 Python 环境中运行我的 Python 代码。这使得 Python 包管理特定于一个项目，而不需要任何包管理安装，并且它非常容易配置。要了解更多信息，请查看 Python VirtualEnv 上的指南:

*   [https://medium . com/@ _ Smoljames/python-environments-MAC-best-practices-dd2c 165 Fe 469](https://medium.com/@_Smoljames/python-environments-mac-best-practices-dd2c165fe469)

VS Code Jupyter notebook environment 还支持所有的可视化输出，从数据帧显示到用于绘图和数据显示的软件包，如 Plotly。最后但同样重要的是，您的代码现在可以很容易地用版本控制工具如 Git 和 Github 来管理。这提供了无缝的协作环境和清晰的版本管理。

## 数据科学管道

现在，您已经准备好探索宇宙的秘密，重要的是为您的数据科学管道的最佳实践做好准备，以取得成功。管道代表分析的各个阶段，有效的管道依赖于阶段之间转换的流畅性和自动化。例如，有效的管道可能如下所示:

1.  数据提取
2.  存储原始数据
3.  数据清理
4.  数据处理
5.  存储处理过的数据
6.  生成最终输出(例如指标或图表)

这种管道被认为是有效的，因为整个分析被分成了几个部分，在这些部分中没有不必要的代码运行，并且一个步骤中的失败或更改对另一个步骤的影响很小。例如，如果我在获取数据后忘记保存原始数据，并且我的分析被清除，我将不得不花费时间重新获取相同的数据；我本来可以节省的时间只是在当地的一个地方。csv 文件，。json 文件或数据库。

我推荐的项目结构有三个主要阶段，其中我将每个阶段分成一个单独的文件，每个文件有多个子阶段，表示为单独的单元。例如:

1.  Fetch.py |负责获取数据(从 web 或数据库中)，清理数据，保存原始数据，并创建任何初步文件，如字典。
2.  Analysis.py |负责综合数据分析。
3.  Save.py |负责存储我分析的最终产品和数值结论；主要使用 SQL 数据库，如 PostgreSQL。

我使用本地保存的文件在这些文件之间进行通信。csv 文件，因为 Python 中的 Pandas 库可以有效地在数据帧和。csv 文件。例如，Fetch.py 中的最后一个单元格可能会将 Dataframe 保存为. csv，而 Analysis.py 中的第一个单元格可能会读取。csv 转换成数据帧。这具有为所有关键阶段提供本地保存备份的额外好处。

至于数据科学工具包的面包和黄油，Python 库 Pandas、Numpy、Scipy 和 Plotly 将涵盖任何项目的几乎任何基础。因此，您的第一个单元格可能如下所示:

![](img/7a643a789136787eac06ede04538f17f.png)

任何优秀数据科学项目的基础。

随着存储数据量的增加，第 3 步变得越来越重要。因此，精通 SQL 非常重要，因为它是数据集内 CRUD(创建、读取、更新和删除)操作的主要语言。虽然 SQL 可以直接从终端编写，但我们足够幸运地拥有一些惊人的 Python 包，可以自动将数据直接持久化到数据库中。Python 实例化 SQL 脚本中最新、最棒的是以下两个 Python 包的组合:

*   Asyncpg
*   阿辛西奥

这些包允许直接在 Python 单元中编写 SQL 代码，这有助于使数据持久化连续且几乎是即时的！根据您使用这两种语言的能力，您可以使用其中一种来筛选和处理您选择的指标的数据。要演示如何将信息从. csv 文件写入 PSQL 数据库:

![](img/d62e000b2559860d1cc3cfa42715ffaa.png)

用 Asyncpg 将. csv 文件写入 PostgreSQL 表。

这个 PSQL 实例可以是本地的，也可以是云托管的，例如 Google 云平台 SQL 实例。认证系统的工作原理是一样的。只是要小心云产品的任何成本积累。

恭喜你！你现在已经准备好去分析和破译我们地球上生命的秘密，并为一个越来越符合我们潜意识的世界做出贡献。