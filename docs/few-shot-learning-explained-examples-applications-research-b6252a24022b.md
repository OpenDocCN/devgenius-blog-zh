# 少数镜头学习解释:例子，应用，研究

> 原文：<https://blog.devgenius.io/few-shot-learning-explained-examples-applications-research-b6252a24022b?source=collection_archive---------5----------------------->

![](img/bee0582af21b56042b494edf7cbe9beb.png)

[图像信用](https://unsplash.com/photos/HNiOq7eg8ck)

数据驱动机器学习解决方案。高质量的数据集使训练模型具有所需的检测和分类准确性，尽管有时积累足够的训练数据并将其输入模型是一项复杂的挑战。例如，为了创建数据密集型应用程序，需要人工标注员对大量样本进行标注，这导致了管理的复杂性和企业的高成本。除此之外，还存在与安全法规、隐私或道德问题相关的数据获取困难。

当我们有一个有限的数据集，每个类只包括有限数量的样本时，**少镜头学习**可能是有用的。这种模型训练方法有助于利用小数据集，即使在数据相当稀少的情况下也能达到可接受的精确度。

**在这篇文章中，我将解释什么是少镜头学习，它是如何工作的，并与您分享关于如何使用相对简单的方法从图像分类任务的少镜头学习模型中获得最佳结果的研究结果。**

在了解少量学习的技术和原理之前，让我们找点乐子。

![](img/d3c31918b1c48623425b613f008ca3b4.png)

图像的左边描绘了一只羊驼，右边是一只美洲驼。这些动物很相似，尽管有差异。最重要的区别是羊驼比羊驼更大更重；此外，它们有长长的口鼻，而羊驼的口鼻是扁平的。最容易区分的区别是，羊驼的耳朵长而圆，像香蕉，而羊驼的耳朵又短又漂亮。

你已经学会区分这两种属于骆驼科的动物。考虑到耳朵的不同，试着猜猜下面的查询图片中描绘的是什么动物。

![](img/8c8455852bc370531c2b8706eeb8cec1.png)

[图像信用](https://unsplash.com/photos/sb5kr6-uo2w)

你可能已经发现这是一只美洲驼。四个样本足以让人类区分一种动物和另一种动物，即使这些动物看起来很相似。但是计算机能够处理这样的任务吗？如果类由两个样本组成，机器能做出适当的预测吗？

这项任务比普通的物体分类更复杂，因为缺乏样本使得不可能从头开始训练深度神经网络。这就是少投学习的用武之地。

# 什么是少投学习？

机器学习 app 开发的起点是数据集，数据越多效果越好。通过获得大量的数据，该模型在预测中变得更加准确。然而，在少拍学习(FSL)的情况下，我们需要几乎相同的准确性和更少的数据。这种方法消除了收集和标记数据所需的高模型训练成本。此外，通过 FSL 的应用，我们获得了低维数的数据，减少了计算成本。

请注意，FSL 可以被称为**低射学习** (LSL)，在某些来源中，这构成了训练数据集的容量有限的 ML 问题。

*   FSL 或 LSL 的问题可能与业务挑战有关。它可以是对象识别、图像分类、字符识别、NLP 或其他任务。机器需要执行这些任务，并通过应用 FSL 技术和少量训练数据来处理罕见病例。FSL 的一个显著例子与机器人领域有关。在这个例子中，机器人在熟悉一些演示后，学习如何移动和导航。
*   如果我们只应用一个演示来训练机器人，这将是一个**一次性** ML 问题。在个别情况下，当不是所有的类都在训练中被标记时，我们面临特定类别的零训练样本和一个**零射击** ML 问题。

# 少投学习法

为了解决少量和一次性的机器学习问题，我们可以应用两种方法中的一种。

# 1.数据级方法

如果缺少适合算法的数据，并且为了避免模型的过拟合或欠拟合，则应该添加额外的数据。该算法是数据级方法的核心。各种数据的外部来源有助于其成功实施。例如，在没有足够的不同类别的标记元素的情况下，解决图像分类任务需要分类器。为了构建分类器，我们可以应用具有相似图像的外部数据源，即使这些图像是未标记的并且以半监督的方式集成。

为了补充这种方法，除了外部数据源之外，我们还可以使用一种技术，尝试从与训练数据相同的分布中产生新的数据样本。例如，添加到原始图像的随机噪声导致生成新数据。

或者，可以使用生成对抗网络(GANs)技术来合成新的图像样本。例如，使用这种技术，如果在训练集中有足够多的例子可用，就可以从不同的视角产生新的图像。

# 2.参数级方法

参数级方法涉及元学习——这种技术教会模型理解哪些特征对执行机器学习任务至关重要。这可以通过开发一种策略来控制如何利用模型的参数空间来实现。

限制参数空间有助于解决与过度拟合相关的挑战。基本算法概括了一定数量的训练样本。增强该算法的另一种方法是将它引向广泛的参数空间。

主要任务是教会算法在参数空间选择最优路径，并给出有针对性的预测。在一些资料中，这种技术被称为元学习。

元学习采用教师模型和学生模型。教师模型整理了参数空间的封装。学生模型应该精通如何对训练示例进行分类。从教师模型获得的输出作为学生模型训练的基础。

# 少镜头学习的应用

少量学习形成了最热门领域应用的基本算法**(图 1)** ，即:

*   计算机视觉
*   自然语言处理
*   机器人学
*   音频处理
*   卫生保健
*   物联网

在计算机视觉中，FSL 执行物体和字符识别、图像和视频分类、场景定位等任务。NLP 领域受益于该算法，将其应用于翻译、文本分类、情感分析，甚至刑事指控预测。一个典型的例子是在对几个例子进行短期训练后，机器分析和创建手写字符时提供字符生成。其他用例包括对象跟踪、手势识别、图像字幕和视觉问答。

少数镜头学习有助于训练机器人模仿动作和导航。在音频处理方面，FSL 能够创建克隆语音的模型，并将其转换为不同的语言和用户。

一个很好的例子是药物发现。在这种情况下，该模型正在被训练以研究新的分子，并检测可以添加到新药中的有用分子。没有经过临床试验的新分子可能是有毒的或活性低的，因此使用少量样本训练模型至关重要。

![](img/6b10d82b598df51b56b5f531e0f6a90f.png)

**图一。**少数镜头学习应用

让我们更深入地了解少投学习是如何工作的，并概述 MobiDev 的研究结果。

# 研究:用于图像分类的少镜头学习

我们选择了一个图像分类的问题。为了识别硬币的面额，模型必须确定图像所属的类别。通过将较大的图像分割成包含单个硬币的较小图像，并对每个小图像进行分类，这可以用于快速计算桌子上硬币的总数。

# 数据集

首先，我们需要一些少量的学习数据来进行实验。为此，我们从公共来源收集了一个欧元硬币图像数据集，根据硬币面额的数量分为 8 类**(图 2)** 。

![](img/e27e353cbba84b25d26ac8d59792f3bb.png)

**图二。**图像分类与示例

数据被分成 3 个子集——**支持**(训练)**查询** (val)，以及**测试**集合(关于数据集的统计可以在**图 3** 中看到)。支持和查询数据集被选择来自一个分布，而测试数据集被有目的地选择来自不同的分布——测试中的图像曝光过度/不足、倾斜、显示具有不寻常颜色的硬币、包含模糊等。

这种数据准备是为了模拟生产环境，在这种环境中，模型通常根据来自开放数据集/互联网抓取的高质量数据进行训练和验证，而来自实际操作条件的数据通常是不同的:用户可以使用不同的设备捕捉图像，照明条件较差，等等。一个健壮的 CV 解决方案应该能够在一定程度上解决这些问题，我们的目标是弄清楚这将如何适用于假设我们没有太多数据的少量学习方法。

![](img/68f2fc72b00db176b0229384b87af633.png)

**图 3。**与测试集相比的支持和查询集—测试来自不同的分布

最后，可用数据样本数量的统计可以在**图 4** 中看到。我们设法收集了 121 个数据样本，每个硬币面额约 15 张图像。支持集是平衡的，每个类有相等数量的样本，每个类有多达 4 个图像用于少量的镜头训练，而查询和测试集稍微不平衡，包含大约。每班分别有 7 幅和 4 幅图像。每组的样本数:支持— 32，查询— 57，测试— 31。

![](img/f469c93280e1424a85ba796e6c814618.png)

**图 4。**支持、查询和测试数据集的统计

# 选定的方法

在所选的方法中，我们使用预训练的卷积神经网络(CNN)作为编码器来获得压缩的图像表示。该模型能够生成反映图像内容的有意义的图像表示，因为它已经看到了一个大型数据集，并在少量拍摄学习之前在 [ImageNet](https://www.image-net.org/) 上进行了预训练。然后，这些图像表示可用于少量拍摄学习和分类。

![](img/b63dbaa5c30cf311ad8c624d09b6309e.png)

**图 5。**获取支持矩阵的基线模型工作流

可以采取多个步骤来提高少量学习算法的性能:

1.  基线**(图 5)**
2.  微调
3.  微调+熵正则化
4.  Adam 优化器

# 实验结果

使用选择的模型配置，我们对收集的数据运行了几个实验。首先，我们使用了一个基线模型，没有任何微调或额外的正则化。即使在这种默认设置下，结果也令人惊讶地令人满意，如表 1 所示。查询/测试集的加权 F1 分数为 1: 0.66 / 0.62。我们选择了加权 F1 指标，因为它考虑了班级规模的不平衡，并结合了精确度和召回分数。

在这个阶段，我们试验了支持集的大小。正如预期的，更大的支持集导致更好的查询和测试性能，尽管使用更多样本的好处随着训练集大小的增加而减少**(图 6)** 。

有趣的是，在小支持集规模(1-3)的情况下，查询与测试集的性能会随机变化(一个可以提高，而另一个会降低)，然而，在支持集规模为 4 时，两个集都有所提高。

![](img/480e60f9967efbfdef55b6c34029ca67.png)

**图六**。支持集大小对使用基线模型的**查询**和**测试**集性能的影响

从基线模型开始，通过对来自支持集的小批量应用 Adam optimizer 进行微调，查询和测试集的分数都提高了 2%。当将查询集上的熵正则化添加到微调管道中时，这个结果进一步增强了 1–4%。

需要指出的是，随着加权 F1 分数的提高，精确度也随之提高，这意味着该模型不仅在类别方面表现更好，而且在数据总量方面也表现更好。查询和测试集的最终准确度为 0.7 和 0.68，这意味着只有 4 个图像样本用于训练的模型可以在 40/57 的查询样本和 21/31 的测试集样本中成功地猜出图像的类别。

**表 1。**val/测试数据集上的少量指标

![](img/1a0d8c3d3e8f7487dc09d270d094abbc.png)

查看查询集**(图 7)** 上的混淆矩阵，我们可以发现一些有趣的趋势。首先，模型类别中最容易猜到的是 1 欧元和 2 欧元的大面值硬币，因为这些硬币由两部分组成:内层和外层。两个部分立即使它们与小面值硬币区别开来。

此外，在 1 欧元中，内部由灰色的铜镍合金制成，而外部由金色的镍铜合金制成。在 2 欧元硬币中，合金是反过来的:铜-镍做外层，镍-黄铜做内层。这种特性使得区分硬币变得更加容易。

两个很难弄清楚的组合是 20 美分对 50 美分和 5 美分对 2 美分，因为模型经常混淆这些硬币。这是因为这些类别之间的差别很小:颜色，硬币的形状，甚至文字铭文都是一样的。唯一的区别是硬币的实际面额铭文。由于该模型不是专门针对硬币训练的，所以它不知道应该最关注硬币的哪个区域，因此可能低估面值铭文的重要性。

**图 7。**查询**集合上的**混淆矩阵(集合上的预测遵循相同的模式)

# 包扎

在实践机器学习的高要求世界中，开发的解决方案的准确性与解决方案所需的工作量和数据量之间总是存在平衡。有时，最好快速创建一个仅满足最低精度要求的解决方案，将其部署到生产中，并从那里迭代。在这种情况下，本文描述的方法可以很好地工作。

**我们发现，对于通过图像对硬币进行少量分类的问题，只要给定每个硬币面额 4 个图像样本，就有可能达到约 70%的准确率。**

对于在一组广泛的数据(ImageNet 数据集)上预先训练的模型来说，该问题相当困难，因为该模型不知道它应该关注硬币的哪个特定部分来做出准确的预测，并且我们期望在区别特征将更均匀地分布在图像上(例如，水果类型和质量分类)的情况下，精确度甚至可以更高。

由 [MobiDev](https://mobidev.biz/services/machine-learning-consulting) 的 AI 解决方案架构师 [Maksym Tatariants](https://mobidev.biz/our-team/maksym-tatariants) 撰写。

*全文原载于*[*https://mobidev . biz*](https://mobidev.biz/blog/few-shot-learning-explained-examples-applications-research)*，基于 mobi dev 技术研究。*