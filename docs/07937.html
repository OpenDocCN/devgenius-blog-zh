<html>
<head>
<title>[Failed] Investigating Machine Learning Techniques to Improve Spec Tests — V</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">[失败]调查机器学习技术以改进规格测试— V</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/failed-investigating-machine-learning-techniques-to-improve-spec-tests-v-a388b387bdcd?source=collection_archive---------12-----------------------#2022-05-04">https://blog.devgenius.io/failed-investigating-machine-learning-techniques-to-improve-spec-tests-v-a388b387bdcd?source=collection_archive---------12-----------------------#2022-05-04</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><figure class="gl gn jl jm jn jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi jk"><img src="../Images/27ff06d39ffae4d0bdf0c06b06bce637.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_0pOpIIgHhkv0itoBXP44g.jpeg"/></div></div></figure><h1 id="7096" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">介绍</h1><p id="c138" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">这是与人工智能实现相关的系列博文的一部分。如果你对故事的背景或情节感兴趣:</p><figure class="lr ls lt lu gt jo"><div class="bz fp l di"><div class="lv lw l"/></div></figure><p id="3996" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">本周我们将展示存储和重用训练过的权重，以及我在计算模型的早期结果时犯的严重错误。我们将使用<a class="ae mc" href="https://serpapi.com/organic-results" rel="noopener ugc nofollow" target="_blank"> SerpApi 的 Google Organic Results Scraper API</a>进行数据收集。此外，您可以在<a class="ae mc" href="https://serpapi.com/playground?q=Coffee&amp;location=Austin%2C+Texas%2C+United+States&amp;gl=us&amp;hl=en&amp;no_cache=true&amp;newPara=lr+async+as_qdr" rel="noopener ugc nofollow" target="_blank">操场</a>查看我们将使用的数据的更多详细信息。</p><figure class="lr ls lt lu gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi md"><img src="../Images/25b3a003501bbd39ff2e84677ea243e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*17-cL3YjIgOev2r_.png"/></div></div></figure><h1 id="a372" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">我在计算模型精确度时犯了一个致命的错误</h1><p id="3bb6" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">让我首先给出我用训练例子计算的方法:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="0b86" class="mj jw in mf b gy mk ml l mm mn">true_examples = key_array.map {|el| el = el.first == "1" ? el.second : nil}.compact<br/>false_examples = key_array.map {|el| el = el.first == "0" ? el.second : nil}.compact</span><span id="7ec6" class="mj jw in mf b gy mo ml l mm mn">predictions = []</span><span id="0901" class="mj jw in mf b gy mo ml l mm mn">false_examples.each do |example|<br/>  prediction = test example, 2, vector_array, key_array<br/>  predictions &lt;&lt; prediction<br/>end</span><span id="6235" class="mj jw in mf b gy mo ml l mm mn">predictions.map! {|el| el = el == 1 ? 0 : 1}</span><span id="1ada" class="mj jw in mf b gy mo ml l mm mn">true_examples.each_with_index do |example, index|<br/>  puts "--------------"<br/>  prediction = test example, 2, vector_array, key_array<br/>  predictions &lt;&lt; prediction<br/>  puts "Progress #{(index.to_f/true_examples.size.to_f).to_f}"<br/>  puts "--------------"<br/>end</span><span id="8b55" class="mj jw in mf b gy mo ml l mm mn">prediction_train_accuracy = predictions.sum.to_f / predictions.size.to_f</span><span id="eb15" class="mj jw in mf b gy mo ml l mm mn">puts "Prediction Accuracy for Training Set is: #{prediction_train_accuracy}"</span></pre><p id="e336" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">我们采用的例子是<code class="fe mp mq mr mf b">snippet</code>和<code class="fe mp mq mr mf b">not snippet</code>，并在训练好的模型中运行它们。如果<code class="fe mp mq mr mf b">not snippet</code>实例的预测结果是<code class="fe mp mq mr mf b">0</code>，那么它们将被计为正确预测，如果<code class="fe mp mq mr mf b">snippet</code>结果被计为<code class="fe mp mq mr mf b">1</code>，那么它们也将被计为正确结果。最终正确预测率的结果是<code class="fe mp mq mr mf b">0.8187793427230047</code>。我后来使用了一个更大的数据集，结果大约是<code class="fe mp mq mr mf b">89%</code>。</p><p id="14cc" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">这是我犯下的逻辑谬误；与<code class="fe mp mq mr mf b">snippet</code>结果相比，有更多<code class="fe mp mq mr mf b">non-snippet</code>结果。让我们假设在 10 个单元的示例集中其比率是 1:9。如果模型更倾向于以随机的方式调用事物<code class="fe mp mq mr mf b">non-snippet</code>而不是<code class="fe mp mq mr mf b">snippet</code>，就像这种情况，那么<code class="fe mp mq mr mf b">non-snippet</code>结果将被正确预测，这将在结果中产生偏差。</p><p id="5981" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">之所以在更大的数据集中增加到 89 %,是因为其中有更多类型的键。这导致<code class="fe mp mq mr mf b">snippet</code>大小/ <code class="fe mp mq mr mf b">non-snippet</code>大小进一步最小化，这引发了<code class="fe mp mq mr mf b">non-snippet</code>结果的假阳性预测偏差。</p><p id="5fe4" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">实际上，我应该只使用<code class="fe mp mq mr mf b">snippet</code>例子来测试这个模型。我做了，发现模型没用。我会尝试调整，并找到一种方法，使其有用。但是，我认为更好的办法是在此之前说明我为什么计算失败，以此来通知大家，并防止其他人犯同样的错误。</p><h1 id="d905" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">以定制方式存储训练过的重量</h1><p id="2a9d" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">过了一会儿我才意识到我的错误。在此之前，我已经创建了一种使用模型进行存储和预测的方法。</p><p id="c4ad" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">这是它的完整代码:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="a66d" class="mj jw in mf b gy mk ml l mm mn">class Predict <br/>  def initialize csv_path, trained_weights_path, vocab_path, object = "Snippet", k = 2<br/>    @@csv_path = csv_path<br/>    @@trained_weights_path = trained_weights_path<br/>    @@vocab_path = vocab_path<br/>    @@object = object<br/>    @@k = k<br/>    @@key_arr = []<br/>    @@vector_arr = []<br/>    @@weights = []<br/>    @@maximum_word_size = 0<br/>    @@vocab = {}<br/>  end</span><span id="1cbf" class="mj jw in mf b gy mo ml l mm mn">def self.construct<br/>    @@weights = initialize_trained_weights @@trained_weights_path<br/>    @@vocab = read_vocab @@vocab_path<br/>    @@key_arr = read_csv @@csv_path<br/>    @@vector_arr = define_training_set @@key_arr<br/>    @@maximum_word_size = @@weights.size<br/>    extend_vectors<br/>  end</span><span id="2773" class="mj jw in mf b gy mo ml l mm mn">def self.read_csv csv_path<br/>    CSV.read(csv_path)<br/>  end</span><span id="2e71" class="mj jw in mf b gy mo ml l mm mn">def self.read_vocab vocab_path<br/>    vocab = File.read vocab_path<br/>    JSON.parse(vocab)<br/>  end</span><span id="be11" class="mj jw in mf b gy mo ml l mm mn">def self.initialize_trained_weights trained_weights_path<br/>    weights = File.read trained_weights_path<br/>    weights = JSON.parse(weights)<br/>    Vector.[](*weights)<br/>  end</span><span id="21e8" class="mj jw in mf b gy mo ml l mm mn">def self.define_training_set vectors<br/>    @@key_arr.map { |word| word_to_tensor word[1] }<br/>  end</span><span id="eb6c" class="mj jw in mf b gy mo ml l mm mn">def self.default_dictionary_hash<br/>    {<br/>      /\"/ =&gt; "",<br/>      /\'/ =&gt; " \'  ",<br/>      /\./ =&gt; " . ",<br/>      /,/ =&gt; ", ",<br/>      /\!/ =&gt; " ! ",<br/>      /\?/ =&gt; " ? ",<br/>      /\;/ =&gt; " ",<br/>      /\:/ =&gt; " ",<br/>      /\(/ =&gt; " ( ",<br/>      /\)/ =&gt; " ) ",<br/>      /\// =&gt; " / ",<br/>      /\s+/ =&gt; " ",<br/>      /&lt;br \/&gt;/ =&gt; " , ",<br/>      /http/ =&gt; "http",<br/>      /https/ =&gt; " https ",<br/>    }<br/>  end</span><span id="3efb" class="mj jw in mf b gy mo ml l mm mn">def self.tokenizer word, dictionary_hash = default_dictionary_hash<br/>    word = word.downcase<br/>    dictionary_hash.keys.each do |key|<br/>      word.sub!(key, dictionary_hash[key])<br/>    end<br/>    word.split<br/>  end</span><span id="6f4d" class="mj jw in mf b gy mo ml l mm mn">def self.word_to_tensor word<br/>    token_list = tokenizer word<br/>    token_list.map {|token| @@vocab[token]}<br/>  end</span><span id="87b0" class="mj jw in mf b gy mo ml l mm mn">def self.extend_vector vector<br/>    vector_arr = vector.to_a<br/>    (@@maximum_word_size - vector.size).times { vector_arr &lt;&lt; 1 }<br/>    Vector.[](*vector_arr)<br/>  end</span><span id="be9a" class="mj jw in mf b gy mo ml l mm mn">def self.extend_vectors<br/>    @@vector_arr.each_with_index do |vector, index|<br/>      @@vector_arr[index] = extend_vector vector<br/>    end<br/>  end</span><span id="66bf" class="mj jw in mf b gy mo ml l mm mn">def self.product vector<br/>    @@weights.each_with_index do |weight, index|<br/>      vector[index] = weight * vector[index]<br/>    end</span><span id="10b1" class="mj jw in mf b gy mo ml l mm mn">vector<br/>  end</span><span id="c346" class="mj jw in mf b gy mo ml l mm mn">def self.euclidean_distance vector_1, vector_2<br/>    subtractions = (vector_1 - vector_2).to_a<br/>    subtractions.map! {|sub| sub = sub*sub }<br/>    Math.sqrt(subtractions.sum)<br/>  end</span><span id="0b43" class="mj jw in mf b gy mo ml l mm mn">def self.execute example<br/>    example_vector = word_to_tensor example<br/>    example_vector.map! {|el| el = el.nil? ? 0: el}<br/>    example_vector = extend_vector example_vector<br/>    weighted_example = product example_vector</span><span id="ec4e" class="mj jw in mf b gy mo ml l mm mn">distances = []<br/>    @@vector_arr.each_with_index do |comparison_vector, vector_index|<br/>      distances &lt;&lt; euclidean_distance(comparison_vector, weighted_example)<br/>    end</span><span id="2c79" class="mj jw in mf b gy mo ml l mm mn">indexes = []<br/>    @@k.times do <br/>      index = distances.index(distances.min)<br/>      indexes &lt;&lt; index<br/>      distances[index] = 1000000000<br/>    end</span><span id="83ed" class="mj jw in mf b gy mo ml l mm mn">predictions = []<br/>    indexes.each do |index|<br/>      predictions &lt;&lt; @@key_arr[index].first.to_i<br/>    end</span><span id="b450" class="mj jw in mf b gy mo ml l mm mn">puts "Predictions: #{predictions}"</span><span id="9e96" class="mj jw in mf b gy mo ml l mm mn">prediction = (predictions.sum/predictions.size).to_f<br/>    if prediction &lt; 0.5<br/>      puts "False - Item is not #{@@object}"<br/>      return 0<br/>    else<br/>      puts "True - Item is #{@@object}"<br/>      return 1<br/>    end<br/>  end<br/>end</span><span id="8584" class="mj jw in mf b gy mo ml l mm mn">csv_path = "organic_results/organic_results__snippet.csv"<br/>trained_weights_path = "organic_results/snippet_weights.json"<br/>vocab_path = "organic_results/vocab.json"</span><span id="41d7" class="mj jw in mf b gy mo ml l mm mn">Predict.new csv_path, trained_weights_path, vocab_path, object = "Snippet", k = 5<br/>Predict.construct</span><span id="0719" class="mj jw in mf b gy mo ml l mm mn">true_examples = CSV.read(csv_path)<br/>true_examples = true_examples.map {|el| el = el.first == "1" ? el.second : nil}.compact</span><span id="489d" class="mj jw in mf b gy mo ml l mm mn">true_examples.each_with_index do |example, index|<br/>  puts "--------"<br/>  puts "#{index}"<br/>  Predict.execute example<br/>  puts "--------"<br/>end</span></pre><h1 id="6d08" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">结论</h1><p id="b1eb" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">我真诚地尝试了一个可以减轻考试写作压力的领域，但我失败了。定制代码上的细微错误可能会发生，并导致整体失败。我很感激我尝试了一下，并发现这种方法没有我想象的那么有效。我将在未来继续这方面的工作。然而，在下一篇博文中，主题很可能会有所不同。对于之前博文给出的误导性结果，我向读者道歉，感谢他们的关注。</p></div><div class="ab cl ms mt hr mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ig ih ii ij ik"><p id="d910" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated"><em class="mz">原载于 2022 年 5 月 4 日 https://serpapi.com</em><em class="mz"/><a class="ae mc" href="https://serpapi.com/blog/investigating-macg/" rel="noopener ugc nofollow" target="_blank"><em class="mz">。</em></a></p></div></div>    
</body>
</html>