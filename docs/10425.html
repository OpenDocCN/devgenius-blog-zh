<html>
<head>
<title>Know GOMAXPROCS before deploying your GO app to Kubernetes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在将您的 GO 应用程序部署到 Kubernetes 之前了解 GOMAXPROCS</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/know-gomaxprocs-before-deploying-your-go-app-to-kubernetes-7a458fb63af1?source=collection_archive---------1-----------------------#2022-11-01">https://blog.devgenius.io/know-gomaxprocs-before-deploying-your-go-app-to-kubernetes-7a458fb63af1?source=collection_archive---------1-----------------------#2022-11-01</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><p id="52a9" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">如果您正在编写 Go 并发应用程序并在 Kubnernetes 上运行它，这是您需要了解的配置。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/16705bf0c81bfc850cf6b0204db5836d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3_pdNlEZAsCQjoR9aMP8nw.png"/></div></div></figure><h1 id="451c" class="ku kv in bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">问题是</h1><p id="2a81" class="pw-post-body-paragraph jk jl in jm b jn ls jp jq jr lt jt ju jv lu jx jy jz lv kb kc kd lw kf kg kh ig bi translated">在我们的测试中，我们注意到当服务在高负载下不堪重负时，性能会急剧下降。当我们将用户数量从 30 增加到 50 和 100 时，您可以看到中值和 p95 延迟呈指数级增长。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lx"><img src="../Images/d658650930ceea1b4b1d54549f12d804.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y2PITL9aT3bP1t26MY4z1w.png"/></div></div><figcaption class="ly lz gj gh gi ma mb bd b be z dk translated">当我们对大量用户进行负载测试时，存在响应时间缓慢的问题。</figcaption></figure><p id="3366" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">在查看多个跟踪后，我们在<a class="ae mc" href="https://docs.newrelic.com/docs/apm/agents/go-agent/features/go-runtime-page-troubleshoot-performance-problems/" rel="noopener ugc nofollow" target="_blank"> newrelic 的</a> go-runtime monitor 中发现了一个不寻常的 GC 暂停时间(即<a class="ae mc" href="https://medium.com/a-journey-with-go/go-how-does-go-stop-the-world-1ffab8bc8846" rel="noopener">stop-the-world</a>garbage collection ),这可能是响应时间缓慢的根源。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi md"><img src="../Images/e5c10811a7e7c7792229dbba35fd4717.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C-DoqkaVzw0Pmlb1GiUBTw.png"/></div></div></figure><h1 id="25b5" class="ku kv in bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">根</h1><p id="0517" class="pw-post-body-paragraph jk jl in jm b jn ls jp jq jr lt jt ju jv lu jx jy jz lv kb kc kd lw kf kg kh ig bi translated">但是<strong class="jm io">为什么</strong>GC 暂停时间这么高？—Pods/Go 运行时或 Goroutine 配置有什么办法吗？</p><p id="2907" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">在寻找解决方案时，我们发现了一篇文章，<a class="ae mc" href="https://medium.com/inlocotech/running-go-application-on-kubernetes-6fb55f908258" rel="noopener"> <em class="me">在 Kubernetes </em> </a>上运行 Go 应用程序，其中提到了关于 Go 运行时变量 GOMAXPROCS 的内容。</p><blockquote class="mf mg mh"><p id="0def" class="jk jl me jm b jn jo jp jq jr js jt ju mi jw jx jy mj ka kb kc mk ke kf kg kh ig bi translated">这控制了它可以产生的系统线程的数量。这意味着实际上可以并行运行的 goroutines 的数量。在 Kubernetes 中，<strong class="jm io">节点上所有可用的 CPU 核心对其 pod</strong>可见(而不是清单中配置的限制)”</p></blockquote><p id="9863" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io"> &gt;这意味着，</strong>如果您将一个 pod CPU 限制设置为<code class="fe ml mm mn mo b">1 core</code>，但您的节点有<code class="fe ml mm mn mo b">64 cores</code>的 CPU，您的 Go 应用程序将获取实际的节点资源并设置<code class="fe ml mm mn mo b">GOMAXPROC to 64.</code> <strong class="jm io"> </strong>因此，您过度分配了比 Pod CPU 更多的线程。这会影响表演。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mp"><img src="../Images/44d4a16f48c2047276a162109700ea40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bsJ_slVRZWq760ptpx1Ebg.png"/></div></div><figcaption class="ly lz gj gh gi ma mb bd b be z dk translated">我得验证一下这是不是真的。于是我更新了代码，在带 cpu 的 K8s 上运行。<code class="fe ml mm mn mo b">limit=1</code>。它显示<code class="fe ml mm mn mo b">GOMAXPROCS</code>为 64(与节点 CPU 相同)。</figcaption></figure><p id="b9d0" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">这也得到了<a class="ae mc" href="https://github.com/uber-go/automaxprocs/issues/12" rel="noopener ugc nofollow" target="_blank">github.com/uber-go/automaxprocs/issues/12</a>的证实，</p><blockquote class="mf mg mh"><p id="b29e" class="jk jl me jm b jn jo jp jq jr js jt ju mi jw jx jy mj ka kb kc mk ke kf kg kh ig bi translated"><em class="in">“当 GOMAXPROCS 高于分配的 CPU 配额时，我们也看到了显著的节流”</em>。</p></blockquote><p id="210f" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">下图显示了基准测试结果，当<code class="fe ml mm mn mo b">GOMAXPROCS</code>设置为等于给定的 cpu 时，它提供了最佳性能。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mq"><img src="../Images/1d68c003eb5fabf77d0f9f915efaf2bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*yDSfy4zfKDrtk5U6.png"/></div></div><figcaption class="ly lz gj gh gi ma mb bd b be z dk translated"><a class="ae mc" href="https://github.com/uber-go/automaxprocs/issues/12#issuecomment-569019892" rel="noopener ugc nofollow" target="_blank">https://github . com/Uber-go/auto maxprocs/issues/12 # issue comment-569019892</a></figcaption></figure><h1 id="3959" class="ku kv in bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">解决方案</h1><p id="af4d" class="pw-post-body-paragraph jk jl in jm b jn ls jp jq jr lt jt ju jv lu jx jy jz lv kb kc kd lw kf kg kh ig bi translated">正如在基准测试结果中所讨论的，应该将<code class="fe ml mm mn mo b">GOMAXPROCS</code>设置为 pod 中可用的核心数。对于一个简单的配置，优步的<a class="ae mc" href="https://github.com/uber-go/automaxprocs" rel="noopener ugc nofollow" target="_blank">auto expross</a>通过在代码中添加一个导入行来帮助你完成。</p><pre class="kj kk kl km gt mr mo ms mt aw mu bi"><span id="c66f" class="mv kv in mo b gy mw mx l my mz">import _ "go.uber.org/automaxprocs</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/920cd756cfc10b5cb746464757a5d6bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EW4yussnlioZvOwRqV6wKQ.png"/></div></div></figure><h1 id="853e" class="ku kv in bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">结果</h1><p id="097c" class="pw-post-body-paragraph jk jl in jm b jn ls jp jq jr lt jt ju jv lu jx jy jz lv kb kc kd lw kf kg kh ig bi translated">现在我们得到了正确的配置，让我们来证明结果。下图是<code class="fe ml mm mn mo b">automaxprocs</code>设置前后的情况。它表明，在高负载下，响应时间更短且更稳定。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/afb7ec80566b96d8cef0b636132bafc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P9R9OpPE_JcHvSaWVQ6JEg.png"/></div></div><figcaption class="ly lz gj gh gi ma mb bd b be z dk translated">蝗虫负载测试</figcaption></figure><p id="37cf" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">至于<a class="ae mc" href="https://docs.newrelic.com/docs/apm/agents/go-agent/features/go-runtime-page-troubleshoot-performance-problems/" rel="noopener ugc nofollow" target="_blank"> newrelic 的</a>监视器，注意 GC 暂停时间减少到 1ms 左右，GC 暂停频率<em class="me">(stop-the-world 垃圾收集每分钟调用次数)</em>也减少了。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nc"><img src="../Images/597fe87678c527ff5dadbb704677c0f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FLAvOEH54lG8hfVAL2AP5A.png"/></div></div><figcaption class="ly lz gj gh gi ma mb bd b be z dk translated">新遗迹开始运行时监控</figcaption></figure><p id="c35c" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">最后，cpu 的利用率更高，消耗的资源更少。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/2b2945f9f1eef73f3ddbdee4e0e88cfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BSCuAGW_MaMEYrhr6xTjpA.png"/></div></div><figcaption class="ly lz gj gh gi ma mb bd b be z dk translated">Openshif 资源指标</figcaption></figure><p id="1c49" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">在一个更高强度的应用程序中，你会看到更多这样的性能差异。在我们的例子中，如果不设置它，速度会慢 50%以上</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/2736891d4ca1c15bf9a2966494c4f669.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s60hYWe8SOznJeZbbwLk7Q.png"/></div></div></figure></div><div class="ab cl nf ng hr nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="ig ih ii ij ik"><p id="af1d" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><em class="me">Plus:</em><a class="ae mc" href="https://github.com/uber-go/automaxprocs/issues/54" rel="noopener ugc nofollow" target="_blank"><em class="me">k8s 端 cpu 配额小于 1 核会怎样？</em> </a>，<em class="me">我也测试过这个假设。事实证明，1 个核心的 1 个 pod 比 5 个 200m 核心的 pod 效率更高。此外，当 cpu 限制设置为 200m 内核时，</em> <code class="fe ml mm mn mo b"><em class="me">automaxprocs</em></code> <em class="me">不会低于 1。</em></p></div><div class="ab cl nf ng hr nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="ig ih ii ij ik"><p id="819b" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io">最后的想法</strong></p><p id="75a0" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">如果你在 Kubernetes 中运行你的 GO 应用程序，GOMAXPROCS 是至关重要的，应该进行配置，否则你可以使用<a class="ae mc" href="https://github.com/uber-go/automaxprocs" rel="noopener ugc nofollow" target="_blank"> automaxprocs </a>来完成这项工作。最好使用全内核 CPU，因为 GOMAXPROCS 消耗整数数量的内核。这确保有足够的资源来利用线程。</p></div></div>    
</body>
</html>