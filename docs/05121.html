<html>
<head>
<title>Cache Design For Modern Applications</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">现代应用的高速缓存设计</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/cache-design-for-modern-applications-5d549d1c70a0?source=collection_archive---------1-----------------------#2021-06-19">https://blog.devgenius.io/cache-design-for-modern-applications-5d549d1c70a0?source=collection_archive---------1-----------------------#2021-06-19</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><figure class="gl gn jl jm jn jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi jk"><img src="../Images/7ad9d5be3d831386cbc06c88aa67fc85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*AtUf10OJVt_BX8-W.jpg"/></div></div></figure><h1 id="f236" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated"><strong class="ak">什么是缓存？</strong></h1><p id="e4cd" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">根据<a class="ae lr" href="https://en.wikipedia.org/wiki/Cache_%28computing%29" rel="noopener ugc nofollow" target="_blank">维基</a>的说法，在计算中，缓存是一个高速数据存储层，存储数据的子集，通常是短暂的，以便未来对该数据的请求可以比访问数据的主存储位置更快地得到服务。缓存允许我们有效地重用以前检索或计算的数据。</p><h1 id="346a" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated"><strong class="ak">现代缓存库的指导原则</strong></h1><h2 id="231c" class="ls jw in bd jx lt lu dn kb lv lw dp kf le lx ly kj li lz ma kn lm mb mc kr md bi translated"><strong class="ak">快速访问</strong></h2><p id="ca9e" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">缓存的唯一目的是加快数据访问速度。为了获得良好的性能，高速缓存必须具有以下特性:</p><ul class=""><li id="ae6f" class="me mf in kv b kw mg la mh le mi li mj lm mk lq ml mm mn mo bi translated">高<strong class="kv io">命中率，</strong>这是缓存之外的请求数占总请求数的一部分。</li><li id="8260" class="me mf in kv b kw mp la mq le mr li ms lm mt lq ml mm mn mo bi translated">内核数量可扩展</li><li id="fcaa" class="me mf in kv b kw mp la mq le mr li ms lm mt lq ml mm mn mo bi translated">高读写吞吐量</li></ul><p id="38ad" class="pw-post-body-paragraph kt ku in kv b kw mg ky kz la mh lc ld le mu lg lh li mv lk ll lm mw lo lp lq ig bi translated">这些是我们在设计缓存时需要克服的一些挑战。</p><h2 id="5344" class="ls jw in bd jx lt lu dn kb lv lw dp kf le lx ly kj li lz ma kn lm mb mc kr md bi translated"><strong class="ak">高并发性和抗争用性</strong></h2><p id="bbdc" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">高负载下的缓存性能由其支持的并发级别决定。所有缓存系统都面临争用的问题，因为对缓存的每次访问(get 和 set)都是对某个共享状态的写入。由于这个原因，在大多数缓存中，争用成为一个瓶颈，并最终导致系统变慢。因此，这是设计缓存时要记住的一个重要因素。</p><h2 id="505d" class="ls jw in bd jx lt lu dn kb lv lw dp kf le lx ly kj li lz ma kn lm mb mc kr md bi translated"><strong class="ak">内存绑定</strong></h2><p id="f11c" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">缓存的大小总是有限的，只能提供有限的数据量。现在，由于缓存可以包含从几个字节到几十亿字节不等的值，为了明智地处理键，我们可以选择为每个键-值对分配一个<strong class="kv io">成本</strong>。这意味着当缓存满负荷运行时，一个重的项目可能会取代许多轻的项目。</p><h1 id="1880" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">需要一种替代的缓存机制</h1><p id="5964" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">缓存算法中使用了几种流行的缓存策略。其中最受欢迎的是最近最少缓存(LRU ),它根据最近原则工作，最晚到达的项目将被优先考虑。这个缓存的一个主要缺点是<strong class="kv io">“这个缓存中的一击奇效”</strong>。这种类型的缓存可能导致在稀疏突发期间踢出真正的项目。</p><p id="625b" class="pw-post-body-paragraph kt ku in kv b kw mg ky kz la mh lc ld le mu lg lh li mv lk ll lm mw lo lp lq ig bi translated">类似地，最少使用(LFU)基于频率原理工作。这种缓存在实际应用中受到很大影响。假设内存中的一个项目在短时间内被重复引用，并且在很长一段时间内不再被访问，那么它将继续享受留在内存中的<strong class="kv io">【特权】</strong>并占用不必要的空间。</p><p id="1863" class="pw-post-body-paragraph kt ku in kv b kw mg ky kz la mh lc ld le mu lg lh li mv lk ll lm mw lo lp lq ig bi translated">因此，我们需要一种缓存策略，它特别关注所有的可能性，同时强制消除缺点。</p></div><div class="ab cl mx my hr mz" role="separator"><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc"/></div><div class="ig ih ii ij ik"><h1 id="7073" class="jv jw in bd jx jy ne ka kb kc nf ke kf kg ng ki kj kk nh km kn ko ni kq kr ks bi translated">一种高性能缓存的设计</h1><h2 id="d3b6" class="ls jw in bd jx lt lu dn kb lv lw dp kf le lx ly kj li lz ma kn lm mb mc kr md bi translated"><strong class="ak">通过锡林浩特的入学政策</strong></h2><p id="f02b" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">设计缓存时的一个大问题是:<strong class="kv io">我们应该将什么放入缓存？</strong>这由缓存准入策略来回答。上面我们谈到了流行的政策和它们的缺点。TinyLFU 解决了这些问题。</p><p id="96d8" class="pw-post-body-paragraph kt ku in kv b kw mg ky kz la mh lc ld le mu lg lh li mv lk ll lm mw lo lp lq ig bi translated"><strong class="kv io"> TinyLFU </strong>是一种驱逐无关的准入策略，旨在以极小的内存开销提高命中率。主要的想法是，<strong class="kv io">只让一个新的项目，如果它的估计高于被驱逐的项目。</strong>使用<strong class="kv io"> CountMin </strong>草图完成实施，该草图使用计数器矩阵和多个哈希函数来确定项目的频率。</p><pre class="nj nk nl nm gt nn no np nq aw nr bi"><span id="0d2a" class="ls jw in no b gy ns nt l nu nv"><strong class="no io">Glossary : How does a CountMin Sketch work?<br/></strong>CountMin sketch is a probabilistic data structure that serves as a frequency table of events in a stream of data. It uses hash functions to map events to frequencies, but unlike a hash table, it uses only sub-linear space, at the expense of over-counting some events due to collisions.</span></pre><figure class="nj nk nl nm gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi nw"><img src="../Images/8adf6c6fe3f7e2e5f143b1ad5707ac9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eiMr5U9WhzqNv0FR4Z0I8A.jpeg"/></div></div><figcaption class="nx ny gj gh gi nz oa bd b be z dk translated">参考:谷歌图片</figcaption></figure><p id="f756" class="pw-post-body-paragraph kt ku in kv b kw mg ky kz la mh lc ld le mu lg lh li mv lk ll lm mw lo lp lq ig bi translated">这种方法让我们通过调整矩阵的宽度和深度，在空间、效率和由于冲突导致的错误率之间进行权衡。<strong class="kv io">窗口 TinyLFU (W-TinyLFU)，</strong>TinyLFU 的一个变体，使用这个草图作为过滤器，如果一个新条目的频率比必须被驱逐以腾出空间的条目的频率高，则接纳该新条目。这项政策提供了一个准入窗口，让参赛者有机会建立自己的知名度。这避免了连续未命中，尤其是在稀疏突发(LRU 缓存问题)的情况下，条目可能不适合长期保留。为了保持历史的新鲜，定期或递增地执行老化过程，以将所有计数器减半(LFU 缓存的问题)。</p><h2 id="5e2a" class="ls jw in bd jx lt lu dn kb lv lw dp kf le lx ly kj li lz ma kn lm mb mc kr md bi translated"><strong class="ak">驱逐政策</strong></h2><p id="5daf" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">缓存的逐出策略试图估计哪些条目最有可能在短期内再次使用，从而最大化命中率。当缓存达到最大容量时，每个传入的键都应该替换缓存中存在的一个或多个键。因此，驱逐策略旨在找到那些 countMin sketch 估计值低于传入键的键</p><p id="9e70" class="pw-post-body-paragraph kt ku in kv b kw mg ky kz la mh lc ld le mu lg lh li mv lk ll lm mw lo lp lq ig bi translated">当新关键字到达时，高速缓存搜索具有最低估计值的关键字，如果该估计值低于输入关键字的估计值，则拒绝该关键字，否则拒绝输入关键字。我们将在<strong class="kv io">所有组件共同发挥作用</strong>一节中了解一个键的流行度是如何建立的。</p><h2 id="fadd" class="ls jw in bd jx lt lu dn kb lv lw dp kf le lx ly kj li lz ma kn lm mb mc kr md bi translated">过期策略</h2><p id="9050" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">高速缓存还接纳具有到期时间的密钥，在到期时间之后，不管高速缓存存储器的空间可用性如何，这些密钥都被丢弃。所以现在需要一种机制来驱逐过期的密钥并回收空闲空间。为了实现这一点，定期使用一个清道夫线程来清除所有无用的项目。</p><h2 id="e06c" class="ls jw in bd jx lt lu dn kb lv lw dp kf le lx ly kj li lz ma kn lm mb mc kr md bi translated">竞争阻力</h2><p id="edb4" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">我们在开始时提到，争用是缓存机制的一个主要威胁，可能会导致整个系统变慢。<strong class="kv io">实现高命中率需要管理关于缓存中存在什么以及缓存中应该存在什么的元数据。</strong>在线程间平衡缓存的性能和可伸缩性时，这变得非常困难。<a class="ae lr" href="https://github.com/dgraph-io/ristretto" rel="noopener ugc nofollow" target="_blank"><strong class="kv io"><em class="ob">BP-Wrapper</em></strong></a><strong class="kv io"/>解决了这个问题，它讨论了一个系统框架，使得任何替换算法几乎无锁争用。</p><p id="f907" class="pw-post-body-paragraph kt ku in kv b kw mg ky kz la mh lc ld le mu lg lh li mv lk ll lm mw lo lp lq ig bi translated">访问被记录到条带化的环形缓冲区中，在该缓冲区中，条带由特定于线程的散列来选择，并且当检测到争用时，条带的数量会增加。当<strong class="kv io">环形缓冲区</strong>已满时，将调度异步清空，并丢弃对该缓冲区的后续添加，直到空间变得可用(这将导致以速度为代价的有损行为)。</p><figure class="nj nk nl nm gt jo gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/504b2eaca04342b32efa06fe125ef4d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/format:webp/1*5kAQ234L4jmGg93nkbiAAg.png"/></div><figcaption class="nx ny gj gh gi nz oa bd b be z dk translated">Ref: HighScalability [dot] com</figcaption></figure><p id="d6bc" class="pw-post-body-paragraph kt ku in kv b kw mg ky kz la mh lc ld le mu lg lh li mv lk ll lm mw lo lp lq ig bi translated">在写入的情况下，使用更传统的并发队列，并且每次更改都计划立即清空。虽然数据丢失是不可接受的，但仍有方法优化写缓冲区。这两种类型的缓冲区都由多个线程写入，但在给定的时间内只由一个线程使用。这种多生产者/单消费者行为允许使用更简单、更有效的算法。</p><h1 id="8727" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">所有组件一起运行</h1><p id="50db" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">我们探讨了高性能缓存所需的策略。现在我们需要看看他们是如何走到一起的。让我们看看进入高速缓冲存储器的密钥的周期是如何操作的:</p><p id="f063" class="pw-post-body-paragraph kt ku in kv b kw mg ky kz la mh lc ld le mu lg lh li mv lk ll lm mw lo lp lq ig bi translated">当高速缓存有新条目的空间时，准入策略允许每个键进入其中，而不驱逐任何现有的键。但是，在直接输入密钥之前，它首先被发送给<strong class="kv io">看门人。</strong>它决定是否需要将密钥发送给准入标准策略。如果看门人允许该密钥，则该策略无论如何都会接纳该密钥(因为我们有可用的内存空间)。在这种情况下，不会发生驱逐。</p><p id="7524" class="pw-post-body-paragraph kt ku in kv b kw mg ky kz la mh lc ld le mu lg lh li mv lk ll lm mw lo lp lq ig bi translated">现在，当高速缓存满负荷运行时，会进行上述检查，但在这种情况下，驱逐策略还会决定驱逐哪些键。</p><pre class="nj nk nl nm gt nn no np nq aw nr bi"><span id="e531" class="ls jw in no b gy ns nt l nu nv"><strong class="no io">Glossary : How does a Doorkeeper work?<br/></strong>Before we place a key through TinyLFU, the cache uses a bloom filter to first check if the key has been seen before. Only if the key is already present in the bloom filter, it is inserted into the TinyLFU. This is to avoid polluting TinyLFU with a long tail of keys that are not seen more than once.</span></pre><p id="2879" class="pw-post-body-paragraph kt ku in kv b kw mg ky kz la mh lc ld le mu lg lh li mv lk ll lm mw lo lp lq ig bi translated">W-TinyLFU 使用分段 LRU (SLRU)策略进行长期保留。条目从试用段开始，在随后的访问中，它被提升到受保护段(容量上限为 80%)。当受保护段已满时，它驱逐到试用段，这可能触发试用条目被丢弃。这确保了具有小重用间隔的条目(最热的)被保留，而那些不经常被重用的条目(最冷的)有资格被驱逐。</p><figure class="nj nk nl nm gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi od"><img src="../Images/b5d982afea3e1587f8c5e1023d49f998.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6EJjf73F19nZCw7R8wRPNA.png"/></div></div><figcaption class="nx ny gj gh gi nz oa bd b be z dk translated">Ref: HighScalability [dot] com</figcaption></figure><h1 id="80c3" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">上述高速缓存设计的现有实现</h1><h2 id="c078" class="ls jw in bd jx lt lu dn kb lv lw dp kf le lx ly kj li lz ma kn lm mb mc kr md bi translated"><a class="ae lr" href="https://github.com/ben-manes/caffeine" rel="noopener ugc nofollow" target="_blank">咖啡因(爪哇)</a></h2><p id="7fca" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">Caffeine 是一个用 JAVA 编写的高性能接近最优的缓存库。它使用谷歌番石榴启发的 API 提供内存缓存。对于 JAVA 原生结构，它在很大程度上遵循了上述设计。</p><h2 id="d323" class="ls jw in bd jx lt lu dn kb lv lw dp kf le lx ly kj li lz ma kn lm mb mc kr md bi translated"><a class="ae lr" href="https://github.com/dgraph-io/ristretto" rel="noopener ugc nofollow" target="_blank">里斯特雷托(戈朗)</a></h2><p id="0c64" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">Ristretto 是一个快速、并发的高速缓存库，主要关注性能和正确性。高速缓存是根据 Dgraph 中无争用高速缓存的需求而构建的。Ristretto 使用 SampledLFU 进行缓存回收。要了解更多信息，请查看他们的官方知识库。</p><h1 id="d241" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">业绩和结论</h1><p id="315d" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">在咖啡因和 ristretto 中，上述缓存设计实现在命中率和速度方面提供了接近最优的性能。</p><figure class="nj nk nl nm gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi oe"><img src="../Images/7ee138ece1ea17f174a0eff68e1910a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z1iuaf_ELaAqCqiy2xIehw.png"/></div></div><figcaption class="nx ny gj gh gi nz oa bd b be z dk translated">Ref: HighScalability [dot] com(咖啡因性能)</figcaption></figure><h1 id="9898" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">参考</h1><ol class=""><li id="d2ed" class="me mf in kv b kw kx la lb le of li og lm oh lq oi mm mn mo bi translated">high scalability[dot]com:<a class="ae lr" href="http://highscalability.com/blog/2016/1/25/design-of-a-modern-cache.html" rel="noopener ugc nofollow" target="_blank">http://high scalability . com/blog/2016/1/25/design-of-a-modern-cache . html</a></li></ol><p id="29c1" class="pw-post-body-paragraph kt ku in kv b kw mg ky kz la mh lc ld le mu lg lh li mv lk ll lm mw lo lp lq ig bi translated">2.锡纸:<a class="ae lr" href="https://arxiv.org/pdf/1512.00727.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1512.00727.pdf</a></p><p id="99d5" class="pw-post-body-paragraph kt ku in kv b kw mg ky kz la mh lc ld le mu lg lh li mv lk ll lm mw lo lp lq ig bi translated">3.BP 包装:<a class="ae lr" href="https://dgraph.io/blog/refs/bp_wrapper.pdf" rel="noopener ugc nofollow" target="_blank">https://dgraph.io/blog/refs/bp_wrapper.pdf</a></p><p id="cc71" class="pw-post-body-paragraph kt ku in kv b kw mg ky kz la mh lc ld le mu lg lh li mv lk ll lm mw lo lp lq ig bi translated">4.https://www.youtube.com/watch?v=MUbrERcoyYc</p><p id="bdb9" class="pw-post-body-paragraph kt ku in kv b kw mg ky kz la mh lc ld le mu lg lh li mv lk ll lm mw lo lp lq ig bi translated">5.维基百科文章</p></div></div>    
</body>
</html>