<html>
<head>
<title>How to select appropriate Features — Feature Selection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何选择合适的特征—特征选择</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/how-to-select-appropriate-features-feature-selection-fc40ae39731f?source=collection_archive---------13-----------------------#2022-10-26">https://blog.devgenius.io/how-to-select-appropriate-features-feature-selection-fc40ae39731f?source=collection_archive---------13-----------------------#2022-10-26</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><p id="2cb2" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">了解统计方法中的要素选择过程-相关性和协方差</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/14e8ed691a17cc341014b54fb30c9475.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*copHBZxy22slZF6v"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上<a class="ae ky" href="https://unsplash.com/@drown_in_city?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> drown_ in_city </a>拍摄</figcaption></figure><p id="378c" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">让我们首先了解相关性，然后我们将继续协方差，然后我会告诉你为什么我们需要它们，以及它们有什么不同。</p><h1 id="11ec" class="kz la in bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">相互关系</h1><p id="1b83" class="pw-post-body-paragraph jk jl in jm b jn lx jp jq jr ly jt ju jv lz jx jy jz ma kb kc kd mb kf kg kh ig bi translated">根据维基百科的一篇文章:</p><blockquote class="mc md me"><p id="ec82" class="jk jl mf jm b jn jo jp jq jr js jt ju mg jw jx jy mh ka kb kc mi ke kf kg kh ig bi translated"><em class="in">中的</em> <a class="ae ky" href="https://en.wikipedia.org/wiki/Statistics" rel="noopener ugc nofollow" target="_blank"> <em class="in">统计</em></a><em class="in"/><strong class="jm io"><em class="in">相关性</em> </strong> <em class="in">或</em> <strong class="jm io"> <em class="in">依赖性</em> </strong> <em class="in">是任意统计关系，无论</em> <a class="ae ky" href="https://en.wikipedia.org/wiki/Causality" rel="noopener ugc nofollow" target="_blank"> <em class="in">因果</em> </a> <em class="in">与否，两个</em> <a class="ae ky" href="https://en.wikipedia.org/wiki/Random_variable" rel="noopener ugc nofollow" target="_blank"> <em class="in">随机变量</em> </a> <em class="in">或</em>尽管在最广泛的意义上，相关性“可以指任何类型的关联，但在统计学中，它通常指一对变量线性相关的程度<a class="ae ky" href="https://en.wikipedia.org/wiki/Line_(geometry)" rel="noopener ugc nofollow" target="_blank"/><em class="in">。</em></p></blockquote><p id="0acc" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">那么我们对这个定义的理解是什么呢？让我们使用虹膜数据集，如果我们创建一个花瓣长度和花瓣宽度之间的图表:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/7629bd63281af1178a36216d3493922a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/0*0rY3qEWpvXyhcVYh"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">花瓣长度和花瓣宽度之间的折线图，图片由作者提供</figcaption></figure><p id="0ba0" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">我们可以看到该图大致上升，即随着花瓣长度值的增加，花瓣宽度值也增加。现在，通过查看该图，我们可以说花瓣长度和花瓣宽度正相关，我们不能说在这一点上有多少相关，但我们可以肯定地说，它们都是正相关的，这足以用于特征选择。当然，如果我们知道他们两个有多紧密的联系，我们可以选择其中的一个用于 ML 模型的建立。那么让我们来介绍一下相关系数(r)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mk"><img src="../Images/e70fc9d76d82b46447aadf4574e1f13a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*sZtLIchZnIC37Pjx"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">相关基础，作者图片</figcaption></figure><p id="c577" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">因此，如果图形具有正斜率，那么它具有正相关性，如果图形具有负斜率，那么它具有负相关性，如果图形是倾斜的，即没有斜率，那么它意味着变量不相关。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ml"><img src="../Images/977a260d6cfd4e1a4d58d4e11562ff94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VmOTlYmzDcllcOXn"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图形相关性基础，图片由作者提供</figcaption></figure><p id="a14b" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">现在让我们来看看 iris 数据集中特征的相关系数和散点图。</p><p id="9cbf" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">这是一个相关矩阵，显示了每个特征之间的相关系数。</p><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="9518" class="mr la in mn b gy ms mt l mu mv">data.corr()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/983b7e243ed7693e178f0d0573ccc79d.png" data-original-src="https://miro.medium.com/v2/resize:fit:862/0*frJrZ7Vmvo704NXP"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">虹膜数据集(相关矩阵)特征之间的相关性，按作者分类的图像</figcaption></figure><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="9571" class="mr la in mn b gy ms mt l mu mv">plt.rcParams["figure.figsize"] = (20,12)<br/>plt.subplot(2,2,1)<br/>p = sns.scatterplot(x=data['petal_length'],y=data['petal_width'])<br/>p.set(title = "correlation = 0.962865")<br/>plt.grid()</span><span id="3462" class="mr la in mn b gy mx mt l mu mv">plt.subplot(2,2,2)<br/>p = sns.scatterplot(x=data['sepal_width'],y=data['petal_length'])<br/>p.set(title = "correlation = -0.428440")<br/>plt.grid()</span><span id="40ae" class="mr la in mn b gy mx mt l mu mv">plt.subplot(2,2,3)<br/>p = sns.scatterplot(x=data['petal_width'],y=data['sepal_length'])<br/>p.set(title = "correlation = 0.817941")<br/>plt.grid()</span><span id="c4b7" class="mr la in mn b gy mx mt l mu mv">plt.subplot(2,2,4)<br/>p = sns.scatterplot(x=data['sepal_width'],y=data['sepal_length'])<br/>p.set(title = "correlation = -0.117570")<br/>plt.grid()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mk"><img src="../Images/5913d9c1026dcbd22c5ca32c685dac27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1bmXxPx00ID4p3kF"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">虹膜数据集中的相关图，按作者分类的图片</figcaption></figure><p id="71d1" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">为了使相关性直观，我们还可以绘制一个配对图。</p><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="e98d" class="mr la in mn b gy ms mt l mu mv">sns.pairplot(data)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi my"><img src="../Images/ecffdc84e09beb84ea4e8e7f62099a56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0RBJ7qV4kaE_WLag"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">虹膜数据集中的配对图，图像由作者提供</figcaption></figure><p id="e55f" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">我们也可以画出同样的热图</p><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="206b" class="mr la in mn b gy ms mt l mu mv">sns.heatmap(data.corr(),annot=True)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/30fbef25f0b7f1e3c244fa9f8efee4b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/0*bvxd_EQC19Ij0rB2"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">iris 数据集中的关联热图，图片由作者提供</figcaption></figure><p id="356e" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">颜色越浅，相关性越强。</p><p id="370a" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">现在我们来了解一下协方差。</p><h1 id="6489" class="kz la in bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">协方差</h1><p id="f91f" class="pw-post-body-paragraph jk jl in jm b jn lx jp jq jr ly jt ju jv lz jx jy jz ma kb kc kd mb kf kg kh ig bi translated">根据维基百科的一篇文章:</p><blockquote class="mc md me"><p id="5a0f" class="jk jl mf jm b jn jo jp jq jr js jt ju mg jw jx jy mh ka kb kc mi ke kf kg kh ig bi translated"><em class="in">中的</em> <a class="ae ky" href="https://en.wikipedia.org/wiki/Probability_theory" rel="noopener ugc nofollow" target="_blank"> <em class="in">概率论中的</em></a><em class="in"/><a class="ae ky" href="https://en.wikipedia.org/wiki/Statistics" rel="noopener ugc nofollow" target="_blank"><em class="in">统计学中的</em> </a> <em class="in">，</em> <strong class="jm io"> <em class="in">协方差</em> </strong> <em class="in">是两个</em> <a class="ae ky" href="https://en.wikipedia.org/wiki/Random_variable" rel="noopener ugc nofollow" target="_blank"> <em class="in">随机变量</em> </a> <em class="in">的联合变异性的度量。如果一个变量的较大值主要与另一个变量的较大值相对应，并且较小值也是如此(即变量往往表现出相似的行为)，则协方差为正。在相反的情况下，当一个变量的较大值主要对应于另一个变量的较小值时，(即变量往往表现出相反的行为)，协方差为负。协方差的符号因此显示了在</em> <a class="ae ky" href="https://en.wikipedia.org/wiki/Linear_relationship" rel="noopener ugc nofollow" target="_blank"> <em class="in">变量之间的线性关系</em> </a> <em class="in">。</em></p></blockquote><p id="9746" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">一些重要的提示:</p><ul class=""><li id="f79a" class="na nb in jm b jn jo jr js jv nc jz nd kd ne kh nf ng nh ni bi translated">协方差用于量化两个变量变化之间的关系</li><li id="c515" class="na nb in jm b jn nj jr nk jv nl jz nm kd nn kh nf ng nh ni bi translated">当两个变量之间的差值增大时，协方差变为负值，如果差值减小，协方差变为正值</li><li id="98f7" class="na nb in jm b jn nj jr nk jv nl jz nm kd nn kh nf ng nh ni bi translated">它与相关系数完全不同</li><li id="6294" class="na nb in jm b jn nj jr nk jv nl jz nm kd nn kh nf ng nh ni bi translated">协方差评估两个随机变量的平均值如何一起移动</li></ul><p id="fdcb" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">协方差的公式:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi no"><img src="../Images/df9c9343522b9435fb447e4989274e9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/format:webp/1*_WW1nPNctZyPapD5-yaJ3Q.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">协方差公式，作者图像</figcaption></figure><ul class=""><li id="70d1" class="na nb in jm b jn jo jr js jv nc jz nd kd ne kh nf ng nh ni bi translated">xi =一个 x 数据点</li><li id="93a8" class="na nb in jm b jn nj jr nk jv nl jz nm kd nn kh nf ng nh ni bi translated">xbar =值的平均值</li><li id="1bab" class="na nb in jm b jn nj jr nk jv nl jz nm kd nn kh nf ng nh ni bi translated">yi =一个 y 数据点</li><li id="c1c1" class="na nb in jm b jn nj jr nk jv nl jz nm kd nn kh nf ng nh ni bi translated">ybar =值的平均值</li><li id="42fe" class="na nb in jm b jn nj jr nk jv nl jz nm kd nn kh nf ng nh ni bi translated">n =数据集的样本大小</li></ul><p id="4543" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">在 python 中我们只用。cov()方法，我们在 iris 数据集上试试。</p><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="9762" class="mr la in mn b gy ms mt l mu mv">import pandas as pd<br/>import seaborn as sns<br/>data = sns.load_dataset('iris')<br/>data.cov()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/d17af099193da3cc243c21be6bada27b.png" data-original-src="https://miro.medium.com/v2/resize:fit:866/0*1bpiSKY8RIdoAZaJ"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">虹膜数据集中的协方差矩阵，图片由作者提供</figcaption></figure><p id="0a5c" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">我们可以这样理解协方差:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/c8c078542921ef713a64170d9a020ccc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/0*WeK_-wNzlPJJwLBD"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">协方差的要点，作者的图像</figcaption></figure><p id="4a5c" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">如果协方差为零，则变量之间没有关系。</p><p id="63b1" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">为了更好地理解，我们还可以创建自己的函数:</p><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="ae6a" class="mr la in mn b gy ms mt l mu mv">def cov_custom(x,y,data,n):<br/>    cov1 = 0<br/>    for i in range(len(data[x])):<br/>        cov1 += ((data[x][i]-data[x].mean())*(data[y][i]-data[y].mean())/(n-1))<br/>    return cov1<br/>cov_custom("sepal_length",'sepal_width',data,len(data))</span></pre><blockquote class="mc md me"><p id="a621" class="jk jl mf jm b jn jo jp jq jr js jt ju mg jw jx jy mh ka kb kc mi ke kf kg kh ig bi">-0.042434004474272945</p></blockquote><p id="53d9" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">而且我们得到的答案是准确的。</p><p id="0c2f" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">与相关性类似，我们可以创建协方差图:</p><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="2372" class="mr la in mn b gy ms mt l mu mv">sns.heatmap(data.cov(),annot=True)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/04951ec8d7c2ed898b7954f0c8e13fd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/0*Bw1eU1e3-nY5ZHUm"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">虹膜数据集中协方差矩阵的热图，图片由作者提供</figcaption></figure><h1 id="5ba5" class="kz la in bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">不同类型的相关系数</h1><p id="7c82" class="pw-post-body-paragraph jk jl in jm b jn lx jp jq jr ly jt ju jv lz jx jy jz ma kb kc kd mb kf kg kh ig bi translated">这些都使用了相关和协方差的概念</p><ol class=""><li id="d434" class="na nb in jm b jn jo jr js jv nc jz nd kd ne kh ns ng nh ni bi translated">皮尔逊相关系数</li><li id="84d3" class="na nb in jm b jn nj jr nk jv nl jz nm kd nn kh ns ng nh ni bi translated">人员等级相关系数</li><li id="0890" class="na nb in jm b jn nj jr nk jv nl jz nm kd nn kh ns ng nh ni bi translated">皮尔逊积矩相关</li><li id="b942" class="na nb in jm b jn nj jr nk jv nl jz nm kd nn kh ns ng nh ni bi translated">斯皮尔曼相关系数</li><li id="307f" class="na nb in jm b jn nj jr nk jv nl jz nm kd nn kh ns ng nh ni bi translated">斯皮尔曼等级相关系数</li><li id="074f" class="na nb in jm b jn nj jr nk jv nl jz nm kd nn kh ns ng nh ni bi translated">多轴相关系数</li></ol></div><div class="ab cl nt nu hr nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="ig ih ii ij ik"><p id="f4cc" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">如果你喜欢这些内容，请留下👏，它激励我写更多这样的文章😊</p><p id="7058" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">联系人:<a class="ae ky" href="https://linktr.ee/a.kayyy" rel="noopener ugc nofollow" target="_blank">https://linktr.ee/a.kayyy</a></p></div></div>    
</body>
</html>