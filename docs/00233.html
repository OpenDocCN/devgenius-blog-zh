<html>
<head>
<title>A Neglected Fact About Apache Spark: Performance Comparison Of coalesce And repartition</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于Apache Spark的一个被忽略的事实:合并和重新分配的性能比较</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/a-neglected-fact-about-apache-spark-performance-comparison-of-coalesce-1-and-repartition-1-80bb4e30aae4?source=collection_archive---------0-----------------------#2020-05-26">https://blog.devgenius.io/a-neglected-fact-about-apache-spark-performance-comparison-of-coalesce-1-and-repartition-1-80bb4e30aae4?source=collection_archive---------0-----------------------#2020-05-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="879e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用coalesce(1)或repartition(1)时Spark运行速度比预期慢的另一个原因是</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/9485abbc2057fda45b8a18608ef57df1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*REJbZpIY0PmbFxCNxi5l7w.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">关于Apache Spark的一个被忽视的事实:coalesce(1)和repartition(1)的性能比较(作者)</figcaption></figure><p id="6508" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在Spark中，<strong class="kx ir"> coalesce </strong>和<strong class="kx ir"> repartition </strong>都是众所周知的函数，可以根据人们的明确要求来调整分区的数量。人们经常更新配置:<code class="fe lr ls lt lu b">spark.sql.shuffle.partition</code>来改变分区的数量(缺省值:200)，这是Spark性能调优策略的一个重要部分。尽管在Spark中调整<code class="fe lr ls lt lu b">spark.sql.shuffle.partition</code>来减少计算时间是一项艺术，但如果分区数量很大，这可能会导致一些令人头疼的问题。由于此配置控制HDFS中最终文件的数量，它可能与您想要的不一样，有时您可能只想要一个文件。在本文中，我们将讨论Apache Spark在<strong class="kx ir"> coalesce(1) </strong>和<strong class="kx ir"> repartition(1) </strong>之间被忽略的部分，这可能是您在检查Spark作业性能时需要注意的一件事。</p><p id="f36a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">减少文件数量的常见方法是减少分区数量，我们可以在代码中显式调用<strong class="kx ir"> coalesce </strong>或<strong class="kx ir"> repartition </strong>来实现这一目标。如果您有一个Spark数据框架，并且希望将输出文件的数量改为一个，那么您应该主要写下以下内容:</p><pre class="kg kh ki kj gt lv lu lw lx aw ly bi"><span id="8705" class="lz ma iq lu b gy mb mc l md me">df.<strong class="lu ir">coalesce</strong>(1).write.format("csv").save(filepath)<br/>// OR<br/>df.<strong class="lu ir">repartition</strong>(1).write.format("csv").save(filepath)</span></pre><p id="83e2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">两者都应该给你正确的结果，<strong class="kx ir">合并</strong>或<strong class="kx ir">重新分配有什么区别？</strong></p><h2 id="b801" class="lz ma iq bd mf mg mh dn mi mj mk dp ml le mm mn mo li mp mq mr lm ms mt mu mv bi translated">合并和再分配的定义</h2><p id="c5f3" class="pw-post-body-paragraph kv kw iq kx b ky mw jr la lb mx ju ld le my lg lh li mz lk ll lm na lo lp lq ij bi translated">这两个函数都是<a class="ae nb" href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset" rel="noopener ugc nofollow" target="_blank">数据集</a>类中的方法。来自官方Spark文档:</p><blockquote class="nc nd ne"><p id="dc55" class="kv kw nf kx b ky kz jr la lb lc ju ld ng lf lg lh nh lj lk ll ni ln lo lp lq ij bi translated"><strong class="kx ir"> coalesce: </strong>当请求更少的分区时，返回一个正好有<code class="fe lr ls lt lu b"><em class="iq">numPartitions</em></code>分区的新数据集。</p><p id="95ac" class="kv kw nf kx b ky kz jr la lb lc ju ld ng lf lg lh nh lj lk ll ni ln lo lp lq ij bi translated"><strong class="kx ir">重新分区:</strong>返回一个新的数据集，它正好有<code class="fe lr ls lt lu b"><em class="iq">numPartitions</em></code>个分区。</p></blockquote><p id="94c0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">类似于<code class="fe lr ls lt lu b">cache()</code>的功能，叫做<code class="fe lr ls lt lu b">persist(StorageLevel.MEMORY_ONLY)</code>。如果我们看一下<a class="ae nb" href="https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala#L482-L484" rel="noopener ugc nofollow" target="_blank"> Spark源代码</a> , <strong class="kx ir">重新分区</strong>是一个友好的名字，通过直接调用<strong class="kx ir"> coalesce </strong>但是将shuffle锁定为true。</p><pre class="kg kh ki kj gt lv lu lw lx aw ly bi"><span id="7b16" class="lz ma iq lu b gy mb mc l md me">coalesce(numPartitions, shuffle = true)</span></pre><p id="501a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">正如你所看到的，<strong class="kx ir">重新分配</strong>将触发洗牌，这是一个昂贵的操作。另一方面，没有shuffle标志的coalesce不会执行shuffle，因此会导致狭窄的依赖关系。</p><h2 id="ea87" class="lz ma iq bd mf mg mh dn mi mj mk dp ml le mm mn mo li mp mq mr lm ms mt mu mv bi translated">合并(1)和重新划分(1)性能评估</h2><blockquote class="nc nd ne"><p id="0a54" class="kv kw nf kx b ky kz jr la lb lc ju ld ng lf lg lh nh lj lk ll ni ln lo lp lq ij bi translated">如果要增加分区数量，请使用repartition，如果要减少分区数量，请使用coalesce，在减少分区数量时，<code class="fe lr ls lt lu b"><em class="iq">coalesce</em></code>的性能优于<code class="fe lr ls lt lu b"><em class="iq">repartition</em></code>。— —在线推荐</p></blockquote><p id="9ae6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">以上推荐总体来说还是不错的。然而，它不是一颗银弹。在这种情况下，如果你认为<code class="fe lr ls lt lu b"><em class="nf">coalesce(1)</em></code> <em class="nf"> </em>可以适用于所有你想保持单个文件结果时的场景，请继续阅读，我们可以展示结果。感谢谷歌，我们将使用谷歌的Colab进行调查。</p><ul class=""><li id="522e" class="nj nk iq kx b ky kz lb lc le nl li nm lm nn lq no np nq nr bi translated">将spark会话中的“Spark . SQL . shuffle . partitions”显式设置为2001，以便能够注意到差异。如果您想使用Spark UI，您需要使用colab的本地计算模式。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/41ffdb2f07cf8daa75e8f87817b1cee2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BDZUYo633rSdjmvhX5lMVQ.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">在Colab中初始化Spark(作者)</figcaption></figure><ul class=""><li id="2a7c" class="nj nk iq kx b ky kz lb lc le nl li nm lm nn lq no np nq nr bi translated">用在线数据集创建一个简单的Spark数据框架，这里我们<a class="ae nb" href="https://www.kaggle.com/austinreese/craigslist-carstrucks-data/data#" rel="noopener ugc nofollow" target="_blank"> craigslist-car-data </a>。数据集的内容或模式在我们的性能测试中无关紧要。</li><li id="fe79" class="nj nk iq kx b ky nt lb nu le nv li nw lm nx lq no np nq nr bi translated">初始分区将与colab给我们的内核相同，或者如果您运行在本地模式，它将与内核相同。在执行join操作之后，您会注意到分区与我们最初设置的一样。为了进行演示，我们在这里使用自连接，但是您可以假设将不同的数据帧连接在一起。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/f97d197fec9bc00d77f0a43a62070314.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xub0H3xoNNnF8x22OamrNw.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">检查分区数量(按作者)</figcaption></figure><ul class=""><li id="c388" class="nj nk iq kx b ky kz lb lc le nl li nm lm nn lq no np nq nr bi translated">现在我们可以尝试使用coalesce(1)编写输出并检查Spark UI</li></ul><pre class="kg kh ki kj gt lv lu lw lx aw ly bi"><span id="1201" class="lz ma iq lu b gy mb mc l md me">df_joined.coalesce(1).write.csv(‘/tmp/coalesce’)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/91ceae2d32fb3a4bd8a2e0e06145afa2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rPZmpdcLdY4WpQ_8FTNbkA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">合并(1)性能(按作者)</figcaption></figure><ul class=""><li id="2101" class="nj nk iq kx b ky kz lb lc le nl li nm lm nn lq no np nq nr bi translated">然后，我们可以尝试使用repartition(1)来编写输出</li></ul><pre class="kg kh ki kj gt lv lu lw lx aw ly bi"><span id="b10f" class="lz ma iq lu b gy mb mc l md me">df_joined.repartition(1).write.csv(‘/tmp/repartition’)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/e71642121c4811912ce3208186aadccc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bcztO9OJKLcRdNYT30KyRg.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">再分配(1)性能(按作者)</figcaption></figure><p id="cea7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">正如您所注意到的，合并(1)需要大约17秒，总共只有25个任务，而重新分区(1)需要13秒，总共有2026 (2001+25)个任务。</p><p id="be9d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果我们看DAG，coalesce(1)有三个阶段，但是repartition(1)有四个阶段。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/9256e55c5e2d4fe7498957f7b07f5ef9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-LTHjb8FwwNRPp2KDMM08Q.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">coalesce(1) DAG(按作者)</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/70945422293185aa6bcbd8e4e262e328.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lS4zBjyDCdWq_1qaCAbZ-w.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">重新分区(1) DAG(按作者)</figcaption></figure><p id="adb3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这种情况下，由于repartition(1) envoke shuffle，您会在Spark UI上看到第四个阶段。如果您单击coalesce(1)的join阶段，并检查与repartition(1)比较的任务数量，您会很快发现瓶颈在哪里。我们只使用一个分区来执行join操作，另一方面，repartition(1)仍然使用2001。如果你有一个巨大的数据集，你需要执行连接或洗牌一个分区不会利用火花优势，使并行执行。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/693c082c79c57a378c6d3fa37821d410.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*56WgTJp4JKBGlZI2dHoRCw.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">合并(1)个分区(按作者)</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oe"><img src="../Images/eacffcd6f634b9b310cf7fb0088f3bbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UDaSs0gc9_E5a4lwo-uBKQ.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">重新分区(1)分区(按作者)</figcaption></figure><p id="c70e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">被忽略的事实是执行coalesce(1)并避免洗牌，它收缩其父RDD以显式使用相同数量的分区。相反，repartition(1)保留其父分区的数量。如果在一次昂贵的洗牌后立即调用coalesce(1 ),您会在Spark UI上看到这种行为。我们注意到在一个数据集中只有大约1.5GB的差异。对于大型数据集，差异可能会更大。</p><h2 id="a938" class="lz ma iq bd mf mg mh dn mi mj mk dp ml le mm mn mo li mp mq mr lm ms mt mu mv bi translated">最终想法</h2><p id="3563" class="pw-post-body-paragraph kv kw iq kx b ky mw jr la lb mx ju ld le my lg lh li mz lk ll lm na lo lp lq ij bi translated">Spark API页面上也记录了性能事实。您需要展开<strong class="kx ir"> coalesce </strong>函数来查看细节。</p><blockquote class="nc nd ne"><p id="0432" class="kv kw nf kx b ky kz jr la lb lc ju ld ng lf lg lh nh lj lk ll ni ln lo lp lq ij bi translated">但是，如果您正在进行剧烈的合并，例如numPartitions = 1，这可能会导致您的计算在比您希望的更少的节点上进行(例如，在numPartitions = 1的情况下只有一个节点)。为了避免这种情况，您可以调用repartition。这将增加一个shuffle步骤，但意味着当前的上游分区将被并行执行(无论当前的分区是什么)。— <a class="ae nb" href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset" rel="noopener ugc nofollow" target="_blank"> Spark文档</a></p></blockquote><p id="94c7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在我们之前演示的示例中，这是一个剧烈的合并，由于没有并行性来执行join操作，所以性能很差。总之，Spark中没有合并和重新分配的灵丹妙药。这取决于您的数据量和您的业务逻辑，以检查您最终是否希望使用合并和重新分区。有些情况下，您需要在Spark中以不同的方式处理在线推荐；在匆忙下结论之前，自己先试一试是个好主意。</p><p id="2f19" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">下面是上面</strong>所示例子的详细代码</p><div class="of og gp gr oh oi"><a href="https://colab.research.google.com/drive/1V09wHg1P0tppAB2QBKpdAqc0DJ0z6r_9?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="oj ab fo"><div class="ok ab ol cl cj om"><h2 class="bd ir gy z fp on fr fs oo fu fw ip bi translated">火花_性能_比较_联合_重新分配</h2><div class="op l"><h3 class="bd b gy z fp on fr fs oo fu fw dk translated">Colab _示例</h3></div><div class="oq l"><p class="bd b dl z fp on fr fs oo fu fw dk translated">colab.research.google.com</p></div></div><div class="or l"><div class="os l ot ou ov or ow kp oi"/></div></div></a></div></div><div class="ab cl ox oy hu oz" role="separator"><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc"/></div><div class="ij ik il im in"><p id="2baa" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">希望这个故事对你有帮助。本文是我的工程&amp;数据科学系列的<strong class="kx ir">部分，目前包括以下内容:</strong></p><div class="of og gp gr oh"><div role="button" tabindex="0" class="ab bv gv cb fp pe pf bn pg kp ex"><div class="ph l"><div class="ab q"><div class="l di"><img alt="Chengzhi Zhao" class="l de bw pi pj fe" src="../Images/51b8d26809e870b4733e4e5b6d982a9f.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/2*SGCkys53sdZUZKnpRQoq_A.jpeg"/><div class="fb bw l pi pj fc n aw fd"/></div><div class="hh l fo"><p class="bd b dl z fp fq fr fs ft fu fv fw dk translated"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://chengzhizhao.medium.com/?source=post_page-----80bb4e30aae4--------------------------------" rel="noopener follow" target="_top">赵承志</a></p></div></div><div class="pm pn gw l"><h2 class="bd ir uo nj fp up fr fs oo fu fw ip bi translated">数据工程和数据科学故事</h2></div><div class="ab q"><div class="l fo"><a class="bd b be z bi uq au ur us ut rf uu an eh ei uv uw ux el em eo de bk ep" href="https://chengzhizhao.medium.com/list/data-engineering-data-science-stories-ddab37f718e7?source=post_page-----80bb4e30aae4--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="uy l fo"><span class="bd b dl z dk">49 stories</span></div></div></div><div class="pz dh qa fp ab qb fo di"><div class="di pr bv ps pt"><div class="dh l"><img alt="" class="dh" src="../Images/8bc7ea181a6ffac2c724d2d9a702176a.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*4eeANzhZ1-8eJ0amxrtrqA.png"/></div></div><div class="di pr bv pu pv pw"><div class="dh l"><img alt="" class="dh" src="../Images/3019888d9e7a1233b7e2a83f0c2017db.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*-wGLbKpFwLbHKIODKOCZEQ.jpeg"/></div></div><div class="di bv px py pw"><div class="dh l"><img alt="" class="dh" src="../Images/4ba0357365403d685da42e6cb90b2b7e.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/da:true/resize:fill:388:388/1*b4EVtemQ1EQEup3o1ewz1w.gif"/></div></div></div></div></div><p id="7870" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">你也可以<a class="ae nb" href="https://chengzhizhao.medium.com/subscribe" rel="noopener"> <strong class="kx ir">订阅我的新文章</strong> </a>或者成为<a class="ae nb" href="https://chengzhizhao.medium.com/membership" rel="noopener"> <strong class="kx ir">推荐媒介会员</strong> </a> <strong class="kx ir"> </strong>无限制访问媒介上的所有故事。</p><p id="771b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果有问题/评论，<strong class="kx ir">请不要犹豫，写下这个故事的评论</strong>或通过<a class="ae nb" href="https://www.linkedin.com/in/chengzhizhao/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>或<a class="ae nb" href="https://twitter.com/ChengzhiZhao" rel="noopener ugc nofollow" target="_blank"> Twitter </a>直接<strong class="kx ir">联系我。</strong></p></div></div>    
</body>
</html>