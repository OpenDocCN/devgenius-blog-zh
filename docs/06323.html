<html>
<head>
<title>Intro to PyTorch Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch神经网络简介</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/intro-to-pytorch-neural-networks-6029f91e47f8?source=collection_archive---------8-----------------------#2021-12-30">https://blog.devgenius.io/intro-to-pytorch-neural-networks-6029f91e47f8?source=collection_archive---------8-----------------------#2021-12-30</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><figure class="gl gn jl jm jn jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi jk"><img src="../Images/c7bed63d069b90b7cef7388e0ae6a823.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/1*cW7UW2vnNP04TQFQypSX8w.png"/></div></div></figure><p id="0609" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">深度学习重新唤起了人们对人工智能的兴趣。道理很简单:深度学习就是管用。它给了我们创造以前无法创造的技术的力量。它开辟了新的商业前景，总体上提高了技术水平。</p><p id="0770" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">要进行深度学习，你需要会编码，尤其是用Python。在那里，您可以从广泛的深度学习库中进行选择，包括TensorFlow、Keras、MXNet、MatConvNet以及最近的Pytorch！</p><p id="4f1e" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">Pytorch在首次发布后迅速流行起来。它被称为TensorFlow杀手，因为它更加用户友好，使用简单。事实上，您将了解到Pytorch和深度学习的入门是多么简单。</p><h1 id="fd5d" class="kt ku in bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">从PyTorch开始</h1><p id="5def" class="pw-post-body-paragraph jv jw in jx b jy lr ka kb kc ls ke kf kg lt ki kj kk lu km kn ko lv kq kr ks ig bi translated">Pytorch开发的目标是使其尽可能与Python的Numpy相媲美。这将在标准Python代码、Numpy和Pytorch之间实现简单无缝的接口，使开发更快更容易。</p><p id="0efd" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">首先，我们可以通过Pip安装PyTorch:</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="7642" class="mf ku in mb b gy mg mh l mi mj">pip install torch torchvision</span></pre><h2 id="2750" class="mf ku in bd kv mk ml dn kz mm mn dp ld kg mo mp lh kk mq mr ll ko ms mt lp mu bi translated">张量</h2><p id="015c" class="pw-post-body-paragraph jv jw in jx b jy lr ka kb kc ls ke kf kg lt ki kj kk lu km kn ko lv kq kr ks ig bi translated">张量是每个深学习包最基本的组成部分。张量是类似矩阵的数据结构，其执行和行为类似于Numpy数组。事实上，在大多数情况下，您可以将它们视为Numpy数组。两者之间最显著的区别是张量可能在当代深度学习包(非常快)的CPU或GPU上实现。</p><p id="c4ea" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">可以使用基本张量对象在PyTorch中声明张量:</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="c142" class="mf ku in mb b gy mg mh l mi mj">import torch <br/>a = torch.Tensor(3, 3)</span></pre><p id="76d2" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">前面的代码生成一个大小为(3，3)的张量，即三行三列浮点零:</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="3e7e" class="mf ku in mb b gy mg mh l mi mj">0.  0.  0.<br/>0.  0.  0.<br/>0.  0.  0.<br/>[torch.FloatTensor of size 3x3]</span></pre><p id="1304" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">您也可以创建一个张量填充的随机浮点值:</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="87e9" class="mf ku in mb b gy mg mh l mi mj">x = torch.rand(3, 3)<br/>print(x)</span><span id="ffdb" class="mf ku in mb b gy mv mh l mi mj">"""<br/>Prints out:<br/>tensor([[0.3211, 0.1423, 0.6453],<br/>        [0.0343, 0.7986, 0.3213],<br/>        [0.0767, 0.5432, 0.3456]])<br/>"""</span></pre><p id="1cd0" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">使用Pytorch，张量相乘、相加和其他基本数学运算轻而易举:</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="ebdf" class="mf ku in mb b gy mg mh l mi mj">a = torch.ones(3, 3)<br/>b = torch.ones(3, 3) * 4<br/>c = a + b<br/>print(c)</span><span id="5f5d" class="mf ku in mb b gy mv mh l mi mj">"""<br/>Prints out:<br/>tensor([[5., 5., 5.],<br/>        [5., 5., 5.],<br/>        [5., 5., 5.]])<br/>"""</span></pre><p id="4098" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">Pytorch张量甚至支持Numpy风格的切片功能！</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="3e5a" class="mf ku in mb b gy mg mh l mi mj">a = torch.ones(3, 3) * 5<br/>b = x[:, :2]<br/>print(b)<br/>"""<br/>Prints out:<br/>tensor([[5., 5.],<br/>        [5., 5.],<br/>        [5., 5.]])<br/>"""</span></pre><p id="2f93" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">因此，Pytorch张量的使用和操作方式与Numpy数组非常相似。现在我们来看看如何使用这些简单的Pytorch张量来构建深层网络！</p><h1 id="bc1c" class="kt ku in bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">制造神经网络</h1><p id="1d56" class="pw-post-body-paragraph jv jw in jx b jy lr ka kb kc ls ke kf kg lt ki kj kk lu km kn ko lv kq kr ks ig bi translated">在Pytorch中，神经网络被定义为Python类。该网络是通过扩展Torch库的torch.nn.Module的类来定义的。让我们创建一个卷积神经网络(CNN)类，我们可以在MNIST数据集上使用它。</p><p id="36ab" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">看看下面定义我们网络的代码！</p><figure class="lw lx ly lz gt jo"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="649b" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">__init__()和forward()过程是Pytorch网络类中最关键的函数。__init__()函数用于设置模型将采用的任何网络层。forward()函数是将所有层堆叠在一起以创建模型的地方。</p><p id="f18e" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">在init函数中，我们为模型定义了两个卷积层，其中一个我们将多次重用(conv2)。最后，我们将应用最大池层和全局平均池层。为了得到最终的输出概率，我们使用全连接(FC)层和softmax。</p><p id="8b59" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">我们指定我们的层如何堆叠在一起以在正向函数中产生整个模型。该网络是传统网络，具有堆叠的conv、池和FC层。Pytorch的美妙之处在于，我们可以在forward()方法中的任何地方用一个简单的print语句打印中间层中任何张量的形式和结果！</p><h1 id="5795" class="kt ku in bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">培训、测试，还有储蓄！</h1><h2 id="d7f1" class="mf ku in bd kv mk ml dn kz mm mn dp ld kg mo mp lh kk mq mr ll ko ms mt lp mu bi translated">加载数据</h2><p id="8af3" class="pw-post-body-paragraph jv jw in jx b jy lr ka kb kc ls ke kf kg lt ki kj kk lu km kn ko lv kq kr ks ig bi translated">是时候准备我们训练的数据了！我们将开始设置适当的导入，初始化设置，并确保Pytorch配置为使用GPU。下面的代码行利用torch.device()来验证Pytorch是否支持CUDA，如果支持，它就使用GPU！</p><figure class="lw lx ly lz gt jo"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="461a" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">MNIST数据集可以直接从Pytorch中检索。我们将下载数据并将其分成两个张量:一个用于训练，一个用于测试。我们将把数据输入到torch DataLoader中，它将为传递给模型做好准备，并设置批量大小和可选的洗牌。</p><figure class="lw lx ly lz gt jo"><div class="bz fp l di"><div class="mw mx l"/></div></figure><h2 id="b29d" class="mf ku in bd kv mk ml dn kz mm mn dp ld kg mo mp lh kk mq mr ll ko ms mt lp mu bi translated">培养</h2><p id="955b" class="pw-post-body-paragraph jv jw in jx b jy lr ka kb kc ls ke kf kg lt ki kj kk lu km kn ko lv kq kr ks ig bi translated">其他深度学习框架如TensorFlow、Keras和MXNet都有类似的优化器(我们将使用Adam)和损失函数(我们将使用交叉熵)。</p><figure class="lw lx ly lz gt jo"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="02aa" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">在Pytorch中，所有网络模型和数据集都必须手动从CPU移动到GPU。将. to()方法应用到下面的模型中可以做到这一点。稍后，我们将对我们的图片数据执行同样的操作。</p><figure class="lw lx ly lz gt jo"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="0e26" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">最后，我们可以将我们的训练循环写在纸上。要了解它是如何工作的，请看下面的代码。</p><ol class=""><li id="60ca" class="my mz in jx b jy jz kc kd kg na kk nb ko nc ks nd ne nf ng bi translated">在训练数据加载器中，所有Pytorch训练循环将遍历每个时期和批次。</li><li id="be7e" class="my mz in jx b jy nh kc ni kg nj kk nk ko nl ks nd ne nf ng bi translated">在每次循环迭代中，图片数据和标签被传输到GPU。</li><li id="cacf" class="my mz in jx b jy nh kc ni kg nj kk nk ko nl ks nd ne nf ng bi translated">正向传递、反向传递和优化阶段都明确应用于每个训练循环。</li><li id="5190" class="my mz in jx b jy nh kc ni kg nj kk nk ko nl ks nd ne nf ng bi translated">当将该模型应用于该批中的照片时，估计该批的损失。</li><li id="a7bd" class="my mz in jx b jy nh kc ni kg nj kk nk ko nl ks nd ne nf ng bi translated">网络的梯度被计算并反向传输。</li></ol><figure class="lw lx ly lz gt jo"><div class="bz fp l di"><div class="mw mx l"/></div></figure><h1 id="27da" class="kt ku in bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">测试和保存</h1><p id="ad5a" class="pw-post-body-paragraph jv jw in jx b jy lr ka kb kc ls ke kf kg lt ki kj kk lu km kn ko lv kq kr ks ig bi translated">在Pytorch中，测试网络性能会创建一个类似于训练阶段的循环。主要区别在于梯度不需要向后传播。我们将继续向前传递，只在网络输出中寻找概率最高的标签。</p><p id="cbfa" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">在这个场景中，经过10个时期后，我们的网络的测试集准确率达到了99.06%。</p><figure class="lw lx ly lz gt jo"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="8cc6" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">只需使用torch.save()将模型保存到磁盘供以后使用。这就是全部了！</p><figure class="lw lx ly lz gt jo"><div class="bz fp l di"><div class="mw mx l"/></div></figure></div></div>    
</body>
</html>