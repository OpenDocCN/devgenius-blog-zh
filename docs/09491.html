<html>
<head>
<title>K8s — Service Introduction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">K8s —服务介绍</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/k8s-service-introduction-b1197f5d0ab4?source=collection_archive---------6-----------------------#2022-08-24">https://blog.devgenius.io/k8s-service-introduction-b1197f5d0ab4?source=collection_archive---------6-----------------------#2022-08-24</a></blockquote><div><div class="fc if ig ih ii ij"/><div class="ik il im in io"><div class=""/><div class=""><h2 id="8027" class="pw-subtitle-paragraph jo iq ir bd b jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf dk translated">K8s 服务介绍</h2></div><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div class="gi gj kg"><img src="../Images/3eebd6ee9bd343d486963822ba7feaff.png" data-original-src="https://miro.medium.com/v2/resize:fit:826/format:webp/0*iumBQTxpiOFGl-xh.png"/></div></figure><p id="9a03" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">之前，我谈到了两个 API 对象，<a class="ae lk" rel="noopener ugc nofollow" target="_blank" href="/k8s-controller-deployment-b1434f17fc9d">部署</a>和<a class="ae lk" href="https://medium.com/geekculture/k8s-controller-daemonset-226b2ea15088" rel="noopener"> DaemonSet </a>。它们都是在线服务，但是使用不同的策略部署应用程序。部署创建任意数量的实例，守护进程为每个节点创建一个实例。</p><p id="2c20" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">这两个 API 对象可以部署各种形式的应用，在云原生时代，微服务无疑是应用的主流形式。</p><p id="7b00" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">为了更好地支持<code class="fe ll lm ln lo b">microservices</code>、<code class="fe ll lm ln lo b">service meshes</code>等应用架构，K8s 专门定义了一个新的对象:<code class="fe ll lm ln lo b">Service</code>，这是一种集群内的负载均衡机制，用于解决服务发现的关键问题。</p><h1 id="55cf" class="lp lq ir bd lr ls lt lu lv lw lx ly lz jx ma jy mb ka mc kb md kd me ke mf mg bi translated">为什么选择 K8s 服务</h1><p id="1795" class="pw-post-body-paragraph ko kp ir kq b kr mh js kt ku mi jv kw kx mj kz la lb mk ld le lf ml lh li lj ik bi translated">有了部署和守护进程，我们在集群中发布应用程序的工作就容易多了。借助 K8s 强大的自动化运维能力，我们可以将应用更新和在线应用的频率从以前的每月和每周级别提高到每天和每小时级别，将服务质量提升到一个新的水平。</p><p id="02bd" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">然而，在应用对快速版本进行迭代的同时，另一个问题也逐渐显现出来，那就是“服务发现”。</p><p id="ff21" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">K8s 集群中一个 Pod 的生命周期比较“短”。虽然 Deployment 和 DaemonSet 可以维持吊舱整体数量的稳定，但在运行过程中不可避免地会出现吊舱被破坏和重建的情况，这就造成了吊舱集合处于动态状态。</p><p id="7042" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">这种“动态稳定”对于现在流行的<code class="fe ll lm ln lo b">microservice</code>架构是非常致命的。试想一下，后台 Pod 的 IP 地址总是在变，客户端应该怎么访问？如果不处理好这个问题，Pod 的部署和 DaemonSet 管理就一文不值。</p><p id="2c6c" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">其实这个问题并不难。对于这种“不稳定”的后端服务，业界早已有解决方案，即“<strong class="kq is">负载均衡</strong>”。典型的应用包括 LVS、Nginx 等等。</p><p id="ebf4" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">他们在前端和后端之间增加了一个“中间层”，屏蔽后端的变化，为前端提供稳定的服务。</p><p id="a8db" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">但是 LVS 和 Nginx 毕竟不是云原生技术，所以 K8s 按照这个思路定义了一个新的 API 对象:<strong class="kq is"> Service </strong>。</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div class="gi gj mm"><img src="../Images/11e74728a5be03d08e936634e284d365.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/0*cXn1VRgAe0aFDD5U.png"/></div></figure><p id="e656" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">所以你可以想象 Service 的工作原理和 LVS、Nginx 差不多。K8s 会给它分配一个静态 IP 地址，然后它会自动管理和维护后面动态变化的那组 pod。当客户端访问服务时，它会根据一定的策略，将流量转发到一个 Pod。</p><p id="93b5" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">下图清楚地显示了 K8s 中服务的工作方式:</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gi gj mn"><img src="../Images/87c930553f1a10bd2eb56a9c62e08535.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Q5Rri8drNpzjh2LB"/></div></div><figcaption class="ms mt gk gi gj mu mv bd b be z dk translated">来自<a class="ae lk" href="https://kubernetes.io/zh-cn/docs/concepts/services-networking/service/" rel="noopener ugc nofollow" target="_blank"> k8s.io </a>的图片</figcaption></figure><p id="f9f3" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">如您所见，该服务在这里使用了<code class="fe ll lm ln lo b">iptables</code>技术。每个节点上的<code class="fe ll lm ln lo b">kube-proxy</code>组件自动维护<code class="fe ll lm ln lo b">iptables</code>规则。客户不再关心 Pod 的具体地址。</p><p id="50d4" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">只要访问到服务的固定 IP 地址，就会按照<code class="fe ll lm ln lo b">iptables</code>规则转发服务。请求多个 pod 进行管理是一种典型的负载平衡架构。</p><p id="c797" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">然而，服务并不仅仅使用<code class="fe ll lm ln lo b">iptables</code>来实现负载均衡。它还有另一个名为<code class="fe ll lm ln lo b"><strong class="kq is">ipvs</strong></code>的实现，性能更好。</p><h1 id="a3b9" class="lp lq ir bd lr ls lt lu lv lw lx ly lz jx ma jy mb ka mc kb md kd me ke mf mg bi translated">服务演示</h1><p id="bbbe" class="pw-post-body-paragraph ko kp ir kq b kr mh js kt ku mi jv kw kx mj kz la lb mk ld le lf ml lh li lj ik bi translated">让我们做一个快速的服务演示来帮助您更好地理解。在以下 YAML 文件中，我定义了一个典型的 K8s 服务:</p><pre class="kh ki kj kk gu mw lo mx my aw mz bi"><span id="9a92" class="na lq ir lo b gz nb nc l nd ne">apiVersion: v1<br/>kind: Service<br/>metadata:<br/>  name: hostnames<br/>spec:<br/>  selector:<br/>    app: hostnames<br/>  ports:<br/>  - name: default<br/>    protocol: TCP<br/>    port: 80<br/>    targetPort: 9376</span></pre><p id="4c9a" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">在上面的例子中，我使用了选择器字段来声明这个服务只代理标签为<code class="fe ll lm ln lo b">app=hostnames</code>的 pod。此外，该服务的端口 80 正在代理 Pod 的端口 9376。</p><p id="7e1a" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">应用程序部署 YAML 看起来像这样:</p><pre class="kh ki kj kk gu mw lo mx my aw mz bi"><span id="8685" class="na lq ir lo b gz nb nc l nd ne">apiVersion: apps/v1<br/>kind: Deployment<br/>metadata:<br/>  name: hostnames<br/>spec:<br/>  selector:<br/>    matchLabels:<br/>      app: hostnames<br/>  replicas: 3<br/>  template:<br/>    metadata:<br/>      labels:<br/>        app: hostnames<br/>    spec:<br/>      containers:<br/>      - name: hostnames<br/>        image: k8s.gcr.io/serve_hostname<br/>        ports:<br/>        - containerPort: 9376<br/>          protocol: TCP</span></pre><p id="d899" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">该应用程序每次访问端口 9376 时都会返回自己的主机名。选择器选择的 Pods 称为服务的<strong class="kq is">端点，您可以使用<code class="fe ll lm ln lo b">kubectl get ep</code>命令查看它们，如下所示:</strong></p><pre class="kh ki kj kk gu mw lo mx my aw mz bi"><span id="72eb" class="na lq ir lo b gz nb nc l nd ne">$ kubectl get endpoints hostnames<br/>NAME        ENDPOINTS<br/>hostnames   10.244.0.5:9376,10.244.0.6:9376,10.244.0.7:9376</span></pre><p id="1006" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">应该注意，只有处于运行状态并通过<code class="fe ll lm ln lo b">readinessProbe</code>检查的 pod 才会出现在服务的端点列表中。而且，当 Pod 出现问题时，K8s 会自动将其从服务中删除。</p><p id="8c6f" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">此时，通过服务<code class="fe ll lm ln lo b">10.0.1.175,</code>的 VIP 地址，您可以访问它所代理的 Pod:</p><pre class="kh ki kj kk gu mw lo mx my aw mz bi"><span id="26ce" class="na lq ir lo b gz nb nc l nd ne">$ kubectl get svc hostnames<br/>NAME        TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE<br/>hostnames   ClusterIP   10.0.1.175   &lt;none&gt;        80/TCP    5s</span><span id="0c92" class="na lq ir lo b gz nf nc l nd ne">$ curl 10.0.1.175:80<br/>hostnames-0uton</span><span id="947d" class="na lq ir lo b gz nf nc l nd ne">$ curl 10.0.1.175:80<br/>hostnames-yp2kp</span><span id="9451" class="na lq ir lo b gz nf nc l nd ne">$ curl 10.0.1.175:80<br/>hostnames-bvc05</span></pre><p id="919d" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">此 VIP 地址由 K8s 为服务自动分配。而且和上面一样，通过连续三次访问服务的 VIP 地址和代理端口 80，它依次为我们返回三个 pod 的主机名。这也证实了服务提供的负载平衡是循环法。对于这种方法，我们称之为:ClusterIP 模式下的服务。</p><h1 id="b3fe" class="lp lq ir bd lr ls lt lu lv lw lx ly lz jx ma jy mb ka mc kb md kd me ke mf mg bi translated">使用 YAML 描述服务</h1><p id="4ba1" class="pw-post-body-paragraph ko kp ir kq b kr mh js kt ku mi jv kw kx mj kz la lb mk ld le lf ml lh li lj ik bi translated">了解了服务的基本工作原理，让我们来看看如何为服务编写一个 YAML 描述文件。</p><p id="e7fe" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">像往常一样，我们仍然可以使用命令<code class="fe ll lm ln lo b">kubectl api-resources</code>查看它的基本信息，我们可以知道它的缩写是<code class="fe ll lm ln lo b">svc</code>,<code class="fe ll lm ln lo b">apiVersion</code>是<code class="fe ll lm ln lo b">v1</code>。</p><p id="78e4" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">注意，这意味着它和 Pod 一样，属于 K8s 的核心对象，不与业务应用关联，与 Job 和 Deployment 不同。</p><p id="039e" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">让我们看一个真实的例子。假设我们想为 ngx-dep 应用程序生成一个服务，该命令应该写成这样:</p><pre class="kh ki kj kk gu mw lo mx my aw mz bi"><span id="d483" class="na lq ir lo b gz nb nc l nd ne">$ kubectl expose deploy ngx-dep --port=80 --target-port=80 --dry-run=client -o yaml</span></pre><p id="68c9" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">输出将类似于:</p><pre class="kh ki kj kk gu mw lo mx my aw mz bi"><span id="c0d8" class="na lq ir lo b gz nb nc l nd ne">apiVersion: v1<br/>kind: Service<br/>metadata:<br/>  creationTimestamp: null<br/>  labels:<br/>    app: ngx-dep<br/>  name: ngx-dep<br/>spec:<br/>  ports:<br/>  - port: 80<br/>    protocol: TCP<br/>    targetPort: 80<br/>  selector:<br/>    app: ngx-dep<br/>status:<br/>  loadBalancer: {}</span></pre><p id="4362" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">你会发现服务的定义很简单，在“spec”中只有两个关键字段，<code class="fe ll lm ln lo b">selector</code>和<code class="fe ll lm ln lo b">ports</code>。</p><p id="3b13" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">选择器的作用与 Deployment/DaemonSet 中的作用相同，用于筛选出那些要代理的 pod。因为我们指定了代理部署，所以 K8s 会自动为我们填充 ngx-dep 标签，并且这个部署对象部署的所有 pod 都会被选中。</p><p id="d9bf" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">从这里也可以看出，K8s 的标签机制虽然很简单，但是非常强大有效，很容易让人联想到部署的 Pod。</p><p id="a3dd" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">端口很好理解。里面的三个字段代表外部端口、内部端口和使用的协议。在这里，内部和外部都使用端口 80，协议是 TCP。</p><p id="4c61" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">当然，也可以将端口改为“8080”等其他端口，这样外部服务看到的是服务给定的端口，并不知道 Pod 真正的服务端口。</p><p id="fa4c" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">下图应该有助于您清楚地了解服务和 Pod 之间的关系:</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gi gj ng"><img src="../Images/b9ca607b0b693b3ba72ef84911fe7626.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S4936xVgVw9KROzM53jw6g.png"/></div></div></figure><p id="0252" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">当我们定义服务时，我们可以指定我们需要的服务类型。如果我们不指定，默认是<code class="fe ll lm ln lo b">ClusterIP</code>类型。</p><p id="841f" class="pw-post-body-paragraph ko kp ir kq b kr ks js kt ku kv jv kw kx ky kz la lb lc ld le lf lg lh li lj ik bi translated">我们可以使用的服务类型如下:</p><ul class=""><li id="8cfe" class="nh ni ir kq b kr ks ku kv kx nj lb nk lf nl lj nm nn no np bi translated"><strong class="kq is"> ClusterIP </strong>:通过集群内部 IP 公开服务。如果选择此值，则只能在群集内访问服务，这也是默认的服务类型。</li><li id="ab71" class="nh ni ir kq b kr nq ku nr kx ns lb nt lf nu lj nm nn no np bi translated"><strong class="kq is"> NodePort </strong>:通过每个节点 Node 上的 IP 和静态端口(NodePort)公开服务。NodePort 服务被路由到自动创建的 ClusterIP 服务。通过请求<code class="fe ll lm ln lo b">NodeIp:NodePort</code>，可以从集群外部访问节点端口服务。</li><li id="b0f6" class="nh ni ir kq b kr nq ku nr kx ns lb nt lf nu lj nm nn no np bi translated"><strong class="kq is">负载平衡器</strong>:使用云提供商的负载平衡器向外界公开服务。外部负载平衡器可以路由到 NodePort 服务和 ClusterIP 服务，这些服务需要与特定的云供应商一起操作。</li><li id="228b" class="nh ni ir kq b kr nq ku nr kx ns lb nt lf nu lj nm nn no np bi translated"><strong class="kq is"> ExternalName </strong>:通过返回<code class="fe ll lm ln lo b">CNAME</code>及其值，服务可以映射到<code class="fe ll lm ln lo b">externalName</code>字段的内容(例如 foo.bar.example.com)。</li></ul><h1 id="97ef" class="lp lq ir bd lr ls lt lu lv lw lx ly lz jx ma jy mb ka mc kb md kd me ke mf mg bi translated">结论</h1><p id="5c17" class="pw-post-body-paragraph ko kp ir kq b kr mh js kt ku mi jv kw kx mj kz la lb mk ld le lf ml lh li lj ik bi translated">我们在这篇文章中讨论了 K8s 服务的基础，接下来我们将讨论 K8s 中服务的具体工作方式，以及<code class="fe ll lm ln lo b">iptables</code>和<code class="fe ll lm ln lo b">ipvs</code>之间的区别。</p></div></div>    
</body>
</html>