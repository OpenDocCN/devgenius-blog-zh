# Hadoop 是什么？

> 原文：<https://blog.devgenius.io/what-is-hadoop-5047a94f44fb?source=collection_archive---------1----------------------->

![](img/d13cf8410cfa8e5303724d9246ed0764.png)

Hadoop 框架提供了一个开源平台来处理跨计算机集群的大量数据。由于其强大的功能，在大数据领域变得异常热门。Hadoop 允许我们存储任何类型的数据，并处理多个并发任务。今天，我们将了解更多关于该平台的信息，并讨论 Hadoop 生态系统、Hadoop 的工作原理、优缺点以及更多内容。

我们开始吧！

**我们将讲述**:

*   什么是 Apache Hadoop？
*   Hadoop 生态系统
*   Hadoop 是如何工作的？
*   Hadoop 的优点、缺点和使用案例
*   Hadoop vs Spark
*   总结和后续步骤

# 什么是 Apache Hadoop？

Hadoop 是由 Apache 软件基金会开发的开源软件框架。它使用编程模型**处理大型数据集**。Hadoop 是用 Java 编写的，它建立在 **Hadoop 集群**之上。这些集群是计算机或节点的集合，它们一起工作来执行数据计算。Apache 还有其他与 Hadoop 集成的软件项目，包括执行数据存储、管理 Hadoop 作业、分析数据等等。我们可以将 Hadoop 与亚马逊 AWS、微软 Azure 和 Cloudera 等云服务结合使用，来管理和组织我们的**大数据工作**。

# Hadoop 的历史

Apache Hadoop 始于 2002 年，当时 Doug Cutting 和 Mike Cafarella 正在开发 Apache Nutch。他们了解到 Nutch 并不完全有能力处理大量数据，所以他们开始头脑风暴寻找解决方案。他们学习了 Google 文件系统(GFS)的架构和 MapReduce 技术，后者可以处理大型数据集。他们开始在他们的开源 Nutch 项目中实现 **GFS 和 MapReduce 技术**，但是 Nutch 仍然不能完全满足他们的需求。

当 Cutting 在 2006 年加入雅虎时，他组建了一个名为 Hadoop 的新项目。他从 Apache Nutch 中分离出分布式计算部分，并与雅虎合作设计 Hadoop，使其能够处理成千上万的节点。2007 年，雅虎在 1000 个节点的集群上测试了 Hadoop，并开始在内部使用。2008 年初，Hadoop 作为开源项目在 Apache 软件基金会发布。同年晚些时候，他们在一个 4000 节点的集群上成功测试了 Hadoop。

2009 年，Hadoop 能够处理数十亿次搜索，并索引数百万个网页。此时，Cutting 加入了 Cloudera 团队，帮助将 Hadoop 推广到云行业。终于在 2011 年，Hadoop 1.0 版本发布。最新版本(3.3.1)发布于 2021 年。

# Hadoop 生态系统

Hadoop 生态系统是一套**服务**，我们可以用它来处理大数据计划。生态系统的四个主要元素包括:

*   MapReduce
*   Hadoop 分布式文件系统(HDFS)
*   又一个资源协商者(YARN)
*   Hadoop Common 让我们仔细看看这些服务。

# MapReduce

Hadoop MapReduce 是一个用于分布式计算的**编程模型**。有了这个模型，我们可以在大型商用硬件集群上并行处理大量数据。有了 MapReduce，我们可以用*地图*和*还原*。使用 Map，我们可以将一组数据转换成元组(键/值对)。Reduce 将 Map 的输出作为输入，并将元组组合成更小的元组集。MapReduce 使得扩展数据处理变得容易**在集群中运行数万台机器**。

在 MapReduce 作业期间，Hadoop 将任务发送到集群中各自的服务器。当任务完成时，集群收集数据并将其归纳为结果，然后将结果发送回 Hadoop 服务器。

# Hadoop 分布式文件系统(HDFS)

顾名思义，HDFS 是一个**分布式文件系统**。它可以处理大量的数据，并在商用硬件上运行。HDFS 帮助我们将单个 Hadoop 集群扩展到多个节点，并帮助我们执行**并行处理**。内置服务器 *NameNode* 和 *DataNode* 帮助我们检查集群的状态。HDFS 的设计具有高度的容错性、可移植性和成本效益。

# 又一个资源协商者(YARN)

Hadoop YARN 是一个**集群资源管理**和作业调度工具。YARN 还处理我们存储在 HDFS 的数据，使我们能够执行以下任务:

*   图形处理
*   交互式处理
*   流处理
*   成批处理

它动态地分配资源和调度应用程序处理。YARN 支持 MapReduce，以及其他多种处理模型。它有效地利用了资源，并且是**向后兼容的**，这意味着它可以在以前的 Hadoop 版本上运行，没有任何问题。

# Hadoop 常见

Hadoop Common，也称为 Hadoop Core，提供了我们可以在所有 Hadoop 模块中使用的 Java 库。

# 其他组件包括:

*   Cassandra 是一个宽列商店 NoSQL 数据库管理系统。
*   **Flume** : Flume 聚集、收集和移动大量的日志数据。
*   **Pig** : Pig 是一种用于分析大型数据集的高级编程语言。
*   HBase 是一个运行在 HDFS 之上的非关系数据库管理系统。
*   **Hive** : Apache Hive 是一个容错的、类似 SQL 的数据仓库软件，处理数据的读取、写入和管理。
*   **Lucene** : Lucene 是用 Java 编写的开源搜索引擎软件库。它提供了强大的搜索和索引功能。
*   **Mahout** : Apache Mahout 是一个开源项目，用于创建可扩展的机器学习算法。
*   **Oozie** : Oozie 是一个用于处理 Hadoop 任务的工作负载调度系统。
*   **Spark MLib** : MLlib 是一个可扩展的机器学习库，拥有 Java、Scala、R 和 Python APIs。
*   Solr 是一个基于 Lucene 的企业搜索平台。
*   Sqoop 是一个 CLI 应用程序，用于在关系数据库和 Hadoop 之间传输数据。
*   **潜水艇**:潜水艇是一个云端原生的机器学习和深度学习平台。它支持数据处理、算法开发、ML 框架和容器化工作。
*   **Zookeeper** : Zookeeper 是一个集中式服务器，用于可靠的分布式云应用协调。

# Hadoop 是如何工作的？

在上一节中，我们讨论了大量与 Hadoop 集成的服务。我们现在知道 Hadoop 生态系统很大并且可扩展。它允许我们执行许多任务，如收集、存储、分析、处理和管理大数据。Hadoop 为我们提供了一个可以构建其他服务和应用的平台。

应用程序可以使用 **API 操作**连接到 NameNode 并将数据放入 Hadoop 集群。`NameNode`跨 DataNodes 以块的形式复制这些数据。我们可以使用 MapReduce 在 HDFS 运行作业、查询数据和减少任务。Map 任务根据我们提供的文件在每个节点上运行，并减少任务，或减少器，聚集和组织我们的输出。

# Hadoop 的优点、缺点和使用案例

Hadoop 是一个流行的平台，有它的优点和缺点。让我们看一看它们，然后我们将讨论一些用例。

# 赞成的意见

*   **性价比高**:传统上，存储大量数据需要花费大量资金。Hadoop 解决了这个问题，它还存储所有原始数据，以便在需要时可以随时访问。
*   **高可用性**:HDFS 高可用性特性允许我们在同一个集群中运行两个或更多冗余的 NameNodes，这允许在机器崩溃或出现故障的情况下进行快速故障转移。
*   **可扩展性**:通过添加更多节点，可以轻松提高存储和处理能力。
*   系统化:HDFS 周到地处理所有组件和程序。
*   **灵活性** : Hadoop 可以处理结构化数据和非结构化数据。
*   活跃社区:Hadoop 拥有庞大的用户群，因此很容易找到有用的文档或与您遇到的任何问题相关的帮助。
*   MapReduce 功能强大，可以通过 Java 或 Apache Pig 来利用。
*   **丰富的生态系统** : Hadoop 拥有如此多的配套工具和服务，可以轻松集成到平台中。这些服务允许我们执行许多与数据相关的不同任务。
*   **并行处理** : Hadoop 高效执行并行处理，甚至可以处理数 Pb 的数据。
*   **数据格式化**:在不同类型的数据格式之间转换有时会造成数据丢失，但在 Hadoop 中格式不需要改变。

# 骗局

*   小文件:HDFS 缺乏支持小文件的能力，因为它是为处理高容量的情况而设计的。
*   **无实时处理** : Hadoop 不适合实时数据处理。Apache Spark 或 Apache Flink 是帮助加速这个过程的很好的资源。
*   **安全性** : Hadoops 在存储和网络层面缺乏加密，这意味着你的数据可能面临风险。Spark 提供安全奖励来帮助克服 Hadoop 的局限性。
*   **响应时间**:MapReduce 编程框架有时会运行缓慢。
*   **学习曲线**:有许多不同的模块和服务可用于 Hadoop，这些可能需要花费大量时间来学习。
*   **复杂界面**:界面不是很直观，所以可能需要一段时间来熟悉平台。

# 用例

**数据驱动的决策**

我们可以集成数据仓库或关系数据库中没有使用的结构化和非结构化数据。这使我们能够基于广泛的数据做出更精确的决策。

**大数据分析和访问**

Hadoop 非常适合数据科学家和 ML 工程师，因为它允许我们执行高级分析来发现模式并开发准确有效的预测模型。

**数据湖泊**

Hadoop 治理解决方案可以帮助我们实现数据湖的数据集成、安全性和质量。

**金融服务**

Hadoop 可以帮助我们构建和运行应用程序来评估风险、设计投资模型和创建交易算法。

**医疗保健**

Hadoop 帮助我们跟踪大规模的健康指数，并跟踪患者记录。

**销售预测**

Hadoop 用于零售公司，通过研究历史数据来帮助预测销售和增加利润。

# Hadoop vs Spark

Apache Hadoop 和 Apache Spark 经常被相互比较，因为它们都是用于大数据处理的开源框架。Spark 是一个较新的项目，最初开发于 2012 年。它专注于跨集群的数据并行处理，它**在内存**中工作。这意味着它比 MapReduce 快得多。

如果您正在批量处理大量数据，Hadoop 是更好的平台。如果你在流数据、创建图形计算或进行机器学习，Spark 是更好的平台。Spark 支持**实时**数据处理和批处理。Spark 可以使用许多不同的库，包括用于机器学习、SQL 任务、流数据和图形的库。

# 总结和后续步骤

祝贺您迈出 Apache Hadoop 的第一步！Hadoop 生态系统强大而广泛，关于 Hadoop 还有很多东西需要学习。接下来推荐的一些概念包括:

*   弹性分布式数据集
*   Hadoop 数据管理
*   Avro 和拼花地板

*快乐学习！*