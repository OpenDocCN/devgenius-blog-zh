<html>
<head>
<title>HDFS Commands</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">HDFS 命令</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/hdfs-commands-db5865e6305e?source=collection_archive---------9-----------------------#2022-11-01">https://blog.devgenius.io/hdfs-commands-db5865e6305e?source=collection_archive---------9-----------------------#2022-11-01</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><figure class="gl gn jl jm jn jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi jk"><img src="../Images/a91a82dcabe096e5c47e029ffa60bf74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LPhUfj_26ZoE9xAW9fRU1A.jpeg"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk translated">他们只需要一个前缀😗</figcaption></figure><p id="10f9" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">之后，我们安装了 Cloudera Quickstart VM，我们可以开始尝试在终端上运行一些基本命令，并尝试做一些基本的事情，如重命名文件、创建文件等。如果你还没有在你的机器上安装 Quickstart VM，那就按照我上一篇<a class="ae kx" href="https://medium.com/@prikshitsingla78/installation-of-hadoop-on-windows-266671e79921" rel="noopener">文章</a>在 windows 上安装吧(我没有 mac💻直到现在，但我一定会写安装步骤，当我得到一个)。</p><p id="bf79" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">要打开终端，只需点击顶部的终端图标</p><figure class="kz la lb lc gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi ky"><img src="../Images/3017db9edaf446fd673ded7e72ac5b1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7fOBICgDkxeCbPHH1XZAUA.png"/></div></div></figure><p id="49f7" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">在开始编写代码之前，让我们先了解一下 hdfs 的基本文件结构。</p><p id="a077" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">我们可以使用两种主目录，一种是本地目录，另一种是 HDFS 目录本地目录就像 windows 或 Linux 中的任何其他目录一样，没有分布式处理，而在 HDFS 有分布式处理。</p><p id="d807" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">本地用户的主目录:<strong class="kb io"> /home/cloudera </strong></p><p id="f597" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">HDFS 用户的主目录:<strong class="kb io">/用户/云时代</strong></p><h1 id="1fb1" class="ld le in bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">HDFS 命令是如何工作的？</h1><figure class="kz la lb lc gt jo gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/f398d3f7024bf7f2a9ae8379dbae402a.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/format:webp/1*UXwbqO7VoWwJx3YlBwoXmA.jpeg"/></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">😶😶</figcaption></figure><p id="099a" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">所有 HDFS 命令都将与名称节点交互(例如:ls)。但是，有些命令会转到数据节点，从文件中读取数据(例如:cat、tail)</p><h2 id="78df" class="mc le in bd lf md me dn lj mf mg dp ln kk mh mi lr ko mj mk lv ks ml mm lz mn bi translated"><strong class="ak">一些有助于进一步理解的基本符号</strong></h2><ol class=""><li id="659e" class="mo mp in kb b kc mq kg mr kk ms ko mt ks mu kw mv mw mx my bi translated">根文件夹<strong class="kb io"> / </strong></li><li id="839a" class="mo mp in kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">首页<strong class="kb io"> ~ </strong></li><li id="0be0" class="mo mp in kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">当前。</li><li id="e2c7" class="mo mp in kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">父级<strong class="kb io">..</strong></li><li id="fd83" class="mo mp in kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">上一个<strong class="kb io"> - </strong></li></ol><h1 id="29c7" class="ld le in bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">一些 HDFS 命令</h1><p id="94bd" class="pw-post-body-paragraph jz ka in kb b kc mq ke kf kg mr ki kj kk ne km kn ko nf kq kr ks ng ku kv kw ig bi translated">命令就像 Linux 中的命令一样，但我们只是在每个命令中都有<strong class="kb io"> <em class="nh"> hadoop fs </em> </strong> -或<strong class="kb io"> <em class="nh"> hdfs dfs - </em> </strong>前缀，所以命令变成了。</p><figure class="kz la lb lc gt jo gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/b56ba11ac3d90412541f24555ed0b22a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/1*Zo8UEEoSglzM3wCMlobD7w.jpeg"/></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk translated">这就是 HDFS 处理大数据的方式🌋🌋</figcaption></figure><pre class="kz la lb lc gt nj nk nl nm aw nn bi"><span id="8bf4" class="mc le in nk b gy no np l nq nr"><strong class="nk io">hadoop fs - &lt;command name&gt;<br/>hdfs dfs - &lt;command name&gt;</strong></span></pre><blockquote class="ns nt nu"><p id="b320" class="jz ka nh kb b kc kd ke kf kg kh ki kj nv kl km kn nw kp kq kr nx kt ku kv kw ig bi translated">注意:-获取任何命令的帮助<strong class="kb io"> hadoop fs -help &lt;命令名&gt; </strong></p></blockquote><h2 id="0352" class="mc le in bd lf md me dn lj mf mg dp ln kk mh mi lr ko mj mk lv ks ml mm lz mn bi translated">ls 命令</h2><p id="c302" class="pw-post-body-paragraph jz ka in kb b kc mq ke kf kg mr ki kj kk ne km kn ko nf kq kr ks ng ku kv kw ig bi translated">查看目录中的文件列表</p><pre class="kz la lb lc gt nj nk nl nm aw nn bi"><span id="fa7e" class="mc le in nk b gy no np l nq nr"><strong class="nk io">hadoop fs -ls /user/cloudera<br/>hadoop fs -ls (it will display all the files and folders in current directory)</strong></span></pre><p id="e549" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">按时间排序文件</p><pre class="kz la lb lc gt nj nk nl nm aw nn bi"><span id="7a56" class="mc le in nk b gy no np l nq nr"><strong class="nk io">hadoop fs -ls -t -r /</strong></span></pre><p id="bf20" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><em class="nh">这里，t 代表时间，r 代表反向，因此最早的文件将首先显示</em></p><p id="ac66" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">按大小排序(默认情况下，最大的在顶部)</p><pre class="kz la lb lc gt nj nk nl nm aw nn bi"><span id="dad5" class="mc le in nk b gy no np l nq nr"><strong class="nk io">hadoop fs -ls -S /<br/>hadoop fs -ls -S -h / (size will be displayed now in human readable form)</strong></span></pre><p id="7b65" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">使用 grep 在列出的文件中搜索</p><pre class="kz la lb lc gt nj nk nl nm aw nn bi"><span id="c6a8" class="mc le in nk b gy no np l nq nr"><strong class="nk io">hadoop fs - ls /user | grep cloudera</strong></span></pre><p id="6896" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">我们将首先在/user 目录中查找文件，然后在该列表中查找 cloudera。当我们需要一个接一个地使用命令时，可以使用管道运算符(|)。</p><h2 id="8055" class="mc le in bd lf md me dn lj mf mg dp ln kk mh mi lr ko mj mk lv ks ml mm lz mn bi translated">mkdir 命令</h2><p id="cddc" class="pw-post-body-paragraph jz ka in kb b kc mq ke kf kg mr ki kj kk ne km kn ko nf kq kr ks ng ku kv kw ig bi translated">它用于创建目录</p><pre class="kz la lb lc gt nj nk nl nm aw nn bi"><span id="0b09" class="mc le in nk b gy no np l nq nr"><strong class="nk io">hadoop fs -mkdir /user/cloudera/testing</strong></span></pre><h2 id="4d35" class="mc le in bd lf md me dn lj mf mg dp ln kk mh mi lr ko mj mk lv ks ml mm lz mn bi translated">rm 命令</h2><p id="65cb" class="pw-post-body-paragraph jz ka in kb b kc mq ke kf kg mr ki kj kk ne km kn ko nf kq kr ks ng ku kv kw ig bi translated">rm 可以用来删除文件</p><pre class="kz la lb lc gt nj nk nl nm aw nn bi"><span id="8d1f" class="mc le in nk b gy no np l nq nr"><strong class="nk io">hadoop fs -rm /user/cloudera/file1.txt (will just remove files not directories)</strong></span><span id="7e19" class="mc le in nk b gy ny np l nq nr"><strong class="nk io">hadoop fs -rm -R /user/cloudera/testing (will remove directory)</strong></span></pre><h2 id="0526" class="mc le in bd lf md me dn lj mf mg dp ln kk mh mi lr ko mj mk lv ks ml mm lz mn bi translated">将文件或文件夹从本地复制到 hdfs</h2><p id="c4e8" class="pw-post-body-paragraph jz ka in kb b kc mq ke kf kg mr ki kj kk ne km kn ko nf kq kr ks ng ku kv kw ig bi translated">(copyFromLocal 或 put)命令用于将本地文件复制到 hdfs。</p><pre class="kz la lb lc gt nj nk nl nm aw nn bi"><span id="1821" class="mc le in nk b gy no np l nq nr"><em class="nh">hadoop fs -copyFromLocal &lt;local_path&gt; &lt;hdfs_path&gt;</em></span><span id="d4d6" class="mc le in nk b gy ny np l nq nr"><strong class="nk io">hadoop fs -copyFromLocal Desktop/file1.txt /data<br/>hadoop fs -put Desktop/file1.txt /data</strong></span></pre><h2 id="3d11" class="mc le in bd lf md me dn lj mf mg dp ln kk mh mi lr ko mj mk lv ks ml mm lz mn bi translated">将文件或文件夹从 hdfs 复制到本地</h2><p id="a4c5" class="pw-post-body-paragraph jz ka in kb b kc mq ke kf kg mr ki kj kk ne km kn ko nf kq kr ks ng ku kv kw ig bi translated">(copyToLocal 或 get)命令用于将 hdfs 文件复制到本地。</p><pre class="kz la lb lc gt nj nk nl nm aw nn bi"><span id="a49f" class="mc le in nk b gy no np l nq nr"><em class="nh">hadoop fs -copyToLocal &lt;hdfs_path&gt; &lt;local_path&gt;<br/>hadoop fs -get &lt;hdfs_path&gt; &lt;local_path&gt;</em></span></pre><h2 id="2d07" class="mc le in bd lf md me dn lj mf mg dp ln kk mh mi lr ko mj mk lv ks ml mm lz mn bi translated"><strong class="ak"> cp 命令</strong></h2><p id="ed39" class="pw-post-body-paragraph jz ka in kb b kc mq ke kf kg mr ki kj kk ne km kn ko nf kq kr ks ng ku kv kw ig bi translated">将一个位置从一个 hdfs 位置复制到另一个位置</p><pre class="kz la lb lc gt nj nk nl nm aw nn bi"><span id="65e3" class="mc le in nk b gy no np l nq nr"><em class="nh">hadoop fs -cp &lt;hdfs_path1&gt; &lt;hdfs_path2&gt;</em></span></pre><h2 id="1bde" class="mc le in bd lf md me dn lj mf mg dp ln kk mh mi lr ko mj mk lv ks ml mm lz mn bi translated">mv 命令</h2><p id="aec4" class="pw-post-body-paragraph jz ka in kb b kc mq ke kf kg mr ki kj kk ne km kn ko nf kq kr ks ng ku kv kw ig bi translated">该命令用于将文件从一个位置移动到另一个位置。这仅仅意味着我们正在重命名一个文件。所以只需要更新元数据，这非常快</p><pre class="kz la lb lc gt nj nk nl nm aw nn bi"><span id="ba18" class="mc le in nk b gy no np l nq nr"><em class="nh">hadoop fs -mv &lt;hdfs_path1&gt; &lt;hdfs_path2&gt;</em></span></pre><blockquote class="ns nt nu"><p id="4f9c" class="jz ka nh kb b kc kd ke kf kg kh ki kj nv kl km kn nw kp kq kr nx kt ku kv kw ig bi translated">注意:-对于 cp 和 mv 命令，条件是我们可以在 hdfs 或本地移动/复制它。使用这些命令无法在本地和 hdfs 之间进行交叉移动，反之亦然</p></blockquote><h2 id="884b" class="mc le in bd lf md me dn lj mf mg dp ln kk mh mi lr ko mj mk lv ks ml mm lz mn bi translated">测向命令</h2><p id="200a" class="pw-post-body-paragraph jz ka in kb b kc mq ke kf kg mr ki kj kk ne km kn ko nf kq kr ks ng ku kv kw ig bi translated">df 命令用于检查可用磁盘空间</p><pre class="kz la lb lc gt nj nk nl nm aw nn bi"><span id="0d3c" class="mc le in nk b gy no np l nq nr"><strong class="nk io">hadoop fs -df -h /user/cloudera (h is for human readable form)</strong></span></pre><p id="8ae2" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io">杜命令</strong></p><p id="6690" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">du 命令用于检查磁盘使用情况</p><pre class="kz la lb lc gt nj nk nl nm aw nn bi"><span id="df93" class="mc le in nk b gy no np l nq nr"><strong class="nk io">hadoop fs -du -h /user/cloudera</strong></span></pre><h1 id="ffbc" class="ld le in bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">一些重要且有用的命令</h1><h2 id="01ac" class="mc le in bd lf md me dn lj mf mg dp ln kk mh mi lr ko mj mk lv ks ml mm lz mn bi translated">动态改变复制因子</h2><p id="e62a" class="pw-post-body-paragraph jz ka in kb b kc mq ke kf kg mr ki kj kk ne km kn ko nf kq kr ks ng ku kv kw ig bi translated">为了更改默认情况下数据节点的复制因子<strong class="kb io"> 3 </strong>，我们需要设置以下属性</p><p id="4bd8" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io"> dfs.replication=5 </strong></p><h2 id="b3cf" class="mc le in bd lf md me dn lj mf mg dp ln kk mh mi lr ko mj mk lv ks ml mm lz mn bi translated">fsck 命令</h2><p id="6b20" class="pw-post-body-paragraph jz ka in kb b kc mq ke kf kg mr ki kj kk ne km kn ko nf kq kr ks ng ku kv kw ig bi translated">该命令用于查看 hdfs 中的元数据。fsck 代表文件系统检查</p><pre class="kz la lb lc gt nj nk nl nm aw nn bi"><span id="6594" class="mc le in nk b gy no np l nq nr"><strong class="nk io">hdfs  fsck  /user/data.csv -files  -blocks  -locations</strong></span></pre><p id="3ff2" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">上述命令将给出数据块信息和复制信息，以及保存数据块的数据节点的 ip 地址。</p><figure class="kz la lb lc gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi nz"><img src="../Images/52a5c90ba70ceca664fbb874888f420a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-1NDC2YSJmFZQk-Lrkoang.jpeg"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk translated">当我键入这些命令时，我的父母和兄弟姐妹如何看待我🤣🤣</figcaption></figure><p id="4a38" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">我想今天要消化的太多了。我知道这可能看起来像是一个很长的命令列表，但实际上您并不需要学习它们，您实际上可以看到命令名称实际上告诉了它很多信息，因为我们将练习这些命令，我们将掌握它们。所以，不要担心和冷却🧊.我们将会有很多的乐趣📝部分之后会有很多实用的东西。</p><p id="101d" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">下一次，我们见面的时候，我们将开始我们的冒险🎢使用 Map Reduce，您将看到 Hadoop 的实际功率⚡。相信我，这是令人敬畏的家伙！我们今天已经伸展够久了。</p><p id="53bd" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">让我们结束这篇博客吧🤗暂时的！</p><figure class="kz la lb lc gt jo gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/cd937df5a1b1ecf4ff14f7858e5e9bd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/1*1LvOPP3sIrwztIztrWAYoQ.gif"/></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk translated">直到下次伙计们🥰🥰</figcaption></figure><p id="ff41" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io">谢谢！为了阅读。</strong></p><p id="a60a" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">如果你喜欢这个博客，请鼓掌回应👏</p><p id="f502" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io">跟随..☺️ </strong> <a class="ae kx" href="https://medium.com/@prikshitsingla78" rel="noopener"> <strong class="kb io">我</strong> </a> <strong class="kb io">更多这样有见地的 articles✍️ </strong></p><p id="56a9" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">请在评论中分享你的想法，并请分享对需要改进的部分的反馈，以便我下次改进。</p><p id="1fab" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">祝大家有美好的一天！</p></div></div>    
</body>
</html>