<html>
<head>
<title>Sample Reactor Kafka Producer and Consumer with Spring boot in Kotlin</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">科特林的样本反应堆 Kafka 生产者和消费者</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/sample-reactor-kafka-producer-and-consumer-with-spring-boot-in-kotlin-145b5f46e59e?source=collection_archive---------2-----------------------#2022-07-12">https://blog.devgenius.io/sample-reactor-kafka-producer-and-consumer-with-spring-boot-in-kotlin-145b5f46e59e?source=collection_archive---------2-----------------------#2022-07-12</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><p id="e8b7" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">创建了<a class="ae ki" href="https://github.com/seetharamani/sample-reactor-kafka-springboot" rel="noopener ugc nofollow" target="_blank">sample-reactor-kafka-springboot</a>存储库来展示如何使用 project-reactor 和 spring boot 启动 Kafka 消费者和生产者</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi kj"><img src="../Images/26dc039df058830d1773dfd755b0fcca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*18LF7eb3ncJUfGTbKREyyQ.png"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">@nasawebb</figcaption></figure><h1 id="11ca" class="kz la in bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">发布者配置</h1><p id="b5b7" class="pw-post-body-paragraph jk jl in jm b jn lx jp jq jr ly jt ju jv lz jx jy jz ma kb kc kd mb kf kg kh ig bi translated">这里需要注意的几件事是</p><ul class=""><li id="0656" class="mc md in jm b jn jo jr js jv me jz mf kd mg kh mh mi mj mk bi translated">我已经用<code class="fe ml mm mn mo b">String</code>数据类型的键和<code class="fe ml mm mn mo b">ByteArray</code>数据类型的值配置了发布者，从而配置了<code class="fe ml mm mn mo b">SenderOptions</code>中的<code class="fe ml mm mn mo b">StringSerializer</code>和<code class="fe ml mm mn mo b">ByteArraySerializer</code></li><li id="d335" class="mc md in jm b jn mp jr mq jv mr jz ms kd mt kh mh mi mj mk bi translated">这些配置只是为了举例。根据您的使用情况和负载相应地调整它们</li><li id="9681" class="mc md in jm b jn mp jr mq jv mr jz ms kd mt kh mh mi mj mk bi translated">只有在构造 ProducerRecord 时，才会构造 Publisher 主题。<code class="fe ml mm mn mo b">KafkaSender</code>中未配置主题</li></ul><pre class="kk kl km kn gt mu mo mv mw aw mx bi"><span id="c9e3" class="my la in mo b gy mz na l nb nc">@Component<br/>@ConfigurationProperties("kafka")<br/>class PublisherConfiguration {<br/>    lateinit var kafkaBootstrapServers: String<br/>    lateinit var clientId: String<br/>    lateinit var publisherTopic: String<br/>    lateinit var acks: String<br/><br/>    var maxRequestSize: Int = 0<br/>    var retries: Int = 0<br/>    var lingerMs: Int = 0<br/>    var reconnectBackoffMs: Int = 0<br/>    var retryBackoffMs: Int = 0<br/>    var batchSize: Int = 16384<br/><br/>    // this is default, in general should be much less, <br/>    // but &gt; replica.lag.time.max.ms<br/>    var requestTimeoutMs: Int = 30 * 1000<br/><br/>    private fun getSenderOptions(): <br/>SenderOptions&lt;String, ByteArray&gt; {<br/>        val properties = Properties()<br/>        properties[ProducerConfig.BOOTSTRAP_SERVERS_CONFIG] = kafkaBootstrapServers<br/>        properties[ProducerConfig.CLIENT_ID_CONFIG] = clientId<br/>        properties[ProducerConfig.ACKS_CONFIG] = acks<br/>        properties[ProducerConfig.RETRIES_CONFIG] = retries<br/>        properties[ProducerConfig.LINGER_MS_CONFIG] = lingerMs<br/>        properties[ProducerConfig.MAX_REQUEST_SIZE_CONFIG] = maxRequestSize<br/>        properties[ProducerConfig.RECONNECT_BACKOFF_MS_CONFIG] = reconnectBackoffMs<br/>        properties[ProducerConfig.RETRY_BACKOFF_MS_CONFIG] = retryBackoffMs<br/>        properties[ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG] = StringSerializer::class.java<br/>        properties[ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG] = ByteArraySerializer::class.java<br/>        properties[ProducerConfig.BATCH_SIZE_CONFIG] = batchSize<br/>        properties[ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG] = requestTimeoutMs<br/><br/>        log.info("Kafka publisher properties configured : {}", properties)<br/><br/>        return SenderOptions.create(properties)<br/>    }<br/><br/>    @Bean<br/>    fun kafkaSender(<br/>           publisherConfiguration: PublisherConfiguration<br/>        ): KafkaSender&lt;String, ByteArray&gt; {</span><span id="1274" class="my la in mo b gy nd na l nb nc">        return KafkaSender.create(<br/>             publisherConfiguration.getSenderOptions()<br/>             )<br/>    }<br/><br/>    companion object {<br/>        private val log = LoggerFactory<br/>                 .getLogger(PublisherConfiguration::class.java)<br/>    }<br/>}</span></pre><h1 id="4a76" class="kz la in bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">接收器配置</h1><p id="dcb9" class="pw-post-body-paragraph jk jl in jm b jn lx jp jq jr ly jt ju jv lz jx jy jz ma kb kc kd mb kf kg kh ig bi translated">这里需要注意的几件事是</p><ul class=""><li id="62fb" class="mc md in jm b jn jo jr js jv me jz mf kd mg kh mh mi mj mk bi translated">确保为您的接收器设置群组 id</li><li id="a0c2" class="mc md in jm b jn mp jr mq jv mr jz ms kd mt kh mh mi mj mk bi translated">我已经用<code class="fe ml mm mn mo b">String</code>数据类型的键和<code class="fe ml mm mn mo b">ByteArray</code>数据类型的值配置了发布者，因此配置了<code class="fe ml mm mn mo b">ReceiverOptions</code>中的<code class="fe ml mm mn mo b">StringDeserializer</code>和<code class="fe ml mm mn mo b">ByteArrayDeserializer</code></li><li id="8167" class="mc md in jm b jn mp jr mq jv mr jz ms kd mt kh mh mi mj mk bi translated">这些配置只是为了举例。根据您的使用情况和负载相应地调整它们</li><li id="5f22" class="mc md in jm b jn mp jr mq jv mr jz ms kd mt kh mh mi mj mk bi translated">消费主题作为<code class="fe ml mm mn mo b">KafkaReceiver</code>的一部分进行配置</li></ul><pre class="kk kl km kn gt mu mo mv mw aw mx bi"><span id="30ae" class="my la in mo b gy mz na l nb nc">@Component<br/>@ConfigurationProperties("kafka")<br/>class ReceiverConfiguration {<br/><br/>    lateinit var kafkaBootstrapServers: String<br/>    lateinit var groupId: String<br/>    lateinit var clientId: String<br/>    lateinit var receiverTopic: String<br/>    lateinit var autoOffsetReset: String<br/><br/>    var concurrency: Int = 1<br/>    var maxPollTimeoutMs: Int = 10000<br/>    var backtrackTimeSeconds: Int = 15 * 60<br/><br/>    var retryBackoffMs: Int = 1000<br/>    var maxPollRecords: Int = 250<br/>    var maxPollIntervalMs: Int = 300_000<br/>    var sessionTimeoutMs: Int = 10_000<br/>    var heartbeatIntervalMs: Int = 3000<br/>    var requestTimeoutMs: Int = 30_000<br/>    var autoCommitIntervalMs: Int = 5000<br/>    var commitBatchSize: Int = 0<br/>    var commitIntervalMs: Long = 5000L<br/><br/>    fun getReceiverOptions(): ReceiverOptions&lt;String?, ByteArray&gt; {<br/>        val properties = Properties()<br/>        properties[ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG] = kafkaBootstrapServers<br/>        properties[ConsumerConfig.GROUP_ID_CONFIG] = groupId<br/>        properties[ConsumerConfig.CLIENT_ID_CONFIG] = clientId<br/>        properties[ConsumerConfig.RETRY_BACKOFF_MS_CONFIG] = retryBackoffMs<br/>        properties[ConsumerConfig.AUTO_OFFSET_RESET_CONFIG] = autoOffsetReset<br/>        properties[ConsumerConfig.MAX_POLL_RECORDS_CONFIG] = maxPollRecords<br/>        properties[ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG] = maxPollIntervalMs<br/>        properties[ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG] = sessionTimeoutMs<br/>        properties[ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG] = heartbeatIntervalMs<br/>        properties[ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG] = requestTimeoutMs<br/>        properties[ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG] = StringDeserializer::class.java<br/>        properties[ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG] = ByteArrayDeserializer::class.java<br/>        properties[ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG] = autoCommitIntervalMs<br/><br/>        log.info("Kafka receiver properties configured : {}", properties)<br/><br/>        return ReceiverOptions.create&lt;String?, ByteArray&gt;(properties)<br/>            .commitInterval(Duration.ofMillis(commitIntervalMs))<br/>            .commitBatchSize(commitBatchSize)<br/>    }<br/><br/>    @Bean<br/>    fun kafkaReceiver(receiverConfiguration: ReceiverConfiguration): KafkaReceiver&lt;String, ByteArray&gt; {<br/>        return KafkaReceiver.create&lt;String, ByteArray&gt;(<br/>            receiverConfiguration.getReceiverOptions().subscription(<br/>                listOf(<br/>                    receiverTopic<br/>                )<br/>            )<br/>        )<br/>    }<br/><br/><br/>    companion object {<br/>        private val log = LoggerFactory.getLogger(ReceiverConfiguration::class.java)<br/>    }<br/>}</span></pre><h1 id="6f52" class="kz la in bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">启动和停止消费者</h1><p id="4ebc" class="pw-post-body-paragraph jk jl in jm b jn lx jp jq jr ly jt ju jv lz jx jy jz ma kb kc kd mb kf kg kh ig bi translated"><code class="fe ml mm mn mo b">kafkaReceiver.receive().subscribe()</code>启动消费者，将它放在<code class="fe ml mm mn mo b">Workflow</code>类的<code class="fe ml mm mn mo b">PostConstruct</code>中可以确保一旦应用程序上下文被加载并且 bean 创建完成，接收者就开始消费消息。</p><pre class="kk kl km kn gt mu mo mv mw aw mx bi"><span id="9f32" class="my la in mo b gy mz na l nb nc">private val disposables = Disposables.composite()<br/><br/>@PostConstruct<br/>fun connect() {<br/>    disposables.add(<br/>        receive()<br/>            .subscribe(<br/>                <strong class="mo io">{ </strong>log.info("Ended subscription to Kafka Receiver") <strong class="mo io">}</strong>,<br/>                <strong class="mo io">{ </strong>err <strong class="mo io">-&gt; </strong>log.error("Error in Kafka Receiver flow", err) <strong class="mo io">}<br/>            </strong>)<br/>    )<br/>}<br/><br/>@PreDestroy<br/>fun disconnect() {<br/>    this.disposables.dispose()<br/>}</span></pre><h1 id="777e" class="kz la in bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">整合测试</h1><p id="8f95" class="pw-post-body-paragraph jk jl in jm b jn lx jp jq jr ly jt ju jv lz jx jy jz ma kb kc kd mb kf kg kh ig bi translated">使用<code class="fe ml mm mn mo b">EmbeddedKafka</code>注释配置带有输入和输出主题的 IT 测试</p><pre class="kk kl km kn gt mu mo mv mw aw mx bi"><span id="02c0" class="my la in mo b gy mz na l nb nc">@EmbeddedKafka(<em class="ne"><br/>    </em>partitions = 1,<br/>    topics = ["input", "output"]<br/>)</span></pre><p id="f057" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">除了我们在 PublisherConfiguration 和 ReceiverConfiguration 类中创建的 KafkaReceiver 和 KafkaSender 之外，我们还需要一个测试 kafka sender 来将消息发布到<code class="fe ml mm mn mo b">input</code>主题，以测试工作流应用测试 kafka sender 在<code class="fe ml mm mn mo b">@BeforeClass</code>设置中的配置，就像其他 kafka sender 发布到输出主题一样。</p><p id="b5c5" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">由于 kafka 接收器在应用程序启动后立即启动，我们需要确保以这种方式在<code class="fe ml mm mn mo b">@BeforeEach</code>中断开接收器，我们可以在我们的测试用例中订阅接收器以进行实际验证。</p><pre class="kk kl km kn gt mu mo mv mw aw mx bi"><span id="36b0" class="my la in mo b gy mz na l nb nc">@BeforeEach<br/>fun setUp() {<em class="ne"><br/>    </em>workflow.disconnect()<br/>}</span></pre><p id="8760" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">最后，作为测试的一部分，在验证之后处置订户。</p><p id="a750" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">完整项目在此—<a class="ae ki" href="https://github.com/seetharamani/sample-reactor-kafka-springboot" rel="noopener ugc nofollow" target="_blank">https://github . com/seetharamani/sample-reactor-Kafka-spring boot</a></p></div></div>    
</body>
</html>