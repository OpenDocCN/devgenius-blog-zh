# “AWS 中的以太坊数据分析和集成”:YouTube 演讲转录

> 原文：<https://blog.devgenius.io/ethereum-data-analysis-and-integration-youtube-talk-transcription-3a9b45c7ed2f?source=collection_archive---------10----------------------->

最近，我在 PyChain 2022 会议上做了一个关于为以太坊建立一个高级数据平台的报告。YouTube 上现在有一段视频[。这个演讲长达 19 分钟，所以为了方便起见，我在本文中提供了带转录的幻灯片。](https://youtu.be/MtBakcKJUCQ)

![](img/0d0cdec08dcf042a20bf578bf5db5f55.png)

大家好，感谢你们参加 PyChain 会议！我是安东，您今天的专业数据工程师。在我的演讲“AWS 中的以太坊数据分析和集成”中，我将…

![](img/dde67d826560e095bb26bdb2c1f4cd81.png)

…向您展示我在区块链地区的最新解决方案。这是一个数据平台，用于**分析以太坊数据，并将其用于实时应用**。

其实这个演讲是对[我的原创媒体文章](https://betterprogramming.pub/how-to-dump-full-ethereum-history-to-s3-296fb3ad175)关于**向 S3** 输出以太坊全史的一个简要总结。这篇文章涵盖了所有的细节，而我的演讲则侧重于一些**亮点和主要要点**。

为了有效地掌握知识，我向你推荐以下几点:

1.  首先，听听我的演讲，了解一下大概情况👀
2.  然后，浏览文章并深入了解细节📖
3.  最后，如果您有任何问题，请联系我( [LinkedIn](https://www.linkedin.com/in/bryzgaloff/) ， [Telegram](https://bryzgaloff.t.me/) )🤝

如果您正在构建类似的东西，我很乐意与您讨论解决方案并提供帮助。

所以，现在我们开始，我希望你喜欢我今天的演讲！

![](img/69694bd14a495ec9b02e397ac1f7fe3b.png)

我最初为 CoinStats.app 开发了这个数据平台，这是一个加密投资组合管理器。业务目标是计算每个钱包的代币余额。

该 API 应该为每个进入钱包的令牌返回一个余额，并支持最流行的令牌标准，如 ERC-20、ERC-721 和 ERC-1155。此外，我们还对每个钱包的代币转移列表感兴趣。

![](img/ef6225d239a7e83098966bca9ecc5131.png)

下面是一个预期的 API 请求的例子:对于一个由地址(绿色)标识的钱包，它返回一个由它们的合同地址标识的所有令牌的列表，以及它们的当前余额(蓝色)。示例响应包括具有合同地址、令牌 ID 和余额的条目列表。

![](img/98dd320c19e2c6b0a0e3cabe3e16050b.png)

为了计算这些余额，我们必须**扫描代币转移的全部历史**并且**简单地合计**它们的值。

现在有几十亿几十亿的转移，所以这是一个常规的大数据挑战。让我们将通用数据管道**映射到 CoinStats 用例。**

通用管道包括三个主要步骤:

1.  **摄取**:对于我们的用例，输入数据是以太坊块、事务和其他特定于以太坊的数据，如日志。
    *我们为什么需要日志？*因为它们代表代币转账，所以这是余额计算的最重要数据。
2.  **查询**:原始数据存储到 S3，然后使用 Athena 进行查询，Athena 是一个非常方便的工具，它提供了一个 SQL 接口来访问存储在 S3 的数据。
3.  作为一个输出，我们应该通过一个低延迟的面向客户的 API 提供对数据的访问。

现在让我们详细讨论所有这些步骤！

![](img/bb0d64edac9a3257cdeb1481309f473d.png)

我们从数据摄取步骤开始。

我们所做的是使用 JSON RPC API 直接从以太坊节点获取数据。下面是一个获取块信息的请求示例:以太坊 API 接受 POST 请求(绿色),请求体中包含详细信息。

使用的 API 方法是`eth_getBlockByNumber`(蓝色)。第一个参数(红色)是作为十六进制值的块号。第二个参数(黄色)是一个布尔值(称为`hydrated`)。后者的含义如下:

*   当`false`使块响应只包含事务散列时。
*   当`true`时，交易被*嵌入*为具有全部属性的完全质押物。

让我们看一个例子。

![](img/c5660d6978f62c8bf02103fbbe61c7f0.png)

来自以太坊 API 的示例响应包括块细节，如数字、散列和许多其他信息。

和*所有*该区块的交易细节，如发件人地址，天然气，价值和许多其他信息。`hydrated=true`参数允许在单个请求中导出单个块的所有交易，而不是单独提取它们。

此外，以太坊 API 支持批处理模式，因此您可以在一次调用中导出**多个块，并减少 HTTP 开销。**

获取块和事务后，我们运行另一个 API 方法(`eth_getTransactionReceipt`)来导出包含日志的事务收据。

这就完成了数据摄取阶段！现在，我们已经将所有原始数据存储到我们的 S3 存储桶中。

![](img/df008fcaefbd4346c3bf7569722e0414.png)

但是，我们使用了哪个以太坊节点来获取数据呢？

您可能已经注意到，在示例请求中，我使用了`eth.public-rpc.com`作为 URL。这是众多公开可用的以太坊 API 端点之一:[ethereumnodes.com](https://ethereumnodes.com/)包含了一系列这样的服务。

其中一些是免费的。其他一些提供试用期或有限的免费访问。因此，对于一个基本的用例，你**甚至不必运行你自己的以太坊**节点来导出数据！

![](img/e96d7394a3fb7f1105753ecad056da37.png)

但是，我们来做一个简单的对比，看看是不是要自己跑一个节点。

当运行一个*公共*节点时，你**不必维护**节点软件或者支付资源费用。

鉴于，*拥有*一个节点需要你**运行一个虚拟机**并配置以太坊节点软件包。一个完全同步的节点还需要**一个巨大的磁盘**来存储几万亿字节的以太坊数据。

然而，当使用*公共*节点时，您会受到服务提供商的**限制。一个提供者可能会限制你发送到一个节点的请求数量，甚至不支持一些以太坊 API 方法。**

最后但同样重要的是 API 性能。当请求一个*公共*节点时，你会受到 **HTTP 开销**的影响。

有了*自己的*节点，你可以通过本地 IPC 连接以**闪电般的速度**直接访问它的数据，只受你的节点资源带宽的限制。

无论如何，对于我们的用例来说，一些带有后备策略的免费公共节点提供者足以在几周内导出完整的历史。

因此，运行一个公共节点绝对是快速原型制作的最佳选择。而拥有一个节点可以在资源层面上为您提供无限的优化。

![](img/d5f6e7313a6d9935148a45269ef05906.png)

那么，现在，一旦我们将所有的原始数据存储在我们的 S3 中，**我们应该如何查询它呢？**

我是 AWS Athena 的超级粉丝，这是一个基于脸书开源软件的查询引擎。

它不是数据库，因为它没有自己的存储。相反，它直接从 S3 读取数据，从而为 S3 的数据提供一个 SQL 接口。

Athena 能够解析 JSON。所以，一旦数据到达 S3，我们可以马上运行雅典娜的查询。

例如，让我们从具有扁平日志的块中获取最小块的时间戳，并通过事件签名进行过滤。结果，我们得到了第一个 ERC-20 的转移日期。也就是 2015 年 10 月 27 日！

坦率地说，这不是一个完全有效的 Athena SQL，但是提供了使用数组和嵌套结构(如 JSON)的基本感觉。

然而，使用 Athena 需要一些技巧。它是按扫描数据量计费的。因此，对于一个*单个*查询，运行一个简单的选择将花费我们*20 多美元*。

为了降低成本，我将数据重新格式化为压缩拼花。这使我们的体积减少了**97%**,从而节省了相同的成本！

Athena 的唯一限制是以太坊操作 256 位数字。Athena 对整数的限制是 64 位。我的解决方法是在 Athena SQL 中实现长运算。

由于会议讨论的时间限制，我现在将跳过细节。但你可能会在[我关于 Medium](https://betterprogramming.pub/how-to-dump-full-ethereum-history-to-s3-296fb3ad175) 的原创文章中找到细节。我真的建议你熟悉我的方法，因为这是一个惊人的挑战！

那么，下一步是什么？鉴于 Athena 支持的巨大数字，我们现在可以通过简单地合计所有转账值来计算所有代币的余额。所以，这个流水线阶段完成了👍

![](img/d7a722f593bb299c36529b99e5fe8c90.png)

这是管道的最后一步:为我们的数据消费者提供访问。您可能还记得第一张幻灯片，我们希望有一个 API 返回每个钱包的代币余额。

因此，对于一个以太坊地址，我们得到它包含的令牌列表，以及它们的 id 和余额。转帐历史 API 非常相似。

为此，我决定简单地使用 AWS Lambda 函数，但是…

![](img/4b9d90440c0a996f26a9eb72f58d3599.png)

…使用什么作为该 API 的数据库？

我们可以直接从计算余额的 Athena 中读取余额。但 Athena 的目的是分析，这意味着它被设计成一次处理大量数据。

而一个面向客户的 API，比如我们正在构建的，需要一次只读取一个*个人*记录或者几个记录。

如果您不熟悉这些访问模式的差异，您可以在 google 上搜索“OLTP 与 OLAP 数据库”来了解关于这个主题的更多细节。为了方便起见，我在这张幻灯片上展示了这些缩写。

简而言之，使用合适的数据库可以显著减少延迟和成本。

因此，我们的余额和转账 API 需要另一个数据库，一个更快和更具成本效益的*个人*记录检索。DynamoDB 在这里是个不错的选择！

所以，我们现在做的是:使用 Athena 计算每个钱包的余额和转账，然后将这个缩小的特定目的数据集导入 DynamoDB。在 S3，我们有一个完整的原始数据数据集，而 DynamoDB 只包含令牌余额和转账。

我们如何将数据导入 DynamoDB？我很幸运地在 AWS 中出现了一个新功能后开始了这项工作:它被称为“从 S3 进口”。它太新了，以至于在 AWS web 控制台上仍然有相应的标签！

这个函数非常适合从 S3 上传大量数据集到 DynamoDB。我们的数据集大小接近 1TB，所以使用 PutItem 之类的常规 DynamoDB API 调用来上传它需要几天时间，并且成本很高。但是当使用这个令人敬畏的功能时，时间下降到几个小时！

![](img/2bf8211d0179d29f2ee6e8e3e766631a.png)

然而，我们每天*向 S3*出口新的木块。我们希望 DynamoDB 表能够实时更新，这意味着一旦出现新的数据块，我们应该*立即*更新所有受影响钱包的余额。

为此，我引入了解决方案的流部分。它的逻辑非常简单:脚本不断地从以太坊 API 请求最新的块号。当块号增加时，脚本获取最新的块及其收据，并将余额更新直接应用到 DynamoDB。

轮询间隔为 10 秒，因此从新数据块出现时起，流式传输部分的延迟为**不到 10 秒！⚡️**

但是如果我们想**减少延迟呢？我认为有几种方法可以达到这个目的。其中之一是使用 **websockets** 代替轮询方法。**

当前为了获取新的块，流脚本轮询以太坊 API 以获得最新的块号。当数量增加时，脚本获取新的块。如果没有新的块，脚本会休眠 10 秒钟。这个休眠间隔是可配置的，所以我们可以减少它，但这种方法仍然是基于轮询的。

与其这样，我建议使用 API 的`eth_subscribe`方法。它基于 websocket 连接，并在出现新块时通知客户端。这允许立即开始处理新的块*，而不是再等待几秒钟直到下一个轮询周期*

*此外，运行我们自己的节点将减少数据提取开销。通过调整节点的硬件，我们甚至可以获得更好的性能💪🏻*

*![](img/45b85ba55493cde7f1671c3d78b3d705.png)*

*概括地说，我们现在拥有的是:*

*   *每天运行的批次零件(蓝色)*
*   *流式部分(黄色)持续运行。*

*澄清一下，我们不会每天重新运行 DynamoDB 导入:每天，我们只收集新的块和日志到 S3(绿色)。这使我们能够基于直到最后一天的完整历史重新运行余额计算。*

*特别是，当引入 ERC-721 和 ERC-1155 支持时，我们进行了完整的重新运行，因为这需要重新扫描所有日志并从中提取那些令牌传输。然后将数据重新加载到 DynamoDB，并附加一个流脚本来实时更新表格。*

*流式脚本持续监听新数据块，并保持 API 数据最新。事实上，流式传输部分还将导出的块存储到 S3，以供复制。*

*![](img/b4d0e03ce9f939385280edd259fcd444.png)*

*我向您展示的解决方案是*灵活*、*通用*和*可扩展*足以支持其他区块链。*

*特别是 EVM 的 Solana，因为他们为区块链数据提取提供了相同的 API。*

*然而，解决方案不仅限于总部位于 EVM 的区块链，例如，我们也可能支持比特币。惟一的挑战是实现一个用于数据提取的适配器并找到一个数据节点。*

*![](img/e08117c4b5d551df598487e0a6b48d0e.png)*

*这是我的数据平台演示块的结尾。让我提醒你们注意我的演讲的要点。*

*如果您正在构建一个类似的解决方案，请使用公共以太坊节点进行快速原型制作。并且记住他们可能经常失败！因此，如果某些提供者不可用，可以实现一个后备策略来在它们之间切换。*

*作为一个最佳的数据工程实践，以与数据源相同的格式存储数据*。这允许您重新运行任何数据处理，而不依赖错误的数据源。因为通过这种方式，您实际上拥有弹性大数据基础架构中的完整数据集。在我们的例子中，最原始的格式显然是 JSON。**

*实际上，这个话题缺少了一样东西:带有以太坊数据的公共 **BigQuery 数据集**。是的，谷歌托管着所有人都可以访问的公共数据集，你可以使用它们来获得以太坊大规模数据的基本概念。*

*它包含块、事务、日志和许多其他内容的单独表，甚至包括跟踪。跟踪很有价值，因为从以太坊节点获取它们需要特殊的配置和更多的磁盘空间。*

*但是请记住:当您对数据集运行任何查询时，*您需要*为此付费。因此，如果您运行 SELECT 而不进行任何数据过滤，您将为仅仅一个*单个*查询支付*几美元*。*

*我最初是从 BigQuery 数据集开始的，所以这种方法在我的原始文章中有很好的描述，包括它的限制和警告。但是无论如何，我建议您首先使用它们来了解一些数据。*

*🏆这里有一条任何架构的*黄金*法则:*为正确的工作使用正确的工具！**

*记住 Athena 的例子:它只适用于大数据，不应该用于单个记录的检索。如果另一个组件能更好地满足特定需求，不要害怕向您的基础架构中引入它。*

*是的，选择正确的工具实际上是我们作为解决方案架构师的报酬，而且报酬丰厚😄*

*![](img/a1a81bb07a646e47e95957efcda5ce24.png)*

*感谢您今天的关注！*

*让我提醒你，我的演讲是基于我的媒体文章。它详细地涵盖了大部分方面，甚至更多。特别是:*

*   *公共大查询数据集:如何有效地使用它们*。甚至如何重用 S3 的 BigQuery 数据来预填充您的数据湖。**
*   **这些数据集使用一个叫做 ethereum-etl 的开源包进行更新。在我的文章中，我描述了它的优点和局限性。并分享我从零开始实现自己的管道而不是使用这个工具的动机。**
*   **另外，前面提到的 256 位数在 Athena 中也得到支持。这篇文章描述了我的纯 SQL 长运算解决方案。老实说，这是一个惊人的挑战！所以我会*真的*很高兴听到你的想法！**
*   **此外，在本文中，我分享了导出和托管数据的所有估计。**
*   **实际上，在一开始，我解释了为什么 CoinStats 对现有的解决方案不满意。以及基于产品需求，我的架构满足了哪一组确切的需求。**

**我希望你喜欢阅读，就像你喜欢演讲一样！🔥[链接到文章](https://betterprogramming.pub/how-to-dump-full-ethereum-history-to-s3-296fb3ad175)。**

**![](img/09a3039467cc0d244f56df28d70627a0.png)**

**最后，让我告诉你一些关于我自己的事情。**

**我是一名专家数据工程师和云解决方案架构师。我帮助初创公司**推出他们的数据平台**。与从电子商务到金融的各种领域合作。**

**去年**为 20 多家成功的数据创业公司**提供建议，并直接参与其中 6 家的实施工作。其中两个实际上是在 2021 年由 y combinator 支持的。**

**所以，请随时通过 [LinkedIn](https://www.linkedin.com/in/bryzgaloff/) 或 [Telegram](https://t.me/bryzgaloff) 与我联系。**

****🔥期待帮助你打造数据领域的又一件大事！****

**非常感谢您的关注！**

**感谢您的阅读！你可以在 YouTube 上观看[我的演讲，并查看](https://www.youtube.com/watch?v=MtBakcKJUCQ)[原文](https://betterprogramming.pub/how-to-dump-full-ethereum-history-to-s3-296fb3ad175)。喜欢，鼓掌，分享非常感谢😉**