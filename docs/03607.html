<html>
<head>
<title>How To Scale A NodeJS Application To All CPU Cores Of A Machine</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何将 NodeJS 应用程序扩展到机器的所有 CPU 核心</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/how-to-scale-a-nodejs-application-a51d3e8e2d36?source=collection_archive---------0-----------------------#2020-11-24">https://blog.devgenius.io/how-to-scale-a-nodejs-application-a51d3e8e2d36?source=collection_archive---------0-----------------------#2020-11-24</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><figure class="gl gn jl jm jn jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi jk"><img src="../Images/7d45f4bb8e19b5c70cfe472de171c83b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-NwsRTbJRqFXcVUhO5__KA.jpeg"/></div></div></figure><p id="594b" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">项目链接:【https://github.com/Joker666/NodeJS-MultiCore-Demo T2】</p><p id="7779" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi ku translated"><span class="l kv kw kx bm ky kz la lb lc di"> J </span> avascript 是单线程语言，因此只有一个调用栈和一个内存堆。NodeJS 使用 Javascript 开发服务器端应用程序，并共享相同的行为。它运行在一个 CPU 内核上，无论您的机器或云中的虚拟机有多少个 CPU 内核。Javascript 的单线程特性在基于浏览器的系统中实际上是好的，但是在后端系统中就不尽如人意了，因为后端需要机器提供的所有设备来驱动，以免浪费资源。</p><p id="b40f" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">但是 NodeJS 是用 C 构建的，C 拥有构建多线程应用程序所需的所有电池。NodeJS 创建者经过深思熟虑决定避免信号量和/或互斥锁，因为它们会给代码带来难以调试的错误和复杂性。但是 NodeJS 中的可伸缩性并不是事后才想到的，它内置于带有<a class="ae kt" href="https://nodejs.org/api/cluster.html" rel="noopener ugc nofollow" target="_blank">集群</a>模块的运行时中，该模块可以利用机器的所有 CPU 内核。</p></div><div class="ab cl ld le hr lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ig ih ii ij ik"><h1 id="f81f" class="lk ll in bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">单核性能</h1><p id="1847" class="pw-post-body-paragraph jv jw in jx b jy mi ka kb kc mj ke kf kg mk ki kj kk ml km kn ko mm kq kr ks ig bi translated">让我们构建一个 NodeJS 应用程序并对其进行负载测试，看看它的性能如何。我们将使用惊人的<a class="ae kt" href="https://www.fastify.io/" rel="noopener ugc nofollow" target="_blank"> Fastify </a>框架进行测试，因为这是一个开销非常低的简单框架。我将使用他们网站上提供的 hello world 服务器的例子。</p><figure class="mn mo mp mq gt jo"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="6b46" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">这是一个非常简单的 fastify 应用程序，它从端口 3000 开始，并返回一个 hello world json。现在让我们运行服务器并用<a class="ae kt" href="https://github.com/giltene/wrk2" rel="noopener ugc nofollow" target="_blank"> wrk2 </a>对其进行负载测试。我有一台 12 核的机器，所以我将使用 12 个线程和 1，000 个连接运行<code class="fe mt mu mv mw b">wrk</code>命令 30 秒，每秒 200，000 个请求。</p><pre class="mn mo mp mq gt mx mw my mz aw na bi"><span id="ede0" class="nb ll in mw b gy nc nd l ne nf">wrk -t12 -c1000 -d30s -R200000 <a class="ae kt" href="http://localhost:3000/" rel="noopener ugc nofollow" target="_blank">http://localhost:3000/</a></span></pre><blockquote class="ng nh ni"><p id="59a3" class="jv jw nj jx b jy jz ka kb kc kd ke kf nk kh ki kj nl kl km kn nm kp kq kr ks ig bi translated">结果显示 vanilla fastify 服务器每秒可以处理大约 25000 个请求。</p></blockquote><pre class="mn mo mp mq gt mx mw my mz aw na bi"><span id="0981" class="nb ll in mw b gy nc nd l ne nf">Running 30s test @ <a class="ae kt" href="http://localhost:3000/" rel="noopener ugc nofollow" target="_blank">http://localhost:3000/</a><br/>  12 threads and 1000 connections<br/>  Thread Stats   Avg      Stdev     Max   +/- Stdev<br/>    Latency    17.30s     4.94s   26.17s    58.16%<br/>    Req/Sec     2.08k     1.66     2.09k    91.67%<br/>  753447 requests in 30.03s, 134.37MB read<br/>Requests/sec:  25087.51<br/>Transfer/sec:  4.47MB</span></pre></div><div class="ab cl ld le hr lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ig ih ii ij ik"><h1 id="2745" class="lk ll in bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">进入集群模式</h1><p id="c546" class="pw-post-body-paragraph jv jw in jx b jy mi ka kb kc mj ke kf kg mk ki kj kk ml km kn ko mm kq kr ks ig bi translated">版本 0.8 左右引入的集群模块可以处理一个节点进程集群。主进程可以<code class="fe mt mu mv mw b">fork</code>并启动其他子进程，然后这些子进程并行运行。让我们看看它的实际效果</p><figure class="mn mo mp mq gt jo"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="cdbf" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">这里我们使用<code class="fe mt mu mv mw b">os</code>模块来检测系统拥有的 CPU 内核数量。如果内核数量为 1，它只是像以前一样运行应用程序。如果它有更多的内核，它会在<code class="fe mt mu mv mw b">cluster</code>模块的帮助下检测正在运行的进程是否是<code class="fe mt mu mv mw b">Master</code>进程。然后，它遍历机器的 CPU 数量，并使用<code class="fe mt mu mv mw b">cluster.fork()</code>方法分叉当前进程。</p><p id="2404" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated"><code class="fe mt mu mv mw b">fork</code>所做的实际上只是运行同一个程序的另一个节点进程，类似于运行<code class="fe mt mu mv mw b">node index.js</code>。当子进程执行时，<code class="fe mt mu mv mw b">cluster</code>模块的<code class="fe mt mu mv mw b">isMaster</code>返回 false，它照常运行程序。</p><p id="a40e" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">主进程监听我们的 HTTP 服务器端口，并在工作进程中对所有请求进行负载平衡。输出如下所示</p><pre class="mn mo mp mq gt mx mw my mz aw na bi"><span id="d69f" class="nb ll in mw b gy nc nd l ne nf">server listening on 3000 and worker 280474<br/>server listening on 3000 and worker 280473<br/>server listening on 3000 and worker 280483<br/>server listening on 3000 and worker 280480<br/>server listening on 3000 and worker 280492<br/>server listening on 3000 and worker 280503<br/>server listening on 3000 and worker 280510<br/>server listening on 3000 and worker 280517<br/>server listening on 3000 and worker 280504<br/>server listening on 3000 and worker 280533<br/>server listening on 3000 and worker 280526<br/>server listening on 3000 and worker 280536</span></pre><p id="1796" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">根据系统中内核的数量，输出会因机器而异。我的系统有 12 个内核，所以它运行 12 个进程。</p><p id="4ba2" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">当我们多次访问 web 服务器时，请求将开始由具有不同进程 id 的不同工作进程处理。主人以循环的方式在工人中分配负载。</p><p id="f231" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">现在让我们再次进行负载测试，</p><pre class="mn mo mp mq gt mx mw my mz aw na bi"><span id="d3c2" class="nb ll in mw b gy nc nd l ne nf">Running 30s test @ <a class="ae kt" href="http://localhost:3000/" rel="noopener ugc nofollow" target="_blank">http://localhost:3000/</a><br/>  12 threads and 1000 connections<br/>  Thread Stats   Avg      Stdev     Max   +/- Stdev<br/>    Latency     8.86s     2.69s   15.56s    60.54%<br/>    Req/Sec     9.19k   427.09    10.17k    70.83%<br/>  3262051 requests in 30.00s, 581.74MB read<br/>Requests/sec: 108729.29<br/>Transfer/sec: 19.39MB</span></pre><p id="4179" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">我们看到单线程 NodeJS 服务器的性能有了显著的提高。我们现在每秒能够处理 10 万个请求，几乎是以前的 4 倍。这是一个真正的收获，不需要任何外部机制，只需要内置的工具。</p><p id="765e" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">现在您有了一个 NodeJS 应用程序，可以在机器的所有内核中运行！</p></div><div class="ab cl ld le hr lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ig ih ii ij ik"><h1 id="95b1" class="lk ll in bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">高可用性</h1><p id="4acf" class="pw-post-body-paragraph jv jw in jx b jy mi ka kb kc mj ke kf kg mk ki kj kk ml km kn ko mm kq kr ks ig bi translated">当我们运行 Node server 的单个实例时，我们必须在崩溃或部署新代码时重启它。运行程序的多个进程缓解了这个问题。当一个进程崩溃时，我们可以派生一个新的进程。让我们看看它的实际效果</p><figure class="mn mo mp mq gt jo"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="2a22" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">完整文件可在<a class="ae kt" href="https://github.com/Joker666/NodeJS-MultiCore-Demo/blob/main/ha.js" rel="noopener ugc nofollow" target="_blank">这里</a>获得。这里，我们模拟一个随机崩溃，并确保崩溃发生在一个工作进程中，而不是主进程中。如果主进程崩溃，我们仍然需要重启应用程序。但是对于子进程，我们可以在看到崩溃时再次<code class="fe mt mu mv mw b">fork</code>。我们在分叉前添加条件，以确保它是一个崩溃，而不是被主杀死或断开。当我们运行它时，我们看到</p><pre class="mn mo mp mq gt mx mw my mz aw na bi"><span id="8ff4" class="nb ll in mw b gy nc nd l ne nf">server listening on 3000 and worker 287932<br/>server listening on 3000 and worker 287921<br/>server listening on 3000 and worker 287928<br/>server listening on 3000 and worker 287922<br/>server listening on 3000 and worker 287940<br/>server listening on 3000 and worker 287959<br/>server listening on 3000 and worker 287967<br/>server listening on 3000 and worker 287984<br/>server listening on 3000 and worker 287951<br/>server listening on 3000 and worker 287981<br/>server listening on 3000 and worker 287973<br/>server listening on 3000 and worker 287952<br/>Worker 5  has exited.<br/>server listening on 3000 and worker 288053<br/>Worker 1  has exited.<br/>server listening on 3000 and worker 288064<br/>Worker 7  has exited.<br/>server listening on 3000 and worker 288075<br/>Worker 14  has exited.<br/>server listening on 3000 and worker 288086<br/>Worker 10  has exited.<br/>server listening on 3000 and worker 288097</span></pre><p id="2165" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">每当一个工人离开，就会有新的工人加入。这很好，因为我们已经确保应用程序在任何崩溃的情况下都可以运行。我们确实需要找到根本原因并尽快修复，但这将使应用程序在此期间保持运行。</p></div><div class="ab cl ld le hr lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ig ih ii ij ik"><h1 id="dedb" class="lk ll in bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">警告</h1><p id="6141" class="pw-post-body-paragraph jv jw in jx b jy mi ka kb kc mj ke kf kg mk ki kj kk ml km kn ko mm kq kr ks ig bi translated">使用<code class="fe mt mu mv mw b">cluster</code>模块是扩展 NodeJS 应用程序的一个很好的方法，但是你需要注意一些情况。</p><ul class=""><li id="dac1" class="nn no in jx b jy jz kc kd kg np kk nq ko nr ks ns nt nu nv bi translated"><strong class="jx io">没有内存缓存:</strong>现在我们有多个进程并行运行，我们将无法在内存中缓存和访问一些对象。因为进程之间没有共享内存。我认为这很好，因为专用缓存技术胜过内存缓存。现在，我们将被迫使用一些缓存机制，如 Redis 或 Memcache，并能够从任何进程中访问它们。</li><li id="50c2" class="nn no in jx b jy nw kc nx kg ny kk nz ko oa ks ns nt nu nv bi translated"><strong class="jx io">无状态通信:</strong>有状态的网络调用将不再工作，因为不能保证通信是与同一个工作者进行的。所以会话不起作用。最好选择基于无状态令牌的认证机制，如 JWT。我相信这也很好，这确实使我们的服务器无状态。</li></ul></div><div class="ab cl ld le hr lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ig ih ii ij ik"><h1 id="e42b" class="lk ll in bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">生产环境</h1><p id="205b" class="pw-post-body-paragraph jv jw in jx b jy mi ka kb kc mj ke kf kg mk ki kj kk ml km kn ko mm kq kr ks ig bi translated">基于这项技术开发的工具可以在生产环境中帮助我们，这样我们就不必做繁重的工作了。让我们探索一下这些工具中的一个，<a class="ae kt" href="https://pm2.io/" rel="noopener ugc nofollow" target="_blank"> PM2 </a>。有一个企业版，但也有一个免费版本，我们可以使用。让我们从 pm2 开始最初的 fastify 例子。</p><pre class="mn mo mp mq gt mx mw my mz aw na bi"><span id="dcb6" class="nb ll in mw b gy nc nd l ne nf">npm i -g pm2<br/>pm2 start index.js -i max</span></pre><p id="5fa2" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">首先，我们在全球范围内安装 pm2。然后，我们运行 pm2 命令。这将使 NodeJS 应用程序达到 CPU 的最大内核数。在我的机器里我看到</p><figure class="mn mo mp mq gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi ob"><img src="../Images/7a3ea6616edd9ad7ac8a81fd8584971f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tOxfhNjaBTaFDErYPHcgfA.png"/></div></div></figure><p id="f14f" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">因此，应用程序的 12 个实例正在加速运行。让我们再次进行负载测试</p><pre class="mn mo mp mq gt mx mw my mz aw na bi"><span id="51fe" class="nb ll in mw b gy nc nd l ne nf">Running 30s test @ <a class="ae kt" href="http://localhost:3000/" rel="noopener ugc nofollow" target="_blank">http://localhost:3000/</a><br/>  12 threads and 1000 connections<br/>  Thread Stats   Avg      Stdev     Max   +/- Stdev<br/>    Latency    12.29s     3.46s   20.43s    59.21%<br/>    Req/Sec     6.55k    52.83     6.66k    66.67%<br/>  2305130 requests in 30.00s, 411.09MB read<br/>Requests/sec:  76837.29<br/>Transfer/sec:  13.70MB</span></pre><p id="4098" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">它是在单核上运行的原始性能的 3 倍，而不是我们自己在旋转工作进程中看到的性能。如果我们在负载测试时运行<code class="fe mt mu mv mw b">pm2 monit</code>,我们可以看到 pm2 没有使用 CPU 的全部能量，而是 70–80%</p><figure class="mn mo mp mq gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi oc"><img src="../Images/fa7827962da57e17a7810045d2027d1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QQiGn-_v7PYrJXMsZrocvA.png"/></div></div></figure><p id="0651" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">这也很好，因为在生产环境中，我们不希望使用 100%的 CPU，如果我们在一段持续时间内达到接近 80%的 CPU，可能会有负载平衡器规则启动另一个虚拟机。这是一个很好的设置，如果我们使用 reload 标志，pm2 可以在进程崩溃时自动重新加载。Pm2 还支持零停机部署。</p></div><div class="ab cl ld le hr lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ig ih ii ij ik"><h1 id="0af1" class="lk ll in bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">结论</h1><p id="d75f" class="pw-post-body-paragraph jv jw in jx b jy mi ka kb kc mj ke kf kg mk ki kj kk ml km kn ko mm kq kr ks ig bi translated">我们可以利用内置的<code class="fe mt mu mv mw b">Cluster</code>模块将 NodeJS 应用程序扩展到机器的所有 CPU 核心。这实现了系统的高可用性。为了获得更好的生产级可伸缩性，我们应该研究容器和水平伸缩策略。</p><h1 id="a291" class="lk ll in bd lm ln od lp lq lr oe lt lu lv of lx ly lz og mb mc md oh mf mg mh bi translated">资源</h1><ul class=""><li id="c8b5" class="nn no in jx b jy mi kc mj kg oi kk oj ko ok ks ns nt nu nv bi translated"><a class="ae kt" href="https://www.freecodecamp.org/news/scaling-node-js-applications-8492bd8afadc/" rel="noopener ugc nofollow" target="_blank">https://www . freecodecamp . org/news/scaling-node-js-applications-8492 BD 8 afadc/</a></li><li id="3eeb" class="nn no in jx b jy nw kc nx kg ny kk nz ko oa ks ns nt nu nv bi translated"><a class="ae kt" href="https://blog.carbonfive.com/taking-advantage-of-multi-processor-environments-in-node-js/" rel="noopener ugc nofollow" target="_blank">https://blog . carbon five . com/taking-advantage-of-multi-processor-environments-in-node-js/</a></li><li id="b784" class="nn no in jx b jy nw kc nx kg ny kk nz ko oa ks ns nt nu nv bi translated">https://nodejs.org/api/cluster.html<a class="ae kt" href="https://nodejs.org/api/cluster.html" rel="noopener ugc nofollow" target="_blank"/></li></ul></div></div>    
</body>
</html>