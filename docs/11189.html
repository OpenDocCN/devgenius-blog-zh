<html>
<head>
<title>Principal Component Analysis with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 Python 实现主成分分析</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/principal-component-analysis-with-python-ddeb284fd1d4?source=collection_archive---------15-----------------------#2022-12-23">https://blog.devgenius.io/principal-component-analysis-with-python-ddeb284fd1d4?source=collection_archive---------15-----------------------#2022-12-23</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><div class=""><h2 id="00d8" class="pw-subtitle-paragraph jk im in bd b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb dk translated">什么是主成分分析，它的用途是什么，分析是如何进行的？</h2></div><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi kc"><img src="../Images/9a040d7951133ff99b2ca1de7d7999ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jBHoQ8AKubQ_Gs0r"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">照片由<a class="ae ks" href="https://unsplash.com/@agforl24?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">泰沛</a>拍摄</figcaption></figure><h1 id="e0fa" class="kt ku in bd kv kw kx ky kz la lb lc ld jt le ju lf jw lg jx lh jz li ka lj lk bi translated">主成分分析</h1><p id="ce95" class="pw-post-body-paragraph ll lm in ln b lo lp jo lq lr ls jr lt lu lv lw lx ly lz ma mb mc md me mf mg ig bi translated">主成分分析(PCA)是一种数据挖掘方法，是一种解释数据集中变量之间关系的方法。</p><ul class=""><li id="0602" class="mh mi in ln b lo mj lr mk lu ml ly mm mc mn mg mo mp mq mr bi translated">主成分分析用于消除依赖结构或降低数据集的维数。</li><li id="48c6" class="mh mi in ln b lo ms lr mt lu mu ly mv mc mw mg mo mp mq mr bi translated">如果数据集中的度量和方差彼此接近，可以使用原始数据矩阵，而如果度量单位不同且相距较远(年龄、工资等)，则建议使用标准化数据矩阵。).</li><li id="15ec" class="mh mi in ln b lo ms lr mt lu mu ly mv mc mw mg mo mp mq mr bi translated">主成分分析的目的是找到在最大水平上代表观察变量方差的成分。</li><li id="588d" class="mh mi in ln b lo ms lr mt lu mu ly mv mc mw mg mo mp mq mr bi translated">它通过将数据从高维空间减少到低维空间，使得检查更容易。</li><li id="f15a" class="mh mi in ln b lo ms lr mt lu mu ly mv mc mw mg mo mp mq mr bi translated">这是一种消除不必要(低优先级)数据的方法。</li><li id="97f9" class="mh mi in ln b lo ms lr mt lu mu ly mv mc mw mg mo mp mq mr bi translated">PCA 之后，我们拥有的数据变得独立。</li><li id="0032" class="mh mi in ln b lo ms lr mt lu mu ly mv mc mw mg mo mp mq mr bi translated">我们有多少变量，就有多少分量，但解释实际意义上的方差的分量是主分量。</li></ul></div><div class="ab cl mx my hr mz" role="separator"><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc"/></div><div class="ig ih ii ij ik"><h1 id="4062" class="kt ku in bd kv kw ne ky kz la nf lc ld jt ng ju lf jw nh jx lh jz ni ka lj lk bi translated">如何进行主成分分析？</h1><h2 id="f7d8" class="nj ku in bd kv nk nl dn kz nm nn dp ld lu no np lf ly nq nr lh mc ns nt lj nu bi translated">1-准备数据集</h2><p id="363c" class="pw-post-body-paragraph ll lm in ln b lo lp jo lq lr ls jr lt lu lv lw lx ly lz ma mb mc md me mf mg ig bi translated">首先，让我们看看我们的数据集。如果我们的变量的单位和度量彼此相差甚远，我们就需要将其标准化。</p><pre class="kd ke kf kg gt nv nw nx bn ny nz bi"><span id="b668" class="oa ku in nw b be ob oc l od oe">import pandas as pd <br/>import numpy as np <br/><br/>path = '../dataset.csv'<br/>df = pd.read_csv(path)<br/>df = df.drop_duplicates()<br/>df.head()</span></pre><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi of"><img src="../Images/b6217df2bd0d73a06189a85e698606e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gSMa0N2kabFBCd4JLASE0g.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">原始数据</figcaption></figure><p id="9310" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">如果你在理解数据集方面有困难，你可以点击这里获取元数据。</p><p id="a3e9" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">我们需要将数据标准化，以便能够比较苹果和梨。</p><pre class="kd ke kf kg gt nv nw nx bn ny nz bi"><span id="c8be" class="oa ku in nw b be ob oc l od oe">df_origin = df<br/>for col in df.columns:<br/>    df[col] = (df[col] - df[col].mean()) / df[col].std()<br/>df_st_backup = df<br/>df.head()</span></pre><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi oj"><img src="../Images/a96c399133ddbe0a1f621d4ba59ee996.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-nNvALPO1Ew1tWlHOdQhtg.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">标准化数据</figcaption></figure><p id="4dad" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">我们来看一下数据，有自变量吗？</p><pre class="kd ke kf kg gt nv nw nx bn ny nz bi"><span id="9237" class="oa ku in nw b be ob oc l od oe">R = df.corr()<br/>np.round(R,2)</span></pre><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi ok"><img src="../Images/24f54d358b8a8905c76135a567236e9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0S3bt3ypyoIav-pk9zqkvA.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">相关矩阵</figcaption></figure><p id="975c" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">将它形象化，以获得更多的见解。</p><pre class="kd ke kf kg gt nv nw nx bn ny nz bi"><span id="b5c9" class="oa ku in nw b be ob oc l od oe">import seaborn as sns<br/>import matplotlib.pyplot as plt <br/><br/>fig, ax = plt.subplots(figsize=(16,9))<br/>ax = sns.heatmap(np.round(R,3), annot=True)<br/>plt.show()</span></pre><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi ol"><img src="../Images/b1758b47c8f7060824f2a76e2496a7d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3aXdoYysMnGcKgpseNbsAw.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">相关矩阵的可视化</figcaption></figure><p id="80de" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">是的，乍一看我们可以说有因变量，但我们也需要从统计上检验这一点。</p><h2 id="e74d" class="nj ku in bd kv nk nl dn kz nm nn dp ld lu no np lf ly nq nr lh mc ns nt lj nu bi translated">2-可以应用主成分分析吗？</h2><p id="e025" class="pw-post-body-paragraph ll lm in ln b lo lp jo lq lr ls jr lt lu lv lw lx ly lz ma mb mc md me mf mg ig bi translated">为了应用主成分分析，我们需要执行球度测试:</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div class="gh gi om"><img src="../Images/7b9a6f361fef2bcc06b3aecc05c00d06.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*t1RaLORQlPvDICNs_GLoFw.png"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">球形度试验</figcaption></figure><p id="f955" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">我们需要找到如上所述的计算和表格值。我们将使用这些计算和表格值进行测试的假设如下:</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div class="gh gi on"><img src="../Images/86faad2a17eddb5b962ef914aecd819c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/1*lsfV5CeKuSm_koXrAnDlPQ.png"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">假设</figcaption></figure><p id="3154" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">如果卡方计算值大于卡方表值，这意味着我们拒绝零假设，我们可以执行主成分分析。</p><pre class="kd ke kf kg gt nv nw nx bn ny nz bi"><span id="8cc8" class="oa ku in nw b be ob oc l od oe">import math<br/><br/>R_det = np.linalg.det(np.array(R))<br/><br/>chi_H = -(((len(df)-1) - 1/6*(2*(len(df.columns)+5)))*math.log(R_det))<br/>chi_H == 10585.965872060862</span></pre><p id="3774" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">如果我们计算上面的公式，我们会发现卡方计算的结果是 10552060862。</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi oo"><img src="../Images/189216421f7f52c7ebda6e46880e6bb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dt1iB8RFq_CZxEV-8gVAXQ.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">卡方表</figcaption></figure><p id="50e6" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">在卡方表中有 5%的误差，我们的 45 度自由度值落在 29.051-34.764 之间。</p><p id="8e4e" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">由于计算值大于本节中的表值，我们可以得出结论，我们可以拒绝零假设。</p><p id="fdcd" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">因此，我们可以有 95%的把握说，我们的数据集中变量之间的关系在统计学上是显著的，并且可以进行主成分分析。</p><h2 id="c3e8" class="nj ku in bd kv nk nl dn kz nm nn dp ld lu no np lf ly nq nr lh mc ns nt lj nu bi translated">组件得分矩阵</h2><p id="878a" class="pw-post-body-paragraph ll lm in ln b lo lp jo lq lr ls jr lt lu lv lw lx ly lz ma mb mc md me mf mg ig bi translated">我们使用下面的公式找到的λ值将是我们的特征值。</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div class="gh gi op"><img src="../Images/2b8a0d414e82dd85bda9ee32e946e9f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:310/format:webp/1*AO_uubSH2IQd64i-2xgeSg.png"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">特征值公式</figcaption></figure><pre class="kd ke kf kg gt nv nw nx bn ny nz bi"><span id="686d" class="oa ku in nw b be ob oc l od oe">from numpy import linalg as LA<br/><br/>lambdas, T = LA.eig(np.array(R))<br/>pd.DataFrame(lambdas).T</span></pre><p id="cce0" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">使用上面的代码，我们可以从 R(相关矩阵)中获得特征值和特征向量(T)矩阵。</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/ead5be315f83a0b69e98db3a82748cf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*Ddvl61awK4rZzlpVpmbalA.png"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">特征值</figcaption></figure><p id="da53" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">我们得到如上所示的熊猫系列输出。</p><ul class=""><li id="4c23" class="mh mi in ln b lo mj lr mk lu ml ly mm mc mn mg mo mp mq mr bi translated">可以说，对于λ≥1，有效维数为 1。但也可以评论为，对于 Lambda ≥ 0.80 (0.80 为可定制水平)，显著维度为 X。</li><li id="baec" class="mh mi in ln b lo ms lr mt lu mu ly mv mc mw mg mo mp mq mr bi translated">检查 Lambda 值时要考虑的另一个问题是，如果第一个值超过阈值，我们只考虑其他值——阈值取决于您希望主成分在多大程度上代表原始数据集，它可以在 0–1 的范围内以百分比值的形式增加。</li><li id="9830" class="mh mi in ln b lo ms lr mt lu mu ly mv mc mw mg mo mp mq mr bi translated">目标是找到尽可能少的重要维度。</li></ul><pre class="kd ke kf kg gt nv nw nx bn ny nz bi"><span id="6b71" class="oa ku in nw b be ob oc l od oe">count = 0 <br/>for i in lambdas:<br/>    if i &gt;= 0.8:<br/>        count+=1<br/>        break<br/>count == 1</span></pre><p id="5797" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">我们可以这样计算我们的 Lambda 值有多少通过了阈值，结果是 1。这意味着我们的第一个λ值已经超过了阈值。我使用 break 命令在满足条件时停止，以便达到阈值。</p><p id="740e" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">在特征向量标题下面的代码中，我们找到了用 T 表示的特征向量矩阵；</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div class="gh gi or"><img src="../Images/e918db1422e41e9fd5da43809d29a449.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*iKKNRvBCp-BPYHqqU3zthQ.png"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">特征向量矩阵</figcaption></figure><p id="0f3a" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">这里我们需要注意的是，特征向量矩阵是一个方阵，<em class="os"> pxp 是</em>变量的个数。</p><h2 id="d274" class="nj ku in bd kv nk nl dn kz nm nn dp ld lu no np lf ly nq nr lh mc ns nt lj nu bi translated">主成分矩阵(V):</h2><p id="4ede" class="pw-post-body-paragraph ll lm in ln b lo lp jo lq lr ls jr lt lu lv lw lx ly lz ma mb mc md me mf mg ig bi translated">主成分矩阵(成分得分矩阵)是根据特征值和特征向量重构数据集得到的矩阵。该矩阵显示数据集的重要方向，通常用于数据分析。</p><p id="35ab" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">组成矩阵。</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/5557e34d7de362e429bbb4da95082ade.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/format:webp/1*_YkddqiwvG5UlNUh9fQI2w.png"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">主成分矩阵公式(五)</figcaption></figure><p id="213d" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">可以使用上面的公式获得主分量矩阵。</p><pre class="kd ke kf kg gt nv nw nx bn ny nz bi"><span id="6fda" class="oa ku in nw b be ob oc l od oe">V = pd.DataFrame()<br/>for i in T:<br/>    V[f"V{i+1}"] = np.sqrt(lambdas[i])*T[i]<br/>V</span></pre><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/40b7aee8f61f01154ba03f1ba98f24aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1222/format:webp/1*g1P6BBSUHiAkba0qe4vggw.png"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">主成分分析矩阵</figcaption></figure><ul class=""><li id="c8b0" class="mh mi in ln b lo mj lr mk lu ml ly mm mc mn mg mo mp mq mr bi translated">分量矩阵应该用它的绝对值来解释。</li><li id="6bf5" class="mh mi in ln b lo ms lr mt lu mu ly mv mc mw mg mo mp mq mr bi translated">根据有效分量的数量选择最佳向量。最佳向量是指最能解释我们的变量的向量。</li><li id="44cd" class="mh mi in ln b lo ms lr mt lu mu ly mv mc mw mg mo mp mq mr bi translated">所选向量将是变量权重最大的向量。</li></ul><pre class="kd ke kf kg gt nv nw nx bn ny nz bi"><span id="a00c" class="oa ku in nw b be ob oc l od oe">V = V.abs()<br/>pd.DataFrame(np.round(V.mean(),2)).T</span></pre><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/71b83063bd3afc952d32c5a1b2c03277.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*sT7wgoEAyWDaguE_xb6l7A.png"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">平均分数特征向量</figcaption></figure><p id="9fcc" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">V1 向量解释了我们的数据集更多，所以我们可以考虑 V1 向量作为一个重要的主成分。然而，让我们仍然检查 V1:V1 向量来解释我们的数据集更多，所以我们可以考虑 V1 向量作为一个重要的主成分。然而，让我们还是来考察一下 V1:</p><pre class="kd ke kf kg gt nv nw nx bn ny nz bi"><span id="b65d" class="oa ku in nw b be ob oc l od oe">v1 = V.iloc[:,0]<br/>pd.DataFrame(v1).T</span></pre><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/e6acd37ed16041f69e1d8c9a6fd426f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*9KRgddtjSqdF9L4AHhFUlw.png"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">每个变量的特征向量分数</figcaption></figure><p id="1f5d" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">由 V1 重要主成分向量解释的变量的百分比，从上到下依次为:</p><ul class=""><li id="75fa" class="mh mi in ln b lo mj lr mk lu ml ly mm mc mn mg mo mp mq mr bi translated">X1(相对紧密度)%88.90</li><li id="a944" class="mh mi in ln b lo ms lr mt lu mu ly mv mc mw mg mo mp mq mr bi translated">X2(表面积)%90.96</li><li id="3afd" class="mh mi in ln b lo ms lr mt lu mu ly mv mc mw mg mo mp mq mr bi">…</li></ul><p id="b84d" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">然而，一些变量没有得到足够好的表示，因此我们可以将这个向量用于它足够好地表示的变量，而不是将整个数据集分配给单个向量。</p><h2 id="5b28" class="nj ku in bd kv nk nl dn kz nm nn dp ld lu no np lf ly nq nr lh mc ns nt lj nu bi translated">累积矩阵(W)</h2><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/31498ad4b93a2743fecf3a5859348020.png" data-original-src="https://miro.medium.com/v2/resize:fit:212/format:webp/1*I9FYW6YObAJh076mWuFhFQ.png"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">累积量公式</figcaption></figure><p id="244b" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">通过取分量矩阵(V)的每个变量的平方，获得平方载荷矩阵(W)。</p><ul class=""><li id="1ca3" class="mh mi in ln b lo mj lr mk lu ml ly mm mc mn mg mo mp mq mr bi translated">列 sum 表示由主成分解释的变量的总变化的百分比。</li><li id="0994" class="mh mi in ln b lo ms lr mt lu mu ly mv mc mw mg mo mp mq mr bi translated">行和给出了由主成分解释的变量的百分比。</li></ul><p id="039a" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">例如，W 矩阵的行和表示由主成分解释的总数据集的百分比，而列和表示由主成分解释的变量的总变化的百分比</p><pre class="kd ke kf kg gt nv nw nx bn ny nz bi"><span id="45ce" class="oa ku in nw b be ob oc l od oe">W = V**2<br/>W</span></pre><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/ab632bbd1a39845896f71b0f3d276fad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*BF-WYtBxRy-GavyPf5kVwQ.png"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">累积矩阵(W)</figcaption></figure><p id="4e2f" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">我们之前选择了 V1 作为最能代表我们数据集的主成分向量，因此将 V1 列的总数除以 p(变量的数量)可以显示出由我们的主成分解释的总变化的百分比:</p><pre class="kd ke kf kg gt nv nw nx bn ny nz bi"><span id="d7ff" class="oa ku in nw b be ob oc l od oe">W['V1'].sum()/len(W.columns) == 0.8637815009306168</span></pre><p id="7df7" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">在这一部分，我们可以说 V1 向量的主成分可以解释数据集中变量总变化的 86.37%。</p><p id="cbaa" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">在这一部分，我们可以说 V1 向量的主成分能够解释数据集变量总变化的 86.37%。这意味着我们可以使用主成分创建一个新的数据集，该主成分以%86.37 的比率表示变量的总变化，并使用它来代替我们的具有较少列的原始数据集。</p><h2 id="c15f" class="nj ku in bd kv nk nl dn kz nm nn dp ld lu no np lf ly nq nr lh mc ns nt lj nu bi translated">主成分对数据集的调整:</h2><p id="d5cb" class="pw-post-body-paragraph ll lm in ln b lo lp jo lq lr ls jr lt lu lv lw lx ly lz ma mb mc md me mf mg ig bi translated">让我们想象一个有 3 个变量(X1，X2，X3)的数据集。让用主成分创建的向量是(Y)来代替这些变量。在这种情况下，这个 Y 变量创建如下:</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi oz"><img src="../Images/2e87c957632e983f6459b5d3ce68a03c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uF0OO0DOo82Ix1mMss9myg.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">建模公式</figcaption></figure><pre class="kd ke kf kg gt nv nw nx bn ny nz bi"><span id="5859" class="oa ku in nw b be ob oc l od oe">for col in df.columns:<br/>    df[col] = T[0][df.columns.get_loc(col)]*df[col]<br/>df</span></pre><p id="5077" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">如上式所示，我们应该将每一列中的每个标准化值乘以所选特征向量的相应索引。然后，我们应该按列将这些乘法的结果相加，并将每一行的结果写入 Y 列。</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi pa"><img src="../Images/7ab7b286a7157fb1ac704c262c7cd5f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Eqq8KoKwOZ8fDh-nL0NKyQ.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">标准化原始数据</figcaption></figure><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi pb"><img src="../Images/621117097579740f5650eeeae220ec5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tKqbSg8RtFqHeE_0mJqRdQ.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">用特征向量加权的数据</figcaption></figure><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/9a6a758ff0e7162418edf6f1befdad7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:282/format:webp/1*D2s-Chhoyg-Rg8zpDMaaJA.png"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">y 数据集</figcaption></figure><h2 id="1cc1" class="nj ku in bd kv nk nl dn kz nm nn dp ld lu no np lf ly nq nr lh mc ns nt lj nu bi translated">报道想法</h2><p id="faf6" class="pw-post-body-paragraph ll lm in ln b lo lp jo lq lr ls jr lt lu lv lw lx ly lz ma mb mc md me mf mg ig bi translated">如上所述，我们的原始数据集总共有 6 个变量，但我们用主成分分析将其减少到一个变量。这使我们能够更容易地处理较小的数据集。</p><p id="4b02" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">在此过程中，我们是否丢失了数据/信息？</p><p id="18c8" class="pw-post-body-paragraph ll lm in ln b lo mj jo lq lr mk jr lt lu og lw lx ly oh ma mb mc oi me mf mg ig bi translated">当然，我们做到了。如上所述，我们的模型可以解释原始数据集中总变化的 86.37%。通过在 13.63%的信息损失的情况下将数据集减少到原来的六分之一，我们使它更易于使用。然而，虽然 PCA 将数据集减少到更少的列，但是所选择的重要主成分向量显示了数据集中最能代表变化的方向，因此丢失数据集中重要信息的风险更小。</p></div><div class="ab cl mx my hr mz" role="separator"><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc"/></div><div class="ig ih ii ij ik"><h2 id="197f" class="nj ku in bd kv nk nl dn kz nm nn dp ld lu no np lf ly nq nr lh mc ns nt lj nu bi translated">[计]元数据</h2><ul class=""><li id="7d84" class="mh mi in ln b lo lp lr ls lu pd ly pe mc pf mg mo mp mq mr bi translated"><a class="ae ks" href="https://archive.ics.uci.edu/ml/datasets/Energy+efficiency#" rel="noopener ugc nofollow" target="_blank">能效数据集</a></li></ul></div></div>    
</body>
</html>