<html>
<head>
<title>Canary on AWS EKS (Kubernetes) without service mesh</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">AWS EKS (Kubernetes)上的金丝雀，无服务网格</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/one-box-to-rule-them-all-8bdbd48f1ec1?source=collection_archive---------8-----------------------#2020-07-16">https://blog.devgenius.io/one-box-to-rule-them-all-8bdbd48f1ec1?source=collection_archive---------8-----------------------#2020-07-16</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><figure class="gl gn jl jm jn jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi jk"><img src="../Images/1ca837402a1b7312fc065e532c48299e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9X4WtpxhFjH1QRCV"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk translated">戴维·克洛德在<a class="ae jz" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><h2 id="4d73" class="ka kb in bd kc kd ke dn kf kg kh dp ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">背景:</h2><p id="888e" class="pw-post-body-paragraph kw kx in ky b kz la lb lc ld le lf lg kj lh li lj kn lk ll lm kr ln lo lp lq ig bi translated">我认为大多数工程师都同意在生产中进行测试是一个坏主意，但我们在生产前环境中经常不会遇到问题，因为我们没有足够的测试，我们没有反映生产的测试数据，我们没有呼叫量和/或我们没有生产的输入多样性。所以<a class="ae jz" href="https://martinfowler.com/bliki/CanaryRelease.html" rel="noopener ugc nofollow" target="_blank">的金丝雀部署</a>是为了在最小化爆炸半径的同时“试水”而开发的。通常这意味着将一小部分生产流量重定向到运行新代码的节点。这个“金丝雀”节点受到严密监控，因此如果出现任何问题，部署工程师都会立即得到通知。然后，新代码被“烘烤”在金丝雀节点中，直到我们有信心将新代码推广到产品中。</p><h2 id="f775" class="ka kb in bd kc kd ke dn kf kg kh dp ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">问题:</h2><p id="fda7" class="pw-post-body-paragraph kw kx in ky b kz la lb lc ld le lf lg kj lh li lj kn lk ll lm kr ln lo lp lq ig bi translated">我一直在努力寻找一种方法来进行金丝雀部署，而不需要将整个<a class="ae jz" href="https://www.redhat.com/en/topics/microservices/what-is-a-service-mesh" rel="noopener ugc nofollow" target="_blank">服务网格</a>应用到我的<a class="ae jz" href="https://aws.amazon.com/eks/" rel="noopener ugc nofollow" target="_blank"> EKS </a>集群上。由于我的集群相对较小，服务网格最终变得多余。服务网格带来了许多功能，如服务发现、跟踪和认证，但我只运行几个不同的服务，只有几个依赖关系。额外的网络跃点的额外延迟和额外的 CPU 和内存消耗不值得服务网格提供的功能。</p><h2 id="c64c" class="ka kb in bd kc kd ke dn kf kg kh dp ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">解决方案:</h2><p id="5aac" class="pw-post-body-paragraph kw kx in ky b kz la lb lc ld le lf lg kj lh li lj kn lk ll lm kr ln lo lp lq ig bi translated">我发现<a class="ae jz" href="https://github.com/kubernetes-sigs/aws-alb-ingress-controller/pull/1088" rel="noopener ugc nofollow" target="_blank">应用负载平衡器(ALB)入口控制器</a>现在支持<a class="ae jz" href="https://github.com/kubernetes-sigs/aws-alb-ingress-controller/pull/1088" rel="noopener ugc nofollow" target="_blank">加权目标</a>。这意味着我们可以控制每个目标接收的流量比例。有了这个，我们可以创建一个金丝雀设置，而不需要任何服务网格。</p><p id="59d4" class="pw-post-body-paragraph kw kx in ky b kz lr lb lc ld ls lf lg kj lt li lj kn lu ll lm kr lv lo lp lq ig bi translated">首先，我们需要在集群上安装 ALB 入口控制器。我会按照 AWS 提供的这个<a class="ae jz" href="https://kubernetes-sigs.github.io/aws-alb-ingress-controller/guide/walkthrough/echoserver/" rel="noopener ugc nofollow" target="_blank">步骤来安装它。</a></p><p id="adab" class="pw-post-body-paragraph kw kx in ky b kz lr lb lc ld ls lf lg kj lt li lj kn lu ll lm kr lv lo lp lq ig bi translated">然后，我们将创建 2 个部署和服务文件。一套部署和服务用于我们的生产环境，另一套用于我们的 canary 环境。<a class="ae jz" href="https://github.com/GnatorX/EKS-Canary/blob/master/echoserver.yaml" rel="noopener ugc nofollow" target="_blank">prod . YAML</a>T7】canary . YAML。</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="5166" class="ka kb in mb b gy mf mg l mh mi">kubectl apply -f echoserver.yaml<br/>kubectl apply -f echoserver-canary.yaml</span></pre><p id="783a" class="pw-post-body-paragraph kw kx in ky b kz lr lb lc ld ls lf lg kj lt li lj kn lu ll lm kr lv lo lp lq ig bi translated">确保它们正在运行。</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="15ac" class="ka kb in mb b gy mf mg l mh mi">kubectl get pods<br/>kubectl get endpoints</span></pre><figure class="lw lx ly lz gt jo gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/a3f41443e6833c0be43b3d92c7166eaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1102/format:webp/1*CpXQ_oXF0p2uQ2Yq_XTP5w.png"/></div></figure><p id="fa92" class="pw-post-body-paragraph kw kx in ky b kz lr lb lc ld ls lf lg kj lt li lj kn lu ll lm kr lv lo lp lq ig bi translated">确认 pods 正在运行，并且两个服务(echoserver + echoserver2-canary)在端点上都有 IPs。</p><p id="2a9c" class="pw-post-body-paragraph kw kx in ky b kz lr lb lc ld ls lf lg kj lt li lj kn lu ll lm kr lv lo lp lq ig bi translated">现在打开入口。<a class="ae jz" href="https://github.com/GnatorX/EKS-Canary/blob/master/ingress.yaml" rel="noopener ugc nofollow" target="_blank"> ingress.yaml </a></p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="2ba9" class="ka kb in mb b gy mf mg l mh mi">kubectl apply -f ingress.yaml</span></pre><p id="80f9" class="pw-post-body-paragraph kw kx in ky b kz lr lb lc ld ls lf lg kj lt li lj kn lu ll lm kr lv lo lp lq ig bi translated">确认入口已创建，并且底层入口已创建。</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="85f2" class="ka kb in mb b gy mf mg l mh mi">kubectl get ingress</span></pre><figure class="lw lx ly lz gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi mk"><img src="../Images/d0fbe9824d42e388f45acee99d18a6ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tTEDTiPFQx2BLwhIG9bYZw.png"/></div></div></figure><p id="16b7" class="pw-post-body-paragraph kw kx in ky b kz lr lb lc ld ls lf lg kj lt li lj kn lu ll lm kr lv lo lp lq ig bi translated">因为入口部分包含创建分流流量的逻辑，所以让我们深入了解一下。</p><figure class="lw lx ly lz gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi ml"><img src="../Images/fe2ff6ade6a6bf455668a4e9ec4f5c53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xNLzr2u-EdRGUS_NyGgeMw.png"/></div></div></figure><p id="c28a" class="pw-post-body-paragraph kw kx in ky b kz lr lb lc ld ls lf lg kj lt li lj kn lu ll lm kr lv lo lp lq ig bi translated">请注意红框注释。动作注释格式看起来像这样:<code class="fe mm mn mo mb b">alb.ingress.kubernetes.io/actions.${action-name}</code>。该注释允许自定义操作，例如重定向请求。您可以给动作一个自定义名称，用<code class="fe mm mn mo mb b">${action-name}</code>表示。然后，通过在入口规则中引用该名称并使用<code class="fe mm mn mo mb b">servicePort: use-annotation</code>，您可以让入口规则执行您的自定义操作。</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="17aa" class="ka kb in mb b gy mf mg l mh mi">{"Type":"forward","ForwardConfig":{"TargetGroups":[{"ServiceName":"echoserver","ServicePort":"80","Weight":95},{"ServiceName":"echoserver2-canary","ServicePort":"80","Weight":5}]}}</span></pre><p id="02c2" class="pw-post-body-paragraph kw kx in ky b kz lr lb lc ld ls lf lg kj lt li lj kn lu ll lm kr lv lo lp lq ig bi translated">在这里，我们利用这一点来为每个目标提供权重。请注意，我们将生产服务<code class="fe mm mn mo mb b">ServiceName: "echoserver"</code>的权重设置为 95，将金丝雀服务<code class="fe mm mn mo mb b">ServiceName:”echoserver2-canary"</code>的权重设置为 5。这意味着 95%的流量会到达 prod，而 5%会到达我们的 canary。</p><h2 id="d7e6" class="ka kb in bd kc kd ke dn kf kg kh dp ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">部署流程:</h2><p id="040d" class="pw-post-body-paragraph kw kx in ky b kz la lb lc ld le lf lg kj lh li lj kn lk ll lm kr ln lo lp lq ig bi translated">现在你可能会问我如何使用它？部署流程是什么样的？</p><p id="20de" class="pw-post-body-paragraph kw kx in ky b kz lr lb lc ld ls lf lg kj lt li lj kn lu ll lm kr lv lo lp lq ig bi translated">在部署阶段，当应用程序准备好进行 canary 测试时，首先将应用程序部署到 canary 部署(echoserver-canary)上，方法是将部署 yaml 文件的容器映像更改为 prod candidate，并将更新的部署应用到您的 EKS 集群。您将监控金丝雀 pod 的日志和指标，并让它烘烤适当的时间。然后，通过对 prod 部署 yaml 进行同样的更改，并将更改应用到您的 EKS 集群，您将部署到 prod。</p><p id="f256" class="pw-post-body-paragraph kw kx in ky b kz lr lb lc ld ls lf lg kj lt li lj kn lu ll lm kr lv lo lp lq ig bi translated">部署到 prod 后，有些人可能会采取不同的清理方法。即使在部署之后，我也将金丝雀作为产品的一部分来运行。由于它运行与生产环境相同的代码，因此它将作为一个额外的节点。有些可能会关闭金丝雀，您可以通过更改入口动作并将生产服务设置为 100 权重并将金丝雀权重设置为 0 来做到这一点。这将需要在每次部署后更改入口，但是从操作角度来看，这是一种更干净的方法，因为只有您的生产部署在为生产流量提供服务。</p><h2 id="25b0" class="ka kb in bd kc kd ke dn kf kg kh dp ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">总结:</h2><ul class=""><li id="8ac1" class="mp mq in ky b kz la ld le kj mr kn ms kr mt lq mu mv mw mx bi translated">我们希望利用金丝雀部署，在最小化爆炸半径(只将一小部分流量重定向到金丝雀)的同时，用生产流量测试我们的新代码</li><li id="1742" class="mp mq in ky b kz my ld mz kj na kn nb kr nc lq mu mv mw mx bi translated">我们通过使用 ALB 的加权目标规则来避免使用服务网格，因为服务网格对于您的集群来说可能是多余的</li><li id="45ce" class="mp mq in ky b kz my ld mz kj na kn nb kr nc lq mu mv mw mx bi translated">我们将入口设置为指向 canary 和 prod，并将生产候选对象部署到 canary 并对其进行监控</li><li id="cf17" class="mp mq in ky b kz my ld mz kj na kn nb kr nc lq mu mv mw mx bi translated">然后，我们将生产候选部署到所有生产节点。</li></ul></div></div>    
</body>
</html>