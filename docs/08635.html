<html>
<head>
<title>Hive Query Optimization on an Amazon Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">亚马逊数据集上的 Hive 查询优化</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/hive-query-optimization-on-an-amazon-dataset-2e36fd5f0d8a?source=collection_archive---------12-----------------------#2022-06-29">https://blog.devgenius.io/hive-query-optimization-on-an-amazon-dataset-2e36fd5f0d8a?source=collection_archive---------12-----------------------#2022-06-29</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><figure class="gl gn jl jm jn jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi jk"><img src="../Images/578a8e8902cd62ebcf1c7873a4978c46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KXVLek2YAOkyGCe9ZKMgIA.jpeg"/></div></div></figure><p id="2cb9" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">作为一名数据工程师，我开发过许多针对大型数据集的复杂 Hive 查询。由于 Hive 是在 Apache Hadoop 框架上构建的，它自带了一套分析功能和优化技术，如分区、分桶、压缩、反规范化、矢量化等。这使得它非常适合像脸书这样处理数 Pb 数据的公司。</p><p id="55de" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">虽然我已经在真实世界的数据中使用了其中的一些概念，但我想进一步探索它们，以了解它是如何工作的以及可以看到多少性能改进。我决定使用亚马逊产品评论数据集，特别是美容产品类别，在其上构建一些查询，以便分析数据。</p><p id="319e" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">我们开始吧，好吗？</p><p id="292f" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated"><strong class="jx io">第一部分:压缩</strong></p><p id="9633" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated"><em class="kt">什么是压缩？</em></p><p id="200f" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">压缩基本上是一种二进制存储格式，它以紧凑的二进制方式存储数据，以减少空间。它可以是面向行的格式，也可以是面向列的格式。面向列的格式使用惰性反序列化，只对被访问的列字段进行反序列化。这无疑降低了数据处理的成本。我们将使用的一种列数据格式是 ORCFile(优化的记录列文件),它将原始数据的大小减少了 75%。</p><p id="e120" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">为了这个小型项目的目的，我们使用两个数据集。一个是亚马逊美容产品评论(300k 行)，另一个是亚马逊美容产品的元数据(30k 行)。首先，我们将在 Hive 中使用 JsonSerDe 从 JSON 文件中获取原始数据。</p><pre class="ku kv kw kx gt ky kz la lb aw lc bi"><span id="caa0" class="ld le in kz b gy lf lg l lh li">create table raw_beauty(`overall` string,`verified` boolean,`reviewTime` string,`reviewerID` string,`asin` string,`reviewerName` string,<br/>`reviewText` string,`summary` string,`unixReviewTime` string,`vote` string,`style` string,`image` string)<br/>ROW FORMAT SERDE<br/>'org.openx.data.jsonserde.JsonSerDe'<br/>WITH SERDEPROPERTIES('mapping.reviewtime'='reviewTime',<br/>'mapping.reviewerid'='reviewerID','mapping.reviewername'='reviewerName','mapping.reviewtext'='reviewText','mapping.unixreviewtime'='unixReviewTime')<br/>STORED AS INPUTFORMAT<br/>'org.apache.hadoop.mapred.TextInputFormat'<br/>OUTPUTFORMAT<br/>'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'<br/>TBLPROPERTIES(<br/>'serialization.null.format'='');</span><span id="039e" class="ld le in kz b gy lj lg l lh li">#Creating the metadata table<br/>create table raw_meta_beauty(title string,image array&lt;string&gt;,brand string,rank string,main_cat string,asin string,<br/>description string,also_view array&lt;string&gt;,also_buy array&lt;string&gt;,price string,similar_item string,details string,feature string,tech1 string,`date` string)<br/>ROW FORMAT SERDE <br/>'org.openx.data.jsonserde.JsonSerDe'<br/>STORED AS INPUTFORMAT<br/>'org.apache.hadoop.mapred.TextInputFormat'<br/>OUTPUTFORMAT<br/>'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'<br/>TBLPROPERTIES(<br/>'serialization.null.format'='');</span></pre><p id="fdf9" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">注意，因为这是一种简单的文本输入格式，所以字段以冗长的文本格式存储，并且不是很紧凑。</p><p id="5e3d" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">此外，我们将创建可信的表，这些表将被 OrcSerDe 压缩，我们将把原始数据接收到这些表中。</p><pre class="ku kv kw kx gt ky kz la lb aw lc bi"><span id="f0bb" class="ld le in kz b gy lf lg l lh li">create table beauty(`verified` boolean,`reviewtime` string,`reviewerid` string,`asin` string,`reviewername` string,<br/>`reviewtext` string,`summary` string,`unixreviewtime` string,`vote` string,`style` string,`image` string,`overall` string)<br/>ROW FORMAT SERDE<br/>'org.apache.hadoop.hive.ql.io.orc.OrcSerde'<br/>STORED AS INPUTFORMAT<br/>'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat'<br/>OUTPUTFORMAT<br/>'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat';</span><span id="c732" class="ld le in kz b gy lj lg l lh li">insert overwrite table beauty<br/>select verified,reviewtime,reviewerid,asin,reviewername,<br/>reviewtext,summary,unixreviewtime,vote,style,image,overall<br/>from raw_beauty;</span><span id="d39f" class="ld le in kz b gy lj lg l lh li">create table meta_beauty(title string,image array&lt;string&gt;,brand string,rank string,main_cat string,asin string,<br/>description string,also_view array&lt;string&gt;,also_buy array&lt;string&gt;,price string)<br/>ROW FORMAT SERDE <br/>'org.apache.hadoop.hive.ql.io.orc.OrcSerde'<br/>STORED AS INPUTFORMAT<br/>'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat'<br/>OUTPUTFORMAT<br/>'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat';</span><span id="f3e2" class="ld le in kz b gy lj lg l lh li">insert overwrite table meta_beauty <br/>select title,image,brand,rank,main_cat,asin,description,<br/>also_view,also_buy,price from raw_meta_beauty</span></pre><p id="95d1" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">我们将在 amazon 产品唯一标识符(asin)上连接这两个表，首先使用原始表，其次使用可信表。让我们看看我们观察到的查询执行时间的差异有多大。</p><pre class="ku kv kw kx gt ky kz la lb aw lc bi"><span id="ee27" class="ld le in kz b gy lf lg l lh li">create table raw_beauty_analysis as <br/>select b.asin,m.title,m.image,m.brand,b.overall,b.reviewerid,<br/>b.reviewername,b.summary,m.also_view<br/>from raw_beauty b inner join raw_meta_beauty m <br/>on b.asin=m.asin;</span></pre><figure class="ku kv kw kx gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi lk"><img src="../Images/ce4dd827e3ef9348fc59a2ac00ba2a43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wpf5RCh5ie-_-BYUgVJL3A.png"/></div></div><figcaption class="ll lm gj gh gi ln lo bd b be z dk translated">总 MapReduce CPU 时间:1 分 3 秒</figcaption></figure><pre class="ku kv kw kx gt ky kz la lb aw lc bi"><span id="9f83" class="ld le in kz b gy lf lg l lh li">create table beauty_analysis as <br/>select b.asin,m.title,m.image,m.brand,b.overall,b.reviewerid,<br/>b.reviewername,b.summary,m.also_view<br/>from beauty b inner join meta_beauty m <br/>on b.asin=m.asin;</span></pre><figure class="ku kv kw kx gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi lp"><img src="../Images/9f2f09bec6ed6277d1f173719ca7f62e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SCpRy4Ij38JiwgOalX68nQ.png"/></div></div><figcaption class="ll lm gj gh gi ln lo bd b be z dk translated">总 MapReduce CPU 时间:18 秒 100 毫秒</figcaption></figure><p id="3a8f" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">因此，我们已经可以看到，在连接压缩的 ORC 表时，MapReduce 的总 CPU 时间减少了 50%以上。</p><p id="39b7" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">但是为什么会这样呢？在简单连接中，Hive 使用了一个 MapReduce 连接框架，其中 2 个不同的映射器将根据连接键对这些表进行排序，并发出一个中间文件，Reducer 将把中间文件作为输入文件，并执行真正的连接工作。</p><p id="1918" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">但是 Hive 有一个名为“hive.auto.convert.join”的参数，该参数默认设置为 true。如果其中一个连接表的大小小于 25MB，则将较小的表加载到内存中，并且在映射阶段本身执行连接，这降低了混洗-排序和归约操作的成本。这是一个地图连接。我们连接压缩表的第二个查询自动执行了映射连接，因为由于压缩，较小的表具有非常紧凑的大小。</p><figure class="ku kv kw kx gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi lq"><img src="../Images/1b67792ebdb8c1a5aac7a4340f717c68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oWPaMv2y7YxD2_coLBDNyQ.png"/></div></div><figcaption class="ll lm gj gh gi ln lo bd b be z dk translated">压缩和非压缩文件的大小比较</figcaption></figure><p id="ed0b" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">我检查了原始和可信元数据表的大小。原始表有 266MB，而可信表只有 12MB。这绝对证明了 ORC 是多么有冲击力。</p><p id="b166" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">顺便说一下，我们可以通过将“hive . map join . small table . filesize”设置为我们选择的值来定制较小文件的大小。</p><p id="322f" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated"><strong class="jx io">第二部分:分区</strong></p><p id="3546" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated"><em class="kt">什么是分区？</em></p><p id="9eb4" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">Hive 中的分区是一种根据分区列的值将表分成不同部分的方法。使用分区可以更快地对数据切片进行查询。</p><p id="b4a2" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">让我们构建一个分区表并查看一些查询示例，好吗？</p><pre class="ku kv kw kx gt ky kz la lb aw lc bi"><span id="4642" class="ld le in kz b gy lf lg l lh li">create table beauty_dpart(verified boolean,reviewtime string,reviewerid string,asin string,reviewername string,<br/>reviewtext string,summary string,unixreviewtime string,vote string,style string,image string)<br/>PARTITIONED BY (overall string)<br/>ROW FORMAT SERDE<br/>'org.apache.hadoop.hive.ql.io.orc.OrcSerde'<br/>STORED AS INPUTFORMAT<br/>'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat'<br/>OUTPUTFORMAT<br/>'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat';</span></pre><p id="f9e1" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">在我们的项目中，我们将使用动态分区，在插入过程中我们可以动态地对数据进行分区。对于我们的表格，我们将在“总体”一栏中对其进行划分，这是评审者给出的评级(从 1 到 5)。</p><pre class="ku kv kw kx gt ky kz la lb aw lc bi"><span id="2cad" class="ld le in kz b gy lf lg l lh li">SET hive.exec.dynamic.partition = true;<br/>SET hive.exec.dynamic.partition.mode = nonstrict;</span><span id="1143" class="ld le in kz b gy lj lg l lh li">insert overwrite table beauty_dpart partition(overall)<br/>select * from beauty order by overall;</span></pre><figure class="ku kv kw kx gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi lr"><img src="../Images/5b3bfa36be817f1bff30e6888863660a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ceCidE8Xbk4sGyBObNy9Qg.png"/></div></div><figcaption class="ll lm gj gh gi ln lo bd b be z dk translated">将数据插入分区表</figcaption></figure><p id="0a78" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">为了试验分区表和非分区表，我决定为以下用例开发查询。</p><ol class=""><li id="8c48" class="ls lt in jx b jy jz kc kd kg lu kk lv ko lw ks lx ly lz ma bi translated"><strong class="jx io">找出排名最高和最低的品牌。</strong></li></ol><p id="95ea" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">让我们看看排名最低的品牌，即出现低评级频率最高的品牌。(注意:我们使用 limit 是因为结果集可能非常大。)</p><pre class="ku kv kw kx gt ky kz la lb aw lc bi"><span id="6f37" class="ld le in kz b gy lf lg l lh li">select * from (<br/>select m.brand,count(m.brand) as count_frequency<br/>from beauty b inner join meta_beauty m on b.asin=m.asin <br/>where b.overall in('1.0','2.0')<br/>group by m.brand) tmp<br/>order by tmp.count_frequency desc<br/>limit 10;</span></pre><figure class="ku kv kw kx gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi mb"><img src="../Images/2a10820166da29d6c9268f11ec601b2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pAtIZPqr8SZqclHFKTrBnQ.png"/></div></div><figcaption class="ll lm gj gh gi ln lo bd b be z dk translated">总 MapReduce CPU 时间:23 秒 60 秒</figcaption></figure><pre class="ku kv kw kx gt ky kz la lb aw lc bi"><span id="b07b" class="ld le in kz b gy lf lg l lh li">select * from (<br/>select m.brand,count(m.brand) as count_frequency<br/>from beauty_dpart b inner join meta_beauty m on b.asin=m.asin <br/>where b.overall in('1.0','2.0')<br/>group by m.brand) tmp<br/>order by tmp.count_frequency desc<br/>limit 10;</span></pre><figure class="ku kv kw kx gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi mc"><img src="../Images/b8cdf05facd2074ca238a1a4608cc056.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8UFCbGXS5ifuM1CYAtjd3w.png"/></div></div><figcaption class="ll lm gj gh gi ln lo bd b be z dk translated">总 MapReduce CPU 时间:13 秒 30 毫秒</figcaption></figure><p id="9ce3" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">当我们使用分区时，有 10 秒的时间差。这是因为我们不需要扫描整个表来查找总体评分 1 和 2，我们已经将它们存储在一个单独的分区文件中。我们观察到的另一件事是，在分区表查询中，跳过了映射连接步骤。stage 2 中两个表的连接本身，而不是为它构建一个不同的 stage，与前面的图相反。</p><p id="0a0c" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated"><strong class="jx io"> 2。找出最满意和最不满意的评价者。</strong></p><p id="261c" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">这里，我们有一个查询来查找最满意的评论者，因为他们给出了最大数量的高评级。我们在这里也使用了一些 Hive 分析函数。</p><pre class="ku kv kw kx gt ky kz la lb aw lc bi"><span id="40e8" class="ld le in kz b gy lf lg l lh li">select distinct c.* from (<br/>select reviewerid,reviewername,<br/>count(overall) over (partition by reviewerid) as ratings_count, avg(overall) over (partition by reviewerid) as avg_rating<br/>from beauty where overall in('4.0','5.0'))c<br/>order by c.ratings_count desc<br/>limit 10; </span></pre><figure class="ku kv kw kx gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi md"><img src="../Images/186add809c42c31ff7f283797db7bcfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iXn0jMjcVZcpiIVjUP7Vkg.png"/></div></div><figcaption class="ll lm gj gh gi ln lo bd b be z dk translated">总 MapReduce CPU 时间:37 秒 450 毫秒</figcaption></figure><pre class="ku kv kw kx gt ky kz la lb aw lc bi"><span id="17ec" class="ld le in kz b gy lf lg l lh li">select distinct c.* from (<br/>select reviewerid,reviewername,<br/>count(overall) over (partition by reviewerid) as ratings_count, avg(overall) over (partition by reviewerid) as avg_rating<br/>from beauty_dpart where overall in('4.0','5.0'))c<br/>order by c.ratings_count desc<br/>limit 10;</span></pre><figure class="ku kv kw kx gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi me"><img src="../Images/d3f8294c75bb7120d0f66e43abe9e400.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EEsfzJKTYiwiCS7Jxzf3yQ.png"/></div></div><figcaption class="ll lm gj gh gi ln lo bd b be z dk translated">总 MapReduce CPU 时间:26 秒 970 毫秒</figcaption></figure><p id="5a3f" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">这将产生 26.97 秒的 CPU 时间，而使用非分区表的相同查询将产生 37.45 秒的 CPU 时间。我们还观察到第一个 MR 任务在非分区表中花费了两倍的时间。这可能是在“总体”上过滤数据的步骤。</p><p id="3aa4" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated"><strong class="jx io"> 3。排名高的产品价格更低吗？</strong></p><pre class="ku kv kw kx gt ky kz la lb aw lc bi"><span id="ca87" class="ld le in kz b gy lf lg l lh li">select distinct b.asin,m.title,m.brand,b.overall,m.price<br/>from beauty b inner join meta_beauty m on b.asin=m.asin<br/>where b.overall in('5.0') and m.price is not null<br/>limit 15;</span></pre><figure class="ku kv kw kx gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi mf"><img src="../Images/26ca9e8e47df48db1e5b265e719627b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vRaRv99Fs1yGcENrmiUPgQ.png"/></div></div><figcaption class="ll lm gj gh gi ln lo bd b be z dk translated">总 MapReduce CPU 时间:18 秒 40 毫秒</figcaption></figure><pre class="ku kv kw kx gt ky kz la lb aw lc bi"><span id="32bd" class="ld le in kz b gy lf lg l lh li">select distinct b.asin,m.title,m.brand,b.overall,m.price<br/>from beauty_dpart b inner join meta_beauty m on b.asin=m.asin<br/>where b.overall in('5.0') and m.price is not null<br/>limit 15;</span></pre><figure class="ku kv kw kx gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi mg"><img src="../Images/4ab285f3bda8c2afce64d5fd6c76f7cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ip0KV0RZYEHspLsgigHkbQ.png"/></div></div><figcaption class="ll lm gj gh gi ln lo bd b be z dk translated">总 MapReduce CPU 时间:11 秒 860 毫秒</figcaption></figure><p id="7f7c" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">因此，一些排名靠前的产品价格较低，而一些则相当昂贵。无论如何，这里的要点是我们再次看到两个查询相差 7 秒。</p><p id="6457" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated"><strong class="jx io"> 4。2005 年至 2010 年间，哪些产品是流行趋势？</strong></p><p id="aa19" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">在这里，我构建了一个查询来获取 2005 年到 2010 年间每个亚马逊产品的平均评分，以及给它的评论总数和验证评论总数。我只考虑有超过 50 个验证评论的产品，因为我认为至少有 50 个人认可一个产品是一个好的衡量标准。</p><pre class="ku kv kw kx gt ky kz la lb aw lc bi"><span id="cb0b" class="ld le in kz b gy lf lg l lh li">select distinct asin,avg_rating,reviews_count,verified_reviews <br/>from(<br/>select asin,avg(overall) over (partition by asin) as avg_rating,<br/>count(overall) over (partition by asin) as reviews_count,<br/>count(case when verified=true then overall else null end) over (partition by asin) as verified_reviews,<br/>year(from_unixtime(unix_timestamp(reviewtime,'MM dd, yyyy'),'yyyy-MM-dd')) as custom_year <br/>from beauty<br/>)tmp<br/>where custom_year&gt;=2005 and custom_year&lt;2010 and verified_reviews&gt;50<br/>order by avg_rating desc<br/>limit 10;</span></pre><figure class="ku kv kw kx gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi mh"><img src="../Images/f9041d1073904ca66ec88f6e5f2e9af4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1SiZsGpvJGw2FB27ET6laQ.png"/></div></div><figcaption class="ll lm gj gh gi ln lo bd b be z dk translated">总 MapReduce CPU 时间:30 秒 520 秒</figcaption></figure><pre class="ku kv kw kx gt ky kz la lb aw lc bi"><span id="4804" class="ld le in kz b gy lf lg l lh li">select distinct asin,avg_rating,reviews_count,verified_reviews <br/>from(<br/>select asin,avg(overall) over (partition by asin) as avg_rating,<br/>count(overall) over (partition by asin) as reviews_count,<br/>count(case when verified=true then overall else null end) over (partition by asin) as verified_reviews,<br/>year(from_unixtime(unix_timestamp(reviewtime,'MM dd, yyyy'),'yyyy-MM-dd')) as custom_year <br/>from beauty_dpart<br/>)tmp<br/>where custom_year&gt;=2005 and custom_year&lt;2010 and verified_reviews&gt;50<br/>order by avg_rating desc<br/>limit 10;</span></pre><figure class="ku kv kw kx gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi mi"><img src="../Images/2478995d52a378d51ca59a12a9e1d312.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u3vffKpa0ufo8E8uCWgV7A.png"/></div></div><figcaption class="ll lm gj gh gi ln lo bd b be z dk translated">总 MapReduce CPU 时间:27 秒 960 毫秒</figcaption></figure><p id="8b4f" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">我们只看到了 CPU 时间上的微小差异，因为我们并没有真正利用我们的分区美丽表的优势。但是，我们使用的是 PARTITION BY analytic 函数，它将结果集划分为多个分区，并在每个分区上应用 window/aggregate 函数。因此，与 GROUP BY 相反，您可以在同一个查询中对不同的字段进行分区。</p><p id="25ca" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">因此，我又构建了几个查询，并制作了一个比较表来计算平均性能改进。当我们使用分区时，我们看到执行时间减少了<strong class="jx io"> 32% </strong>。</p><p id="dbde" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated"><strong class="jx io">第三部分:铲斗</strong></p><p id="a798" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated"><em class="kt">什么是 bucketing？</em></p><p id="ec12" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">分桶是将表(或分区)组织成数据块的技术。对于数据采样来说，这是最有效的，并且在相同列上存储的两个表的连接可以实现为存储桶映射连接。</p><blockquote class="mj mk ml"><p id="dbce" class="jv jw kt jx b jy jz ka kb kc kd ke kf mm kh ki kj mn kl km kn mo kp kq kr ks ig bi translated">映射连接可以利用分桶表，因为处理左侧表的桶的映射器只需要加载右侧表的相应桶来执行连接。</p><p id="5909" class="jv jw kt jx b jy jz ka kb kc kd ke kf mm kh ki kj mn kl km kn mo kp kq kr ks ig bi translated">— Hadoop，权威指南第 4 版</p></blockquote><p id="386a" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">如果两个表在连接列上进行分区，并在该列上进行排序，这通常效果最好，因为这样就变成了一种有效的合并排序。</p><p id="662e" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">以下是如何建立一个桶形表。</p><pre class="ku kv kw kx gt ky kz la lb aw lc bi"><span id="5a0e" class="ld le in kz b gy lf lg l lh li">create table beauty_bucket(verified boolean,reviewtime string,reviewerid string,asin string,reviewername string,<br/>reviewtext string,summary string,unixreviewtime string,vote string,style string,image string,overall string)<br/>CLUSTERED BY(asin) SORTED BY (asin) INTO 8 buckets<br/>ROW FORMAT SERDE<br/>'org.apache.hadoop.hive.ql.io.orc.OrcSerde'<br/>STORED AS INPUTFORMAT<br/>'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat'<br/>OUTPUTFORMAT<br/>'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat';</span></pre><p id="75d0" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">要将数据加载到分桶表中，首先需要在 Hive 中启用分桶参数。我还将最大减速器的数量设置为 4，因为 MR 引擎倾向于将减速器的总数设置为铲斗的总数。</p><pre class="ku kv kw kx gt ky kz la lb aw lc bi"><span id="bf12" class="ld le in kz b gy lf lg l lh li">set hive.enforce.bucketing=true;<br/>set hive.exec.reducers.max=4;</span><span id="bcca" class="ld le in kz b gy lj lg l lh li">insert overwrite table beauty_bucket<br/>select * from beauty order by asin;</span></pre><p id="6ea9" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">因此，我在相同数量的桶上制作了一个分桶元数据表，并用我们在第 1 部分中使用的相同查询将它们连接起来。为了利用桶映射连接，您需要首先设置参数。</p><pre class="ku kv kw kx gt ky kz la lb aw lc bi"><span id="cd67" class="ld le in kz b gy lf lg l lh li">set hive.optimize.bucketmapjoin=true;</span></pre><p id="9f7d" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">对于我的表，我看到非分桶表的执行时间略有减少。也许你应该在一个更大的数据集上尝试一下，看看有什么巨大的不同。您选择的桶的数量也很重要，因为它应该与表的大小相对应。但同时，它不应该有太多的桶，因为这会给资源管理器带来不必要的复杂性。</p><p id="85bc" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated"><strong class="jx io">第四部分:结论</strong></p><p id="1e15" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">虽然有各种各样的 Hive 优化技术，但我在这篇博客中探索了三种非常强大的技术。其他一些值得考虑的是:</p><ol class=""><li id="4cae" class="ls lt in jx b jy jz kc kd kg lu kk lv ko lw ks lx ly lz ma bi translated">Tez 执行引擎(比 MapReduce 引擎强大得多)</li><li id="a7b6" class="ls lt in jx b jy mp kc mq kg mr kk ms ko mt ks lx ly lz ma bi translated">矢量化(用例仅限于过滤器和聚合)</li><li id="2fec" class="ls lt in jx b jy mp kc mq kg mr kk ms ko mt ks lx ly lz ma bi translated">反规格化和基于成本的优化</li></ol><p id="898c" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">对于许多公司来说，Hive 无疑是一个即将到来的查询框架，因为它提供了一个带有分布式执行引擎的类似 SQL 的平台。如果您对数据工程领域感兴趣，您应该在 Hive 中获得一些很好的实践机会。</p><p id="bac4" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">注意:我在一个伪分布式 Hadoop 集群上使用 vagger 实现了这个迷你项目。在我的 VirtualBox 上，我将基本内存设置为 4096MB，并将处理器数量设置为 4。</p><p id="80b3" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">【http://deepyeti.ucsd.edu/jianmo/amazon/index.html】数据集链接:<a class="ae mu" href="http://deepyeti.ucsd.edu/jianmo/amazon/index.html" rel="noopener ugc nofollow" target="_blank"/></p><p id="a9fb" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated"><strong class="jx io">参考文献</strong></p><ol class=""><li id="62d9" class="ls lt in jx b jy jz kc kd kg lu kk lv ko lw ks lx ly lz ma bi translated">Hadoop 权威指南第四版—汤姆·怀特</li><li id="5965" class="ls lt in jx b jy mp kc mq kg mr kk ms ko mt ks lx ly lz ma bi translated"><a class="ae mu" href="https://docs.cloudera.com/HDPDocuments/HDP2/HDP-2.6.3/bk_data-access/content/wn_data_access.html" rel="noopener ugc nofollow" target="_blank">https://docs . cloud era . com/HDP documents/HDP 2/HDP-2 . 6 . 3/bk _ data-access/content/wn _ data _ access . html</a></li><li id="862a" class="ls lt in jx b jy mp kc mq kg mr kk ms ko mt ks lx ly lz ma bi translated"><a class="ae mu" href="https://data-flair.training/blogs/hive-optimization-techniques/" rel="noopener ugc nofollow" target="_blank">https://data-flair . training/blogs/hive-optimization-techniques/</a></li></ol><p id="84f1" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">快乐生活！</p></div></div>    
</body>
</html>