<html>
<head>
<title>How to Solve the Multi-Armed Bandit Problem: Optimistic Initial Values Algorithm</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何解决多臂土匪问题:乐观初始值算法</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/multi-armed-bandit-problem-optimistic-initial-values-89c10f04974c?source=collection_archive---------2-----------------------#2022-06-28">https://blog.devgenius.io/multi-armed-bandit-problem-optimistic-initial-values-89c10f04974c?source=collection_archive---------2-----------------------#2022-06-28</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><div class=""><h2 id="47ed" class="pw-subtitle-paragraph jk im in bd b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb dk translated">ε-贪婪算法的升级</h2></div><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi kc"><img src="../Images/01388e84c0f4db1f0360de5d12ffefd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*C8eaeas_m2H0_uhq"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">照片由<a class="ae ks" href="https://unsplash.com/@jarl_schmidt?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">贾尔·施米特</a>在<a class="ae ks" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="d286" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi lp translated"><span class="l lq lr ls bm lt lu lv lw lx di">在</span>的上一篇文章中，我解释了ε-贪婪算法，以及它如何受益于对不同强盗足够次数的探索，最终识别出最优的一个。</p><p id="6a53" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">不过，你一定注意到了，这种模式(<strong class="kv io"> <em class="ly">【蓝线】</em> </strong>)所能达到的最大奖励率总是略低于最优强盗的奖励率(<strong class="kv io"> <em class="ly">【绿线】</em> </strong>)。</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi lz"><img src="../Images/4c1c5956f2f5fff886a05260479fe56c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_I741rrVPsUhybZ8j0advA.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">ε贪婪算法的仿真结果</figcaption></figure><p id="82ab" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">具有讽刺意味的是，总体报酬率的这种轻微下降是由于探索因素，正是这一因素使得这一算法如此有效。因为，在整个模拟过程中，模型从不停止探索，在每次迭代中，模型总是有一定的机会去探索而不是开发。</p><p id="d433" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">虽然在模拟开始时探索可能是必要的，但随着收集的数据越来越多，重点应该转移到利用收集的数据上。这是一种弥合模型整体胜率和最佳强盗胜率之间微小差异的方法。这个修改叫做<strong class="kv io"> <em class="ly">衰变ε</em></strong>。</p><p id="9d67" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">您可以参考下面的那篇文章，以便更好地理解，因为当前的文章是建立在这篇文章的基础上的。</p><div class="ma mb gp gr mc md"><a rel="noopener  ugc nofollow" target="_blank" href="/how-to-solve-the-multi-armed-bandit-problem-epsilon-greedy-approach-ebe286390578"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd io gy z fp mi fr fs mj fu fw im bi translated">如何解决多臂强盗问题:ε-贪婪算法</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">包括代码解释和模拟结果！</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">blog.devgenius.io</p></div></div><div class="mm l"><div class="mn l mo mp mq mm mr km md"/></div></div></a></div><p id="9406" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated"><em class="ly">因此，底线是过度依赖探索因子(</em><strong class="kv io"><em class="ly">【ε】</em></strong><em class="ly">)会增加选择次优土匪的成本，从而提供比最优土匪稍差的结果。</em></p><p id="ab12" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">那么，如果我们能够在保持一定程度探索能力的同时，将这个ε从等式中去掉，会怎么样呢？</p><p id="9128" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">这就是乐观的初始值出现的原因。</p></div><div class="ab cl ms mt hr mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ig ih ii ij ik"><h1 id="9338" class="mz na in bd nb nc nd ne nf ng nh ni nj jt nk ju nl jw nm jx nn jz no ka np nq bi translated">乐观初始值方法</h1><p id="80fd" class="pw-post-body-paragraph kt ku in kv b kw nr jo ky kz ns jr lb lc nt le lf lg nu li lj lk nv lm ln lo ig bi translated">这种方法之所以如此命名，是因为与ε-贪婪算法不同，我们首先对强盗的胜率持乐观态度，并分配较高的初始胜率。有时甚至比实际可能的还要多。</p><p id="ab91" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">至于探索因素，我们并不依赖于 Epsilon，而是依赖于这样一个事实，即随着每次迭代，乐观的初始胜率将不断下降至其实际胜率。重点是在校准过程中简单地选择估计胜率最高的 bandit。</p><p id="320b" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">胜率估计值的下降将达到这样一个点，即所有次优土匪的胜率估计值将低于最佳土匪的胜率估计值。</p><p id="a977" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">然后，我们只是继续选择这个最佳的强盗，并最大限度地获得回报。</p><h2 id="7816" class="nw na in bd nb nx ny dn nf nz oa dp nj lc ob oc nl lg od oe nn lk of og np oh bi translated">示范</h2><p id="f4ae" class="pw-post-body-paragraph kt ku in kv b kw nr jo ky kz ns jr lb lc nt le lf lg nu li lj lk nv lm ln lo ig bi translated">以下内容将帮助您理解它的工作原理。我们有两个吃角子老虎机(单臂强盗)机器 A 和机器 B，实际胜率分别为 25%和 75%。记住，就像 epsilon-greedy 算法一样，模型不知道实际的胜率。</p><p id="fbc0" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">按照乐观的初始值方法，假设我们给两台机器分配 200%的初始胜率。请注意，可能的最高胜率是 100%,我们分配的初始胜率值根本不可能。</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi oi"><img src="../Images/f197caf12572474836c43029096dde25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z46q5DxfFbt7dvYm9s_ZRg.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">初态</figcaption></figure><h2 id="14ef" class="nw na in bd nb nx ny dn nf nz oa dp nj lc ob oc nl lg od oe nn lk of og np oh bi translated">迭代 1</h2><p id="e2f4" class="pw-post-body-paragraph kt ku in kv b kw nr jo ky kz ns jr lb lc nt le lf lg nu li lj lk nv lm ln lo ig bi translated">由于两台老虎机在初始状态下的胜率相同，我们随机选择一台。</p><p id="c076" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">假设，随机选择 A 机，拉匪臂，没有收到奖励信号。</p><p id="159d" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">然后计算机器 A 的胜率估计值并存储在结果中。</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi oi"><img src="../Images/fdebe35e794a929418ccbfffc303dbfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r8xcxtzKmeFj3pF1gWu9xQ.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">演示—迭代 1</figcaption></figure><h2 id="c7f0" class="nw na in bd nb nx ny dn nf nz oa dp nj lc ob oc nl lg od oe nn lk of og np oh bi translated">迭代 2</h2><p id="4876" class="pw-post-body-paragraph kt ku in kv b kw nr jo ky kz ns jr lb lc nt le lf lg nu li lj lk nv lm ln lo ig bi translated">迭代 1 后，机器 B 具有更高的胜率估计值，因此被选中(<em class="ly">贪婪方法</em>)。</p><p id="f7db" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">土匪手臂一拉，收到了悬赏信号。</p><p id="e69f" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">计算机器 B 的胜率估计值并存储在结果中。</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi oi"><img src="../Images/7376ed8c86a564e5fc55d5581eff1d2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fmws8ojvVbsX-3TfCOURVg.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">演示—迭代 2</figcaption></figure><h2 id="4de5" class="nw na in bd nb nx ny dn nf nz oa dp nj lc ob oc nl lg od oe nn lk of og np oh bi translated">迭代 3</h2><p id="01ed" class="pw-post-body-paragraph kt ku in kv b kw nr jo ky kz ns jr lb lc nt le lf lg nu li lj lk nv lm ln lo ig bi translated">迭代 2 之后，机器 B 具有更高的胜率估计值，因此被选中。</p><p id="a8d7" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">土匪手臂被拉，这次没有收到悬赏信号。</p><p id="c0da" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">计算机器 B 的胜率估计值并存储在结果中。</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi oi"><img src="../Images/a6af69ee7656e64d0c433a9c3c1676d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XGAWZWfTEUd9NEHqPBjBtA.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">演示—迭代 3</figcaption></figure><h2 id="5791" class="nw na in bd nb nx ny dn nf nz oa dp nj lc ob oc nl lg od oe nn lk of og np oh bi translated">迭代 4</h2><p id="4cab" class="pw-post-body-paragraph kt ku in kv b kw nr jo ky kz ns jr lb lc nt le lf lg nu li lj lk nv lm ln lo ig bi translated">迭代 3 后，两台机器都有相同的胜率估计值，因此机器 A 被随机选中。</p><p id="2085" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">土匪手臂被拉，没有收到悬赏信号。</p><p id="7854" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">机器 A 的修正胜率估计被计算并存储在结果中。</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi oi"><img src="../Images/d63515c556736f02077a1b50fd4cda63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JozBpp698d8qW5ixCp-UCQ.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">演示—迭代 4</figcaption></figure><h2 id="d113" class="nw na in bd nb nx ny dn nf nz oa dp nj lc ob oc nl lg od oe nn lk of og np oh bi translated">迭代 5</h2><p id="ddf3" class="pw-post-body-paragraph kt ku in kv b kw nr jo ky kz ns jr lb lc nt le lf lg nu li lj lk nv lm ln lo ig bi translated">迭代 4 之后，机器 B 具有更高的胜率估计值，因此被选中。</p><p id="9d0f" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">土匪手臂被拉，没有收到悬赏信号。</p><p id="faf7" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">计算机器 B 的胜率估计值并存储在结果中。</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi oi"><img src="../Images/86baf8332372f5d69462855f8784154c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tpCAgBRHXO7eoBjV1ezIuQ.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">演示—迭代 5</figcaption></figure><p id="becc" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">请注意，在此迭代中，满足了两个特殊条件:</p><ul class=""><li id="40e0" class="oj ok in kv b kw kx kz la lc ol lg om lk on lo oo op oq or bi translated">机器 B 胜率估计值已经接近其实际胜率。</li><li id="61bd" class="oj ok in kv b kw os kz ot lc ou lg ov lk ow lo oo op oq or bi translated">机器 A 估计胜率低于机器 B 的实际胜率。</li></ul><blockquote class="ox oy oz"><p id="ff04" class="kt ku ly kv b kw kx jo ky kz la jr lb pa ld le lf pb lh li lj pc ll lm ln lo ig bi translated"><strong class="kv io">这些条件的意义在于，探索的目标是将模型暴露给所有强盗，以便识别具有最高胜率的最佳强盗，并且这已经通过该迭代实现。</strong></p></blockquote><p id="1ace" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">由于该模型遵循贪婪的方法，并且总是选择具有最高胜率估计的老虎机，所以即使在即将到来的迭代中它也会继续这样做，并且选择机器 b。</p><p id="c15a" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">由于机器 B 的胜率估计已经收敛到其实际胜率估计，因此，与胜率估计的当前状态相比，波动将非常小。</p><p id="77ff" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">从长远来看，这种对机器 B 的重复选择最终会使回报最大化。</p><p id="ae61" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated"><strong class="kv io">一些关键要点:</strong></p><ul class=""><li id="3a8b" class="oj ok in kv b kw kx kz la lc ol lg om lk on lo oo op oq or bi translated">在乐观初始值方法中，高初始值负责模型的探索。</li><li id="259b" class="oj ok in kv b kw os kz ot lc ou lg ov lk ow lo oo op oq or bi translated"><em class="ly">初始值越高，勘探量越大</em>。这是因为初始值设置得越高，模型收敛到其实际胜率值所需的迭代次数就越多，因此会有更多的探索。</li></ul><blockquote class="ox oy oz"><p id="ba7d" class="kt ku ly kv b kw kx jo ky kz la jr lb pa ld le lf pb lh li lj pc ll lm ln lo ig bi translated"><strong class="kv io">你可能会问，如何为模拟提供最佳初始值？多少需要一些试凑法。然而，如果你手头有这个问题的一些领域知识，那会有所帮助。</strong></p></blockquote><p id="dffb" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">例如，多臂强盗问题在基于在线广告的营销中有广泛的应用。目标是选择具有最高点击率(点击数/印象数)的广告，以便最大化收入。</p><p id="efc0" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">现在，在这个领域有经验的人会知道，2–4%的点击率是不同广告形式中普遍观察到的比率。</p><p id="76cd" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">假设模拟被设计来测试两个不同广告的胜率(在这种情况下是点击率),并选择最佳的一个。那么，乐观初始值的一个好基线可以是 10%。</p><p id="93bc" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">底线是一些领域暴露可能导致一个受过良好教育的猜测。</p><h1 id="5fbf" class="mz na in bd nb nc pd ne nf ng pe ni nj jt pf ju nl jw pg jx nn jz ph ka np nq bi translated">实施代码和结果</h1><p id="2f2f" class="pw-post-body-paragraph kt ku in kv b kw nr jo ky kz ns jr lb lc nt le lf lg nu li lj lk nv lm ln lo ig bi translated">代码模拟了一个场景，有三台老虎机，实际胜率分别为<strong class="kv io"> 25%、50% &amp; 75% </strong>。初始值设置为 1 ( <strong class="kv io"> 100% </strong>胜率估计)。</p><figure class="kd ke kf kg gt kh"><div class="bz fp l di"><div class="pi pj l"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">乐观初始值方法的模拟代码</figcaption></figure><h2 id="a476" class="nw na in bd nb nx ny dn nf nz oa dp nj lc ob oc nl lg od oe nn lk of og np oh bi translated">模拟的结果</h2><p id="19df" class="pw-post-body-paragraph kt ku in kv b kw nr jo ky kz ns jr lb lc nt le lf lg nu li lj lk nv lm ln lo ig bi translated">以下结果是使用本文提供的代码获得的。初始胜率估计值被设置为 100%。</p><p id="3ef1" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">请注意:</p><ul class=""><li id="0f11" class="oj ok in kv b kw kx kz la lc ol lg om lk on lo oo op oq or bi translated"><em class="ly">次优盗匪的胜率估计值永远不会收敛到它们的实际值，因为一旦它们的胜率估计值低于最优盗匪的胜率估计值，它们就永远不会被再次选中。</em></li><li id="e922" class="oj ok in kv b kw os kz ot lc ou lg ov lk ow lo oo op oq or bi translated"><em class="ly">与 Epsilon-Greedy 算法不同，模型的整体胜率(蓝线)与最优 bandit 胜率(红线)之间的差异可以忽略不计。</em></li></ul><p id="3bdd" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">对于<strong class="kv io">模拟结果— 1 </strong>，<code class="fe pk pl pm pn b">times_selected</code>显示:</p><ul class=""><li id="4998" class="oj ok in kv b kw kx kz la lc ol lg om lk on lo oo op oq or bi translated">土匪#1 被选中 20 次[实际胜率:25%]</li><li id="8ff7" class="oj ok in kv b kw os kz ot lc ou lg ov lk ow lo oo op oq or bi translated">土匪#2 被选中 6 次[实际胜率:50%]</li><li id="1462" class="oj ok in kv b kw os kz ot lc ou lg ov lk ow lo oo op oq or bi translated">土匪#3 被选中 9974 次[实际胜率:75%](最佳土匪)</li></ul><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi po"><img src="../Images/dfb384fcfca49175bcd5f0041ec0144a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g1pXcHFXEGcwhCzSeJRgLA.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">模拟结果— 1</figcaption></figure><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi po"><img src="../Images/4711c4afcfcac03ced17052a9e35b44d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2UuUbWB_Vt8g97KZJ8byfA.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">模拟结果— 2</figcaption></figure><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi po"><img src="../Images/c864554ef8df510fa64c6a6d52509acf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EFkKNimgmUhxIlYNRop_FQ.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">模拟结果— 3</figcaption></figure><p id="404d" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">此外，您可以尝试更高的初始值，以强制模型探索更多内容。下图显示了初始胜率估计值设置为 200%而不是之前使用的 100%的模型的结果。</p><p id="3bf4" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">请注意，与之前的配置相比，此模型选择了更多次优的土匪。</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi pp"><img src="../Images/f91f70309b2ab705964da67d0d058026.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rr71kO2wvOCc25WXF9XzMQ.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">模拟结果— 4</figcaption></figure></div><div class="ab cl ms mt hr mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ig ih ii ij ik"><h1 id="e5ff" class="mz na in bd nb nc nd ne nf ng nh ni nj jt nk ju nl jw nm jx nn jz no ka np nq bi translated">感谢阅读！</h1><p id="cedf" class="pw-post-body-paragraph kt ku in kv b kw nr jo ky kz ns jr lb lc nt le lf lg nu li lj lk nv lm ln lo ig bi translated">这给了我很大的鼓励！😃<em class="ly">如果你觉得这个帖子很有趣，还想看更多，可以考虑</em> <a class="ae ks" href="https://medium.com/subscribe/@pratik.pandav" rel="noopener"> <strong class="kv io"> <em class="ly">关注我</em></strong></a><strong class="kv io"><em class="ly"/></strong>🥁<em class="ly">。我每周发布与机器学习、统计和数据分析相关的主题。我喜欢通过可视化来学习，因此，我的帖子包含了大量的图表、模拟和代码示例。</em></p><p id="22a9" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated"><em class="ly">简单地说，我尽最大努力将错误降到最低，但它们是我们学习的一部分，所以，如果你发现了什么，请指出来。最后，请随意提出你希望我写的主题。</em></p></div></div>    
</body>
</html>