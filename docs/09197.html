<html>
<head>
<title>Modelling the brain: neural networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">大脑建模:神经网络</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/modelling-the-brain-neural-networks-6b1149fef1cc?source=collection_archive---------5-----------------------#2022-08-05">https://blog.devgenius.io/modelling-the-brain-neural-networks-6b1149fef1cc?source=collection_archive---------5-----------------------#2022-08-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/6288bf53be33de48538a8b7becb9231e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mUBJc5WP-0vSAAe-"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">由<a class="ae kc" href="https://unsplash.com/@jessedo81?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">杰西·奥里科</a>在<a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="6996" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">到目前为止，我们已经介绍了一些<a class="ae kc" rel="noopener ugc nofollow" target="_blank" href="/entering-the-artificial-intelligence-maze-d58fb6eb5554">人工智能</a>策略:<a class="ae kc" rel="noopener ugc nofollow" target="_blank" href="/evolutionary-algorithms-theoretical-aspects-of-evolution-c7dd021d8bd3">进化</a>和<a class="ae kc" rel="noopener ugc nofollow" target="_blank" href="/genetic-algorithms-applied-evolution-1c3afa0f7f3f">遗传算法</a>，粒子群优化(它也有几种形式，但我们看到了最常见的<a class="ae kc" rel="noopener ugc nofollow" target="_blank" href="/multi-agent-algorithms-particle-swarm-optimization-6f11e6b35736">方法</a>)，最后我们到达了神经网络。既然我们能够模拟进化来迫使解决方案变得越来越好，既然我们能够模拟成群的昆虫寻找食物来帮助我们找到函数的全局最大值，为什么我们不直接模拟大脑呢？那么结果会是什么呢？</p><p id="84d4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">科学家们再次穿上外衣，带着看似简单却分类明确的答案回来了:为了模拟大脑，我们需要模拟神经元以及它们之间的连接。但他们走得更远:我们实际上不需要模拟神经元，只需要模拟它们之间的信号以及它们从一个神经元跳到另一个神经元时经历的转换。由于我们只关心信号，这个问题很快离开了生物领域，进入了信号处理领域，用众所周知的方程定义了问题的整个传输和处理层。</p><h2 id="8c92" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">作为信号处理器的大脑</h2><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lu"><img src="../Images/8d51960c39caba10b5d04dc0f0173977.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Dn6RsmraEcsLIzGo"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">克里斯托弗·伯恩斯在<a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="009a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">结果呢？一个加权函数:<code class="fe lz ma mb mc b">output = sum of weight(n) * input(n)</code>其中<code class="fe lz ma mb mc b">n</code>是进入我们计算其输出的神经元的每个信号。当然，可能有更多的配置选项，如粒子群优化算法中的速度或惯性等，但主要思想仍然是:我们添加加权输入以获得当前神经元的输出。我们从输入(我们的问题数据)开始对所有神经元进行计算，直到我们到达输出(解决方案):信号穿过我们的网络并被转换。</p><p id="2f35" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从我们想要的实际结果中减去得到的结果，就像我们在之前的人工智能算法的适应度函数中所做的那样，我们得到了一个错误。通过调整权重将误差分布到整个网络，猜猜会发生什么？我们刚刚用一种叫做反向传播的方法实现了监督学习。我们的数学方程式让位于一个学习系统，所以我们完成了。神秘的神经元变成了一张纸上的方程式。有一堆这样的方程，你就有了整个大脑，对吗？对吗？</p><h2 id="17da" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">学习策略和结果</h2><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi md"><img src="../Images/b66c8bb400e8dc6c381f5c7d95c030ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*FAh4xe645ROgqSzU"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">马克·弗莱彻·布朗在<a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="ec55" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以看到神经网络的行为与我们之前看到的有点不同。它需要一个已知的数据集来学习。以前的算法可以简单地通过推动一个假设的解决方案直到它适合问题来找到解决方案。有了神经网络，我甚至可能不知道问题所在:我所需要的只是一组已知的结果。我将这些结果输入网络，并修正权重以适应正确的值，这样就完成了。我甚至不需要知道虚拟大脑是如何看起来和工作的，我当然也不需要知道使系统工作的最终权重:它学习并正确响应训练数据，它就完成了。</p><p id="374d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当学习时，我们的神经元束变成矩阵中的细胞。我们从随机矩阵开始，意味着每个神经元的随机权重。当将信号发送到下一列时，每个矩阵单元保持它所具有的权重。我们看到初始信号是我们拥有的每个训练数据行。每个单元接收来自前一列的信号，由列单元值加权。为了让这个矩阵能够学习，我们已经解释了反向传播，这是一种直接的算法:获取误差并进行分配。改变矩阵中的每个单元值以说明一点误差。但是有很多策略可以让矩阵发挥作用。</p><p id="aba8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从该系列的前几篇文章中可以非常明显地看出另一种策略:由于我们从随机权重开始，所以我们以前的所有人工智能算法都是以相同的方式开始的。他们都擅长于将这些初始随机值转化为对已知结果做出反应的东西:这正是我们在这里遇到的问题。因此，我们可以简单地采用粒子群优化算法，例如，一种致命的快速优化算法来寻找我们的权重，更不用说如果我们想要一个真正的工作大脑，我们将使用数百个神经元:这正是粒子群优化算法要解决的问题类型。我在<a class="ae kc" href="https://github.com/raduzaharia-medium/neural-network" rel="noopener ugc nofollow" target="_blank"> Github </a>上编写的代码使用这种方法求解权重。这是我的最爱之一。</p><p id="e7f0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们也可以通过在每一步之后给所有单元添加一个小的随机值来训练网络。如果结果更好，就保留它，如果不好，就放弃它，再试一次。这并没有考虑实际的误差，而是在大脑中引入了一种混乱的变异，如果结果改善了就保留，否则就丢弃。这与将进化算法的特性应用到我们的网络中是一样的。</p><h2 id="c0dd" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">梦想变成现实</h2><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi me"><img src="../Images/4e13a713677672de3f5b964b692412aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zZmUZl7VGe3rPug6"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">照片由<a class="ae kc" href="https://unsplash.com/@yohannlc?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Yohann Lc </a>在<a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="f312" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">那么一旦学习完成会发生什么呢？在矩阵的某个地方隐藏着一个方程式，它被训练来响应我们的数据集。我们看不到。我们可以想象它，因为我们有神经元公式，因为我们在处理多层神经元和矩阵，我们可能在处理一个方程组，但它看起来如何永远隐藏起来。它是一个黑盒子。</p><p id="3a2b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们为什么不给它输入我们不知道答案的数据呢？根据我们有多少训练数据以及我们在哪里解决错误，我们的这个创造可以给我们正确的结果。它可以预测我们无法或不知道如何计算的结果。但是不要被骗了，我们的小预测器只和我们喂给它的数据一样聪明。我们教它如何做加法，或者如何做对数，但仅此而已。网络对其他任何事都没用。</p><p id="4f89" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是我们能通过给它两组数据来教它加法和对数吗？是的，我们可以在数据集中添加一些标志来表示简单的加法或对数的加法。我们当然需要更多的神经元层，但这是可以做到的。那我们可以教它三种操作吗？我们的这个小矩阵能学会思考吗？这真的是我们最初想要的真正人工智能的开始吗？</p><p id="74cb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">那是我的梦想。进化算法和群体优化在优化方面非常成功，以至于人们认为大脑模型将为一般人工智能做同样的事情。但是随着时间的推移，实验失败了，科学家们最终不得不认识到一个显而易见的事实:没有免费的午餐。首先，模拟一个完整的人类大脑还不可能，它需要有这么多行和列的矩阵来保存大脑连接数据，这对当今的计算机来说简直是太多了。</p><p id="a8ab" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">深度神经网络是神经网络武器库中的最新成员，距离模拟完整的人脑还有很长的路要走<em class="mf"/>。例如，如果一个典型的神经网络有 10 或 20 层神经元，深度神经网络有数百层。不要误会我的意思，这是迄今为止我们拥有的最好的神经网络，它显示出了出色的潜力，但仍然只适用于超级特定的任务，即使在那里，它也完全依赖于输入网络的数据。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><p id="d713" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">那么，我们从这一切中学到了什么？总而言之，这是本系列的最后一篇文章，人工智能不是一个单一的东西。这是一种算法，以某种方式实现了我们自然世界的一点点功能。它不能全部实现，也不需要实现。每种算法提供的解决方案足以解决最棘手的优化问题:预测天气，创建平衡的送货时间表，识别照片中的对象、意图和情感，在国际象棋、围棋和星际争霸中击败职业选手。但这一切还不会对生命和宇宙进行思考和推理。这需要比我们现有的能力大得多的能力。</p><p id="617c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是我们当然不应该停止梦想。这种对人工智能的小小入侵只是一个开始，一种试探。让我们停下来看看另一种算法，让我们惊叹于进化优化的美丽和自然大脑的怪异抽象。下次你遇到优化问题时，我希望这些文章能让你尝试一种人工智能方法。真正的那种，而不是产品包装盒上为了听起来酷而宣传的那种。下次见！</p></div></div>    
</body>
</html>