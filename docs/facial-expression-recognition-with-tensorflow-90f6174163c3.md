# å¼ é‡æµäººè„¸è¡¨æƒ…è¯†åˆ«

> åŸæ–‡ï¼š<https://blog.devgenius.io/facial-expression-recognition-with-tensorflow-90f6174163c3?source=collection_archive---------1----------------------->

![](img/751ab3fb815b9474ca3a086da0541e90.png)

æˆ‘å¼€å§‹äº†ä½œä¸ºæœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆçš„æ—…ç¨‹ï¼Œè¯•å›¾å°½å¯èƒ½å¤šåœ°è¿›è¡Œå®è·µï¼Œä¸å…¶ä»–äººå»ºç«‹è”ç³»ï¼Œå¹¶æ¥æ”¶ä¸€äº›åé¦ˆä»¥è¿›è¡Œæ”¹è¿›ã€‚æ‰€ä»¥å¦‚æœä½ æƒ³è°ˆè°ˆæˆ–ç»™æˆ‘ä¸€äº›åé¦ˆï¼Œæˆ‘ä¼šå¾ˆæ„Ÿæ¿€ï¼Œæˆ‘ä¼šè®©æˆ‘çš„ LinkedIn å’Œ GitHub åœ¨æ–‡æœ«ã€‚

æ‰€ä»¥é¦–å…ˆï¼Œæˆ‘æƒ³åšä¸€äº›å›¾åƒåˆ†ç±»å™¨é¡¹ç›®ï¼Œç„¶åæˆ‘åšäº†ä¸€äº›ç ”ç©¶ï¼Œå‘ç°äº†è¿™ä¸ªâ€œæ£€æµ‹æƒ…ç»ªâ€çš„æƒ³æ³•ï¼Œæˆ‘è®¤ä¸ºå®ƒéå¸¸é…·ã€‚æ‰€ä»¥åœ¨æœç´¢äº†ä¸€äº›å…³äºè¿™ä¸ªç‰¹å®šé—®é¢˜çš„æ•°æ®é›†åï¼Œæˆ‘é€‰æ‹©äº†è¿™ä¸ª[è¡¨å¾å­¦ä¹ çš„æŒ‘æˆ˜:æ¥è‡ª](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge) [Kaggle](https://www.kaggle.com) çš„é¢éƒ¨è¡¨æƒ…è¯†åˆ«æŒ‘æˆ˜ã€‚

æˆ‘ä»¬å°†åœ¨æ•°æ®åˆ†æã€æ•°æ®é¢„å¤„ç†å’Œå»ºæ¨¡çš„è¿™äº›è¿‡ç¨‹ä¸­ä½¿ç”¨ Google Colabã€‚ä½†æ˜¯ï¼Œè®©æˆ‘ä»¬è°ˆè°ˆæˆ‘ä»¬çš„æ•°æ®ï¼Œæ•°æ®é›†ä¸ºæˆ‘ä»¬æä¾›äº† 7 ä¸ªç±»ï¼Œå¦‚ä¸‹æ‰€ç¤º:

![](img/e75b5116dc8adfc7ce8a7b1385b33f3a.png)

æƒ…æ„Ÿ

ä½ çœ‹åˆ°çš„å’Œæˆ‘ä¸€æ ·å—ï¼Ÿæˆ‘ä»¬æœ‰ä¸€ä¸ªä¸å¹³è¡¡æ•°æ®çš„é—®é¢˜â€¦æ˜¯çš„ï¼Œé‚£å¾ˆç³Ÿç³•ã€‚ä½†æ˜¯ä¸ºäº†â€œè§£å†³â€è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å°†åªä½¿ç”¨ 4 ä¸ªç±»ï¼Œå› ä¸ºæŸäº›ç±»çš„å›¾åƒæ˜¯ç³Ÿç³•çš„ï¼Œå¹¶ä¸”ä¸ä¼šå¯¹æˆ‘ä»¬çš„æ¨¡å‹æœ‰å¥½å¤„ï¼Œæ‰€ä»¥æˆ‘ä»¬çš„ç±»å°†æ˜¯æ„¤æ€’ã€å¿«ä¹ã€æ‚²ä¼¤å’ŒæƒŠè®¶çš„ã€‚

è®©æˆ‘ä»¬å»æ‰ä¸€äº›æˆ‘ä»¬ä¸ä¼šç”¨åˆ°çš„å€¼ã€‚

```
data = data[data["emotion"] != 1]data = data[data["emotion"] != 2]data = data[data["emotion"] != 6]data["emotion"].value_counts().reset_index(drop=True, inplace=True)
```

æ‰€ä»¥ï¼Œè®©æˆ‘ä»¬æŠŠæ•°æ®åˆ†æˆ X å’Œ yã€‚

```
# Split data into X & yX = data.drop("emotion", axis=1)y = data["emotion"]# Concat train sets into onedf = pd.concat([X, y], axis=1)
```

ä¸‹ä¸€æ­¥æ˜¯å¤„ç†æˆ‘ä»¬çš„å›¾åƒï¼Œå› ä¸ºå®ƒä»¬æ˜¯å­—ç¬¦ä¸²æ ¼å¼ã€‚

```
def pixels_to_array(pixels):array = np.array(pixels.split(),'float64')return array df['pixels'] = df["pixels"].apply(pixels_to_array)
```

å°†æ•°æ®åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚

```
data_train = df[df["Usage"] == "Training"]data_test1 = df[df["Usage"] == "PublicTest"]data_test2 = df[df["Usage"] == "PrivateTest"]data_test = pd.concat([data_test1, data_test2])
```

ç„¶åï¼Œæˆ‘ä»¬å°†é‡å¡‘æˆ‘ä»¬çš„å›¾åƒï¼Œæˆä¸º RGB æ ¼å¼å’Œå½¢çŠ¶(48ï¼Œ48ï¼Œ3)ã€‚

```
def image_reshape(data):image = np.reshape(data.to_list(),(data.shape[0],48,48,1))image = np.repeat(image, 3, -1)return image X_train = image_reshape(data_train["pixels"])X_test = image_reshape(data_test["pixels"])y_train = data_train["emotion"]y_test = data_test["emotion"]
```

å°†ç±»åè®¾ç½®ä¸ºå˜é‡:

```
class_names = ["Angry", "Happy", "Sad", "Surprise"]
```

ç°åœ¨ï¼Œæˆ‘ä»¬éœ€è¦è§£å†³å¦ä¸€ä¸ªé—®é¢˜ï¼Œå› ä¸ºæˆ‘ä»¬ä¸¢å¼ƒäº†ä¸€äº›æƒ…ç»ªï¼Œæˆ‘ä»¬æƒ…ç»ªçš„å€¼æ˜¯è¿ç»­çš„ï¼Œå®ƒä»¬ç°åœ¨æ˜¯è¿™æ ·çš„â€œ0ï¼Œ3ï¼Œ5ï¼Œ7â€ã€‚è¿™å°†æ˜¯ä¸€ä¸ªé—®é¢˜ï¼Œåœ¨ä¸‹ä¸€æ­¥ï¼Œå½“æˆ‘ä»¬å¾—åˆ°å›¾åƒï¼Œå¹¶æŠŠå®ƒä»¬æ”¾å…¥å„è‡ªçš„ç›®å½•ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚

```
# Do the same for y_test
for i in range(len(y_train)):if y_train[i] == 3:y_train[i] = 1elif y_train[i] == 4:y_train[i] = 2elif y_train[i] == 5:y_train[i] = 3for label in range(len(classes)):os.makedirs("/content/data/train/" + classes[label], exist_ok=True)os.makedirs("/content/data/test/" + classes[label], exist_ok=True) for i in range(len(X_train)):emotion = classes[y_train[i]]cv2.imwrite(f"/content/data/train/{emotion}/{emotion}{i}.png", X_train[i])for j in range(len(X_test)):emotion = classes[y_test[j]]cv2.imwrite(f"/content/data/test/{emotion}/{emotion}{j}.png", X_test[j])
```

æˆ‘ä»¬æ¥ä¸‹æ¥çš„æ­¥éª¤å¾ˆé‡è¦ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†æ ‡å‡†åŒ–æˆ‘ä»¬çš„æ•°æ®(å°†å€¼è½¬æ¢ä¸º 0 åˆ° 1 ä¹‹é—´çš„å€¼)ï¼Œè¿™æœ‰åŠ©äºæˆ‘ä»¬çš„æ¨¡å‹æ›´å¥½åœ°å­¦ä¹ å’Œæ‰§è¡Œã€‚å…¶æ¬¡ï¼Œæ‰§è¡Œä¸€äº›æ•°æ®æ‰©å……(é€šè¿‡å¯¹ç°æœ‰æ•°æ®è¿›è¡Œç»†å¾®çš„æ›´æ”¹æ¥æ·»åŠ æ›´å¤šæ•°æ®çš„æŠ€æœ¯)ã€‚æœ€åï¼Œä½†ä»ç„¶é‡è¦çš„æ˜¯ï¼Œå°†æˆ‘ä»¬çš„æ•°æ®åˆ†æ‰¹è½¬æ¢(åŸºæœ¬ä¸Šå°†æˆ‘ä»¬çš„æ•°æ®åˆ†æˆ**ç»„**ï¼Œä»¥ä¾¿æˆ‘ä»¬çš„æ¨¡å‹æƒé‡ä»…åœ¨æ¯ä¸ª**ç»„**ä¹‹åæ›´æ–°)ã€‚

```
from tensorflow.keras.preprocessing.image import ImageDataGeneratorIMAGE_SHAPE = (48, 48)BATCH_SIZE = 64train_dir = "/content/data/train/"test_dir =  "/content/data/test/"train_datagen = ImageDataGenerator(rescale=1/255.,rotation_range=0.1,zoom_range=0.1)test_datagen = ImageDataGenerator(rescale=1/255.) train_data = train_datagen.flow_from_directory(train_dir,target_size=IMAGE_SHAPE,batch_size=BATCH_SIZE,class_mode="categorical",shuffle=True)test_data = test_datagen.flow_from_directory(test_dir,target_size=IMAGE_SHAPE,batch_size=BATCH_SIZE,class_mode="categorical")
```

è®©æˆ‘ä»¬æƒ³è±¡ä¸€ä¸‹æˆ‘ä»¬çš„ç«è½¦åœºæ™¯ä¸­çš„ä¸€ä¸ªå›¾åƒ:

![](img/cdb1cfadb50bfa94cff5aae4fba94859.png)

æˆ‘ä»¬åšäº†æ‰€æœ‰éœ€è¦çš„æ•°æ®å¤„ç†ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬å»ºç«‹æˆ‘ä»¬çš„æ¨¡å‹ã€‚ç»è¿‡ä¸€äº›æµ‹è¯•ï¼Œè¿™ç§æ¶æ„è¾¾åˆ°äº†æœ€ä½³æ•ˆæœ:

```
# Import packagesimport tensorflow as tffrom tensorflow.keras import Sequentialfrom tensorflow.keras.callbacks import ReduceLROnPlateaufrom tensorflow.keras.layers import BatchNormalization tf.random.set_seed(42)# Create the modelmodel_1 = Sequential([tf.keras.layers.Input(shape=(48, 48, 3)),tf.keras.layers.Conv2D(512, (3,3), activation="relu", padding="same"),BatchNormalization(),tf.keras.layers.Conv2D(256, (3,3), activation="relu", padding="same"),BatchNormalization(),tf.keras.layers.MaxPool2D(2),tf.keras.layers.Dropout(0.5),tf.keras.layers.Conv2D(128, (3,3), activation="relu", padding="same"),BatchNormalization(),tf.keras.layers.Conv2D(64, (3,3), activation="relu", padding="same"),BatchNormalization(),tf.keras.layers.MaxPool2D(2),tf.keras.layers.Dropout(0.5),tf.keras.layers.Conv2D(32, (3,3), activation="relu", padding="same"),tf.keras.layers.MaxPool2D(2),tf.keras.layers.Dropout(0.5),tf.keras.layers.Flatten(),tf.keras.layers.Dense(4, activation="softmax")])
```

ç¼–è¯‘å’Œè®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ã€‚

```
# Compile the modelmodel_1.compile(loss="categorical_crossentropy",optimizer=tf.keras.optimizers.Adam(),metrics=["accuracy"])checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath="checkpoint/",save_weights_only=False,save_best_only=True,save_freq="epoch",verbose=1)reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2,patience=8, min_lr=0.00001)# Fit the modelmodel_1.fit(train_data, epochs=80, callbacks=[reduce_lr, checkpoint_callback], validation_data=test_data)
```

å¯¹äºè®­ç»ƒé›†ï¼Œæˆ‘ä»¬å¾—åˆ°äº†å¤§çº¦ 83%çš„ ACCï¼Œå¯¹äºæµ‹è¯•é›†ï¼Œæˆ‘ä»¬å¾—åˆ°äº†å¤§çº¦ 79%çš„ ACCï¼Œè€ƒè™‘åˆ°æˆ‘ä»¬çš„å›¾åƒå­˜åœ¨çš„ä¸€äº›é—®é¢˜ï¼Œè¿™å·²ç»ç›¸å½“ä¸é”™äº†ï¼Œæ¯”å¦‚:
-æ°´å°
-ä¸€äº›å›¾åƒç”¨æ•°å­—å­—ç¬¦(ä¸æ˜¯äºº)
-å°‘é‡æ•°æ®ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥æœç´¢å…¶ä»–ç”¨äºé¢éƒ¨æƒ…æ„Ÿè¯†åˆ«çš„æ•°æ®é›†ï¼Œåˆ é™¤ä¸€äº›ä¸å¥½çš„å›¾åƒï¼Œæˆ–è€…æ·»åŠ æˆ‘ä»¬å¯ä»¥åœ¨æŸä¸ªåœ°æ–¹è·å¾—çš„å›¾åƒã€‚

å› æ­¤ï¼Œæˆ‘ä»¬åˆ†ææˆ‘ä»¬çš„æ•°æ®ï¼Œå¤„ç†å®ƒï¼Œæ‰§è¡Œå»ºæ¨¡å’Œè®­ç»ƒã€‚ä¸‹ä¸€æ­¥æ˜¯ä»€ä¹ˆï¼Ÿçœ‹åˆ°ç°å®ç”Ÿæ´»ä¸­çš„ç»“æœï¼Œæœ€ç²¾å½©çš„éƒ¨åˆ†â€¦

![](img/4bac960f091336bf37838a89c0fd7db9.png)![](img/830e6745591894a4f95cf0692f212eee.png)![](img/1acfd287bb957958adb69c856a3ccb4f.png)![](img/a37f4194aaec1cb16d1f176349825045.png)

å¯¹æˆ‘æ¥è¯´ï¼ŒI.A æœ€ä»¤äººå…´å¥‹çš„éƒ¨åˆ†æ˜¯æ·±åº¦å­¦ä¹ ï¼Œæ‰€ä»¥åšè¿™ä¸ªå…³äºé¢éƒ¨è¡¨æƒ…è¯†åˆ«çš„å°é¡¹ç›®éå¸¸é…·ï¼Œæˆ‘å­¦åˆ°äº†å¾ˆå¤šä¸œè¥¿ã€‚

å¦‚æœä½ æœ‰ä»»ä½•åé¦ˆï¼Œæƒ³è°ˆè°ˆï¼Œæˆ–è€…åªæ˜¯è·Ÿéšæˆ‘åœ¨è¿™ä¸ªæ—…ç¨‹ä¸­ï¼Œæˆ‘ä¼šè®©æˆ‘çš„ LinkedIn å’Œé‚£äº›æƒ³çœ‹å®Œæ•´ä»£ç çš„äººï¼Œæˆ‘çš„ GitHub åœ¨ä¸‹é¢ğŸ˜

é¢†è‹±:[https://www.linkedin.com/in/joaopdss/](https://www.linkedin.com/in/joaopdss/)

GitHub:[https://github.com/joaopdss](https://github.com/joaopdss)