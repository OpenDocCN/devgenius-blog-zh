<html>
<head>
<title>How To Predict Customer Churn Risk using Machine Learning in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用 Python 中的机器学习预测客户流失风险</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/how-to-predict-customer-churn-risk-using-machine-learning-in-python-b11c09759491?source=collection_archive---------0-----------------------#2022-09-12">https://blog.devgenius.io/how-to-predict-customer-churn-risk-using-machine-learning-in-python-b11c09759491?source=collection_archive---------0-----------------------#2022-09-12</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><div class=""><h2 id="0940" class="pw-subtitle-paragraph jk im in bd b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb dk translated">使用 Python、pandas 和 scikit-learn、RFM 分析和 SMOTE 的深入教程</h2></div><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi kc"><img src="../Images/eb8b0e324fe0c09fe651b35c58711d2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*azMl35f8xktASu94"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">Riho Kroll 在<a class="ae ks" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure></div><div class="ab cl kt ku hr kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ig ih ii ij ik"><h1 id="e57a" class="la lb in bd lc ld le lf lg lh li lj lk jt ll ju lm jw ln jx lo jz lp ka lq lr bi translated">介绍</h1><p id="d214" class="pw-post-body-paragraph ls lt in lu b lv lw jo lx ly lz jr ma mb mc md me mf mg mh mi mj mk ml mm mn ig bi translated">对于外行人来说，客户行为很难预测。毕竟，他们是有着反复无常的奇思妙想和欲望的人类。然而，对于一台每秒可以计算数千次的机器来说，趋势和模式越来越明显。企业的目标是吸引顾客，让他们反复光顾商店，每次都产生收入。然而，很难确定哪些客户可能会再次光顾，哪些客户已经对所提供的商品或服务失去了兴趣。</p><p id="2345" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">这里我们引入了<strong class="lu io">顾客流失</strong>的概念:如果顾客主动返回商店，他们就被认为流失了<em class="mt">。而流失客户是指那些不再回来购买更多产品的人。</em></p><p id="6d39" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated"><strong class="lu io">客户流失风险</strong>是客户脱离业务的可能性。因此，我们可以将其定义为:</p><pre class="kd ke kf kg gt mu mv mw mx aw my bi"><span id="48a2" class="mz lb in mv b gy na nb l nc nd">Churn Risk = 1 - Probability of purchase over a determined period</span></pre><p id="5e2d" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">了解你的顾客的行为对于充分利用他们的惠顾是必不可少的。如今，我们可以利用大量可用数据来预测客户继续与您合作的可能性。这在以下方面很有价值:</p><ul class=""><li id="4c7f" class="ne nf in lu b lv mo ly mp mb ng mf nh mj ni mn nj nk nl nm bi translated">提供数据驱动的客户级指标，帮助实施将影响业务的前瞻性决策。</li><li id="cc71" class="ne nf in lu b lv nn ly no mb np mf nq mj nr mn nj nk nl nm bi translated">通过添加另一个维度来执行<strong class="lu io">客户细分</strong>，从而丰富客户数据库。</li><li id="5ecd" class="ne nf in lu b lv nn ly no mb np mf nq mj nr mn nj nk nl nm bi translated">可以进一步准确预测客户何时会再次光顾。</li><li id="0dbc" class="ne nf in lu b lv nn ly no mb np mf nq mj nr mn nj nk nl nm bi translated">了解您的入境和出境客户，有助于了解客户保留率以及客户群的整体健康状况。</li></ul><p id="3841" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">在本教程中，使用在此处找到的<a class="ae ks" href="https://www.kaggle.com/datasets/marian447/retail-store-sales-transactions" rel="noopener ugc nofollow" target="_blank">ka ggle 数据集，</a>我们将采取以下步骤:</p><ul class=""><li id="3c8b" class="ne nf in lu b lv mo ly mp mb ng mf nh mj ni mn nj nk nl nm bi translated">收集并整合我们的数据。</li><li id="8025" class="ne nf in lu b lv nn ly no mb np mf nq mj nr mn nj nk nl nm bi translated">使用递归 RFM(近期-频率-货币值)技术将数据集转换为丰富的要素和标注。</li><li id="f07e" class="ne nf in lu b lv nn ly no mb np mf nq mj nr mn nj nk nl nm bi translated">拟合一个可以根据这些数据进行预测的模型。</li></ul><p id="5b58" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">在许多方面，这种方法与我们用于<a class="ae ks" rel="noopener ugc nofollow" target="_blank" href="/how-to-predict-customer-lifetime-value-using-machine-learning-in-python-4066344d0ab0">客户终身价值</a>的方法相似，只是我们生成标签的方式不同。我用于本教程的笔记本可以在<a class="ae ks" href="https://colab.research.google.com/drive/1eX2t5oKvtkc54OUI7nblmpJ1jQumcg4Q?usp=sharing" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p></div><div class="ab cl kt ku hr kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ig ih ii ij ik"><h1 id="4e05" class="la lb in bd lc ld le lf lg lh li lj lk jt ll ju lm jw ln jx lo jz lp ka lq lr bi translated">步骤 1:收集数据</h1><p id="f6e3" class="pw-post-body-paragraph ls lt in lu b lv lw jo lx ly lz jr ma mb mc md me mf mg mh mi mj mk ml mm mn ig bi translated">对于我们的客户数据，我们基本上只需要 3 列:客户标识符、交易日期/时间和交易值，我们也可以引入其他功能，但您应该确保在功能工程步骤中按客户聚集它们。我们可以使用日期来提取星期几、月份、小时和所有与每笔交易相关的基于时间的特征。如果有不同类别的交易，也可以引入这些列。</p><pre class="kd ke kf kg gt mu mv ns bn nt nu bi"><span id="7cba" class="nv lb in mv b be nw nx l ny nd">import pandas as pd<br/><br/># Load transaction data from CSV<br/>df = pd.read_csv(data_path) # path to your data<br/><br/># Convert Date column to date-time object<br/>df.Date = pd.to_datetime(df.Date)<br/>df.head(10)</span></pre><p id="b0ea" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated"><strong class="lu io">输出:</strong></p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/fc76a702cfcd25a74384dc5bb7d21387.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/format:webp/1*ebI7ZfZ2r6lTLoiZARllQQ.png"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">输出</figcaption></figure></div><div class="ab cl kt ku hr kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ig ih ii ij ik"><h1 id="5e0c" class="la lb in bd lc ld le lf lg lh li lj lk jt ll ju lm jw ln jx lo jz lp ka lq lr bi translated">步骤 2:特征工程</h1><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi oa"><img src="../Images/9f912f75867fe59d6db1614f1f95af80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3IhZsM4IRrY_6XIq.png"/></div></div></figure><h2 id="506e" class="mz lb in bd lc ob oc dn lg od oe dp lk mb of og lm mf oh oi lo mj oj ok lq ol bi translated">新近性、频率和货币价值(RFM)</h2><p id="d893" class="pw-post-body-paragraph ls lt in lu b lv lw jo lx ly lz jr ma mb mc md me mf mg mh mi mj mk ml mm mn ig bi translated"><a class="ae ks" href="https://farapaper.com/wp-content/uploads/2018/08/Fardapaper-Discovering-recency-frequency-and-monetary-RFM.pdf" rel="noopener ugc nofollow" target="_blank"> RFM </a>是一种以有意义的方式量化客户的方法，在对客户特定的交易数据进行任何分析时，可以作为一个很好的基准。</p><p id="1254" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated"><em class="mt">最近度</em>、<em class="mt">频率</em>和<em class="mt">货币价值</em>捕捉客户最近一次交易的时间、他们返回业务的频率以及每位客户的平均销售额。我们可以通过使用任何其他可用特征(如毛利润、年龄、成本保持)或其他预测特征(终身价值)或情感分析来增加这一点。</p><p id="7551" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">其工作方式是，我们可以将训练数据拆分成一个<strong class="lu io"><em class="mt"/></strong>观测期和一个<strong class="lu io"><em class="mt"/></strong>未来期。如果我们想预测一个客户在一年中会花多少钱，我们会将<strong class="lu io"><em class="mt"/></strong>未来期间的长度设置为一年，其余的将归入<strong class="lu io"><em class="mt"/></strong><em class="mt">(如下所示)。</em></p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi om"><img src="../Images/f111d109fad452276d4a8b96f1616d5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AWpxEnyXpTZ6SwEdcRDccA.jpeg"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">观察到的/未来的分裂</figcaption></figure><p id="9ddf" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">这允许我们使用在<strong class="lu io"> <em class="mt">观察到的</em> </strong>期间计算的特征来拟合模型，以对在<strong class="lu io"> <em class="mt">未来</em> </strong>期间从事业务的客户进行分类。</p><pre class="kd ke kf kg gt mu mv ns bn nt nu bi"><span id="c2be" class="nv lb in mv b be nw nx l ny nd"># Data before cut off<br/>observed = df[df[date_col] &lt; cut_off<br/><br/># Data after cut off<br/>future = df[(df[date_col] &gt; cut_off) &amp; (df[date_col] &lt; cut_off + pd.Timedelta(label_period_days, unit='D'))]</span></pre><p id="2fe6" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">这里我们引入截止值的概念。这就是<strong class="lu io"> <em class="mt">观察到的</em> </strong>周期结束的地方，并且定义了我们应该在什么日期之前计算我们的特征。</p><ul class=""><li id="14ea" class="ne nf in lu b lv mo ly mp mb ng mf nh mj ni mn nj nk nl nm bi translated"><strong class="lu io">最近:</strong>距离最近一次交易的时间(小时/天/周)。我们需要设定一个截止值来计算最近的时间。比如:<em class="mt">截止日期后多少天他们做了一笔交易？</em></li></ul><pre class="kd ke kf kg gt mu mv ns bn nt nu bi"><span id="c420" class="nv lb in mv b be nw nx l ny nd"># Copy transactions<br/>cut_off = df.Date.max()<br/>recency = df[df.Date &lt; cut_off].copy()<br/><br/># Group customers by latest transaction<br/>recency = recency.groupby(customer_id_column)[date_column].max()<br/>recency = (max_date - recency).dt.days).reset_index().rename(<br/>columns={date_column:'recency'})</span></pre><ul class=""><li id="83e0" class="ne nf in lu b lv mo ly mp mb ng mf nh mj ni mn nj nk nl nm bi translated"><strong class="lu io">频率:</strong>客户进行交易的不同时间段的数量。这将使我们能够跟踪客户进行了多少交易，以及交易发生的时间。我们还可以保留从截止日期开始计算这些指标的做法，因为这在以后会很方便。</li></ul><pre class="kd ke kf kg gt mu mv ns bn nt nu bi"><span id="bb77" class="nv lb in mv b be nw nx l ny nd"># Copy transactions<br/>cut_off = df.Date.max()<br/>frequency = df[df.Date &lt; cut_off].copy()<br/><br/># Set date column as index<br/>frequency.set_index(date_column, inplace=True)<br/>frequency.index = pd.DatetimeIndex(frequency.index)<br/><br/># Group transactions by customer key and by distinct period<br/># and count transactions in each period<br/>frequency = frequency.groupby([customer_id_column, pd.Grouper(freq="M", level=date_column)]).count()<br/># (Optional) Only count the number of distinct periods a transaction # occurred. Else, we will be calculating total transactions in each # period instead.<br/><br/>frequency[value_column] = 1 # Store all distinct transactions<br/><br/># Sum transactions<br/>frequency = frequency.groupby(customer_id_column).sum().reset_index().rename(<br/>columns={value_column : 'frequency'})</span></pre><ul class=""><li id="ee1a" class="ne nf in lu b lv mo ly mp mb ng mf nh mj ni mn nj nk nl nm bi translated"><strong class="lu io">货币价值</strong>:平均销售额。这里我们简单地计算每个客户所有交易的平均销售额。在最后一步中，我们可以通过取<strong class="lu io"> <em class="mt"> sum </em> </strong>而不是<strong class="lu io"> <em class="mt"> mean </em> </strong>来额外添加“TotalAmountSpent”特征。</li></ul><pre class="kd ke kf kg gt mu mv ns bn nt nu bi"><span id="d139" class="nv lb in mv b be nw nx l ny nd"># Copy transactions<br/>cut_off = df.Date.max()<br/>value = df[df.Date &lt; cut_off].copy()<br/><br/># Set date column as index<br/>value.set_index(date_column, inplace=True)<br/>value.index = pd.DatetimeIndex(value.index)<br/><br/># Get mean or total sales amount for each customer<br/>value = value.groupby(customer_id_column[value_column].mean().reset_index().rename(columns={value_column : 'value'})</span></pre><ul class=""><li id="69f5" class="ne nf in lu b lv mo ly mp mb ng mf nh mj ni mn nj nk nl nm bi translated"><strong class="lu io">年龄:</strong>首次交易后的时间。对于此功能，我们只需找到每个客户第一次交易后的天数。同样，我们需要一个截止日期来计算截止日期和第一笔交易之间的时间。</li></ul><pre class="kd ke kf kg gt mu mv ns bn nt nu bi"><span id="9500" class="nv lb in mv b be nw nx l ny nd"># Copy transactions<br/>cut_off = df.Date.max()<br/>age = df[df.Date &lt; cut_off].copy()<br/><br/># Get date of first transaction<br/>first_purchase = age.groupby(customer_id_column)[date_column].min().reset_index()<br/><br/># Get number of days between cut off and first transaction<br/>first_purchase['age'] = (cut_off - first_purchase[date_column]).dt.days</span></pre><p id="ddc0" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">我们可以用下面的函数将所有这些函数包装在一起:</p><pre class="kd ke kf kg gt mu mv ns bn nt nu bi"><span id="ddb2" class="nv lb in mv b be nw nx l ny nd">def customer_rfm(data, cut_off, date_column, customer_id_column, value_column, freq='M'):<br/>  cut_off = pd.to_datetime(cut_off)<br/>  <br/>   # Compute Recency<br/>  recency = customer_recency(data, cut_off, date_column, customer_id_column)<br/>  <br/>  # Compute Frequency<br/>  frequency = customer_frequency(data, cut_off, date_column, customer_id_column, value_column, freq=freq)<br/>  <br/>  # Compute average value<br/>  monetary_value = customer_value(data, cut_off, date_column, customer_id_column, value_column)<br/>  <br/>  # Compute age<br/>  age = customer_age(data, cut_off, date_column, customer_id_column)<br/>  <br/>  # Merge all columns<br/>  return recency.merge(frequency, on=customer_id_column).merge(on=customer_id_column).merge(age, on=customer_id_column).merge(monetary_value, on=customer_id_column)</span></pre><p id="884d" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">理想情况下，这可以在某个时间段内获取有关客户保持率的信息<em class="mt">。这可能看起来像这样:</em></p><pre class="kd ke kf kg gt mu mv mw mx aw my bi"><span id="87f7" class="mz lb in mv b gy na nb l nc nd"><strong class="mv io">Customer_ID   recency    frequency            value       age</strong>                                     1                 131            1         8.145000       131                      2                  69            1         7.770000        69                       3                 121            1         3.640000       121                      5                   4            4        14.672500       100</span></pre><p id="0448" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">对于这些标签，我们将为那些在<strong class="lu io"> <em class="mt">未来</em> </strong>期间购买了东西的人设置 1，为所有没有购买的人设置 0。</p><pre class="kd ke kf kg gt mu mv ns bn nt nu bi"><span id="f0f7" class="nv lb in mv b be nw nx l ny nd">def generate_churn_labels(future):<br/>   future['DidBuy'] = 1<br/>   return future[['Customer_ID', 'DidBuy']]</span></pre><p id="1b97" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">在某些情况下，对整个数据集执行一次这种操作并拟合一个模型来预测标签可以产生可容忍的准确性。但是，如果你仔细观察，你可能会问:<em class="mt">如果在观察期间发生了有趣的事情呢？问哪个问题是正确的？简单地对数据集进行一次这样的操作会忽略数据中的所有季节性，并且只查看一个特定的标签时段。这里我们介绍一下我称之为<strong class="lu io">的递归 RFM </strong>。</em></p><p id="c30a" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated"><strong class="lu io">递归 RFM </strong></p><p id="51dd" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">让我们应用到目前为止我们所知道的 RFM，并通过数据集进行循环。</p><p id="9147" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">假设数据在年初从左边开始。我们将选择一个频率(例如，一个月)并遍历数据集，根据<strong class="lu io"><em class="mt">(o)</em></strong>计算我们的特征，并根据<strong class="lu io"> <em class="mt">未来(f)生成我们的标签。这个想法是递归地计算这些特征，以便模型了解客户的行为如何随时间变化。</em></strong></p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi on"><img src="../Images/1d56e2045cc854cef1d98ba1dadb4581.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*QjVIhBsvs-GzYkioXywbLw.gif"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">观察的(o)，未来的(f)</figcaption></figure><p id="cb38" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">对于算法的这一部分，我们将首先获取数据集跨度中每个间隔的日期，并使用这些日期中的每个日期作为计算 RFM 要素和标注的截止日期。再次重申，在我们的示例中，我们选择了 1 个月的频率。</p><p id="6362" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">对于每个截止(<strong class="lu io"> co </strong>)日期:</p><ul class=""><li id="64ca" class="ne nf in lu b lv mo ly mp mb ng mf nh mj ni mn nj nk nl nm bi translated">计算截止前所有行(<strong class="lu io"> i </strong>)的 RFM 特征(<strong class="lu io"> i </strong> → <strong class="lu io"> co </strong>)</li><li id="ebe8" class="ne nf in lu b lv nn ly no mb np mf nq mj nr mn nj nk nl nm bi translated">计算截止日期和截止日期后一个月之间(<strong class="lu io"> i </strong>)行的标签(<strong class="lu io">co</strong>→<strong class="lu io">I</strong>→<strong class="lu io">co</strong>+<strong class="lu io">频率</strong>)</li><li id="2c01" class="ne nf in lu b lv nn ly no mb np mf nq mj nr mn nj nk nl nm bi translated"><strong class="lu io">外部连接</strong>基于客户 ID 创建数据集的功能和标签，以填充未进行任何交易的客户。</li></ul><p id="9c79" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">连接循环中的所有数据集。</p><p id="14ff" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">这在下面的代码中实现:</p><pre class="kd ke kf kg gt mu mv ns bn nt nu bi"><span id="3624" class="nv lb in mv b be nw nx l ny nd">def recursive_rfm(data, date_col, id_col, value_col, freq='M', start_length=30, label_period_days=30):<br/>  # Resultant list of datasets<br/>  dset_list = []<br/>  # Get start and end dates of dataset<br/>  start_date = data[date_col].min() + pd.Timedelta(start_length, unit="D")<br/>  end_date = data[date_col].max() - pd.Timedelta(label_period_days, unit="D")<br/>  # Get dates at desired interval<br/>  dates = pd.date_range(<br/>  start=start_date, end=end_date, freq=freq<br/>  data[date_col] = pd.to_datetime(data[date_col]<br/>  )<br/>  for cut_off in dates:<br/>     # split by observed / future<br/>     observed = data[data[date_col] &lt; cut_off<br/>     future = data[<br/>                    (data[date_col] &gt; cut_off) &amp;<br/>                    (data[date_col] &lt; cut_off + pd.Timedelta(<br/>                     label_period_days,  unit='D'))<br/>                  ]<br/>     # Get relevant columns<br/>     rfm_columns = [date_col, id_col, value_col]<br/>     _observed = observed[rfm_columns]<br/>     # Compute features from observed<br/>     rfm_features = customer_rfm(<br/>          _observed, cut_off, date_col, id_col, value_col<br/>     )<br/>     # Set label for everyone who bought in 'future' as 1'<br/>     labels = generate_churn_labels(future)<br/>     # Outer join features with labels to ensure customers <br/>     # not in observed are still recorded with a label of 0<br/>     dset = rfm_features.merge(<br/>          labels, on=id_col, how='outer'<br/>     ).fillna(0)<br/>     dset_list.append(dset)<br/>  # Concatenate all datasets<br/>  full_dataset = pd.concat(dset_list, axis=0)<br/>  res = full_dataset[full_dataset.recency != 0].dropna(axis=1, how='any')<br/>  return res<br/><br/>rec_df = recursive_rfm(data_for_rfm, 'Date', 'Customer_ID', 'Sales_Amount')</span></pre><p id="95fa" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">既然我们已经生成了数据集，现在我们需要做的就是对数据进行洗牌和执行训练/测试分割。我们将 80%用于培训，20%用于测试。</p><pre class="kd ke kf kg gt mu mv ns bn nt nu bi"><span id="bb49" class="nv lb in mv b be nw nx l ny nd">from sklearn.model_selection import train_test_split<br/><br/>rec_df = rec_df.sample(frac=1) # Shuffle<br/><br/># Set X and y<br/>X = rec_df[['recency', 'frequency', 'value', 'age']]<br/>y = rec_df[['Sales_Amount']].values.reshape(-1)<br/><br/># Set test ratio and perform train / test split<br/>test_size = 0.2<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, shuffle=True)</span></pre><p id="0cf4" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated"><strong class="lu io">注:班级失衡</strong></p><p id="dbcd" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">在分类任务中，有时我们想要预测的类别在数据集中是不平衡的。例如，如果有 10 个观察值和两个类；其中 2 个可能在<strong class="lu io"> Class_0 </strong>中，另外 8 个在<strong class="lu io"> Class_1 </strong>中。这可能会在模型中引入偏见，因为它认为一个类别明显多于另一个类别。我们将<strong class="lu io">少数</strong>类定义为观测值较少的一类，将<strong class="lu io">多数</strong>类定义为观测值较多的一类。在我们的教程中，类似于这样:</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/a61f08bc83a8f696cbfa88824e221f3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:618/format:webp/1*7EVg6m6ep-AGYaXdsI2leg.png"/></div></figure><p id="ecd6" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">补救这种情况的一种技术是在下<strong class="lu io">-采样<strong class="lu io">多数</strong>类，或者在</strong>上<strong class="lu io">-采样<strong class="lu io">少数</strong>类。采样是获取数据子集以执行某种操作的实践。此外，欠采样/过采样是指我们复制(过采样)或删除(欠采样)与相关类相关的观测值。对于手头的任务和您正在处理的数据，哪个选项最适合，这绝对值得实验。</strong></p><p id="8db4" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">SMOTE ( <strong class="lu io">合成少数过采样技术)</strong>是我们可以使用的工具。</p><pre class="kd ke kf kg gt mu mv ns bn nt nu bi"><span id="a2b5" class="nv lb in mv b be nw nx l ny nd">from imblearn.over_sampling import SMOTE<br/><br/>oversample = SMOTE()<br/>X_train_over, y_train_over = oversample.fit_resample(X_train, y_train)<br/><br/>pd.Series(y_train_over).value_counts()</span></pre><p id="a0db" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated"><strong class="lu io">输出:</strong></p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div class="gh gi op"><img src="../Images/0efb2f56cfcaf65928369872dc52d37b.png" data-original-src="https://miro.medium.com/v2/resize:fit:344/format:webp/1*1io25FH7PqLKUHX-cYU7hA.png"/></div></figure></div><div class="ab cl kt ku hr kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ig ih ii ij ik"><h1 id="22f2" class="la lb in bd lc ld le lf lg lh li lj lk jt ll ju lm jw ln jx lo jz lp ka lq lr bi translated">第三步:模型</h1><p id="83af" class="pw-post-body-paragraph ls lt in lu b lv lw jo lx ly lz jr ma mb mc md me mf mg mh mi mj mk ml mm mn ig bi translated">当谈到数据科学时，机器学习(及其包含的所有内容)只是一种用于估计变量之间关系的技术。为您的数据找到合适的模型是为您的用例获得最佳结果的另一个旅程。数据科学的真正价值在于使用这些技术在现实世界中做出明智的决策。</p><p id="d469" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">对于这个例子，我们将尝试一个随机森林分类器，因为它们在实现中是即插即用的，所以它们很容易直接尝试。此外，我们将会看到过采样数据的预测是如何比较的。</p><pre class="kd ke kf kg gt mu mv ns bn nt nu bi"><span id="2806" class="nv lb in mv b be nw nx l ny nd">from sklearn.ensemble import RandomForestRegressor<br/><br/># Initialize and fit model on train dataset<br/>rf = RandomForestClassifier().fit(X_train, y_train)<br/><br/># Fit on over-sampled data as well<br/>rf_over = RandomForestClassifier().fit(X_train_over, y_train_over)</span></pre><p id="5795" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">一旦拟合，我们可以在数据框架中查看我们对测试集的预测。</p><pre class="kd ke kf kg gt mu mv ns bn nt nu bi"><span id="f2ee" class="nv lb in mv b be nw nx l ny nd">from sklearn.metrics import accuracy_score<br/><br/># Create Dataframe and populate with predictions and actuals<br/># Train set<br/>predictions = pd.DataFrame()<br/>predictions['true'] = y_train<br/>predictions['preds'] = rf.predict(X_train)<br/><br/># Test set<br/>predictions_test = pd.DataFrame()<br/>predictions_test['true'] = y_test<br/>predictions_test['preds'] = rf.predict(X_test)<br/>predictions_test['preds_over'] = rf_over.predict(X_test)<br/><br/># Compute error<br/>train_acc = accuracy_score(predictions.true, predictions.preds)<br/>test_acc = accuracy_score(<br/>predictions_test.true, predictions_test.preds)<br/>test_acc_over = accuracy_score(<br/>predictions_test.true, predictions_test.preds_over)<br/>print(f"Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}, Test Acc Oversampled: {test_acc_over:.4f}")</span></pre><p id="cc10" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">输出:</p><pre class="kd ke kf kg gt mu mv mw mx aw my bi"><span id="a1b7" class="mz lb in mv b gy na nb l nc nd"><strong class="mv io">Train Acc</strong>: 0.9863, <strong class="mv io">Test Acc</strong>: 0.8772, <strong class="mv io">Test Acc Oversampled</strong>: 0.8671</span></pre></div><div class="ab cl kt ku hr kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ig ih ii ij ik"><h1 id="673f" class="la lb in bd lc ld le lf lg lh li lj lk jt ll ju lm jw ln jx lo jz lp ka lq lr bi translated">结果</h1><p id="5a54" class="pw-post-body-paragraph ls lt in lu b lv lw jo lx ly lz jr ma mb mc md me mf mg mh mi mj mk ml mm mn ig bi translated">有趣的是，两个数据集产生了非常相似的结果，事实上，过采样数据比不平衡数据表现更差。在这里，我们可以查看分类报告，看看预测实际上有多精确。</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/de1d396ebcd65ba345a7db235fa2394e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*0G9NDgh-81EtfHTfoLuy1w.png"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">不平衡数据预测的分类报告</figcaption></figure><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi or"><img src="../Images/a5c8298742f6b52d4f3e8b1b585edfc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6ZMFueHqPAJD21z3rXoMrw.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">过采样数据预测的分类报告</figcaption></figure><p id="c4e1" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">我们可以看到，在这种情况下，使用 SMOTE 没有任何好处，但是，根据您的数据，您的情况可能并非如此。</p><p id="326a" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">现在我们的模型已经被训练好了，我们可以使用<code class="fe os ot ou mv b">predict_proba()</code>函数来获得与每个预测相关的概率。这是预测概率分布图。请记住，模型预测的概率是客户参与业务的可能性，我们寻找的是他们不参与的概率，因此我们可以简单地从 1 中减去每个概率。</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi ov"><img src="../Images/1e64e99cdecb4ac31d841762a46e6a67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zl3WrSww56L_XNaJkmgEDg.png"/></div></div></figure><p id="5c76" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">正如预期的那样，大多数客户都在这个范围的两端。然而，最有意义和可操作的见解是在他们之间找到的。在 0.5 之前说谎的客户脱离的风险较低，因此该图表明大多数客户是健康的。另一方面，那些流失率超过 0.5 的人更有可能离职，因此关注他们的偏好是留住他们的必要条件。</p><h1 id="8e74" class="la lb in bd lc ld ow lf lg lh ox lj lk jt oy ju lm jw oz jx lo jz pa ka lq lr bi translated">结论</h1><p id="6a1f" class="pw-post-body-paragraph ls lt in lu b lv lw jo lx ly lz jr ma mb mc md me mf mg mh mi mj mk ml mm mn ig bi translated">递归 RFM 等特征工程技术允许使用丰富的特征来描述客户。正如这里所看到的，这些特征对于分析他们的行为和预测他们将来可能会做什么很有用。我们还讨论了如何在必要时使用 SMOTE 处理类不平衡。流失风险只是这些可预测指标之一。其他包括客户终身价值和客户细分。流失风险的特殊之处在于，它需要进一步确定客户做更具体的事情的可能性，如购买特定类别的产品，或一周中每一天参与的可能性。客户分析的潜力是深远而有洞察力的，尤其是对企业而言。</p><p id="388c" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">请务必查看我的其他文章，了解更多数据科学和商业机器学习的信息。</p><p id="76ff" class="pw-post-body-paragraph ls lt in lu b lv mo jo lx ly mp jr ma mb mq md me mf mr mh mi mj ms ml mm mn ig bi translated">如果你喜欢这篇文章，给我更多的客户分析内容关注！</p></div></div>    
</body>
</html>