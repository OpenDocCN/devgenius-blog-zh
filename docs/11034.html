<html>
<head>
<title>Understanding Mean Shift Clustering: Hands-On with SciKit-Learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解均值漂移聚类:使用 SciKit-Learn 进行实践</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/understanding-mean-shift-clustering-hands-on-with-scikit-learn-a98e79d6dd9f?source=collection_archive---------9-----------------------#2022-12-14">https://blog.devgenius.io/understanding-mean-shift-clustering-hands-on-with-scikit-learn-a98e79d6dd9f?source=collection_archive---------9-----------------------#2022-12-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="feb2" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">无监督学习—聚类</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/801ba05856705c5816e13511c57f80bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9QXNaa2BraXyxONNxP2Hxw.png"/></div></div></figure><p id="5e50" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">均值漂移聚类是一种无监督的对相似数据点进行分组的机器学习方法。均值漂移算法的工作原理是，根据数据点周围的点密度，将每个数据点分配给一个聚类，然后将每个数据点漂移到其分配聚类的均值。这种聚类方法对于识别使用其他方法可能不容易分离的数据聚类非常有用。</p><h2 id="73e8" class="ln lo iq bd lp lq lr dn ls lt lu dp lv la lw lx ly le lz ma mb li mc md me mf bi translated">它是如何工作的？</h2><p id="834c" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">均值漂移算法是这样工作的:将每个数据点分配给一个聚类，然后迭代地将聚类质心(聚类的“平均值”)移动到分配给该聚类的所有数据点的平均值，直到聚类质心不再移动。这将产生所有数据点或多或少都“偏移”到聚类质心的聚类。</p><h2 id="f63d" class="ln lo iq bd lp lq lr dn ls lt lu dp lv la lw lx ly le lz ma mb li mc md me mf bi translated">我们什么时候应该使用均值漂移？</h2><p id="6924" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">均值漂移聚类不会对数据分布的形状做出任何假设。这使得它成为一种高度灵活的方法，能够适应复杂的非线性数据分布。此外，均值漂移聚类不需要用户指定要找到的聚类数，这在聚类数事先未知的情况下是有益的。</p><p id="f8ba" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">但是，需要注意的是，均值漂移聚类不能保证为给定数据集找到全局最优解。换句话说，可能还有比均值漂移更好的数据聚类。然而，在许多情况下，均值漂移聚类能够找到良好的数据聚类，因此在实践中经常使用。</p><blockquote class="ml"><p id="9e33" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">让我们举个例子试试！</p></blockquote><p id="99a2" class="pw-post-body-paragraph kr ks iq kt b ku mv jr kw kx mw ju kz la mx lc ld le my lg lh li mz lk ll lm ij bi translated">我们将使用在<a class="ae na" href="http://www3.dsi.uminho.pt/pcortez/wine/" rel="noopener ugc nofollow" target="_blank">这里</a>可以找到的白酒质量数据集。您可以将其上传到您的谷歌可乐笔记本上，并从代码开始:</p><pre class="kg kh ki kj gt nb nc nd bn ne nf bi"><span id="ebe8" class="ng lo iq nc b be nh ni l nj nk">#Import libraries:<br/>import pandas as pd<br/>import numpy as np<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt<br/><br/>#Load and read data frame:<br/>df = pd.read_csv('/content/winequality-white.csv', delimiter=';')<br/>df</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nl"><img src="../Images/311445044b388908583eaf0476c8d1a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I_nYAQeX4OgTYA4n82ze5A.png"/></div></div></figure><p id="b7fd" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们有 4898 个数据点和 12 个特征。下一步是检查 NAN 值和数据类型，必要时进行更正:</p><pre class="kg kh ki kj gt nb nc nd bn ne nf bi"><span id="fe22" class="ng lo iq nc b be nh ni l nj nk">#Check NAN values in df:<br/>count_nan = df.isnull().sum()<br/>print('Number of NaN values present: \n' + str(count_nan))<br/><br/>#Check data types:<br/>print(df.dtypes)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nm"><img src="../Images/f08ac4b274ce715204ee095259b42997.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HHX0RagH2IGv7Ri3h2jmGw.png"/></div></div></figure><p id="f353" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，我们将转变和扩展我们的数据:</p><pre class="kg kh ki kj gt nb nc nd bn ne nf bi"><span id="0809" class="ng lo iq nc b be nh ni l nj nk">from sklearn.preprocessing import StandardScaler<br/><br/>#Define X as numpy array:<br/>X = np.array(df)<br/><br/>scaler = StandardScaler()<br/>X = scaler.fit_transform(X)</span></pre><p id="5269" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">是时候建立我们的模型了:</p><pre class="kg kh ki kj gt nb nc nd bn ne nf bi"><span id="852a" class="ng lo iq nc b be nh ni l nj nk">from sklearn.cluster import MeanShift, estimate_bandwidth<br/>from sklearn import metrics<br/><br/># The following bandwidth can be automatically detected using<br/>bandwidth = estimate_bandwidth(X, quantile=0.6, n_samples=100)<br/><br/>#Fit the model:<br/>ms = MeanShift(bandwidth=bandwidth, cluster_all=True, max_iter=10000)<br/>ms.fit(X)<br/>labels = ms.labels_<br/>cluster_centers = ms.cluster_centers_<br/><br/>labels_unique = np.unique(labels)<br/>n_clusters_ = len(labels_unique)<br/><br/>print("number of estimated clusters : %d" % n_clusters_)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/a807cb21fd7d015d25080844a49d4ea1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*ZrmRK4VgjHe0vZh7WKJYnQ.png"/></div></figure><p id="b52d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">您可以使用<strong class="kt ir"> <em class="no">带宽</em> </strong>和<strong class="kt ir"> <em class="no">分位数</em> </strong>参数来控制簇的 de 数。分位数参数越低，聚类数就越高。现在我们有了模型，可以将结果保存到一个新变量中:</p><pre class="kg kh ki kj gt nb nc nd bn ne nf bi"><span id="633f" class="ng lo iq nc b be nh ni l nj nk">#Create new variable and new data-frame:<br/>df_ms = np.array(ms.labels_)<br/>df_ms = pd.DataFrame(df_ms, columns = ['ms'])<br/><br/>#Merge dataframes:<br/>df = pd.concat([df, df_ms], axis=1, join='inner')</span></pre><p id="0001" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最后一步是为我们的模型构建一个图形可视化。我们将尝试 2D 和三维可视化，但我们有一个比其他集群大得多的集群，所以它可能会导致一点混乱:</p><pre class="kg kh ki kj gt nb nc nd bn ne nf bi"><span id="5509" class="ng lo iq nc b be nh ni l nj nk">import matplotlib.pyplot as plt<br/>from itertools import cycle<br/><br/>plt.figure(1)<br/>plt.clf()<br/><br/>colors = cycle("bgrcmykbgrcmykbgrcmykbgrcmyk")<br/>for k, col in zip(range(n_clusters_), colors):<br/>    my_members = labels == k<br/>    cluster_center = cluster_centers[k]<br/>    plt.plot(X[my_members, 0], X[my_members, 1], col + ".")<br/>    plt.plot(<br/>        cluster_center[0],<br/>        cluster_center[1],<br/>        "o",<br/>        markerfacecolor=col,<br/>        markeredgecolor="k",<br/>        markersize=14,<br/>    )<br/>plt.title("Estimated number of clusters: %d" % n_clusters_)<br/>plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi np"><img src="../Images/ce8452697a8850b8695ee8b93bb9b8bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*y8zp5AU4VSDoONpwYgY55g.png"/></div></figure><p id="5680" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">2D 可视化的另一个选择是:</p><pre class="kg kh ki kj gt nb nc nd bn ne nf bi"><span id="c71d" class="ng lo iq nc b be nh ni l nj nk">plt.scatter(X[labels==0, 0], X[labels==0, 1], s=50, marker='o', color='purple', label = 'Cluster 1')<br/>plt.scatter(X[labels==1, 0], X[labels==1, 1], s=50, marker='o', color='orange', label = 'Cluster 2')<br/>plt.scatter(X[labels==2, 0], X[labels==2, 1], s=50, marker='o', color='lightblue', label = 'Cluster 3')<br/>plt.scatter(X[labels==3, 0], X[labels==3, 1], s=50, marker='o', color='red', label = 'Cluster 4')<br/>plt.scatter(X[labels==4, 0], X[labels==4, 1], s=50, marker='o', color='lightgreen', label = 'Cluster 5')<br/>plt.scatter(X[labels==5, 0], X[labels==5, 1], s=50, marker='o', color='lightcoral', label = 'Cluster 6')<br/>plt.scatter(X[labels==6, 0], X[labels==6, 1], s=50, marker='o', color='grey', label = 'Cluster 7')<br/><br/>plt.legend()  <br/>plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi np"><img src="../Images/c4fb025f2dfe19d1bdf8490711fb550d.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*tsCUKZMXUzrpoLAbU70lTQ.png"/></div></figure><p id="d3fb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最后，我们可以尝试三维可视化:</p><pre class="kg kh ki kj gt nb nc nd bn ne nf bi"><span id="8f58" class="ng lo iq nc b be nh ni l nj nk">fig = plt.figure()<br/>  <br/>ax = fig.add_subplot(111, projection ='3d')<br/><br/>ax.scatter(X[labels==0, 0], X[labels==0, 1], s=50, marker='o', color='purple', label = 'Cluster 1')<br/>ax.scatter(X[labels==1, 0], X[labels==1, 1], s=50, marker='o', color='orange', label = 'Cluster 2')<br/>ax.scatter(X[labels==2, 0], X[labels==2, 1], s=50, marker='o', color='lightblue', label = 'Cluster 3')<br/>ax.scatter(X[labels==3, 0], X[labels==3, 1], s=50, marker='o', color='red', label = 'Cluster 4')<br/>ax.scatter(X[labels==4, 0], X[labels==4, 1], s=50, marker='o', color='lightgreen', label = 'Cluster 5')<br/>ax.scatter(X[labels==5, 0], X[labels==5, 1], s=50, marker='o', color='lightcoral', label = 'Cluster 6')<br/>ax.scatter(X[labels==6, 0], X[labels==6, 1], s=50, marker='o', color='grey', label = 'Cluster 7')<br/><br/>  <br/>plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/96dfb42208245fc459b62519eb5a06c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*w40O1wglDIhF9qXxEMAYbw.png"/></div></figure><p id="6b11" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">谢谢你的阅读！如果您有什么建议要添加到本教程中，请告诉我，并且不要忘记订阅以接收关于我未来出版物的通知。</p><p id="74d2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果:你喜欢这篇文章，别忘了关注我，这样你就能收到关于新出版物的所有更新。</p><p id="6fd1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">其他如果:</strong>你想在 Medium 上阅读更多，可以通过<a class="ae na" href="https://cdanielaam.medium.com/membership" rel="noopener"> <strong class="kt ir">我的推荐链接</strong> </a>订阅 Medium 会员。它不会花你更多的钱，但会支付我一杯咖啡。</p><p id="af77" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">其他:</strong>谢谢！</p></div></div>    
</body>
</html>