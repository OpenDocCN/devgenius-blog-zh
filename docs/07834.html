<html>
<head>
<title>Part 3: Linear Discriminant Analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">第三部分:线性判别分析</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/part-3-linear-discriminant-analysis-b311fbef7369?source=collection_archive---------9-----------------------#2022-04-26">https://blog.devgenius.io/part-3-linear-discriminant-analysis-b311fbef7369?source=collection_archive---------9-----------------------#2022-04-26</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><figure class="gl gn jl jm jn jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi jk"><img src="../Images/c2da15d2907d1ec395239704ffd14415.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uYeeaEwp9HVWENOCmrDyJA.png"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk translated"><a class="ae jz" href="https://towardsdatascience.com/probabilistic-linear-discriminant-analysis-plda-explained-253b5effb96" rel="noopener" target="_blank"> TDS </a>的 LDA 与非 LDA 投影</figcaption></figure><p id="c71a" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">线性判别式分析(LDA)是 Fisher 线性判别式的推广，Fisher 线性判别式是一种用于统计、模式识别和机器学习的技术，用于寻找表征或分离两类或更多类对象或事件的特征的线性组合。线性判别分析(LDA)最常用作模型分类和机器学习应用的预处理降维技术。虽然 PCA 和逻辑回归等其他降维技术也被广泛使用，但在一些特定的用例中，线性判别分析更为合适。在本文之后，我们讨论了一种称为 LDA 的受控降维方法，当逻辑回归失败以及处理两个或更多类时，可以进一步将其用作分类器。</p><p id="e7be" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">LDA 已经成功地用于各种应用中，在某种程度上，问题变成了分类问题，这种方法是可以实现的。得到的组合可以用作线性分类器，或者更常见的是，在进一步分类之前用于降维。例如，可以将类划分为多个部分，并且可以使用标准的 Fisher 判别式或 LDA 来对每个部分进行排序。LDA 和 Fisher 鉴别器可以通过内核技巧扩展用于非线性分类。</p><p id="d956" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">另一方面，LDA 是一种监督算法，它使用输入标签和类别标签来查找线性判别式，从而最大化多个类别之间的分离。LDA 的一般方法非常类似于主成分分析(有关 PCA 的更多信息，请参见上一篇文章 Python 中主成分分析(PCA)的分步实施)，但是除了找到最大化我们的数据方差(PCA)的成分轴之外，我们还对最大化多个类之间的分离(LDA)的轴感兴趣。LDA 还与主成分分析(PCA)和因子分析密切相关，因为两者都寻找最佳解释数据的变量的线性组合。线性判别分析(LDA)和主成分分析(PCA)都是广泛使用的线性变换降维方法(都是数据矩阵分解方法)。</p><p id="a9cc" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">LDA 与方差分析(ANOVA)和回归分析密切相关，后者也试图将因变量表示为其他特征或维度的线性组合。逻辑回归是一种重要的线性分类算法，但它也有一些限制，导致需要使用替代的线性分类算法。另一种替代用途是在使用非线性分类算法之前减小尺寸。即使假设被轻微违反，线性判别分析也能很好地工作，并且当使用二分变量时仍然是可靠的(尽管在这种情况下多变量正态假设往往被违反)。</p><p id="29da" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">1936 年，Ronald A. Fisher 首次提出了线性判别式，并展示了其作为分类器的一些实际应用。它被描述为两类问题，随后由 CRRao 在 1948 年概括为多类线性判别分析或多重判别分析。在 LDA 中，我们基本上试图决定哪一组参数能够最好地描述一个类的组关联，以及哪一个是分离这些组的最佳分类模型。</p></div></div>    
</body>
</html>