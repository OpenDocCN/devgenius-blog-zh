<html>
<head>
<title>Getting started in Natural Language Processing with spaCy: Part 4</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">spaCy 自然语言处理入门:第 4 部分</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/getting-started-in-natural-language-processing-with-spacy-part-4-4ab7f005464?source=collection_archive---------21-----------------------#2020-06-06">https://blog.devgenius.io/getting-started-in-natural-language-processing-with-spacy-part-4-4ab7f005464?source=collection_archive---------21-----------------------#2020-06-06</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><p id="ed3e" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">在这个故事中，我们将着重于词汇化和停用词</p><p id="8eae" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">与词干化相反，词汇化看起来不仅仅是单词缩减，而是考虑一种语言的全部词汇来对单词进行形态分析。“was”的引理是“be”，“mice”的引理是“mouse”。此外,“meeting”的引理可能是“meet”或“meeting ”,这取决于它在句子中的用法。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi kj"><img src="../Images/a3ee50418fc6cd06fea40cfd88b930b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HTtQseukwrBiREJf8MSVcA.jpeg"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">图片来自 Spacy.io</figcaption></figure><pre class="kk kl km kn gt kz la lb lc aw ld bi"><span id="e6ad" class="le lf in la b gy lg lh l li lj"><em class="ki"># Perform standard imports:<br/></em><strong class="la io">import</strong> spacy<br/>nlp <strong class="la io">=</strong> spacy.load('en_core_web_sm')<br/>In [2]:<br/>doc1 <strong class="la io">=</strong> nlp(u"I am a runner running in a race because I love to run since I ran today")<br/><strong class="la io">for</strong> token <strong class="la io">in</strong> doc1:<br/>   print(token.text, '\t', token.pos_, '\t', token.lemma, '\t', token.lemma_)<br/>I 	 PRON 	 561228191312463089 	 -PRON-<br/>am 	 VERB 	 10382539506755952630 	 be<br/>a 	 DET 	 11901859001352538922 	 a<br/>runner 	 NOUN 	 12640964157389618806 	 runner<br/>running 	 VERB 	 12767647472892411841 	 run<br/>in 	 ADP 	 3002984154512732771 	 in<br/>a 	 DET 	 11901859001352538922 	 a<br/>race 	 NOUN 	 8048469955494714898 	 race<br/>because 	 ADP 	 16950148841647037698 	 because<br/>I 	 PRON 	 561228191312463089 	 -PRON-<br/>love 	 VERB 	 3702023516439754181 	 love<br/>to 	 PART 	 3791531372978436496 	 to<br/>run 	 VERB 	 12767647472892411841 	 run<br/>since 	 ADP 	 10066841407251338481 	 since<br/>I 	 PRON 	 561228191312463089 	 -PRON-<br/>ran 	 VERB 	 12767647472892411841 	 run<br/>today 	 NOUN 	 11042482332948150395 	 today</span></pre><p id="c935" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">在上面的句子中，<code class="fe lk ll lm la b">running</code>、<code class="fe lk ll lm la b">run</code>和<code class="fe lk ll lm la b">ran</code>都指向同一个引理<code class="fe lk ll lm la b">run</code>(...11841)以免重复。</p><h2 id="ec64" class="le lf in bd ln lo lp dn lq lr ls dp lt jv lu lv lw jz lx ly lz kd ma mb mc md bi translated">显示词条的函数</h2><p id="c47c" class="pw-post-body-paragraph jk jl in jm b jn me jp jq jr mf jt ju jv mg jx jy jz mh kb kc kd mi kf kg kh ig bi translated">既然上面的显示是交错的，难以阅读，那我们就写一个函数，把我们想要的信息更整齐的显示出来。</p><pre class="kk kl km kn gt kz la lb lc aw ld bi"><span id="92fb" class="le lf in la b gy lg lh l li lj">In [3]:<br/><strong class="la io">def</strong> show_lemmas(text):<br/><strong class="la io">for</strong> token <strong class="la io">in</strong> text:<br/>   print(f'{token.text:{12}} {token.pos_:{6}} {token.lemma:<strong class="la io">&lt;</strong>{22}} {token.lemma_}')</span></pre><p id="713c" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">这里我们使用一个<strong class="jm io"> f 字符串</strong>通过设置最小字段宽度和添加 lemma 哈希值左对齐来格式化打印文本。</p><pre class="kk kl km kn gt kz la lb lc aw ld bi"><span id="7e39" class="le lf in la b gy lg lh l li lj">In [4]:doc2 <strong class="la io">=</strong> nlp(u"I saw eighteen mice today!")<br/>show_lemmas(doc2)</span><span id="aece" class="le lf in la b gy mj lh l li lj">I            PRON   561228191312463089     -PRON-<br/>saw          VERB   11925638236994514241   see<br/>eighteen     NUM    9609336664675087640    eighteen<br/>mice         NOUN   1384165645700560590    mouse<br/>today        NOUN   11042482332948150395   today<br/>!            PUNCT  17494803046312582752   !</span></pre><p id="3919" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">注意，<code class="fe lk ll lm la b">saw</code>的引理是<code class="fe lk ll lm la b">see</code>，<code class="fe lk ll lm la b">mice</code>是<code class="fe lk ll lm la b">mouse</code>的复数形式，然而<code class="fe lk ll lm la b">eighteen</code>是它自己的数字，<em class="ki">不是</em>是<code class="fe lk ll lm la b">eight</code>的扩展形式。</p><pre class="kk kl km kn gt kz la lb lc aw ld bi"><span id="79ba" class="le lf in la b gy lg lh l li lj">In [5]:doc3 <strong class="la io">=</strong> nlp(u"I am meeting him tomorrow at the meeting.")<br/>show_lemmas(doc3)</span><span id="10a8" class="le lf in la b gy mj lh l li lj">I            PRON   561228191312463089     -PRON-<br/>am           VERB   10382539506755952630   be<br/>meeting      VERB   6880656908171229526    meet<br/>him          PRON   561228191312463089     -PRON-<br/>tomorrow     NOUN   3573583789758258062    tomorrow<br/>at           ADP    11667289587015813222   at<br/>the          DET    7425985699627899538    the<br/>meeting      NOUN   14798207169164081740   meeting<br/>.            PUNCT  12646065887601541794   .</span></pre><p id="b85c" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">这里<code class="fe lk ll lm la b">meeting</code>的引理是由其词性标签决定的。</p><pre class="kk kl km kn gt kz la lb lc aw ld bi"><span id="6dac" class="le lf in la b gy lg lh l li lj">In [6]:doc4 <strong class="la io">=</strong> nlp(u"That's an enormous automobile")<br/>show_lemmas(doc4)</span><span id="4415" class="le lf in la b gy mj lh l li lj">That         DET    4380130941430378203    that<br/>'s           VERB   10382539506755952630   be<br/>an           DET    15099054000809333061   an<br/>enormous     ADJ    17917224542039855524   enormous<br/>automobile   NOUN   7211811266693931283    automobile</span></pre><p id="a19e" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">注意，词汇化不会将单词简化为最基本的同义词，也就是说，<code class="fe lk ll lm la b">enormous</code>不会变成<code class="fe lk ll lm la b">big</code>,<code class="fe lk ll lm la b">automobile</code>不会变成<code class="fe lk ll lm la b">car</code>。</p><p id="caf3" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">我们应该指出，虽然词汇化查看周围的文本来确定一个给定单词的词性，但它不对短语进行分类。在接下来的讲座中，我们将研究<em class="ki">单词向量和相似度</em>。</p><h2 id="d186" class="le lf in bd ln lo lp dn lq lr ls dp lt jv lu lv lw jz lx ly lz kd ma mb mc md bi translated">停止言语</h2><p id="aeb0" class="pw-post-body-paragraph jk jl in jm b jn me jp jq jr mf jt ju jv mg jx jy jz mh kb kc kd mi kf kg kh ig bi translated">像“a”和“the”这样的词出现得如此频繁，以至于它们不像名词、动词和修饰语那样需要彻底标记。我们把这些<em class="ki">停用词叫做</em>，它们可以从待处理的文本中筛选出来。spaCy 拥有一个大约 305 个英语停用词的内置列表。</p><pre class="kk kl km kn gt kz la lb lc aw ld bi"><span id="04cf" class="le lf in la b gy lg lh l li lj">In [1]:<em class="ki"># Perform standard imports:<br/></em><strong class="la io">import</strong> spacy<br/>nlp <strong class="la io">=</strong> spacy.load('en_core_web_sm')</span><span id="66ba" class="le lf in la b gy mj lh l li lj">In [2]:<em class="ki"># Print the set of spaCy's default stop words (remember that sets are unordered):<br/></em>print(nlp.Defaults.stop_words)</span><span id="741a" class="le lf in la b gy mj lh l li lj">{'hers', 'show', 'though', 'various', 'sixty', 'say', 'quite', 'ten', 'anything', 'although', 'hereby', 'in', 'ours', 'herself', 'among', 'unless', 'and', 'whole', 'anywhere', 'latter', 'therein', 'whereafter', 'that', 'one', 'whose', 'either', 'within', 'eight', 'three', 'latterly', 'anyone', 'a', 'less', 'former', 'been', 'same', 'anyway', 'else', 'cannot', 'five', 'i', 'until', 'last', 'thus', 'give', 'move', 'thereafter', 'via', 'than', 'empty', 'off', 'neither', 'too', 'please', 'over', 'just', 'otherwise', 'has', 'her', 'put', 'its', 'whether', 'herein', 'myself', 'me', 'nevertheless', 'whatever', 'someone', 'towards', 'whereby', 'onto', 'sometimes', 'thence', 'them', 'done', 'at', 'back', 'nor', 'another', 'behind', 'together', 'take', 'amongst', 'being', 'seemed', 'seeming', 'fifteen', 'do', 'further', 'something', 'again', 'this', 'were', 'wherein', 'how', 'up', 'must', 'get', 'whereas', 'much', 'upon', 'yet', 'both', 'many', 'very', 'may', 'after', 'regarding', 'full', 'through', 'below', 'his', 'well', 'everything', 'so', 'our', 'should', 'seem', 'while', 'for', 'might', 'mine', 'when', 'with', 'you', 'few', 'never', 'because', 'own', 'also', 'due', 'hence', 'it', 'more', 'their', 'such', 'becomes', 'first', 'hereupon', 'since', 'third', 'twenty', 'who', 'she', 'nobody', 'name', 'really', 'enough', 'least', 'two', 'whoever', 'which', 'yours', 'moreover', 'seems', 'before', 'therefore', 'then', 'used', 'even', 'nowhere', 'without', 'other', 'around', 'made', 'hundred', 'no', 'twelve', 'several', 'your', 'meanwhile', 'per', 'except', 'yourselves', 'why', 'some', 'not', 'yourself', 'sometime', 'somehow', 'become', 'beyond', 'almost', 'will', 'somewhere', 'the', 'everyone', 'about', 'everywhere', 'anyhow', 'side', 'next', 'fifty', 'they', 'most', 'perhaps', 'across', 'themselves', 'besides', 'against', 'can', 'him', 'there', 'noone', 'under', 'formerly', 'already', 'all', 'if', 'my', 'or', 'serious', 'four', 'thereupon', 'whence', 'here', 'whither', 'beside', 'wherever', 'to', 'himself', 'between', 'ourselves', 'none', 'on', 'became', 'an', 'have', 'part', 'did', 'had', 'each', 'six', 'those', 'from', 'whenever', 'any', 'am', 'would', 'make', 'could', 'does', 'go', 'call', 'indeed', 'these', 'often', 'above', 'during', 'by', 'nine', 'thereby', 'others', 'afterwards', 'throughout', 'whom', 'amount', 'as', 'hereafter', 'top', 'mostly', 'us', 'whereupon', 'once', 'only', 'still', 'namely', 'forty', 'ca', 'along', 'be', 'itself', 'where', 'see', 'into', 'toward', 'but', 'is', 'keep', 'bottom', 'ever', 'becoming', 'every', 'always', 'front', 'nothing', 'we', 'of', 'out', 'eleven', 'alone', 'he', 'however', 'rather', 'down', 'thru', 'now', 'using', 'are', 'doing', 'what', 'beforehand', 're', 'was', 'elsewhere'}</span><span id="2caf" class="le lf in la b gy mj lh l li lj">In [3]:len(nlp.Defaults.stop_words)<br/>Out[3]:305</span></pre><h2 id="e3b6" class="le lf in bd ln lo lp dn lq lr ls dp lt jv lu lv lw jz lx ly lz kd ma mb mc md bi translated">查看一个单词是否是停用词</h2><pre class="kk kl km kn gt kz la lb lc aw ld bi"><span id="c1d2" class="le lf in la b gy lg lh l li lj">In [4]:nlp.vocab['myself'].is_stop<br/>Out[4]:True<br/>In [5]:nlp.vocab['mystery'].is_stop<br/>Out[5]:False</span></pre><h2 id="55c7" class="le lf in bd ln lo lp dn lq lr ls dp lt jv lu lv lw jz lx ly lz kd ma mb mc md bi translated">添加停用词</h2><p id="19a1" class="pw-post-body-paragraph jk jl in jm b jn me jp jq jr mf jt ju jv mg jx jy jz mh kb kc kd mi kf kg kh ig bi translated">有时，您可能希望在默认集合中添加停用字词。也许你决定<code class="fe lk ll lm la b">'btw'</code>(“顺便说一下”的常用简写)应该被认为是一个停用词。</p><pre class="kk kl km kn gt kz la lb lc aw ld bi"><span id="8731" class="le lf in la b gy lg lh l li lj">In [6]:<em class="ki"># Add the word to the set of stop words. Use lowercase!<br/></em>nlp.Defaults.stop_words.add('btw')<br/><em class="ki"># Set the stop_word tag on the lexeme<br/></em>nlp.vocab['btw'].is_stop <strong class="la io">=</strong> <strong class="la io">True<br/></strong>In [7]:len(nlp.Defaults.stop_words)<br/>Out[7]:306<br/>In [8]:nlp.vocab['btw'].is_stop<br/>Out[8]:True</span></pre><p id="4d2f" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">添加停用词时，请始终使用小写。在添加到<strong class="jm io"> vocab </strong>之前，词位被转换成小写。</p><h2 id="e974" class="le lf in bd ln lo lp dn lq lr ls dp lt jv lu lv lw jz lx ly lz kd ma mb mc md bi translated">删除停用词</h2><p id="3183" class="pw-post-body-paragraph jk jl in jm b jn me jp jq jr mf jt ju jv mg jx jy jz mh kb kc kd mi kf kg kh ig bi translated">或者，您可以决定<code class="fe lk ll lm la b">'beyond'</code>不应被视为停用词。</p><pre class="kk kl km kn gt kz la lb lc aw ld bi"><span id="0c49" class="le lf in la b gy lg lh l li lj">In [9]:<em class="ki"># Remove the word from the set of stop words<br/></em>nlp.Defaults.stop_words.remove('beyond')<br/><em class="ki"># Remove the stop_word tag from the lexeme<br/></em>nlp.vocab['beyond'].is_stop <strong class="la io">=</strong> <strong class="la io">False<br/></strong>In [10]:len(nlp.Defaults.stop_words)<br/>Out[10]:305<br/>In [11]:nlp.vocab['beyond'].is_stop<br/>Out[11]:False</span></pre><p id="9597" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">太好了！现在，您应该能够访问 spaCy 的默认停用词集，并根据需要添加或删除停用词。</p><p id="eaa7" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">如果您错过了前面的部分，以下是链接:</p><div class="mk ml gp gr mm mn"><a href="https://medium.com/dev-genius/getting-started-in-natural-language-processing-with-spacy-part-1-5026748cadc2" rel="noopener follow" target="_blank"><div class="mo ab fo"><div class="mp ab mq cl cj mr"><h2 class="bd io gy z fp ms fr fs mt fu fw im bi translated">spaCy 自然语言处理入门:第 1 部分</h2><div class="mu l"><h3 class="bd b gy z fp ms fr fs mt fu fw dk translated">spaCy(https://spacy.io/)是一个开源的 Python 库，可以解析和“理解”大量的文本…</h3></div><div class="mv l"><p class="bd b dl z fp ms fr fs mt fu fw dk translated">medium.com</p></div></div><div class="mw l"><div class="mx l my mz na mw nb kt mn"/></div></div></a></div><div class="mk ml gp gr mm mn"><a href="https://medium.com/@santanudutta85/getting-started-in-natural-language-processing-with-spacy-part-2-73ecb4eac11d" rel="noopener follow" target="_blank"><div class="mo ab fo"><div class="mp ab mq cl cj mr"><h2 class="bd io gy z fp ms fr fs mt fu fw im bi translated">spaCy 自然语言处理入门:第 2 部分</h2><div class="mu l"><h3 class="bd b gy z fp ms fr fs mt fu fw dk translated">如果您错过了第 1 部分。如果您正在寻找基本安装、基本命令、令牌化，请查看它</h3></div><div class="mv l"><p class="bd b dl z fp ms fr fs mt fu fw dk translated">medium.com</p></div></div><div class="mw l"><div class="mx l my mz na mw nb kt mn"/></div></div></a></div><div class="mk ml gp gr mm mn"><a href="https://medium.com/@santanudutta85/getting-started-in-natural-language-processing-with-spacy-part-3-824c1b291d22" rel="noopener follow" target="_blank"><div class="mo ab fo"><div class="mp ab mq cl cj mr"><h2 class="bd io gy z fp ms fr fs mt fu fw im bi translated">spaCy 自然语言处理入门:第 3 部分</h2><div class="mu l"><h3 class="bd b gy z fp ms fr fs mt fu fw dk translated">在这个故事中，我们将重点关注词干。</h3></div><div class="mv l"><p class="bd b dl z fp ms fr fs mt fu fw dk translated">medium.com</p></div></div><div class="mw l"><div class="mx l my mz na mw nb kt mn"/></div></div></a></div><div class="mk ml gp gr mm mn"><a href="https://medium.com/@santanudutta85/getting-started-in-natural-language-processing-with-spacy-part-4-287975381254" rel="noopener follow" target="_blank"><div class="mo ab fo"><div class="mp ab mq cl cj mr"><h2 class="bd io gy z fp ms fr fs mt fu fw im bi translated">spaCy 自然语言处理入门:第 5 部分</h2><div class="mu l"><h3 class="bd b gy z fp ms fr fs mt fu fw dk translated">在这个故事中，我们将关注词汇和搭配。</h3></div><div class="mv l"><p class="bd b dl z fp ms fr fs mt fu fw dk translated">medium.com</p></div></div><div class="mw l"><div class="mx l my mz na mw nb kt mn"/></div></div></a></div></div></div>    
</body>
</html>