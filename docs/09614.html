<html>
<head>
<title>Multinomial data in R</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">R 中的多项式数据</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/multinomial-data-in-r-37d3ba1b6d42?source=collection_archive---------2-----------------------#2022-09-01">https://blog.devgenius.io/multinomial-data-in-r-37d3ba1b6d42?source=collection_archive---------2-----------------------#2022-09-01</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><div class=""><h2 id="ebca" class="pw-subtitle-paragraph jk im in bd b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb dk translated">广义线性混合模型在屠宰数据中的应用</h2></div><p id="5aa7" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">这不是我第一次发表关于<a class="ae ky" rel="noopener ugc nofollow" target="_blank" href="/power-analysis-for-categorical-data-in-sas-multinomial-ordinal-binary-binomial-beta-poisson-9398888491da">有序/多项式数据</a>的文章，有许多方法可以分析这样的数据集，使用<a class="ae ky" href="https://pub.towardsai.net/analyzing-ordinal-data-in-sas-poisson-and-negative-binomial-distribution-5f46b039aaeb" rel="noopener ugc nofollow" target="_blank">泊松或负二项式分布</a>、<a class="ae ky" href="https://pub.towardsai.net/analyzing-ordinal-data-in-sas-using-the-binary-binomial-and-beta-distribution-8efe5fe5af66" rel="noopener ugc nofollow" target="_blank">二元、二项式或贝塔分布</a>，或者完全遵循<a class="ae ky" href="https://pub.towardsai.net/analyzing-ordinal-data-in-sas-fe9d9d35a449" rel="noopener ugc nofollow" target="_blank">多项式</a>本身。然而，这是我第一次展示 R 用于这种类型的分析。这个特定的项目实际上很老了，包含了我在 2017 年对商业数据所做的分析。这就是为什么，不幸的是，我不能分享数据，但我能做的是向你展示我是如何分析的。</p><p id="cb3b" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">让我带你四处看看，并尽可能多地解释我所做的事情。首先，图书馆。我可能没有全部用上，但是如果你愿意，所有的都可以用上。正如我之前提到的，多项式/序数数据可以通过多种方式进行分析。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="33bf" class="li lj in le b gy lk ll l lm ln">rm(list = ls())<br/>#### LIBRARIES ####<br/>library(foreign)<br/>library(lme4)<br/>library(ggplot2)<br/>library(rms)<br/>library(plyr)<br/>library(dplyr)<br/>library(Hmisc)<br/>library(data.table)<br/>library(reshape2)<br/>library(lubridate)<br/>library(boot)<br/>library(sjPlot)<br/>library(sjstats)<br/>library(sjmisc)<br/>library(psych)<br/>library(interval)<br/>library(data.table)<br/>library(effects)<br/>library(AICcmodavg)<br/>library(piecewiseSEM)<br/>require(parallel) <br/>library(scales)        <br/>library(gridExtra)<br/>library(coefplot) <br/>library(coda)      <br/>library(aods3)    <br/>library(plotMCMC) <br/>library(bbmle)     <br/>library(nlme)<br/>library(MCMCglmm)<br/>library(merTools)<br/>library(RLRsim) <br/>library(pbkrtest)<br/>library(blme)<br/>library(MASS)<br/>library(multcomp)<br/>library(glmmLasso)<br/>library(MASS)<br/>library(CCA)</span></pre><p id="7740" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">让我们也载入数据。这是屠宰数据，我们所做的是看看我们是否能找到标记，营养标记，来解释我们在屠宰鸡时看到的白色条纹的水平。WB 和 WS 在很大程度上都是你不希望拥有的东西。</p><p id="c6ed" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">让我们绘制数据。现在，绘制多项式或序数数据本身就是一种技能，我发现几个不同的图，如小提琴，可以帮助你对数据有一个像样的了解。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="dd0a" class="li lj in le b gy lk ll l lm ln">DATA &lt;- read.csv("DATA.csv")<br/>DATA$TT&lt;-as.factor(DATA$TT)<br/>DATA$mincrAO&lt;-as.factor(DATA$mincrAO)<br/>DATA$Caf&lt;-as.factor(DATA$Caf)<br/>DATA$vits&lt;-as.factor(DATA$vits)<br/>DATA$carn&lt;-as.factor(DATA$carn)<br/>DATA$bredol&lt;-as.factor(DATA$bredol)<br/>DATA$ascBCAA&lt;-as.factor(DATA$ascBCAA)<br/>DATA$urs&lt;-as.factor(DATA$urs)<br/>colnames(DATA)[3]&lt;-"BLOCK"<br/>DATA$BLOCK&lt;-as.factor(DATA$BLOCK)<br/>DATA$Caf_order=factor(DATA$Caf, ordered=TRUE)<br/>DATA$urs_order=factor(DATA$urs, ordered=TRUE)<br/>DATA$BOX_cat&lt;-as.factor(DATA$BOX)<br/>DATAcompl&lt;-DATA[complete.cases(DATA$MultinomWS),]<br/>class(DATAcompl$mincrAO)<br/>class(DATAcompl$Caf)<br/>class(DATAcompl$vits)<br/>class(DATAcompl$carn)<br/>class(DATAcompl$bredol)<br/>class(DATAcompl$ascBCAA)<br/>class(DATAcompl$urs)<br/>class(DATAcompl$MultinomWS)<br/>class(DATAcompl$MultinomWB)<br/>skimr::skim(DATAcompl)</span></pre><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi lo"><img src="../Images/52d606ab9591c9582778f60dc5920136.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qNAmixg4X00meHyoTfEjUQ.png"/></div></div></figure><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi lw"><img src="../Images/b26ae53fffc4ffc535dbca545f73affd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SBu6oBY3__nZ6ePWLMcXfw.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">如您所见，数据已经被转换为多项式、序数甚至二进制数(例如重度 WB 与非重度 WB)。这里需要小心多重测试，因此，我更喜欢坚持原来的规模。</figcaption></figure><p id="11f0" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">下面你会看到很多图，我会在 Y 轴上显示多项式/二进制数据，在 x 轴上显示感兴趣的预测值。我要寻找的是小提琴形状的预测值水平(也大多是二进制的)之间的差异。这不是一项容易的任务，但我一直更喜欢图形而不是统计推断，尤其是涉及到这类数据的时候。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="0acb" class="li lj in le b gy lk ll l lm ln">ggplot(DATA, aes(x = TT, y = MultinomWS, fill=TT)) +<br/>  geom_jitter(alpha = .1) +<br/>  geom_violin(alpha = .75) +<br/>  theme_bw()+<br/>  theme(legend.position="none")<br/>ggplot(DATA, aes(x = mincrAO, y = MultinomWS, fill=mincrAO)) +<br/>  geom_jitter(alpha = .1) +<br/>  geom_violin(alpha = .75) +<br/>  theme_bw()+<br/>  theme(legend.position="none")<br/>ggplot(DATA, aes(x = Caf, y = MultinomWS, fill=Caf)) +<br/>  geom_jitter(alpha = .1) +<br/>  geom_violin(alpha = .75) +<br/>  theme_bw()+<br/>  theme(legend.position="none")<br/>ggplot(DATA, aes(x = vits,y=MultinomWS, fill=vits)) +<br/>  geom_jitter(alpha = .1) +<br/>  geom_violin(alpha = .75) +<br/>  theme_bw()+<br/>  theme(legend.position="none")<br/>ggplot(DATA, aes(x = carn,y=MultinomWS, fill=carn)) +<br/>  geom_jitter(alpha = .1) +<br/>  geom_violin(alpha = .75) +<br/>  theme_bw()+<br/>  theme(legend.position="none")<br/>ggplot(DATA, aes(x = bredol,y=MultinomWS, fill=bredol)) +<br/>  geom_jitter(alpha = .1) +<br/>  geom_violin(alpha = .75) +<br/>  theme_bw()+<br/>  theme(legend.position="none")<br/>ggplot(DATA, aes(x = ascBCAA,y=MultinomWS, fill=ascBCAA)) +<br/>  geom_jitter(alpha = .1) +<br/>  geom_violin(alpha = .75) +<br/>  theme_bw()+<br/>  theme(legend.position="none")<br/>ggplot(DATA, aes(x = urs,y=MultinomWS, fill=urs)) +<br/>  geom_jitter(alpha = .1) +<br/>  geom_violin(alpha = .75) +<br/>  theme_bw()+<br/>  theme(legend.position="none")<br/>ggplot(DATA, aes(x = TT, y = MultinomWB, fill=TT)) +<br/>  geom_jitter(alpha = .1) +<br/>  geom_violin(alpha = .75) +<br/>  theme_bw()+<br/>  theme(legend.position="none")<br/>ggplot(DATA, aes(x = mincrAO, y = MultinomWB, fill=mincrAO)) +<br/>  geom_jitter(alpha = .1) +<br/>  geom_violin(alpha = .75) +<br/>  theme_bw()+<br/>  theme(legend.position="none")<br/>ggplot(DATA, aes(x = Caf, y = MultinomWB, fill=Caf)) +<br/>  geom_jitter(alpha = .1) +<br/>  geom_violin(alpha = .75) +<br/>  theme_bw()+<br/>  theme(legend.position="none")<br/>ggplot(DATA, aes(x = vits,y=MultinomWB, fill=vits)) +<br/>  geom_jitter(alpha = .1) +<br/>  geom_violin(alpha = .75) +<br/>  theme_bw()+<br/>  theme(legend.position="none")<br/>ggplot(DATA, aes(x = carn,y=MultinomWB, fill=carn)) +<br/>  geom_jitter(alpha = .1) +<br/>  geom_violin(alpha = .75) +<br/>  theme_bw()+<br/>  theme(legend.position="none")<br/>ggplot(DATA, aes(x = bredol,y=MultinomWB, fill=bredol)) +<br/>  geom_jitter(alpha = .1) +<br/>  geom_violin(alpha = .75) +<br/>  theme_bw()+<br/>  theme(legend.position="none")<br/>ggplot(DATA, aes(x = ascBCAA,y=MultinomWB, fill=ascBCAA)) +<br/>  geom_jitter(alpha = .1) +<br/>  geom_violin(alpha = .75) +<br/>  theme_bw()+<br/>  theme(legend.position="none")<br/>ggplot(DATA, aes(x = urs,y=MultinomWB, fill=urs)) +<br/>  geom_jitter(alpha = .1) +<br/>  geom_violin(alpha = .75) +<br/>  theme_bw()+<br/>  theme(legend.position="none")<br/>ggplot(DATA, aes(x = TT, y = NormWS, fill=TT)) +<br/>  geom_jitter(alpha = .1) +<br/>  geom_violin(alpha = .75) +<br/>  theme_bw() + <br/>  theme(legend.title=element_blank())<br/>ggplot(DATA, aes(x = BLOCK, y = NormWS, fill=BLOCK)) +<br/>  geom_jitter(alpha = .1) +<br/>  geom_violin(alpha = .75) +<br/>  theme_bw() + <br/>  #facet_grid(~.block)+<br/>  theme(legend.title=element_blank())</span></pre><div class="kz la lb lc gt ab cb"><figure class="mb lp mc md me mf mg paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/8c19883f7f32d0d8d3f05227f3eed93d.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*bX7DALuqVvNfSlKqGJi-qA.png"/></div></figure><figure class="mb lp mc md me mf mg paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/3a8ea7c2bee99a4c5a2dfce53c2490ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*D1--jLpOWL1RQev8yU22Jw.png"/></div></figure><figure class="mb lp mc md me mf mg paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/ae02909ffb191b5dcc0f3411745397c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*lw8mcrATZArT4qpD5Y9gMQ.png"/></div></figure></div><div class="ab cb"><figure class="mb lp mc md me mf mg paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/7ebad41bfb7ee3e09d1c2226fcd4643e.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*r38ey65IUN8zs17caaEBBg.png"/></div></figure><figure class="mb lp mc md me mf mg paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/69faa6ae68d9a31401032db8e7c95bab.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*5kaKFqOCaPMZP2tqnrAUyg.png"/></div></figure><figure class="mb lp mc md me mf mg paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/77d48b334defa9ca0e3a9e41210bea19.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*dM4DbBnnlFyWsi8Zy8_W1g.png"/></div></figure></div><div class="ab cb"><figure class="mb lp mc md me mf mg paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/da699762b914c11482b020147f26b4b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*GhwX7M6ys-IbqsYfUulKTA.png"/></div></figure><figure class="mb lp mc md me mf mg paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/30f4e257899ba0949bbde879b0aabfe2.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*Py0DcIHIo02KMloT5MdYzg.png"/></div></figure><figure class="mb lp mc md me mf mg paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/3b8f2e12a31fb5374b896858f85f9c5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*7gi2Zzvgy76YrQLR3RREsg.png"/></div></figure></div><div class="ab cb"><figure class="mb lp mc md me mf mg paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/176ee858b168c60b74ab98c37c0518fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*OVEsm8x0wlaVlrFdAhFvsw.png"/></div></figure><figure class="mb lp mc md me mf mg paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/c1b46d18a08ecdfcd7a603731ee0c5c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*8ntj_HbeF1MxAgY5l_JT6w.png"/></div></figure><figure class="mb lp mc md me mf mg paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/4327ee1410758afe89609e8e6f942d90.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*fZsfTt9BpwDHAqno--pLhw.png"/></div></figure></div><div class="ab cb"><figure class="mb lp mh md me mf mg paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/3ad59159cf48aa2faebcd0f9904514d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*y5lMm2DkgfUIxG4NgLBcRw.png"/></div></figure><figure class="mb lp mh md me mf mg paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/cb224c0d7524200bf65d4464131d2552.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Km0jyDagYyt7jFLMzcM-fg.png"/></div></figure></div><div class="ab cb"><figure class="mb lp mh md me mf mg paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/fa24573bb1e35f09bcfc5afdc71fcf3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*U3b-lqO1WcIlI56FilGbNQ.png"/></div></figure><figure class="mb lp mh md me mf mg paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/d07e5c6ba553e3c525e5b6b642eb0114.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*ixEMJgaT52-B7owas5V4ew.png"/></div></figure></div><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mi"><img src="../Images/53bf5f9fa33a7b94d5fb3dd36b81c335.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xSVUI07O8gUL03Zu1fE4hA.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">正如所料，块之间没有差异。点击<a class="ae ky" href="https://medium.com/mlearning-ai/general-introduction-to-design-of-experiments-in-animal-science-using-sas-for-codes-fe1c5272b37a" rel="noopener">这里</a>阅读更多关于使用阻断机制设计合适研究的内容。</figcaption></figure><p id="893a" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">从上面，你可以发现一些不同，但它们不会改变生活。现在，我们还需要检查我们是否有足够的数据来分析。例如，如果您有包含四个类的序数或多序数数据，但其中一个类几乎没有数据，那么多项式/序数方法将无济于事。你将不得不坚持使用二进制，或者融合一些类别来进行信息量较少的多项式/序数分析。这里，我将从二进制 WS 分析开始，寻找正常/非正常 WS。只是看看我们是否有足够的数据。由于该研究是随机完全区组设计，我将使用<a class="ae ky" href="https://pub.towardsai.net/generalized-linear-mixed-models-in-sas-distributions-link-functions-scales-overdisperion-and-4b1c767bb89a" rel="noopener ugc nofollow" target="_blank">一般线性混合模型</a>。如您所见，我们可以进一步分割数据，因为我们在块内也有副本。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="27b8" class="li lj in le b gy lk ll l lm ln">fit&lt;-glmer(NormWS~1+(1|BOX), <br/>               data=DATA, <br/>               family=binomial, <br/>               control = glmerControl(optimizer = "bobyqa", nAGQ = 10))<br/>fit2&lt;-glmer(NormWS~1+TT+(1|BOX), <br/>           data=DATA, <br/>           family=binomial, <br/>           control = glmerControl(optimizer = "bobyqa", nAGQ = 10))<br/>fit2.1&lt;-glmer(NormWS~1+TT+(1|BLOCK/BOX), <br/>            data=DATA, <br/>            family=binomial, <br/>            control = glmerControl(optimizer = "bobyqa", nAGQ = 10))<br/>anova(fit2, fit2.1)</span></pre><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mj"><img src="../Images/5effc56b32aaaf98472a4c85ca0eaede.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I3OLurec862xSQnkc6Z_ug.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">根据 AIC 和卡方检验，增加更多的方差分量会创建一个更有可能的模型，但并不是所有的模型都一致(如 BIC)。</figcaption></figure><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mk"><img src="../Images/46b88906fff1b7d60a7c7ce022ee7501.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WH421Zgt353jq1DMRjlDNA.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">尽管如此，让我们以 fit2.1 模型为例，进一步探索它。</figcaption></figure><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="8079" class="li lj in le b gy lk ll l lm ln">plot_model(fit2.1)<br/>plot_model(fit2.1, type="diag")<br/>plot_model(fit2.1, type="pred")</span></pre><div class="kz la lb lc gt ab cb"><figure class="mb lp mh md me mf mg paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/377a7d720e3cff2a8f70c3cde0671871.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*CdwEI8Ziow0RNaLI2LkRZA.png"/></div></figure><figure class="mb lp mh md me mf mg paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/a744d7d615fca55b3db7bc32669c90f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*RpnXla-LPTX3zFfIwqW-qQ.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk ml di mm mn translated">治疗优势比——来自数据。</figcaption></figure></div><div class="ab cb"><figure class="mb lp mh md me mf mg paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/7b41ea1b7fce053d2b191531d892c415.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*54Mio6JAZEj-8F0Jmsv1fg.png"/></div></figure><figure class="mb lp mh md me mf mg paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/099d3067b331f65d972dca2788665879.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*9XQzZ3Q4Df4a3nI9mc1o9g.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk ml di mm mn translated">模型看起来不错，显示了方差分量的正态性。</figcaption></figure></div><p id="4ad8" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">让我们提高模型，并添加其他预测因素。它们中的许多都是二进制的，所以这将很快导致大量信息丢失，因为数据需要多次分割。想想决策树。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="93a8" class="li lj in le b gy lk ll l lm ln">fit2.2&lt;-glmer(as.factor(NormWS)~as.factor(mincrAO)+<br/>                as.factor(Caf)+<br/>                as.factor(vits)+<br/>                as.factor(carn)+<br/>                as.factor(bredol)+<br/>                as.factor(ascBCAA)+<br/>                as.factor(urs)+<br/>                (1|BLOCK/BOX), <br/>              data=DATAcompl, <br/>              family=binomial, <br/>              control = glmerControl(optimizer = "bobyqa", nAGQ = 15))<br/>exp(fit2.2@beta)</span></pre><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mo"><img src="../Images/36f4370c0c5c1bd5434ed6cb0bf310e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wCWPl_8VsbeQnffhoknP3w.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">在这里，我们要处理很多部分，所以我们需要删除列。</figcaption></figure><p id="f2cf" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">让我们看看是否能找到任何线性相关性。通常，去除预测因素的最好方法是基于主题知识，我们可以添加线性相关估计。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="6b22" class="li lj in le b gy lk ll l lm ln">fix.formula &lt;- as.factor(MultinomWS)~as.factor(mincrAO)+<br/>  as.factor(Caf)+<br/>  as.factor(vits)+<br/>  as.factor(carn)+<br/>  as.factor(bredol)+<br/>  as.factor(ascBCAA)+<br/>  as.factor(urs)<br/>X &lt;- model.matrix (fix.formula, DATAcompl)<br/>caret::findLinearCombos(X) </span><span id="08e5" class="li lj in le b gy mp ll l lm ln">DATAcompl$ursbin&lt;-ifelse(DATAcompl$urs==1|DATAcompl$urs==2,1,0)</span></pre><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mq"><img src="../Images/1a2ed18031afc531e9c861373949bc23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1350/format:webp/1*_Sfl08Towm-kjMzoMdQwDg.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">我们必须删除模型的第 8 和第 10 部分。这不一定是第 8 款或第 10 款。事实上，这一切都与<strong class="bd mr"> urs </strong>变量有关。</figcaption></figure><p id="7aab" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">新的模型看起来像这样，但是我没有移除。我实际上将<em class="ms"> urs </em>变量转换成了二进制。然后我想再次检查线性依赖，我确实找到了它们，所以我开始添加更多的分类变量，这次是在<em class="ms"> Caf </em>变量上。回顾过去，老实说，我不确定这是否是最明智的选择。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="627a" class="li lj in le b gy lk ll l lm ln">fit2.2&lt;-glmer(as.factor(NormWS)~as.factor(mincrAO)+<br/>                as.factor(Caf)+<br/>                as.factor(vits)+<br/>                as.factor(carn)+<br/>                as.factor(bredol)+<br/>                as.factor(ursbin)+<br/>                (1|BLOCK/BOX), <br/>              data=DATAcompl, <br/>              family=binomial, <br/>              control = glmerControl(optimizer = "bobyqa", nAGQ = 15))</span><span id="b7ee" class="li lj in le b gy mp ll l lm ln">fix.formula &lt;- as.factor(NormWS)~as.factor(mincrAO)+<br/>  as.factor(Caf)+<br/>  as.factor(vits)+<br/>  as.factor(carn)+<br/>  as.factor(bredol)+<br/>  as.factor(ursbin)<br/>X &lt;- model.matrix (fix.formula, DATAcompl)<br/>findLinearCombos(X) <br/>DATAcompl$Cafbin&lt;-ifelse(DATAcompl$Caf==1|DATAcompl$Caf==2,1,0) </span></pre><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mt"><img src="../Images/39b4356c7373caa9b432b2137179ef9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K5JM8WE67LLGuxZs5sG2Qw.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">我想这不是最明智的选择，因为我仍然排名不足。</figcaption></figure><p id="38fc" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">探索秩亏的另一个好而可靠的方法是将数据制成表格。这肯定是一个乏味的过程，但可以教会你很多东西，关于数据是如何建立的，尤其是在单元格太稀疏而没有任何用处的情况下。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="3b25" class="li lj in le b gy lk ll l lm ln">### Look more into rank deficiency or singularity<br/>with(DATAcompl, table(BLOCK, MultinomWS,mincrAO))<br/>with(DATAcompl, table(BLOCK, MultinomWS,Caf))<br/>with(DATAcompl, table(BLOCK, MultinomWS,vits))<br/>with(DATAcompl, table(BLOCK, MultinomWS,carn))<br/>with(DATAcompl, table(BLOCK, MultinomWS,bredol))<br/>with(DATAcompl, table(BLOCK, MultinomWS,ursbin))<br/>with(DATAcompl, table(BLOCK, MultinomWS,ascBCAA))</span><span id="3c26" class="li lj in le b gy mp ll l lm ln">with(DATAcompl, table(BLOCK,mincrAO,ascBCAA))<br/>with(DATAcompl, table(BLOCK,Caf,ascBCAA))<br/>with(DATAcompl, table(BLOCK,vits,ascBCAA))<br/>with(DATAcompl, table(BLOCK,carn,ascBCAA))<br/>with(DATAcompl, table(BLOCK,bredol,ascBCAA))<br/>with(DATAcompl, table(BLOCK,ursbin,ascBCAA))</span><span id="be82" class="li lj in le b gy mp ll l lm ln">with(DATAcompl, table(BLOCK,mincrAO,carn))<br/>with(DATAcompl, table(BLOCK,Caf,carn))<br/>with(DATAcompl, table(BLOCK,vits,carn))<br/>with(DATAcompl, table(BLOCK,ascBCAA,carn))<br/>with(DATAcompl, table(BLOCK,bredol,carn))<br/>with(DATAcompl, table(BLOCK,ursbin,carn))</span></pre><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mu"><img src="../Images/aec6b5082c801b398aa84ab9ce6d7bb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IIpd0AEf_AZl7J1wkuP0Zg.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">例如，您可以看到当您除以预测值 mincrAO 时，单元格如何变为零。这对分析没有帮助，这是需要注意的。</figcaption></figure><p id="a450" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">最终我删除了<em class="ms"> urs </em>变量，保留了原来的<em class="ms"> caf </em>变量。它主要是尝试和错误，由一些线性依赖和列表的探索支持。我本来也可以做，但现在没有做的是应用一种形式的<a class="ae ky" href="https://pub.towardsai.net/multivariate-analysis-using-sas-b4f34ced6d0" rel="noopener ugc nofollow" target="_blank">多元分析</a>，比如主成分分析。尽管处理二进制数据不那么容易，但它可能保留了大部分信息，并且仍然减少了变量的数量。</p><p id="1c73" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">让我们继续。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="1371" class="li lj in le b gy lk ll l lm ln">fit2.2&lt;-glmer(as.factor(NormWS)~as.factor(mincrAO)+<br/>                as.factor(Caf)+<br/>                as.factor(vits)+<br/>                as.factor(carn)+<br/>                as.factor(bredol)+<br/>                (1|BLOCK/BOX), <br/>              data=DATAcompl, <br/>              family=binomial, <br/>              control = glmerControl(optimizer = "bobyqa", nAGQ = 15))<br/>summary(fit2.2)<br/>plot(fit2.2)<br/>plot_model(fit2.2)<br/>plot_model(fit2.2, type="diag")<br/>plot_model(fit2.2, type="pred")</span></pre><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mv"><img src="../Images/679187c99b0fa5682a0fb903ccd5f588.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*le6_Oe3VrsbdsX9KdA9jLg.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">模型正在运行。</figcaption></figure><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mw"><img src="../Images/0f10cc00aecdc68c764395da7ee79aa0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wdyXCt2zdGTBGmT5nRqpyQ.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">当然，一些变量有一些重要的信息。</figcaption></figure><div class="kz la lb lc gt ab cb"><figure class="mb lp mc md me mf mg paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/bfa8d2c5e0059f6c149d211b32d3bc33.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*1s2I2P037DXFYaNExjXgAg.png"/></div></figure><figure class="mb lp mc md me mf mg paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/c11b4743aff6c701d9113b3abc214e4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*lHMsfdRkvJaMnZM6E6AZTw.png"/></div></figure><figure class="mb lp mc md me mf mg paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/69d56a7678492a9731dc9614fae8e7d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*K5fiw3QFID-uCQQJaYcPKQ.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk mx di my mn translated">模特看起来不错。左边是二项式数据的分离，中间和右边是方差分量的正态假设。</figcaption></figure></div><p id="271c" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">让我们根据预测值来绘制预测概率。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="bfe2" class="li lj in le b gy lk ll l lm ln">fit2.2_pred&lt;-broom.mixed::augment(fit2.2)<br/>g1&lt;-ggplot(fit2.2_pred, <br/>       aes(fill=`as.factor(Caf)`, <br/>           x=plogis(.fitted)))+<br/>  geom_density(alpha=0.5)+<br/>  theme_bw()+<br/>  labs(x="Fitted Probability",<br/>       y="Density",<br/>       fill="Caf",<br/>       title = "Fitted probability for variable 'Caf'")<br/>g2&lt;-ggplot(fit2.2_pred, <br/>       aes(fill=`as.factor(vits)`, <br/>           x=plogis(.fitted)))+<br/>  geom_density(alpha=0.5)+<br/>  theme_bw()+<br/>  labs(x="Fitted Probability",<br/>       y="Density",<br/>       fill="Vits",<br/>       title = "Fitted probability for variable 'vits'")<br/>g3&lt;-ggplot(fit2.2_pred, <br/>       aes(fill=`as.factor(carn)`, <br/>           x=plogis(.fitted)))+<br/>  geom_density(alpha=0.5)+<br/>  theme_bw()+<br/>  labs(x="Fitted Probability",<br/>       y="Density",<br/>       fill="Carn",<br/>       title = "Fitted probability for variable 'carn'")<br/>g4&lt;-ggplot(fit2.2_pred, <br/>       aes(fill=`as.factor(bredol)`, <br/>           x=plogis(.fitted)))+<br/>  geom_density(alpha=0.5)+<br/>  theme_bw()+<br/>  labs(x="Fitted Probability",<br/>       y="Density",<br/>       fill="Bredol",<br/>       title = "Fitted probability for variable 'bredol'")<br/>g5&lt;-ggplot(fit2.2_pred, <br/>       aes(fill=`as.factor(mincrAO)`, <br/>           x=plogis(.fitted)))+<br/>  geom_density(alpha=0.5)+<br/>  theme_bw()+<br/>  labs(x="Fitted Probability",<br/>       y="Density",<br/>       fill="MincrAO",<br/>       title = "Fitted probability for variable 'mincrAO'")<br/>grid.arrange(g1,g2,g3,g4,g5,ncol=3)</span></pre><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mz"><img src="../Images/b117e4b1e246fd3ad3e14a40e7b95a80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IFzvZHiqCRLsmNTOKU1Jgg.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">退一步说，这是一些奇怪的分布，这确实与两件事有关:(1)在一个模型中绘制主效应，尽管不包括相互作用，但它有更多的上下文，以及(2)低细胞数。密度图总是倾向于相当奇怪，或者变得奇怪，当有凸起的数字出现时。</figcaption></figure><p id="830b" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">然而，可以肯定的是，该模型可以从一些简化中受益，而且在那时(甚至现在)，我喜欢套索选择器。让我们看看我当时是如何运用它的。</p><p id="b709" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">我在这里做的是建立一个可能的 lambda 值的网格，从中<a class="ae ky" rel="noopener ugc nofollow" target="_blank" href="/predictive-regression-using-splines-partial-least-squares-penalization-cross-validation-and-339b74a7e108">惩罚</a>模型，用 lambda 值反复运行模型，显示 BIC 度量，然后确定哪个 lambda 值是最好的。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="aa22" class="li lj in le b gy lk ll l lm ln">lambda&lt;-seq(5,1,by=-0.1)<br/>BIC_vec&lt;-rep(Inf,length(lambda))<br/>Delta.start&lt;-as.matrix(t(rep(0,6+10))) # fixed(6) + random(10) effects<br/>Q.start&lt;-0.1<br/>family=binomial(link=logit)<br/>for(j in 1:length(lambda))<br/>  {<br/>    print(paste("Iteration ", j,sep=""))<br/>fit2.2.lasso&lt;-try(glmmLasso(NormWS~<br/>                              as.factor(mincrAO)+<br/>                              as.factor(Caf)+<br/>                              as.factor(vits)+<br/>                              as.factor(carn)+<br/>                              as.factor(bredol),<br/>                            rnd=list(BLOCK=~1),<br/>                            family=family,<br/>                            data=DATAcompl,<br/>                            lambda=lambda[j],<br/>                            switch.NR=F,<br/>                            final.re=TRUE),<br/>                  silent = TRUE)<br/>print(colnames(fit2.2.lasso$Deltamatrix)[2:7][fit2.2.lasso$Deltamatrix[fit2.2.lasso$conv.step,2:7]!=0])<br/>BIC_vec[j]&lt;-fit2.2.lasso$bic<br/>Delta.start&lt;-rbind(Delta.start,fit2.2.lasso$Deltamatrix[fit2.2.lasso$conv.step,])<br/>Q.start&lt;-c(Q.start,fit2.2.lasso$Q_long[[fit2.2.lasso$conv.step+1]])<br/>}<br/>opt&lt;-lambda[which.min(BIC_vec)] #2.1</span></pre><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi na"><img src="../Images/5d506c5bc307bbb200d8736d4af29f6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CYh1Cy6V_9vafU0UYvcLEg.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">迭代显示哪些变量被保留，哪些没有。请记住，套索惩罚为零，这意味着它转储它认为没有价值的变量。</figcaption></figure><p id="ec99" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">现在我有了一个最佳的λ值，我可以对它进行积分，建立一个模型，它应该显示出最小的 BIC。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="bf90" class="li lj in le b gy lk ll l lm ln">fit2.2.lasso&lt;-try(glmmLasso(NormWS~<br/>                              as.factor(mincrAO)+<br/>                              as.factor(Caf)+<br/>                              as.factor(vits)+<br/>                              as.factor(carn)+<br/>                              as.factor(bredol),<br/>                            rnd=list(BLOCK=~1),<br/>                            family=family,<br/>                            data=DATAcompl,<br/>                            lambda=lambda[which.min(BIC_vec)],<br/>                            switch.NR=F,<br/>                            final.re=TRUE),<br/>                  silent = TRUE)<br/>summary(fit2.2.lasso)<br/>exp(fit2.2.lasso$coefficients)</span></pre><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi nb"><img src="../Images/d7b2464c530759f99afedbb27817aba3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MVRIE8KML_Y_Vpdxcm2ayQ.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">正如你所看到的，LASSO 过程去掉了 mincrAO 变量，同时也改变了其他的系数。系数的指数显示了优势比。</figcaption></figure><p id="92b3" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">下面你可以看到λ值的曲线图。这个过程到处都是，这并没有给我一个确切的感觉，即我们实际上已经找到了最佳的λ值。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="3fa9" class="li lj in le b gy lk ll l lm ln">par(mfrow = c(3, 2))<br/>plot(lambda,<br/>     Delta.start[2:42,2],<br/>     type="l",<br/>     ylab=expression(hat(beta[j])))<br/>abline(v=opt, lty=2, col="red")<br/>plot(lambda,<br/>     Delta.start[2:42,3],<br/>     type="l",<br/>     ylab=expression(hat(beta[j])))<br/>abline(v=opt, lty=2, col="red")<br/>plot(lambda,<br/>     Delta.start[2:42,4],<br/>     type="l",<br/>     ylab=expression(hat(beta[j])))<br/>abline(v=opt, lty=2, col="red")<br/>plot(lambda,<br/>     Delta.start[2:42,5],<br/>     type="l",<br/>     ylab=expression(hat(beta[j])))<br/>abline(v=opt, lty=2, col="red")<br/>plot(lambda,<br/>     Delta.start[2:42,6],<br/>     type="l",<br/>     ylab=expression(hat(beta[j])))<br/>abline(v=opt, lty=2, col="red")<br/>plot(lambda,<br/>     Delta.start[2:42,7],<br/>     type="l",<br/>     ylab=expression(hat(beta[j])))<br/>abline(v=opt, lty=2, col="red")</span></pre><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi nc"><img src="../Images/1e583794ba58cee2c3124d91b952969c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7a--CyZqnjrbem6oc6jMqw.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">基于λ值的系数。这里，您可以看到系数选择为λ= 2.1，这是遵循使用 BIC 作为选择标准的程序的最佳λ。</figcaption></figure><p id="d10e" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">让我们用五重交叉验证把它提升一个档次。这里的设置很繁琐，我敢肯定现在已经有自动化的软件包可以为你做这件事，但我们走吧。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="13c5" class="li lj in le b gy lk ll l lm ln">N&lt;-dim(DATAcompl)[1]<br/>ind&lt;-sample(N,N) <br/>lambda &lt;- seq(10,0,by=-0.5) <br/>kk&lt;-5<br/>nk &lt;- floor(N/kk) <br/>Devianz_ma&lt;-matrix(Inf,ncol=kk,nrow=length(lambda)) family=binomial(link=logit)<br/>PQL&lt;-glmmPQL(NormWS~1,random=~1|BLOCK,family=family,data=DATAcompl) <br/>summary(PQL)</span><span id="2876" class="li lj in le b gy mp ll l lm ln">Delta.start&lt;-c(as.numeric(PQL$coef$fixed),rep(0,6),<br/>               as.numeric(t(PQL$coef$random$BLOCK)))<br/>Delta.start</span><span id="1a18" class="li lj in le b gy mp ll l lm ln">Q.start&lt;-as.numeric(VarCorr(PQL)[,1]) <br/>Q.start</span><span id="708f" class="li lj in le b gy mp ll l lm ln">for(j in 1:length(lambda))<br/>  {<br/>  print(paste("Iteration ", j,sep=""))<br/>  <br/>  for (i in 1:kk)<br/>  {<br/>    if (i &lt; kk) <br/>    {<br/>    indi &lt;- ind[(i-1)*nk+(1:nk)]<br/>    }else{<br/>      indi &lt;- ind[((i-1)*nk+1):N]<br/>    }</span><span id="f0bb" class="li lj in le b gy mp ll l lm ln">DATAcompl.train&lt;-DATAcompl[-indi,]<br/>DATAcompl.test&lt;-DATAcompl[indi,]</span><span id="e8d7" class="li lj in le b gy mp ll l lm ln">glm2 &lt;- try(glmmLasso(NormWS~as.factor(mincrAO)+<br/>                        as.factor(Caf)+<br/>                        as.factor(vits)+<br/>                        as.factor(carn)+<br/>                        as.factor(bredol),<br/>                        rnd=list(BLOCK=~1),<br/>                        family=family,<br/>                        data=DATAcompl,<br/>                        lambda=lambda[j],<br/>                      switch.NR=F,<br/>                      final.re=TRUE,       control=list(start=Delta.start,<br/>             q_start=Q.start,<br/>             overdispersion=TRUE, <br/>             maxiter=10000)),silent=TRUE)</span><span id="5e7d" class="li lj in le b gy mp ll l lm ln">if(class(glm2)!="try-error")<br/>{<br/>  y.hat&lt;-predict(glm2,DATAcompl.test)  <br/>  Devianz_ma[j,i]&lt;-sum(family$dev.resids(DATAcompl.test$NormWS,<br/>  y.hat, wt=rep(1,length(y.hat))))} <br/>  }<br/>  print(sum(Devianz_ma[j,]))<br/>}</span><span id="7a8b" class="li lj in le b gy mp ll l lm ln">Devianz_vec&lt;-apply(Devianz_ma,1,sum)<br/>opt2&lt;-which.min(Devianz_vec)<br/>lambda[opt2]</span></pre><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi nd"><img src="../Images/63736589bf85273cd440f7ade260c787.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_boZJr-RMQ026r20ryJgiQ.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">这是启动模型的设置，只是为了看看我是否工作。如你所见，我现在使用了一个不同的包，它使用了惩罚似然性。这意味着它也可以整合λ值。使用不同的函数和包来查看它们是否重叠总是好的。</figcaption></figure><p id="8d47" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">从上面来看，我们似乎有足够的数据和组来构建一个广义的线性混合模型，但我们也知道，包括二元预测器会以非常快的速度分割数据，直到什么都没有了。</p><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi ne"><img src="../Images/f74cf80f850af2b419b9086df570c50f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gmiEI3s5Z3sY0mKkkIWxNQ.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">我试图为这个过程找到一个好的初始值，但是正如你所看到的，我当时不太确定这个过程是否正确。</figcaption></figure><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mt"><img src="../Images/c4aaa22450ebfa15b7fcf210b123c4e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3BVqusNxGysJ2X4GfW_tuQ.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">你可以看到选择的标准，偏差，并没有真正改变。偏差是比较模型的一个指标，可以是完整的模型，也可以是空模型。这是一个空模型。越轨越少越好。观察到它确实没有变化，这让我对它找到最佳λ的能力没有太大信心。</figcaption></figure><p id="d6b9" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">当然，你一问，它就会吐出一个最优的 lamba，就是这次的 4.5。这与之前的 2.1 版本有很大不同，但老实说，这并不奇怪。</p><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi nf"><img src="../Images/615ff950dd8030240aeff171468b61c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DbIoc8p3tijcRl6-Gj6r8Q.png"/></div></div></figure><p id="00e4" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">让我们再来看看变化的系数，作为λ的函数。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="1ba6" class="li lj in le b gy lk ll l lm ln">par(ask=FALSE)<br/>plot(lambda[1:17],<br/>     Delta.start,<br/>     type="l",<br/>     ylab=expression(hat(beta[j])))<br/>abline(v=lambda[opt2],lty=2, col="red")</span></pre><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi ng"><img src="../Images/851174e730fe0f646f9d0362663a7446.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xycwkw63d72pUY165osdOQ.png"/></div></div></figure><p id="25db" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">现在，我们可以用我们选择的λ来拟合模型。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="0d7a" class="li lj in le b gy lk ll l lm ln">fit.CV.lasso&lt;-glmmLasso(NormWS~as.factor(mincrAO)+<br/>                           as.factor(Caf)+<br/>                           as.factor(vits)+<br/>                           as.factor(carn)+<br/>                           as.factor(bredol),<br/>                         rnd=list(BLOCK=~1),<br/>                         family=family,<br/>                         data=DATAcompl,<br/>                         lambda=lambda[opt2], switch.NR=F,  <br/>                         final.re=TRUE,<br/>                         control=list(start=Delta.start, <br/>                         q_start=Q.start, overdispersion=TRUE, <br/>                         maxiter=10000))<br/>summary(fit.CV.lasso)<br/>fit.CV.lasso$aic;fit2.2.lasso$aic<br/>fit.CV.lasso$ranef<br/>fit.CV.lasso$fixerror<br/>fit.CV.lasso$ranerror<br/>plot(fit.CV.lasso)<br/>exp(fit.CV.lasso$coefficients)</span></pre><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi nh"><img src="../Images/326f43e7976afd1f81a6f6cc41ae4ec5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R6yP8dtGvXN_on015t7y3w.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">这一次，他们都活了下来。即使是在之前的设置中被删除的 mincrAO 变量。</figcaption></figure><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi ni"><img src="../Images/0c78d71ad0ce83569922f2f6d320f92d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TPbdO0nBixio3Q0bs_b01A.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">如果我们对比之前的车型，一款 lambda 为 2.1(飞度 2.2)，一款 lambda 为 4.5(飞度。CV)，我们看到 AIC 几乎保持平等。没有大的变化。</figcaption></figure><p id="aa9c" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">我们现在可以画出随机效应、固定效应误差和随机效应误差。</p><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi nj"><img src="../Images/1c9501affc229f70b7ddd23f147b0560.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sIUR-bPilK4XS99ZKJ8Tgg.png"/></div></div></figure><p id="9640" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">要时刻记住的是寻找<a class="ae ky" href="https://medium.com/mlearning-ai/analysis-of-repeated-count-data-in-r-the-poisson-quasi-poisson-negative-binomial-e62aff528309" rel="noopener">过度分散</a>。如果你的数据过于分散，那么你对误差的估计就太小了。过度分布是一种令人讨厌的假象，当您在估计方差时应用一个有界于均值参数的分布时就会出现这种情况。如果你的数据过于分散，那么你对误差的估计就太小了。因此，为什么在应用正态分布时看不到它，但在应用二元、二项式或泊松分布时会遇到麻烦(尤其是泊松分布，因为方差和均值是直接关联的)。例如，二元或二项式的方差分别是 p*(1-p)或 np*(1-p)。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="ab7d" class="li lj in le b gy lk ll l lm ln">### Overdispersion<br/>## Point estimate<br/>overdisp_fun &lt;- function(model) {<br/>  ## number of variance parameters in <br/>  ##   an n-by-n variance-covariance matrix<br/>  vpars &lt;- function(m) {<br/>    nrow(m)*(nrow(m)+1)/2<br/>  }<br/>  model.df &lt;- sum(sapply(VarCorr(model),vpars))+length(fixef(model))<br/>  rdf &lt;- nrow(model.frame(model))-model.df<br/>  rp &lt;- residuals(model,type="pearson")<br/>  Pearson.chisq &lt;- sum(rp^2)<br/>  prat &lt;- Pearson.chisq/rdf<br/>  pval &lt;- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)<br/>  c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)<br/>}<br/>overdisp_fun(fit2.2)</span></pre><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi nk"><img src="../Images/2bdc75154c5b446127f317940812fede.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IhQZsfwLO8s4b3z5sJ7Myg.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">从统计上看，没有发现过度分散，尽管我当然也可以用一种更图形化的方式。不过，至少有一些迹象总是好的。另一种可能性是查看置信区间和预测区间，并用观测数据覆盖它们。</figcaption></figure><p id="7351" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">我们也可以自举离差度量。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="29b5" class="li lj in le b gy lk ll l lm ln">FUN &lt;- function(fit) {<br/>  #return(fixef(fit))<br/>  x&lt;-resid(fit,type="pearson")<br/>  return(sum(x^2))<br/>} <br/>m1boot&lt;-bootMer(fit2.2,FUN,1000)<br/>od&lt;-function(bootobject){<br/>  biasvals&lt;-bootobject $t0/bootobject[2]$t<br/>  bias&lt;-mean(biasvals,na.rm=T)<br/>  intervals&lt;-quantile(biasvals,c(0.025,0.975),na.rm=T)<br/>  dat&lt;-c(bias,intervals)<br/>  return(dat)<br/>}<br/>od(m1boot)</span></pre><figure class="kz la lb lc gt lp gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/f0f583b1844333d3e05784ca79c64ed6.png" data-original-src="https://miro.medium.com/v2/resize:fit:490/format:webp/1*J2M4u-r89PqKD0IoVJVVxw.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">没有过度分散，值 1 落在范围内。</figcaption></figure><p id="c857" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">让我们尝试另一个模型，在这个模型中，我更深入地研究了我可以(或者应该)包括的方差分量。请记住，每次我添加一层，我也会增加组件之间的相关性，如果它们是嵌套的。来自相同上下文的值通常非常相似，因此它们不会真正添加额外的信息。因此，添加另一个方差分量并不一定会添加更多的信息。有时候会打破分析。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="7783" class="li lj in le b gy lk ll l lm ln">DATA$resid&lt;-as.factor(1:dim(DATA)[1]) <br/>fit3&lt;-glmer(NormWS~1+TT+(1|BOX)+(1|Number), <br/>            data=DATA, <br/>            family=binomial, <br/>            control = glmerControl(optimizer = "bobyqa", nAGQ = 10))<br/>summary(fit3) # variance for residuals is 0 <br/>anova(fit2, fit3)</span></pre><figure class="kz la lb lc gt lp gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/c0397fd256c30da683d28f21efa72849.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*j5fyS4bzOG7NFGxyOKjugw.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">如您所见，添加的方差分量并没有真正增加任何东西。</figcaption></figure><p id="1601" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">所以，我们回到原始数据，而不是使用套索和分析它。虽然套索在处理过度拟合方面被证明是一个更好的模型，但这个实验的目的是确定营养成分。因此，需要尽可能地接近实验，从而保持变量和系数不变。“无偏见”。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="8e00" class="li lj in le b gy lk ll l lm ln">DATAcompl$resid&lt;-as.factor(1:dim(DATAcompl)[1]) <br/>fit2.3&lt;-glmer(as.factor(NormWS)~<br/>                as.factor(mincrAO)+<br/>                as.factor(Caf)+<br/>                as.factor(vits)+<br/>                as.factor(carn)+<br/>                as.factor(bredol)+<br/>                (1|BLOCK/BOX)+<br/>                (1|Number), <br/>            data=DATAcompl, <br/>            family=binomial, <br/>            control = glmerControl(optimizer = "bobyqa", nAGQ = 15))<br/>summary(fit2.3) <br/>anova(fit2.3, fit2.2) </span></pre><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi nn"><img src="../Images/6f5964f010ec3ecfc6788e98a45a6aa5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GQwHhl8ZMmqadzIssPtrbQ.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">这个模型，以及一个显示增加更多方差分量没有任何作用的比较。</figcaption></figure><p id="3e72" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">现在，让我们运行模型 fit2.2，使用 bootstrapping 来获得固定效应的 bootstrapping 估计。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="dca6" class="li lj in le b gy lk ll l lm ln">(nc &lt;- detectCores())<br/>cl &lt;- makeCluster(rep("localhost", nc))<br/>fit2.2.boot&lt;-confint(fit2.2, method = "boot", boot.type = "basic", nsim = 2000, parallel = "snow", ncpus=8, cl=cl)<br/>exp(fit2.2.boot)</span></pre><figure class="kz la lb lc gt lp gh gi paragraph-image"><div class="gh gi no"><img src="../Images/b0f318892eac53754f2a09608ed90661.png" data-original-src="https://miro.medium.com/v2/resize:fit:588/format:webp/1*mQPrvdjCAkyVDnLhOyzgLA.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">比值比的引导区间中包含 1 表明固定效应和参考值之间没有差异。</figcaption></figure><p id="240d" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">我们还可以使用内置的重采样方法对固定和随机效应进行自举估计。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="3d5b" class="li lj in le b gy lk ll l lm ln">fit2.fesim&lt;-FEsim(fit2.2, n.sims=10000, oddsRatio=TRUE)<br/>fit2.resim&lt;-REsim(fit2.2, n.sims=10000, oddsRatio=TRUE)<br/>fit2.fesim<br/>fit2.resim</span></pre><figure class="kz la lb lc gt lp gh gi paragraph-image"><div class="gh gi np"><img src="../Images/c048cc49d2a1e4e29686a6ce98ba2ba3.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/format:webp/1*4heqw_9f6GomfZ4Mh91qLQ.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">无法计算标准偏差。老实说，这不是一件好事，我也从来没有真正弄清楚问题出在哪里。</figcaption></figure><p id="cdfc" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">绘制最终模型，显示白色条纹的比值比(正常与非正常)。原来<em class="ms"> carn </em>有一个主要的作用，增加了正常乳房里脊的几率。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="6a96" class="li lj in le b gy lk ll l lm ln">tab_model(fit2.2, depvar.labels = "WS (yes vs. no)")</span></pre><figure class="kz la lb lc gt lp gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/6e19ad5e52c4008b6dd92716a3308b53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/format:webp/1*_vcXxApfPJD7hgoTr3EORA.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">模型本身并不是最强的模型，随机成分很难解释，模型本身也有问题，这可以从 R 平方值看出。不是没有自己的问题，R 平方这么低不是你想看到的。</figcaption></figure><p id="cf93" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">从这个模型，除了它的问题，我们可以得到比较估计。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="7049" class="li lj in le b gy lk ll l lm ln">comp1&lt;-glht(fit2, mcp(TT="Tukey"))<br/>comp1.cld&lt;-cld(comp1)<br/>par(mai=c(1,1.5,1,1), no.readonly=TRUE)<br/>plot(comp1.cld)<br/>par(mai=c(1,1.5,1,1), no.readonly=TRUE)<br/>plot(comp1) # ugly but informative plot <br/>abline(v=0,lty=2,col="gray50")</span></pre><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi nr"><img src="../Images/8498fa615f656934ed9ab4a2e7725893.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*USXkcUAz9wEUXG597CM-hA.png"/></div></div></figure><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi nr"><img src="../Images/a3924f99c2b374d0308479b0e3b84cca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j8AzO8YAH0ZMcjP9OCiC0Q.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">没有一种治疗方法显示出彼此之间有任何差异。</figcaption></figure><p id="5ea1" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">因此，到目前为止，我们已经总结了多项式/顺序响应变量的二元方法。让我们把它提高一个档次，回到原来的规模，实际上做多项式/序数分析。</p></div><div class="ab cl ns nt hr nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="ig ih ii ij ik"><p id="0101" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">我在这里要做的实际上是使用全白色条纹尺度，并应用序数模型。在有序逻辑回归中，感兴趣的事件是观察到特定的分数或更低的分数。对于 WS 的评级，您模拟以下赔率:</p><ol class=""><li id="0786" class="nz oa in ke b kf kg ki kj kl ob kp oc kt od kx oe of og oh bi translated">θ0 | 1 =概率(得分为 0) /概率(得分大于 0)</li><li id="c416" class="nz oa in ke b kf oi ki oj kl ok kp ol kt om kx oe of og oh bi translated">θ1 | 2 =概率(得分为 0 或 1) /概率(得分大于 1)</li><li id="5ad0" class="nz oa in ke b kf oi ki oj kl ok kp ol kt om kx oe of og oh bi translated">θ2 | 3 =概率(得分为 0、1 或 1) /概率(得分大于 2)</li></ol><p id="b6a7" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">当你看到一个二分因子的正系数时，你就知道第一类更有可能得到更高的分数。负系数告诉你分数越低的可能性越大。对于连续变量，正系数告诉你，随着变量的值增加，更大分数的可能性也增加。因此，与较高分数的关联意味着较低分数的累积概率较小，因为它们不太可能发生</p><p id="3425" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">阈值并不真的很有趣，但这取决于你可能会问。例如，它们的值不依赖于特定情况下独立变量的值，人们应该将它们视为线性回归中的截距，只是每个阈值现在都有自己的阈值。在序数或多项式变量中，总有一个阈值比级数少。</p><p id="8ae8" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">为了更快地开始，我将从以前的模型中选择变量。至少，这应该给我一个比我现在得到的等级不足警告更好的开始。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="0681" class="li lj in le b gy lk ll l lm ln">fit.multinomWS&lt;-ordinal::clmm(MultinomWS~<br/>                       mincrAO+<br/>                       Caf+<br/>                       vits+<br/>                       carn+<br/>                       bredol+<br/>                       (1|BLOCK), <br/>                     data=DATAcompl,<br/>                     Hess = TRUE,<br/>                     nAGQ = 10)<br/>summary(fit.multinomWS)<br/>exp(coef(fit.multinomWS))<br/>exp(confint(fit.multinomWS))<br/>fit.multinomWS$ranef<br/>fit.multinomWS$condVar<br/>plot(fitted(fit.multinomWS)~BLOCK, data=DATAcompl)</span></pre><figure class="kz la lb lc gt lp gh gi paragraph-image"><div class="gh gi on"><img src="../Images/0743e5fbfd3be0725d796c4e842d49c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/1*UqubD-XDGp7CGoq-1s62Cw.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">您可以清楚地看到阈值 logit 值。</figcaption></figure><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi oo"><img src="../Images/860321880d2e0462894d75231bd82140.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*swKkhK0oYEkttwzQgncXmQ.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">这里，我们有模型的指数系数(比值比)，它们的置信区间和随机成分。</figcaption></figure><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi nr"><img src="../Images/7f484e511ed7e8515731a6c5cf427584.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JGPnt1JXsKed-_yUpxSLpw.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">看起来相当相等的按块拟合的值。</figcaption></figure><p id="d3a0" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">现在，我现在最可爱的自动变量选择器之一是<a class="ae ky" href="https://rdrr.io/cran/VGAM/man/drop1.html" rel="noopener ugc nofollow" target="_blank"> <em class="ms"> drop1 </em> </a>函数。我真的真的很喜欢它，因为它以一种非常快速的方式提供了一个在 AIC 的机会，基于你放弃的变量。这不仅能告诉你一些关于感兴趣的变量的信息，还能告诉你模型本身的稳定性。巨大的变化不仅意味着你有一个非常重要的预测指标，而且意味着样本量也有变化。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="5096" class="li lj in le b gy lk ll l lm ln">fitdrop&lt;-drop1(fit.multinomWS, trace=T)<br/>drop1(fit.multinomWS, test="Chi")</span></pre><figure class="kz la lb lc gt lp gh gi paragraph-image"><div class="gh gi op"><img src="../Images/77a80ada9fbacd97a01eb99db8491957.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*7pjckdMFxvgUJ2OijLpEYg.png"/></div></figure><figure class="kz la lb lc gt lp gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/06951d927bed58b404f21498927117ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*NcfMmAkSaag1nz4gXsjbjg.png"/></div></figure><p id="3b7f" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">让我们继续使用一个模型，但这一次没有随机组件。所以，这不是广义的线性混合模型，而是一般的线性模型。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="3bc0" class="li lj in le b gy lk ll l lm ln">fit.multinomWS.clm&lt;-ordinal::clm(MultinomWS~<br/>                      mincrAO+<br/>                      Caf+<br/>                      vits+<br/>                      carn+<br/>                      bredol,<br/>                    data=DATAcompl,<br/>                    Hess = TRUE,<br/>                    nAGQ = 10)<br/>anova(fit.multinomWS.clm,fit.multinomWS) <br/>ci&lt;-fit.multinomWS$ranef + qnorm(0.975) * sqrt(fit.multinomWS$condVar) %o% c(-1, 1)<br/>ord.re &lt;- order(fit.multinomWS$ranef)<br/>ci &lt;- ci[order(fit.multinomWS$ranef),]<br/>plot(1:10, fit.multinomWS$ranef[ord.re], axes=FALSE, ylim=range(ci),<br/>       xlab="BLOCK", ylab="BLOCK effect")<br/>axis(1, at=1:10, labels = ord.re)<br/>axis(2)<br/>for(i in 1:10) segments(i, ci[i,1], i, ci[i, 2])<br/>abline(h = 0, lty=2)</span></pre><figure class="kz la lb lc gt lp gh gi paragraph-image"><div class="gh gi or"><img src="../Images/770d9a620c2134868b22d75550f1fcee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1330/format:webp/1*W08z9jHa6tiWYGNPciYKrg.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">glmm 模型更可取，尽管我不得不提到，信息量的增加确实微不足道。</figcaption></figure><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi nr"><img src="../Images/22090bff2bd9fd96ba8a51e3776e1f14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OYHCZq-lCjDdp0k96cU6Uw.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">每个区块的随机效应。它们都接触到零，所以在我看来，说存在随机的阻滞效应有点过了。实验设计的顽固分子会告诉你我们需要包括 block，因为这是我们最初设计研究的方式。然而，可以肯定的是，从定义上来说，这并不是更节俭的模式。</figcaption></figure><p id="ea5c" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">现在我们有了模型，或者至少是我们认为可以得到的最佳模型，是时候展示模型的概率了。因为我们有一个有四个级别(0，1，2，3)的顺序模型，所以我们得到了四个类别的概率。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="532f" class="li lj in le b gy lk ll l lm ln">DATAcompl&lt;-cbind(DATAcompl, fitted(fit.multinomWS)) <br/>ggplot(DATAcompl, <br/>       aes(x=fitted(fit.multinomWS), <br/>           fill=as.factor(MultinomWS)))+<br/>  geom_density(alpha=0.6)+<br/>  theme_bw()+<br/>  labs(x="P(Category|model)", <br/>       y="Density", <br/>       fill="Category")</span></pre><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi os"><img src="../Images/b2c05f912de712a8c06bfe7120efbd76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PPzdNA4VedVzOfpMcsxU7A.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">就像这样。如你所见，基于数据，我们预测进入 1 班的概率最高。这应该不会让你吃惊。</figcaption></figure><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="6879" class="li lj in le b gy lk ll l lm ln">table(DATAcompl$MultinomWS)</span><span id="cac2" class="li lj in le b gy mp ll l lm ln">0    1    2    3 <br/>375  617  337  99</span></pre><p id="03a6" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">从上表(收集的数据的频率表)可以很容易地看出，类别 1 的频率最高，类别 0 和类别 2 的频率大致相同，类别 3 的频率最低。这都体现在上面的剧情中。事实上，上面的图实际上只是检查模型是否能够复制频率表的一种方法，但并没有显示潜在预测因素的影响。</p><p id="d33b" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">我能做的是建立一个网格，然后在网格上运行模型，这样可以更好地显示上面的图。</p><pre class="kz la lb lc gt ld le lf lg aw lh bi"><span id="56e9" class="li lj in le b gy lk ll l lm ln">qnorm(0.95) * c(-1, 1) *fit.multinomWS$ST$BLOCK[1]</span><span id="8276" class="li lj in le b gy mp ll l lm ln"><br/># Probabilities for the four conditions at baseline experimental conditions<br/>pred &lt;-<br/>  function(eta, theta, cat = 1:(length(theta)+1), inv.link = plogis)<br/>  {<br/>    Theta &lt;- c(-1e3, theta, 1e3)<br/>    sapply(cat, function(j)<br/>      inv.link(Theta[j+1] - eta) - inv.link(Theta[j] - eta) )<br/>  }<br/>pred(qnorm(0.05)*fit.multinomWS$ST$BLOCK[1],fit.multinomWS$Theta)<br/></span><span id="8722" class="li lj in le b gy mp ll l lm ln"># compute and plot probabilities for average, 5th and 95th percetile BLOCKs<br/>mat &lt;- expand.grid(BLOCK = qnorm(0.95) * c(-1, 0, 1) * fit.multinomWS$ST$BLOCK[1],<br/>                   mincrAO=c(0, fit.multinomWS$beta[1]),<br/>                   Caf1=c(0, fit.multinomWS$beta[2]),<br/>                   Caf2=c(0, fit.multinomWS$beta[3]),<br/>                   vits=c(0, fit.multinomWS$beta[4]),<br/>                   carn=c(0, fit.multinomWS$beta[5]),<br/>                   bredol=c(0, fit.multinomWS$beta[6]))<br/>pred.mat &lt;- pred(eta=rowSums(mat), theta=fit.multinomWS$Theta)<br/>dim(mat);dim(pred.mat)<br/>df&lt;-melt(pred.mat)<br/>ggplot(df,<br/>       aes(x=value, <br/>           fill=as.factor(Var2-1)))+<br/>  geom_density(alpha=0.6)+<br/>  theme_bw()+<br/>  labs(x="P(Category|model)", <br/>       y="Density", <br/>       fill="Category")</span></pre><figure class="kz la lb lc gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi os"><img src="../Images/ee683231e6a7451d16c81389a0845579.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wgnTG8qZYEqoNeIlnr41hg.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">看起来好多了。</figcaption></figure><p id="81d4" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">这个例子到此结束。希望你喜欢。当然，我本可以表现得更多，做得更多，但现在，我认为这已经足够了。如果缺少了什么，如果您有问题，或者想了解更多，请联系我们！</p></div></div>    
</body>
</html>