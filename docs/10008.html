<html>
<head>
<title>Types of Activation Functions in Deep Learning explained with Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 Keras 解释深度学习中激活函数的类型</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/types-of-activation-functions-in-deep-learning-explained-with-keras-cd1e0b85e003?source=collection_archive---------1-----------------------#2022-09-29">https://blog.devgenius.io/types-of-activation-functions-in-deep-learning-explained-with-keras-cd1e0b85e003?source=collection_archive---------1-----------------------#2022-09-29</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><p id="f40b" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">激活是指通过点击来激活你的车吗(当然，如果有的话)，这是相同的概念，但在神经元方面，神经元就像在人脑中一样吗？，再近一点，神经元不过在人工神经网络(ANN)中。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/a093616566205fe1eaca99bbd411b7c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*LwgUSQVIM6ad-2-C.png"/></div></figure><p id="8f78" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">激活函数决定一个神经元是否应该被激活。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kq"><img src="../Images/b217fc2d7184b12d59db8a95d09d8a43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QJY-TLxecC8hP6aRUTU14g.png"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">人脑中的生物神经元</figcaption></figure><p id="219b" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">如果你见过人工神经网络，我真诚地希望你见过，你已经看到它们在本质上是线性的，所以为了在它们中使用非线性，我们使用激活函数并从输入网络的输入值产生输出。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kz"><img src="../Images/82383b6a9f80bdab58c1bbee239ec76a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k8i8P-1W9-GOex9WeFui9w.png"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">一个样本人工神经网络</figcaption></figure><p id="bf6e" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">激活功能可以分为三种类型</p><ol class=""><li id="9bc3" class="la lb in jm b jn jo jr js jv lc jz ld kd le kh lf lg lh li bi translated"><strong class="jm io">线性激活功能</strong></li><li id="6cfc" class="la lb in jm b jn lj jr lk jv ll jz lm kd ln kh lf lg lh li bi translated"><strong class="jm io">二进制步进激活功能</strong></li><li id="6bfe" class="la lb in jm b jn lj jr lk jv ll jz lm kd ln kh lf lg lh li bi translated"><strong class="jm io">非线性激活功能</strong></li></ol><h1 id="9ee3" class="lo lp in bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated"><strong class="ak">线性激活功能</strong></h1><p id="90c0" class="pw-post-body-paragraph jk jl in jm b jn mm jp jq jr mn jt ju jv mo jx jy jz mp kb kc kd mq kf kg kh ig bi translated">它与输出值成比例，它只是将加权总和添加到输出中。范围从(-∞到∞之间)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mr"><img src="../Images/ed5b518579a78da717fe87123b660bc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zcAR1FkJNHlzqo3zMOpllA.png"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">显示线性激活函数的图形</figcaption></figure><p id="3bf7" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io">数学上的</strong>，同样可以写成</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/eb7bbd22506bef21531154b4ffa26550.png" data-original-src="https://miro.medium.com/v2/resize:fit:258/format:webp/1*relH6sbpWyr_JjCL83xqRA.jpeg"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">线性激活方程</figcaption></figure><p id="fa5c" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">Keras 中的实现如下所示，</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mt mu l"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">Keras 中的线性激活函数</figcaption></figure><h1 id="cf6e" class="lo lp in bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">二元阶跃激活函数</h1><p id="38e1" class="pw-post-body-paragraph jk jl in jm b jn mm jp jq jr mn jt ju jv mo jx jy jz mp kb kc kd mq kf kg kh ig bi translated">它有一个特定的阈值，决定一个神经元是否应该被激活。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/5a6fff3e6579d88d94a108f7a9ee4f35.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/format:webp/1*7wquCeA8pZMXnY6Tr7jH0w.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">二元阶跃激活函数图</figcaption></figure><p id="f550" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io">数学上的</strong>，这是函数的方程式</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/bfc69c516a1b9aa5eb726ca799053b91.png" data-original-src="https://miro.medium.com/v2/resize:fit:902/format:webp/1*1OymFD5Pno58XNb3DHzcLA.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">二元阶跃激活函数方程</figcaption></figure><p id="f2cd" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">Keras 中没有相同的实现，因此使用 TensorFlow 创建一个自定义函数，如下所示</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mt mu l"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">TensorFlow 中的自定义二元步进激活函数</figcaption></figure><h1 id="08ac" class="lo lp in bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">非线性激活函数</h1><p id="e643" class="pw-post-body-paragraph jk jl in jm b jn mm jp jq jr mn jt ju jv mo jx jy jz mp kb kc kd mq kf kg kh ig bi translated">它允许人工神经网络根据各种数据进行调整，并区分输出。它允许多层的堆叠，因为输出是通过多层神经网络的输入的组合。</p><p id="aace" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">下面讨论各种非线性激活函数</p><h2 id="f6b9" class="mx lp in bd lq my mz dn lu na nb dp ly jv nc nd mc jz ne nf mg kd ng nh mk ni bi translated">Sigmoid 激活函数</h2><p id="acd5" class="pw-post-body-paragraph jk jl in jm b jn mm jp jq jr mn jt ju jv mo jx jy jz mp kb kc kd mq kf kg kh ig bi translated">该函数接受输入(数字)并返回一个介于 0 和 1 之间的数字。它主要用于二进制分类，因为输出范围在 0 和 1 之间，例如，你训练一只狗和猫的分类器，不管那只狗有多毛茸茸，它都将其分类为狗而不是猫，没有中间值，sigmoid 非常适合它。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi nj"><img src="../Images/bf9e8cc523eaf31e4af57dbe5135350e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D-30olNWMYHUKWtV0nm05g.png"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">Sigmoid 函数的图形</figcaption></figure><p id="1667" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io">数学上</strong>，等式看起来是这样的</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/e13fe6c2a90943ad5863fb59bcf2a46f.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*5FXmWrnmqzNdx0rs00UyJg.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">Sigmoid 函数方程</figcaption></figure><p id="ed34" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">Keras 中的实现如下所示，</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mt mu l"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">Keras 中的乙状结肠激活功能</figcaption></figure><h2 id="d131" class="mx lp in bd lq my mz dn lu na nb dp ly jv nc nd mc jz ne nf mg kd ng nh mk ni bi translated">TanH 激活函数</h2><p id="7fdb" class="pw-post-body-paragraph jk jl in jm b jn mm jp jq jr mn jt ju jv mo jx jy jz mp kb kc kd mq kf kg kh ig bi translated">该激活函数将该值映射到范围[ -1，1 ]中。输出以零为中心，这有助于将负输入值映射为强负值，零值映射到绝对零。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi nl"><img src="../Images/390c879418d9717f466a477468c4f58a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p5Vbj8YE3l4JdgKOy6YqVg.jpeg"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">tanh 与乙状结肠的比较</figcaption></figure><p id="28d9" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io">数学上</strong>，等式看起来是这样的</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/54ad48739fbac64ad6edc699358c084a.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*J72VWAZ8kcu9BXATY2TiKQ.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">双曲正切方程</figcaption></figure><p id="52be" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">Keras 中的相同实现如下所示</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mt mu l"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">Keras 中的 tanh 激活功能</figcaption></figure><h2 id="06bf" class="mx lp in bd lq my mz dn lu na nb dp ly jv nc nd mc jz ne nf mg kd ng nh mk ni bi translated"><strong class="ak"> ReLU(整流线性单元)</strong></h2><p id="fa23" class="pw-post-body-paragraph jk jl in jm b jn mm jp jq jr mn jt ju jv mo jx jy jz mp kb kc kd mq kf kg kh ig bi translated">它是最常用的激活函数之一，解决了函数最大值为 1 时梯度消失的问题。ReLU 的范围是[ 0，∞ ]。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi nn"><img src="../Images/b39eaeadf45176e5af69452ba7bb0df2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*29VH_NiSdoLJ1jUMLrURCA.png"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">比较 Sigmoid 和 ReLU 的图形</figcaption></figure><p id="a484" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io">数学上</strong>，等式看起来是这样的</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi no"><img src="../Images/d0862ba72282850b7e140a3dd6c7953d.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*u3hD9SmPM9XfcEmTxzJFUw.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">ReLU 方程</figcaption></figure><p id="36f0" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">Keras 中的实现如下所示，</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mt mu l"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">Keras 中的 ReLU 实现</figcaption></figure><h2 id="d27f" class="mx lp in bd lq my mz dn lu na nb dp ly jv nc nd mc jz ne nf mg kd ng nh mk ni bi translated">泄漏 ReLU</h2><p id="b6dd" class="pw-post-body-paragraph jk jl in jm b jn mm jp jq jr mn jt ju jv mo jx jy jz mp kb kc kd mq kf kg kh ig bi translated">ReLU like Covid 变体的升级版本..敏感话题…好吧..回到泄漏的 ReLU，它被升级，因为它解决了垂死的 ReLU 问题，因为它在负区域具有小的正斜率。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/956fa2ec9c5339fc75c2ca83a96324d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*PK57PYGbv8N_P9L2fKqdRQ.jpeg"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">ReLU(左)和泄漏 ReLU(右)的比较</figcaption></figure><p id="71ca" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io">数学上的</strong>，等式看起来是这样的</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/21a563af3f714fc19bfb36ffada831e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*01VbbdU-pf2L8YYQmLZHgQ.png"/></div></figure><p id="0ab7" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">下面是 Keras 的实现</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mt mu l"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">喀拉斯的漏雨</figcaption></figure><h2 id="4a4d" class="mx lp in bd lq my mz dn lu na nb dp ly jv nc nd mc jz ne nf mg kd ng nh mk ni bi translated">SoftMax 激活功能</h2><p id="b10d" class="pw-post-body-paragraph jk jl in jm b jn mm jp jq jr mn jt ju jv mo jx jy jz mp kb kc kd mq kf kg kh ig bi translated">让我们猜猜看..是 tanh 吗，嗯不完全是，ReLU？没有或其泄漏的对应物..嗯，不完全是…好吧，让我们揭示它..它是许多乙状结肠的组合。它决定了相对概率。</p><p id="e98c" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">在多类分类中，它最常用于分类器的最后一层。它给出了当前类相对于其他类的概率。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi nr"><img src="../Images/05c1f5698c43b97670c1b6487daf51ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QUfA8BxtGrTc38HYTyoMpg.jpeg"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">Softmax 函数示例</figcaption></figure><p id="88fd" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">数学上，这个等式看起来像这样</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/0d8f44259d3f4837ef8f8cb1cf4d6b12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*2TduFFBM03IVCzLnnCpMLw.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">Softmax 函数方程</figcaption></figure><p id="c424" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">Keras 的实施情况如下</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mt mu l"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">Keras 中的 Softmax 函数</figcaption></figure><p id="0bb3" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">包含上述所有代码的整个笔记本</p><div class="ns nt gp gr nu nv"><a href="https://colab.research.google.com/drive/1PPhCPSfPrM-8Bk5fbD_GPZAckjC5bGG3?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd io gy z fp oa fr fs ob fu fw im bi translated">谷歌联合实验室</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">编辑描述</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">colab.research.google.com</p></div></div><div class="oe l"><div class="of l og oh oi oe oj ko nv"/></div></div></a></div><p id="8742" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">如果你想联系我，让我们在下面的 LinkedIn 链接上联系</p><p id="f31b" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><a class="ae ok" href="https://www.linkedin.com/in/tripathiadityaprakash/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/tripathiadityaprakash/</a></p></div></div>    
</body>
</html>