<html>
<head>
<title>Facial Expression Recognition with TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">张量流人脸表情识别</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/facial-expression-recognition-with-tensorflow-90f6174163c3?source=collection_archive---------1-----------------------#2022-03-20">https://blog.devgenius.io/facial-expression-recognition-with-tensorflow-90f6174163c3?source=collection_archive---------1-----------------------#2022-03-20</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><figure class="gl gn jl jm jn jo gh gi paragraph-image"><div class="gh gi jk"><img src="../Images/751ab3fb815b9474ca3a086da0541e90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/1*XidkH_SxYmLT3VeN0oPqfg.png"/></div></figure><p id="898a" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">我开始了作为机器学习工程师的旅程，试图尽可能多地进行实践，与其他人建立联系，并接收一些反馈以进行改进。所以如果你想谈谈或给我一些反馈，我会很感激，我会让我的 LinkedIn 和 GitHub 在文末。</p><p id="1884" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">所以首先，我想做一些图像分类器项目，然后我做了一些研究，发现了这个“检测情绪”的想法，我认为它非常酷。所以在搜索了一些关于这个特定问题的数据集后，我选择了这个<a class="ae kp" href="https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge" rel="noopener ugc nofollow" target="_blank">表征学习的挑战:来自<a class="ae kp" href="https://www.kaggle.com" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>的面部表情识别挑战</a>。</p><p id="c851" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">我们将在数据分析、数据预处理和建模的这些过程中使用 Google Colab。但是，让我们谈谈我们的数据，数据集为我们提供了 7 个类，如下所示:</p><figure class="kr ks kt ku gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kq"><img src="../Images/e75b5116dc8adfc7ce8a7b1385b33f3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*77XItkVczWPfLb-J3QDo9g.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">情感</figcaption></figure><p id="a3b9" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">你看到的和我一样吗？我们有一个不平衡数据的问题…是的，那很糟糕。但是为了“解决”这一点，我们将只使用 4 个类，因为某些类的图像是糟糕的，并且不会对我们的模型有好处，所以我们的类将是愤怒、快乐、悲伤和惊讶的。</p><p id="c44c" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">让我们去掉一些我们不会用到的值。</p><pre class="kr ks kt ku gt ld le lf lg aw lh bi"><span id="68ca" class="li lj in le b gy lk ll l lm ln">data = data[data["emotion"] != 1]</span><span id="c043" class="li lj in le b gy lo ll l lm ln">data = data[data["emotion"] != 2]</span><span id="e9b8" class="li lj in le b gy lo ll l lm ln">data = data[data["emotion"] != 6]</span><span id="8f6d" class="li lj in le b gy lo ll l lm ln">data["emotion"].value_counts().reset_index(drop=True, inplace=True)</span></pre><p id="6ac1" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">所以，让我们把数据分成 X 和 y。</p><pre class="kr ks kt ku gt ld le lf lg aw lh bi"><span id="053b" class="li lj in le b gy lk ll l lm ln"># Split data into X &amp; y</span><span id="da7f" class="li lj in le b gy lo ll l lm ln">X = data.drop("emotion", axis=1)</span><span id="753d" class="li lj in le b gy lo ll l lm ln">y = data["emotion"]</span><span id="bb5c" class="li lj in le b gy lo ll l lm ln"># Concat train sets into one</span><span id="88f3" class="li lj in le b gy lo ll l lm ln">df = pd.concat([X, y], axis=1)</span></pre><p id="4a76" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">下一步是处理我们的图像，因为它们是字符串格式。</p><pre class="kr ks kt ku gt ld le lf lg aw lh bi"><span id="09ec" class="li lj in le b gy lk ll l lm ln">def pixels_to_array(pixels):</span><span id="7a67" class="li lj in le b gy lo ll l lm ln">array = np.array(pixels.split(),'float64')</span><span id="2e3a" class="li lj in le b gy lo ll l lm ln">return array<br/></span><span id="6968" class="li lj in le b gy lo ll l lm ln">df['pixels'] = df["pixels"].apply(pixels_to_array)</span></pre><p id="10b6" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">将数据分为训练集和测试集。</p><pre class="kr ks kt ku gt ld le lf lg aw lh bi"><span id="731d" class="li lj in le b gy lk ll l lm ln">data_train = df[df["Usage"] == "Training"]</span><span id="2945" class="li lj in le b gy lo ll l lm ln">data_test1 = df[df["Usage"] == "PublicTest"]</span><span id="9a13" class="li lj in le b gy lo ll l lm ln">data_test2 = df[df["Usage"] == "PrivateTest"]</span><span id="d5a6" class="li lj in le b gy lo ll l lm ln">data_test = pd.concat([data_test1, data_test2])</span></pre><p id="fe31" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">然后，我们将重塑我们的图像，成为 RGB 格式和形状(48，48，3)。</p><pre class="kr ks kt ku gt ld le lf lg aw lh bi"><span id="ab10" class="li lj in le b gy lk ll l lm ln">def image_reshape(data):</span><span id="1c43" class="li lj in le b gy lo ll l lm ln">image = np.reshape(data.to_list(),(data.shape[0],48,48,1))</span><span id="1d35" class="li lj in le b gy lo ll l lm ln">image = np.repeat(image, 3, -1)</span><span id="4255" class="li lj in le b gy lo ll l lm ln">return image<br/></span><span id="ebca" class="li lj in le b gy lo ll l lm ln">X_train = image_reshape(data_train["pixels"])</span><span id="33c8" class="li lj in le b gy lo ll l lm ln">X_test = image_reshape(data_test["pixels"])</span><span id="1a34" class="li lj in le b gy lo ll l lm ln">y_train = data_train["emotion"]</span><span id="488b" class="li lj in le b gy lo ll l lm ln">y_test = data_test["emotion"]</span></pre><p id="c432" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">将类名设置为变量:</p><pre class="kr ks kt ku gt ld le lf lg aw lh bi"><span id="53f5" class="li lj in le b gy lk ll l lm ln">class_names = ["Angry", "Happy", "Sad", "Surprise"]</span></pre><p id="e141" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">现在，我们需要解决另一个问题，因为我们丢弃了一些情绪，我们情绪的值是连续的，它们现在是这样的“0，3，5，7”。这将是一个问题，在下一步，当我们得到图像，并把它们放入各自的目录，所以让我们来解决这个问题。</p><pre class="kr ks kt ku gt ld le lf lg aw lh bi"><span id="ea97" class="li lj in le b gy lk ll l lm ln"># Do the same for y_test<br/>for i in range(len(y_train)):</span><span id="3edd" class="li lj in le b gy lo ll l lm ln">if y_train[i] == 3:</span><span id="1667" class="li lj in le b gy lo ll l lm ln">y_train[i] = 1</span><span id="3380" class="li lj in le b gy lo ll l lm ln">elif y_train[i] == 4:</span><span id="502a" class="li lj in le b gy lo ll l lm ln">y_train[i] = 2</span><span id="1ce8" class="li lj in le b gy lo ll l lm ln">elif y_train[i] == 5:</span><span id="1da9" class="li lj in le b gy lo ll l lm ln">y_train[i] = 3</span><span id="4ff1" class="li lj in le b gy lo ll l lm ln">for label in range(len(classes)):</span><span id="ca04" class="li lj in le b gy lo ll l lm ln">os.makedirs("/content/data/train/" + classes[label], exist_ok=True)</span><span id="d33c" class="li lj in le b gy lo ll l lm ln">os.makedirs("/content/data/test/" + classes[label], exist_ok=True)<br/></span><span id="3976" class="li lj in le b gy lo ll l lm ln">for i in range(len(X_train)):</span><span id="e236" class="li lj in le b gy lo ll l lm ln">emotion = classes[y_train[i]]</span><span id="68ef" class="li lj in le b gy lo ll l lm ln">cv2.imwrite(f"/content/data/train/{emotion}/{emotion}{i}.png", X_train[i])</span><span id="96b7" class="li lj in le b gy lo ll l lm ln">for j in range(len(X_test)):</span><span id="2ec7" class="li lj in le b gy lo ll l lm ln">emotion = classes[y_test[j]]</span><span id="236e" class="li lj in le b gy lo ll l lm ln">cv2.imwrite(f"/content/data/test/{emotion}/{emotion}{j}.png", X_test[j])</span></pre><p id="5200" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">我们接下来的步骤很重要。首先，我们将标准化我们的数据(将值转换为 0 到 1 之间的值)，这有助于我们的模型更好地学习和执行。其次，执行一些数据扩充(通过对现有数据进行细微的更改来添加更多数据的技术)。最后，但仍然重要的是，将我们的数据分批转换(基本上将我们的数据分成<strong class="jt io">组</strong>，以便我们的模型权重仅在每个<strong class="jt io">组</strong>之后更新)。</p><pre class="kr ks kt ku gt ld le lf lg aw lh bi"><span id="993b" class="li lj in le b gy lk ll l lm ln">from tensorflow.keras.preprocessing.image import ImageDataGenerator</span><span id="813d" class="li lj in le b gy lo ll l lm ln">IMAGE_SHAPE = (48, 48)</span><span id="d108" class="li lj in le b gy lo ll l lm ln">BATCH_SIZE = 64</span><span id="e55d" class="li lj in le b gy lo ll l lm ln">train_dir = "/content/data/train/"</span><span id="16d5" class="li lj in le b gy lo ll l lm ln">test_dir =  "/content/data/test/"</span><span id="97ef" class="li lj in le b gy lo ll l lm ln">train_datagen = ImageDataGenerator(rescale=1/255.,</span><span id="33e6" class="li lj in le b gy lo ll l lm ln">rotation_range=0.1,</span><span id="3dfe" class="li lj in le b gy lo ll l lm ln">zoom_range=0.1)</span><span id="6e10" class="li lj in le b gy lo ll l lm ln">test_datagen = ImageDataGenerator(rescale=1/255.)<br/></span><span id="5f7a" class="li lj in le b gy lo ll l lm ln">train_data = train_datagen.flow_from_directory(train_dir,</span><span id="43a9" class="li lj in le b gy lo ll l lm ln">target_size=IMAGE_SHAPE,</span><span id="275e" class="li lj in le b gy lo ll l lm ln">batch_size=BATCH_SIZE,</span><span id="1c25" class="li lj in le b gy lo ll l lm ln">class_mode="categorical",</span><span id="bd00" class="li lj in le b gy lo ll l lm ln">shuffle=True)</span><span id="6c72" class="li lj in le b gy lo ll l lm ln">test_data = test_datagen.flow_from_directory(test_dir,</span><span id="f3cd" class="li lj in le b gy lo ll l lm ln">target_size=IMAGE_SHAPE,</span><span id="ee41" class="li lj in le b gy lo ll l lm ln">batch_size=BATCH_SIZE,</span><span id="c0b4" class="li lj in le b gy lo ll l lm ln">class_mode="categorical")</span></pre><p id="d247" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">让我们想象一下我们的火车场景中的一个图像:</p><figure class="kr ks kt ku gt jo gh gi paragraph-image"><div class="gh gi lp"><img src="../Images/cdb1cfadb50bfa94cff5aae4fba94859.png" data-original-src="https://miro.medium.com/v2/resize:fit:96/format:webp/1*sRXfgvAsJ0LFOpK3Sa1jVw.png"/></div></figure><p id="49f5" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">我们做了所有需要的数据处理，所以让我们建立我们的模型。经过一些测试，这种架构达到了最佳效果:</p><pre class="kr ks kt ku gt ld le lf lg aw lh bi"><span id="642f" class="li lj in le b gy lk ll l lm ln"># Import packages</span><span id="a3f6" class="li lj in le b gy lo ll l lm ln">import tensorflow as tf</span><span id="c5bf" class="li lj in le b gy lo ll l lm ln">from tensorflow.keras import Sequential</span><span id="2a33" class="li lj in le b gy lo ll l lm ln">from tensorflow.keras.callbacks import ReduceLROnPlateau</span><span id="fd14" class="li lj in le b gy lo ll l lm ln">from tensorflow.keras.layers import BatchNormalization<br/></span><span id="823a" class="li lj in le b gy lo ll l lm ln">tf.random.set_seed(42)</span><span id="0c0e" class="li lj in le b gy lo ll l lm ln"># Create the model</span><span id="cd0f" class="li lj in le b gy lo ll l lm ln">model_1 = Sequential([</span><span id="6547" class="li lj in le b gy lo ll l lm ln">tf.keras.layers.Input(shape=(48, 48, 3)),</span><span id="18ff" class="li lj in le b gy lo ll l lm ln">tf.keras.layers.Conv2D(512, (3,3), activation="relu", padding="same"),</span><span id="18e3" class="li lj in le b gy lo ll l lm ln">BatchNormalization(),</span><span id="9252" class="li lj in le b gy lo ll l lm ln">tf.keras.layers.Conv2D(256, (3,3), activation="relu", padding="same"),</span><span id="07c1" class="li lj in le b gy lo ll l lm ln">BatchNormalization(),</span><span id="52fe" class="li lj in le b gy lo ll l lm ln">tf.keras.layers.MaxPool2D(2),</span><span id="0053" class="li lj in le b gy lo ll l lm ln">tf.keras.layers.Dropout(0.5),</span><span id="f674" class="li lj in le b gy lo ll l lm ln">tf.keras.layers.Conv2D(128, (3,3), activation="relu", padding="same"),</span><span id="19cd" class="li lj in le b gy lo ll l lm ln">BatchNormalization(),</span><span id="7e4f" class="li lj in le b gy lo ll l lm ln">tf.keras.layers.Conv2D(64, (3,3), activation="relu", padding="same"),</span><span id="eaff" class="li lj in le b gy lo ll l lm ln">BatchNormalization(),</span><span id="ae9a" class="li lj in le b gy lo ll l lm ln">tf.keras.layers.MaxPool2D(2),</span><span id="b7ef" class="li lj in le b gy lo ll l lm ln">tf.keras.layers.Dropout(0.5),</span><span id="e81a" class="li lj in le b gy lo ll l lm ln">tf.keras.layers.Conv2D(32, (3,3), activation="relu", padding="same"),</span><span id="52ed" class="li lj in le b gy lo ll l lm ln">tf.keras.layers.MaxPool2D(2),</span><span id="2bc2" class="li lj in le b gy lo ll l lm ln">tf.keras.layers.Dropout(0.5),</span><span id="3e1a" class="li lj in le b gy lo ll l lm ln">tf.keras.layers.Flatten(),</span><span id="5fb9" class="li lj in le b gy lo ll l lm ln">tf.keras.layers.Dense(4, activation="softmax")</span><span id="63bc" class="li lj in le b gy lo ll l lm ln">])</span></pre><p id="b32b" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">编译和训练我们的模型。</p><pre class="kr ks kt ku gt ld le lf lg aw lh bi"><span id="58b6" class="li lj in le b gy lk ll l lm ln"># Compile the model</span><span id="3784" class="li lj in le b gy lo ll l lm ln">model_1.compile(loss="categorical_crossentropy",</span><span id="2c10" class="li lj in le b gy lo ll l lm ln">optimizer=tf.keras.optimizers.Adam(),</span><span id="ec48" class="li lj in le b gy lo ll l lm ln">metrics=["accuracy"])</span><span id="3ab6" class="li lj in le b gy lo ll l lm ln">checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath="checkpoint/",</span><span id="1add" class="li lj in le b gy lo ll l lm ln">save_weights_only=False,</span><span id="c306" class="li lj in le b gy lo ll l lm ln">save_best_only=True,</span><span id="cb1a" class="li lj in le b gy lo ll l lm ln">save_freq="epoch",</span><span id="491e" class="li lj in le b gy lo ll l lm ln">verbose=1)</span><span id="3e1f" class="li lj in le b gy lo ll l lm ln">reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2,</span><span id="96fb" class="li lj in le b gy lo ll l lm ln">patience=8, min_lr=0.00001)</span><span id="aa90" class="li lj in le b gy lo ll l lm ln"># Fit the model</span><span id="58a8" class="li lj in le b gy lo ll l lm ln">model_1.fit(train_data, epochs=80, callbacks=[reduce_lr, checkpoint_callback], validation_data=test_data)</span></pre><p id="dde7" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">对于训练集，我们得到了大约 83%的 ACC，对于测试集，我们得到了大约 79%的 ACC，考虑到我们的图像存在的一些问题，这已经相当不错了，比如:<br/> -水印<br/> -一些图像用数字字符(不是人)<br/> -少量数据。为了解决这些问题，我们可以搜索其他用于面部情感识别的数据集，删除一些不好的图像，或者添加我们可以在某个地方获得的图像。</p><p id="3852" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">因此，我们分析我们的数据，处理它，执行建模和训练。下一步是什么？看到现实生活中的结果，最精彩的部分…</p><div class="kr ks kt ku gt ab cb"><figure class="lq jo lr ls lt lu lv paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><img src="../Images/4bac960f091336bf37838a89c0fd7db9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*tpASb2lfZ-WhRkORBmK78g.png"/></div></figure><figure class="lq jo lw ls lt lu lv paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><img src="../Images/830e6745591894a4f95cf0692f212eee.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*FN-QBfOVEvMC6eDsYwQyHA.png"/></div></figure></div><div class="ab cb"><figure class="lq jo lx ls lt lu lv paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><img src="../Images/1acfd287bb957958adb69c856a3ccb4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*_fx6gScmk6dUFuzK8jbXjQ.png"/></div></figure><figure class="lq jo ly ls lt lu lv paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><img src="../Images/a37f4194aaec1cb16d1f176349825045.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*JAR0xQt3_w8l4FsJH6EIFQ.png"/></div></figure></div><p id="607a" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">对我来说，I.A 最令人兴奋的部分是深度学习，所以做这个关于面部表情识别的小项目非常酷，我学到了很多东西。</p><p id="929e" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">如果你有任何反馈，想谈谈，或者只是跟随我在这个旅程中，我会让我的 LinkedIn 和那些想看完整代码的人，我的 GitHub 在下面😁</p><p id="84b7" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">领英:<a class="ae kp" href="https://www.linkedin.com/in/joaopdss/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/joaopdss/</a></p><p id="05bf" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">GitHub:<a class="ae kp" href="https://github.com/joaopdss" rel="noopener ugc nofollow" target="_blank">https://github.com/joaopdss</a></p></div></div>    
</body>
</html>