<html>
<head>
<title>Investigating Machine Learning Techniques to Improve Spec Tests — IV</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">研究机器学习技术以改进规格测试— IV</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/investigating-machine-learning-techniques-to-improve-spec-tests-iv-8155275d40e8?source=collection_archive---------16-----------------------#2022-04-22">https://blog.devgenius.io/investigating-machine-learning-techniques-to-improve-spec-tests-iv-8155275d40e8?source=collection_archive---------16-----------------------#2022-04-22</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><figure class="gl gn jl jm jn jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi jk"><img src="../Images/9b0f0d75d0bdadde154cc84cb4468e16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JBnySjd0yZV5FnuH.jpg"/></div></div></figure><h1 id="24ab" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">介绍</h1><p id="e7db" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">这是与人工智能实现相关的系列博文的一部分。如果你对故事的背景或情节感兴趣:</p><figure class="lr ls lt lu gt jo"><div class="bz fp l di"><div class="lv lw l"/></div></figure><p id="d3f4" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">本周我们将展示测试过程和模型的早期结果。我们将使用<a class="ae mc" href="https://serpapi.com/organic-results" rel="noopener ugc nofollow" target="_blank"> SerpApi 的 Google Organic Results Scraper API</a>进行数据收集。此外，您可以在<a class="ae mc" href="https://serpapi.com/playground?q=Coffee&amp;location=Austin%2C+Texas%2C+United+States&amp;gl=us&amp;hl=en&amp;no_cache=true&amp;newPara=lr+async+as_qdr" rel="noopener ugc nofollow" target="_blank">游乐场</a>查看我们将使用的更详细的数据。</p><figure class="lr ls lt lu gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi md"><img src="../Images/dcafeca9d7784de5a9822426937cac0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Artzv4nRE9Pe8H9O.png"/></div></div></figure><h1 id="e25b" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">培训用数据</h1><p id="a387" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">下面是我们存储在 json 文件中用于训练的数据的结构分解:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="71e7" class="mj jw in mf b gy mk ml l mm mn">[<br/>  { <br/>    "Key 1": Value_1,<br/>    "Key 2": Value_2,<br/>    "Key 3": Value_3,<br/>    "Key 4": [<br/>      "Value_1",<br/>      ...<br/>    ],<br/>    "Key 5": {<br/>      "Inner Key 1": Inner_Value_1,<br/>      ...<br/>  },<br/>  ...<br/>]</span></pre><p id="5f26" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">这里有一个例子:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="fa01" class="mj jw in mf b gy mk ml l mm mn">[<br/>  {<br/>    "position": 1,<br/>    "title": "Coffee - Wikipedia",<br/>    "link": "https://en.wikipedia.org/wiki/Coffee",<br/>    "displayed_link": "https://en.wikipedia.org › wiki › Coffee",<br/>    "snippet": "Coffee is a brewed drink prepared from roasted coffee beans, the seeds of berries from certain flowering plants in the Coffea genus. From the coffee fruit, ...",<br/>    "snippet_highlighted_words": [<br/>      "Coffee",<br/>      "coffee",<br/>      "coffee"<br/>    ],<br/>    ...<br/>  },<br/>  ...<br/>]</span></pre><p id="5a71" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">链接我们收集了来自谷歌的有机结果:<br/> <a class="ae mc" href="https://serpapi.com/playground?q=Tea&amp;location=Austin%2C+Texas%2C+United+States&amp;gl=us&amp;hl=en&amp;num=100&amp;newPara=lr+async+as_qdr" rel="noopener ugc nofollow" target="_blank">茶的链接(100 个结果左右)</a> <br/> <a class="ae mc" href="https://serpapi.com/playground?q=Coffee&amp;location=Austin%2C+Texas%2C+United+States&amp;gl=us&amp;hl=en&amp;num=100&amp;newPara=lr+async+as_qdr" rel="noopener ugc nofollow" target="_blank">咖啡的链接(100 个结果左右)</a></p><h1 id="c260" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">测试结构</h1><p id="77a4" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">我们已经在过去三周的博客文章中详细介绍了我们是如何训练数据的。今天，我们将通过计算训练精度来测试假设是否成立。</p><p id="4477" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">我们可以重用<code class="fe mo mp mq mf b">Train</code>和<code class="fe mo mp mq mf b">Database</code>类来创建示例，并使用以下代码行创建示例向量:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="cb9f" class="mj jw in mf b gy mk ml l mm mn">example_vector = Database.word_to_tensor example<br/>  example_vector.map! {|el| el = el.nil? ? 0: el}<br/>  example_vector = Train.extend_vector example_vector<br/>  weighted_example = Train.product example_vector</span></pre><p id="a342" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">这里是我们提供的字符串。Google Organic Results 中被转换为字符串的任何键的任何值都将是有效的示例。<br/>我们可以重用<code class="fe mo mp mq mf b">Database.word_to_tensor</code>来获得与我们的词汇表一致的字符串的矢量化版本。<br/>如果任何值是<code class="fe mo mp mq mf b">nil</code> (null)，在我们的词汇表中没有，它将被替换为<code class="fe mo mp mq mf b">0</code>，这是我们的<code class="fe mo mp mq mf b">&lt;unk&gt;</code>(未知)的值。然后，<br/> <code class="fe mo mp mq mf b">example_vector</code>应该扩展到最大字符串大小，以便使用<code class="fe mo mp mq mf b">1</code> s 进行计算。<br/> <code class="fe mo mp mq mf b">weighted_example</code>将是我们之前使用矢量化示例计算的<code class="fe mo mp mq mf b">@@weights</code>的乘积。从我们提供的示例来看，多维空间中该值的最近向量应该具有相同的键，或者它们的平均值应该引导我们找到相同的键。因此，在我们的例子中，如果我们提供的例子不是一个<code class="fe mo mp mq mf b">snippet</code>，那么围绕<code class="fe mo mp mq mf b">weighted_example</code>的最近向量平均应该给出<code class="fe mo mp mq mf b">less than 0.5</code>(它们的标识是<code class="fe mo mp mq mf b">0</code>和<code class="fe mo mp mq mf b">1</code>)。结论应该是<code class="fe mo mp mq mf b">the example isn't a snippet</code>。</p><p id="391b" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">我们使用多维空间的欧几里德距离公式来测量我们的示例与数据集中每个示例的距离:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="4adb" class="mj jw in mf b gy mk ml l mm mn">distances = []<br/>  vector_array.each_with_index do |comparison_vector, vector_index|<br/>    distances &lt;&lt; Train.euclidean_distance(comparison_vector, weighted_example)<br/>  end</span></pre><p id="ff27" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">我们取最小距离的指数(k 的许多倍):</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="2e94" class="mj jw in mf b gy mk ml l mm mn">indexes = []<br/>  k.times do <br/>    index = distances.index(distances.min)<br/>    indexes &lt;&lt; index<br/>    distances[index] = 1000000000<br/>  end</span></pre><p id="4455" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">然后，我们得到每个向量的真实身份:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="9e0d" class="mj jw in mf b gy mk ml l mm mn">predictions = []<br/>  indexes.each do |index|<br/>    predictions &lt;&lt; key_array[index].first.to_i<br/>  end</span></pre><p id="3207" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated"><code class="fe mo mp mq mf b">key_array</code>这里是每行第一项包含<code class="fe mo mp mq mf b">0</code>或<code class="fe mo mp mq mf b">1</code>的数组，第二项包含字符串。举个例子:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="78b7" class="mj jw in mf b gy mk ml l mm mn">[<br/>  ...<br/>  ["0", "https://www.coffeebean.com"],<br/>  ["1", "Born and brewed in Southern California since 1963, The Coffee Bean &amp; Tea Leaf® is passionate about connecting loyal customers with carefully handcrafted ..."],<br/>  ["0", "4"],<br/>  ...<br/>]</span></pre><p id="be29" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated"><code class="fe mo mp mq mf b">1</code>表示该项是片段，<code class="fe mo mp mq mf b">0</code>表示不是。</p><p id="9e98" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">让我们返回预测:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="a959" class="mj jw in mf b gy mk ml l mm mn">prediction = (predictions.sum/predictions.size).to_f<br/>  if prediction &lt; 0.5<br/>    puts "False - Item is not Snippet"<br/>    return 0<br/>  else<br/>    puts "True - Item is Snippet"<br/>    return 1<br/>  end</span></pre><p id="33a6" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">下面是完整的方法:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="9dab" class="mj jw in mf b gy mk ml l mm mn">def test example, k, vector_array, key_array<br/>  example_vector = Database.word_to_tensor example<br/>  example_vector.map! {|el| el = el.nil? ? 0: el}<br/>  example_vector = Train.extend_vector example_vector<br/>  weighted_example = Train.product example_vector</span><span id="631f" class="mj jw in mf b gy mr ml l mm mn">  distances = []<br/>  vector_array.each_with_index do |comparison_vector, vector_index|<br/>    distances &lt;&lt; Train.euclidean_distance(comparison_vector, weighted_example)<br/>  end</span><span id="6319" class="mj jw in mf b gy mr ml l mm mn">  indexes = []<br/>  k.times do <br/>    index = distances.index(distances.min)<br/>    indexes &lt;&lt; index<br/>    distances[index] = 1000000000<br/>  end</span><span id="f099" class="mj jw in mf b gy mr ml l mm mn">  predictions = []<br/>  indexes.each do |index|<br/>    predictions &lt;&lt; key_array[index].first.to_i<br/>  end</span><span id="04ec" class="mj jw in mf b gy mr ml l mm mn">  puts "Predictions: #{predictions}"</span><span id="9468" class="mj jw in mf b gy mr ml l mm mn">  prediction = (predictions.sum/predictions.size).to_f<br/>  if prediction &lt; 0.5<br/>    puts "False - Item is not Snippet"<br/>    return 0<br/>  else<br/>    puts "True - Item is Snippet"<br/>    return 1<br/>  end<br/>end</span></pre><h1 id="0cbb" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">使用 Google Organic Results for Snippet 测试</h1><p id="82a7" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">现在我们有了一个测试函数，让我们在例子中将代码片段与非代码片段分开:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="fd12" class="mj jw in mf b gy mk ml l mm mn">true_examples = key_array.map {|el| el = el.first == "1" ? el.second : nil}.compact<br/>false_examples = key_array.map {|el| el = el.first == "0" ? el.second : nil}.compact</span></pre><p id="39e7" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">这将使我们更容易计算。</p><p id="a64b" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">让我们声明一个空数组来收集预测，从非片段开始:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="ba50" class="mj jw in mf b gy mk ml l mm mn">predictions = []</span><span id="884e" class="mj jw in mf b gy mr ml l mm mn">false_examples.each do |example|<br/>  prediction = test example, 2, vector_array, key_array<br/>  predictions &lt;&lt; prediction<br/>end</span><span id="87d6" class="mj jw in mf b gy mr ml l mm mn">predictions.map! {|el| el = el == 1 ? 0 : 1}</span></pre><p id="abd2" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">既然我们知道这些例子都不是<code class="fe mo mp mq mf b">snippet</code>，那么任何给出<code class="fe mo mp mq mf b">1</code>的预测都将是错误的。因此，如果我们用错误的例子来测试我们的模型，然后将<code class="fe mo mp mq mf b">1</code> s 反转为<code class="fe mo mp mq mf b">0</code> s，将<code class="fe mo mp mq mf b">0</code> s 反转为<code class="fe mo mp mq mf b">1</code> s，我们就可以将它与我们的真实例子结合起来:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="d8a6" class="mj jw in mf b gy mk ml l mm mn">true_examples.each do |example|<br/>  prediction = test example, 2, vector_array, key_array<br/>  predictions &lt;&lt; prediction<br/>end</span></pre><p id="3146" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">现在我们已经填充了所需的数组:</p><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="682d" class="mj jw in mf b gy mk ml l mm mn">prediction_train_accuracy = predictions.sum.to_f / predictions.size.to_f</span><span id="25fe" class="mj jw in mf b gy mr ml l mm mn">puts "Prediction Accuracy for Training Set is: #{prediction_train_accuracy}"</span></pre><p id="2ceb" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">如果我们将<code class="fe mo mp mq mf b">1</code>的数量除以预测的数量，我们可以计算出准确性结果。</p><h1 id="a010" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">初步结果</h1><p id="652d" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">我们对前面提到的数据进行了完全相同的处理。片段的预测数为<code class="fe mo mp mq mf b">1065</code>，<code class="fe mo mp mq mf b">k</code>值为<code class="fe mo mp mq mf b">2</code>，<code class="fe mo mp mq mf b">n-gram</code>值为<code class="fe mo mp mq mf b">2</code>。</p><p id="8198" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">模型正确预测了<code class="fe mo mp mq mf b">872</code>次。这意味着训练精度为<code class="fe mo mp mq mf b">0.8187793427230047</code> ( <code class="fe mo mp mq mf b">%81.87</code>)。</p><p id="2608" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">这是一个很好的开始，随着更多的调整，以及用更大的数据集进行测试，最初的假设可能被证明是正确的。</p><h1 id="9590" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">完整代码</h1><pre class="lr ls lt lu gt me mf mg mh aw mi bi"><span id="b087" class="mj jw in mf b gy mk ml l mm mn">class Database<br/>  def initialize json_data, vocab = { "&lt;unk&gt;" =&gt; 0, "&lt;pad&gt;" =&gt; 1 }<br/>    super()<br/>    @@pattern_data = []<br/>    @@vocab = vocab<br/>  end</span><span id="718c" class="mj jw in mf b gy mr ml l mm mn">## Related to creating main database<br/>  def self.add_new_data_to_database json_data, csv_path = nil<br/>    json_data.each do |result|<br/>      recursive_hash_pattern result, ""<br/>    end</span><span id="8869" class="mj jw in mf b gy mr ml l mm mn">@@pattern_data = @@pattern_data.reject { |pattern| pattern.include? nil }.uniq.compact</span><span id="7a1b" class="mj jw in mf b gy mr ml l mm mn">path = "#{csv_path}master_database.csv"<br/>    File.write(path, @@pattern_data.map(&amp;:to_csv).join)<br/>  end</span><span id="7741" class="mj jw in mf b gy mr ml l mm mn">def self.element_pattern result, pattern<br/>    @@pattern_data.append([result, pattern].flatten)<br/>  end</span><span id="cfd5" class="mj jw in mf b gy mr ml l mm mn">def self.element_array_pattern result, pattern<br/>    result.each do |element|<br/>      element_pattern element, pattern<br/>    end<br/>  end</span><span id="03ba" class="mj jw in mf b gy mr ml l mm mn">def self.assign hash, key, pattern<br/>    if hash[key].is_a?(Hash)<br/>      if pattern.present?<br/>        pattern = "#{pattern}__#{key}"<br/>      else<br/>        pattern = "#{key}"<br/>      end</span><span id="1198" class="mj jw in mf b gy mr ml l mm mn">recursive_hash_pattern hash[key], pattern<br/>    elsif hash[key].present? &amp;&amp; hash[key].is_a?(Array) &amp;&amp; hash[key].first.is_a?(Hash)<br/>      if pattern.present?<br/>        pattern = "#{pattern}__#{key}__n"<br/>      else<br/>        pattern = "#{key}"<br/>      end</span><span id="f652" class="mj jw in mf b gy mr ml l mm mn">hash[key].each do |hash_inside_array|<br/>        recursive_hash_pattern hash_inside_array, pattern<br/>      end<br/>    elsif hash[key].present? &amp;&amp; hash[key].is_a?(Array)<br/>      if pattern.present?<br/>        pattern = "#{pattern}__n"<br/>      else<br/>        pattern = "#{key}"<br/>      end</span><span id="b708" class="mj jw in mf b gy mr ml l mm mn">element_array_pattern hash[key], pattern<br/>    else<br/>      if pattern.present?<br/>        pattern = "#{pattern}__#{key}"<br/>      else<br/>        pattern = "#{key}"<br/>      end</span><span id="8ba7" class="mj jw in mf b gy mr ml l mm mn">element_pattern hash[key], pattern<br/>    end<br/>  end<br/> <br/>  def self.recursive_hash_pattern hash, pattern<br/>    hash.keys.each do |key|<br/>      assign hash, key, pattern<br/>    end<br/>  end</span><span id="13cb" class="mj jw in mf b gy mr ml l mm mn">## Related to tokenizing<br/>  def self.default_dictionary_hash<br/>    {<br/>      /\"/ =&gt; "",<br/>      /\'/ =&gt; " \'  ",<br/>      /\./ =&gt; " . ",<br/>      /,/ =&gt; ", ",<br/>      /\!/ =&gt; " ! ",<br/>      /\?/ =&gt; " ? ",<br/>      /\;/ =&gt; " ",<br/>      /\:/ =&gt; " ",<br/>      /\(/ =&gt; " ( ",<br/>      /\)/ =&gt; " ) ",<br/>      /\// =&gt; " / ",<br/>      /\s+/ =&gt; " ",<br/>      /&lt;br \/&gt;/ =&gt; " , ",<br/>      /http/ =&gt; "http",<br/>      /https/ =&gt; " https ",<br/>    }<br/>  end</span><span id="d26e" class="mj jw in mf b gy mr ml l mm mn">def self.tokenizer word, dictionary_hash = default_dictionary_hash<br/>    word = word.downcase</span><span id="5b13" class="mj jw in mf b gy mr ml l mm mn">dictionary_hash.keys.each do |key|<br/>      word.sub!(key, dictionary_hash[key])<br/>    end</span><span id="9b75" class="mj jw in mf b gy mr ml l mm mn">word.split<br/>  end</span><span id="6a8f" class="mj jw in mf b gy mr ml l mm mn">def self.iterate_ngrams token_list, ngrams = 2<br/>    token_list.each do |token|<br/>      1.upto(ngrams) do |n|<br/>        permutations = (token_list.size - n + 1).times.map { |i| token_list[i...(i + n)] }<br/>        <br/>        permutations.each do |perm|<br/>          key = perm.join(" ")</span><span id="5f01" class="mj jw in mf b gy mr ml l mm mn">unless @@vocab.keys.include? key<br/>            @@vocab[key] = @@vocab.size<br/>          end<br/>        end<br/>      end<br/>    end<br/>  end</span><span id="ec50" class="mj jw in mf b gy mr ml l mm mn">def self.word_to_tensor word<br/>    token_list = tokenizer word<br/>    token_list.map {|token| @@vocab[token]}<br/>  end</span><span id="a0b2" class="mj jw in mf b gy mr ml l mm mn">## Related to creating key-specific databases <br/>  def self.create_key_specific_databases result_type = "organic_results", csv_path = nil, dictionary = nil, ngrams = nil, vocab_path = nil<br/>    keys, examples = create_keys_and_examples</span><span id="3f3d" class="mj jw in mf b gy mr ml l mm mn">keys.each do |key|<br/>      specific_pattern_data = []<br/>      @@pattern_data.each_with_index do |pattern, index|<br/>        word = pattern.first.to_s<br/>        <br/>        next if word.blank?</span><span id="cd4f" class="mj jw in mf b gy mr ml l mm mn">if dictionary.present?<br/>          token_list = tokenizer word, dictionary<br/>        else<br/>          token_list = tokenizer word<br/>        end</span><span id="f77b" class="mj jw in mf b gy mr ml l mm mn">if ngrams.present?<br/>          iterate_ngrams token_list, ngrams<br/>        else<br/>          iterate_ngrams token_list<br/>        end</span><span id="db0e" class="mj jw in mf b gy mr ml l mm mn">if key == pattern.second<br/>          specific_pattern_data &lt;&lt; [ 1, word ]<br/>        elsif (examples[key].to_s.to_i == examples[key]) &amp;&amp; word.to_i == word<br/>          next<br/>        elsif (examples[key].to_s.to_i == examples[key]) &amp;&amp; word.numeric?<br/>          specific_pattern_data &lt;&lt; [ 0, word ]<br/>        elsif examples[key].numeric? &amp;&amp; word.numeric?<br/>          next<br/>        elsif key.split("__").last == pattern.second.to_s.split("__").last<br/>          specific_pattern_data &lt;&lt; [ 1, word ]<br/>        else<br/>          specific_pattern_data &lt;&lt; [ 0, word ]<br/>        end<br/>      end</span><span id="d9ed" class="mj jw in mf b gy mr ml l mm mn">path = "#{csv_path}#{result_type}__#{key}.csv"<br/>      File.write(path, specific_pattern_data.map(&amp;:to_csv).join)<br/>    end</span><span id="fbc4" class="mj jw in mf b gy mr ml l mm mn">if vocab_path.present?<br/>      save_vocab vocab_path<br/>    else<br/>      save_vocab<br/>    end<br/>  end</span><span id="1934" class="mj jw in mf b gy mr ml l mm mn">def self.create_keys_and_examples<br/>    keys = @@pattern_data.map { |pattern| pattern.second }.uniq</span><span id="ea63" class="mj jw in mf b gy mr ml l mm mn">examples = {}<br/>    keys.each do |key|<br/>      examples[key] = @@pattern_data.find { |pattern| pattern.first.to_s if pattern.second == key }<br/>    end</span><span id="eef9" class="mj jw in mf b gy mr ml l mm mn">[keys, examples]<br/>  end</span><span id="816e" class="mj jw in mf b gy mr ml l mm mn">def self.numeric?<br/>    return true if self =~ /\A\d+\Z/<br/>    true if Float(self) rescue false<br/>  end</span><span id="c998" class="mj jw in mf b gy mr ml l mm mn">def self.save_vocab vocab_path = ""<br/>    path = "#{vocab_path}vocab.json"<br/>    vocab = JSON.parse(@@vocab.to_json)<br/>    File.write(path, JSON.pretty_generate(vocab))<br/>  end</span><span id="84ac" class="mj jw in mf b gy mr ml l mm mn">def self.read_vocab vocab_path<br/>    vocab = File.read vocab_path<br/>    @@vocab = JSON.parse(vocab)<br/>  end</span><span id="dbbb" class="mj jw in mf b gy mr ml l mm mn">def self.return_vocab<br/>    @@vocab<br/>  end<br/>end</span><span id="6fba" class="mj jw in mf b gy mr ml l mm mn">class Train<br/>  def initialize csv_path<br/>    @@csv_path = csv_path<br/>    @@vector_arr = []<br/>    @@word_arr = []<br/>    @@maximum_word_size = 100<br/>    @@weights = Vector[]<br/>    @@losses = []<br/>  end</span><span id="fc77" class="mj jw in mf b gy mr ml l mm mn">def self.read<br/>    @@word_arr = CSV.read(@@csv_path)<br/>    @@word_arr<br/>  end</span><span id="5f87" class="mj jw in mf b gy mr ml l mm mn">def self.define_training_set vectors<br/>    @@vector_arr = vectors<br/>  end</span><span id="ea79" class="mj jw in mf b gy mr ml l mm mn">def self.auto_define_maximum_size<br/>    @@maximum_word_size = @@vector_arr.map {|el| el.size}.max<br/>  end</span><span id="16e9" class="mj jw in mf b gy mr ml l mm mn">def self.extend_vector vector<br/>    vector_arr = vector.to_a<br/>    (@@maximum_word_size - vector.size).times { vector_arr &lt;&lt; 1 }<br/>    Vector.[](*vector_arr)<br/>  end</span><span id="713a" class="mj jw in mf b gy mr ml l mm mn">def self.extend_vectors<br/>    @@vector_arr.each_with_index do |vector, index|<br/>      @@vector_arr[index] = extend_vector vector<br/>    end<br/>  end</span><span id="d3f8" class="mj jw in mf b gy mr ml l mm mn">def self.initialize_weights<br/>    weights = []<br/>    @@maximum_word_size.times { weights &lt;&lt; 1.0 }<br/>    @@weights = Vector.[](*weights)<br/>  end</span><span id="f8c2" class="mj jw in mf b gy mr ml l mm mn">def self.config k = 1, lr = 0.001<br/>    [k, lr]<br/>  end</span><span id="3c6f" class="mj jw in mf b gy mr ml l mm mn">def self.product vector<br/>    @@weights.each_with_index do |weight, index|<br/>      vector[index] = weight * vector[index]<br/>    end</span><span id="5cc4" class="mj jw in mf b gy mr ml l mm mn">vector<br/>  end</span><span id="6041" class="mj jw in mf b gy mr ml l mm mn">def self.euclidean_distance vector_1, vector_2<br/>    subtractions = (vector_1 - vector_2).to_a<br/>    subtractions.map! {|sub| sub = sub*sub }<br/>    Math.sqrt(subtractions.sum)<br/>  end</span><span id="598b" class="mj jw in mf b gy mr ml l mm mn">def self.k_neighbors distances, k<br/>    indexes = []<br/>    (k).times do<br/>      min = distances.index(distances.min)<br/>      indexes &lt;&lt; min<br/>      distances[min] = distances.max + 1<br/>    end</span><span id="c97d" class="mj jw in mf b gy mr ml l mm mn">indexes<br/>  end</span><span id="6d18" class="mj jw in mf b gy mr ml l mm mn">def self.make_prediction indexes<br/>    predictions = []<br/>    indexes.each do |index|<br/>      predictions &lt;&lt; @@word_arr[index][0].to_i<br/>    end</span><span id="05e7" class="mj jw in mf b gy mr ml l mm mn">predictions.sum/predictions.size<br/>  end</span><span id="551a" class="mj jw in mf b gy mr ml l mm mn">def self.update_weights result, indexes, vector, lr<br/>    indexes.each do |index|<br/>      subtractions = @@vector_arr[index] - vector<br/>      subtractions.each_with_index do |sub, sub_index|<br/>        if result == 0 &amp;&amp; sub &gt;= 0<br/>          @@weights[sub_index] = @@weights[sub_index] + lr<br/>        elsif result == 0 &amp;&amp; sub &lt; 0<br/>          @@weights[sub_index] = @@weights[sub_index] - lr<br/>        elsif result == 1 &amp;&amp; sub &gt;= 0<br/>          @@weights[sub_index] = @@weights[sub_index] - lr<br/>        elsif result == 1 &amp;&amp; sub &lt; 0<br/>          @@weights[sub_index] = @@weights[sub_index] + lr<br/>        end<br/>      end<br/>    end<br/>  end</span><span id="c529" class="mj jw in mf b gy mr ml l mm mn">def self.mean_absolute_error real, indexes<br/>    errors = []<br/>    indexes.each do |index|<br/>      errors &lt;&lt; (@@word_arr[index][0].to_i - real).abs<br/>    end</span><span id="d899" class="mj jw in mf b gy mr ml l mm mn">(errors.sum/errors.size).to_f<br/>  end</span><span id="9153" class="mj jw in mf b gy mr ml l mm mn">def self.train vector, index<br/>    k, lr = config<br/>    vector = extend_vector vector<br/>    vector = product vector<br/>    <br/>    distances = []<br/>    @@vector_arr.each_with_index do |comparison_vector, vector_index|<br/>      if vector_index == index<br/>        distances &lt;&lt; 100000000<br/>      else<br/>        distances &lt;&lt; euclidean_distance(comparison_vector, vector)<br/>      end<br/>    end</span><span id="2a6d" class="mj jw in mf b gy mr ml l mm mn">indexes = k_neighbors distances, k<br/>    real = @@word_arr[index][0].to_i<br/>    prob_prediction = make_prediction indexes<br/>    prediction = prob_prediction &gt; 0.5 ? 1 : 0<br/>    result = real == prediction ? 1 : 0</span><span id="5217" class="mj jw in mf b gy mr ml l mm mn">update_weights result, indexes, vector, lr<br/>    loss = mean_absolute_error real, indexes<br/>    @@losses &lt;&lt; loss<br/>    <br/>    puts "Result : #{real}, Prediction: #{prediction}"<br/>    puts "Loss: #{loss}"</span><span id="cb19" class="mj jw in mf b gy mr ml l mm mn">prediction<br/>  end<br/>end</span><span id="e6da" class="mj jw in mf b gy mr ml l mm mn">json_path = "organic_results/example.json"<br/>json_data = File.read(json_path)<br/>json_data = JSON.parse(json_data)</span><span id="1b02" class="mj jw in mf b gy mr ml l mm mn">Database.new json_data<br/>## For training from scratch                     <br/>Database.add_new_data_to_database json_data, csv_path = "organic_results/"<br/>Database.create_key_specific_databases result_type = "organic_results", csv_path = "organic_results/"<br/>##</span><span id="0499" class="mj jw in mf b gy mr ml l mm mn">Database.read_vocab "vocab.json"</span><span id="9e3f" class="mj jw in mf b gy mr ml l mm mn">## We will use an iteration of csvs within a specific path in the end<br/>csv_path = "organic_results/organic_results__snippet.csv"</span><span id="fd3a" class="mj jw in mf b gy mr ml l mm mn">Train.new csv_path<br/>key_array = Train.read</span><span id="6006" class="mj jw in mf b gy mr ml l mm mn">vector_array = key_array.map { |word| Database.word_to_tensor word[1] }<br/>Train.define_training_set vector_array<br/>Train.auto_define_maximum_size<br/>Train.extend_vectors<br/>Train.initialize_weights<br/>Train.config k = 2</span><span id="ec8a" class="mj jw in mf b gy mr ml l mm mn">vector_array.each_with_index do |vector, index|<br/>  Train.train vector, index<br/>end</span><span id="bb3e" class="mj jw in mf b gy mr ml l mm mn">def test example, k, vector_array, key_array<br/>  example_vector = Database.word_to_tensor example<br/>  example_vector.map! {|el| el = el.nil? ? 0: el}<br/>  example_vector = Train.extend_vector example_vector<br/>  weighted_example = Train.product example_vector</span><span id="409c" class="mj jw in mf b gy mr ml l mm mn">distances = []<br/>  vector_array.each_with_index do |comparison_vector, vector_index|<br/>    distances &lt;&lt; Train.euclidean_distance(comparison_vector, weighted_example)<br/>  end</span><span id="16d1" class="mj jw in mf b gy mr ml l mm mn">indexes = []<br/>  k.times do <br/>    index = distances.index(distances.min)<br/>    indexes &lt;&lt; index<br/>    distances[index] = 1000000000<br/>  end</span><span id="fc78" class="mj jw in mf b gy mr ml l mm mn">predictions = []<br/>  indexes.each do |index|<br/>    predictions &lt;&lt; key_array[index].first.to_i<br/>  end</span><span id="8408" class="mj jw in mf b gy mr ml l mm mn">puts "Predictions: #{predictions}"</span><span id="4d73" class="mj jw in mf b gy mr ml l mm mn">prediction = (predictions.sum/predictions.size).to_f<br/>  if prediction &lt; 0.5<br/>    puts "False - Item is not Snippet"<br/>    return 0<br/>  else<br/>    puts "True - Item is Snippet"<br/>    return 1<br/>  end<br/>end</span><span id="b7ec" class="mj jw in mf b gy mr ml l mm mn">true_examples = key_array.map {|el| el = el.first == "1" ? el.second : nil}.compact<br/>false_examples = key_array.map {|el| el = el.first == "0" ? el.second : nil}.compact</span><span id="bde5" class="mj jw in mf b gy mr ml l mm mn">predictions = []</span><span id="300e" class="mj jw in mf b gy mr ml l mm mn">false_examples.each do |example|<br/>  prediction = test example, 2, vector_array, key_array<br/>  predictions &lt;&lt; prediction<br/>end</span><span id="472a" class="mj jw in mf b gy mr ml l mm mn">predictions.map! {|el| el = el == 1 ? 0 : 1}</span><span id="5aee" class="mj jw in mf b gy mr ml l mm mn">true_examples.each do |example|<br/>  prediction = test example, 2, vector_array, key_array<br/>  predictions &lt;&lt; prediction<br/>end</span><span id="04f6" class="mj jw in mf b gy mr ml l mm mn">prediction_train_accuracy = predictions.sum.to_f / predictions.size.to_f</span><span id="3e02" class="mj jw in mf b gy mr ml l mm mn">puts "Prediction Accuracy for Training Set is: #{prediction_train_accuracy}"</span><span id="b1c5" class="mj jw in mf b gy mr ml l mm mn">end</span></pre><h1 id="3ae2" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">结论</h1><p id="7bba" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">我要为博客文章晚了一天向读者道歉。两周后，我们将展示如何存储它们以供实现，并进一步调整以提高准确性。</p><p id="6fb9" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">这个项目的最终目标是创建一个<code class="fe mo mp mq mf b">open-source gem</code>，每个人都可以在代码中使用 JSON 数据结构来实现它。</p><p id="3dfd" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated">我要感谢读者的关注，感谢才华横溢的塞尔帕皮人在艰难时刻创造奇迹，感谢他们的支持。</p></div><div class="ab cl ms mt hr mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ig ih ii ij ik"><p id="f5f9" class="pw-post-body-paragraph kt ku in kv b kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq ig bi translated"><em class="mz">原载于 2022 年 4 月 21 日</em><a class="ae mc" href="https://serpapi.com/blog/investigating-machine-learning-techniques-to-improve-spec-tests-iv/" rel="noopener ugc nofollow" target="_blank"><em class="mz">https://serpapi.com</em></a><em class="mz">。</em></p></div></div>    
</body>
</html>