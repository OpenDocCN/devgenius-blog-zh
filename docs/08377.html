<html>
<head>
<title>How to fine-tune Swin Transformer using Huggingface</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用 Huggingface 微调 Swin 变压器</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/how-to-fine-tune-swin-transformer-using-huggingface-83b5a1e5b51d?source=collection_archive---------1-----------------------#2022-06-10">https://blog.devgenius.io/how-to-fine-tune-swin-transformer-using-huggingface-83b5a1e5b51d?source=collection_archive---------1-----------------------#2022-06-10</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><div class=""><h2 id="788f" class="pw-subtitle-paragraph jk im in bd b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb dk translated">使用训练器 API 微调预训练的 SOTA 模型</h2></div><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi kc"><img src="../Images/5296240f234f796729d75718947c6d50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*clny9mG-rM4N7aBDenJt9A.jpeg"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">詹姆斯·哈里森在 Unsplash 上的照片</figcaption></figure><p id="be42" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">CNN 统治计算机视觉领域的日子已经一去不复返了，现在基于变形金刚的模型比以往任何时候都更能展示 SOTA 在许多任务上的表现。</p><p id="4141" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">在本教程中，我将向你展示如何微调其中一个模型，用于图像分类的<a class="ae ks" href="https://arxiv.org/abs/2103.14030" rel="noopener ugc nofollow" target="_blank"> Swin Transformer </a>。我将只使用<a class="ae ks" href="https://huggingface.co" rel="noopener ugc nofollow" target="_blank"> Huggingface </a>平台在<a class="ae ks" href="https://huggingface.co/datasets/food101" rel="noopener ugc nofollow" target="_blank"> Foods101 </a>数据集上进行，更具体地说，是使用 transformers 和 datasets 库。</p></div><div class="ab cl lp lq hr lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ig ih ii ij ik"><p id="8d14" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated"><strong class="kv io">备注:</strong></p><ol class=""><li id="4a73" class="lw lx in kv b kw kx kz la lc ly lg lz lk ma lo mb mc md me bi translated">如果您想在继续之前亲自测试该模型，可以找到<a class="ae ks" href="https://huggingface.co/aspis/swin-finetuned-food101" rel="noopener ugc nofollow" target="_blank">(此处)</a>。</li><li id="7230" class="lw lx in kv b kw mf kz mg lc mh lg mi lk mj lo mb mc md me bi translated">要理解本教程，你需要具备 python 和迁移学习的中级知识。</li><li id="6849" class="lw lx in kv b kw mf kz mg lc mh lg mi lk mj lo mb mc md me bi translated">如果你想知道更多关于 Swin 变压器的工作原理，<a class="ae ks" href="https://medium.com/towards-data-science/a-comprehensive-guide-to-swin-transformer-64965f89d14c" rel="noopener">这篇伟大的文章</a>深入解释了它。</li><li id="dc6d" class="lw lx in kv b kw mf kz mg lc mh lg mi lk mj lo mb mc md me bi translated">如果你只是想要完整的代码，可以在这个 Google Colab 笔记本里找到<a class="ae ks" href="https://colab.research.google.com/drive/15VROFR3wY56ubXh31iUR3Oa54-yGg2L8?usp=sharing" rel="noopener ugc nofollow" target="_blank">(这里)</a>。</li></ol><h2 id="4c55" class="mk ml in bd mm mn mo dn mp mq mr dp ms lc mt mu mv lg mw mx my lk mz na nb nc bi translated">总结:</h2><ol class=""><li id="a3e6" class="lw lx in kv b kw nd kz ne lc nf lg ng lk nh lo mb mc md me bi translated">步骤 1:加载和预处理数据。</li><li id="88f1" class="lw lx in kv b kw mf kz mg lc mh lg mi lk mj lo mb mc md me bi translated">步骤 2:初始化模型。</li><li id="3817" class="lw lx in kv b kw mf kz mg lc mh lg mi lk mj lo mb mc md me bi translated">第三步:培训和评估。</li></ol></div><div class="ab cl lp lq hr lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ig ih ii ij ik"><h2 id="7f92" class="mk ml in bd mm mn mo dn mp mq mr dp ms lc mt mu mv lg mw mx my lk mz na nb nc bi translated">步骤 1:加载和预处理数据。</h2><p id="c474" class="pw-post-body-paragraph kt ku in kv b kw nd jo ky kz ne jr lb lc ni le lf lg nj li lj lk nk lm ln lo ig bi translated">本教程中使用的数据集是<a class="ae ks" href="https://huggingface.co/datasets/food101" rel="noopener ugc nofollow" target="_blank"> Foods101 数据集</a>，它已经在<a class="ae ks" href="https://huggingface.co/docs/datasets/index" rel="noopener ugc nofollow" target="_blank"> Huggingface 的 datasets </a>库中可用，但在自定义数据集上执行此任务将是直接的，您只需有一个 csv 文件，其列的格式为:[PIL 图像|标签]，并使用 datasets 库加载它。</p><p id="2fa0" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">foods101 数据集是一个为图像分类而设计的数据集，它由 101 类食物的 101000 张图片组成，包括寿司、草莓酥饼、马卡龙等等。</p><p id="4c27" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">为了加载数据，我们只需使用<a class="ae ks" href="https://huggingface.co/docs/datasets/loading" rel="noopener ugc nofollow" target="_blank"> load_dataset </a>函数，并可视化数据集的结构、示例图像和所有可用的标签</p><figure class="kd ke kf kg gt kh"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="0697" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">但是我们不能只是将原始图像输入到我们的模型中，还需要一些预处理步骤，比如调整图像的大小和归一化，直到我们得到模型作为输入接收的像素值。为此，我们将使用 transformers 库中提供的该模型的内置特征提取器，然后将其批量应用于我们数据集中的图像:</p><figure class="kd ke kf kg gt kh"><div class="bz fp l di"><div class="nl nm l"/></div></figure><h2 id="2066" class="mk ml in bd mm mn mo dn mp mq mr dp ms lc mt mu mv lg mw mx my lk mz na nb nc bi translated">步骤 2:初始化模型。</h2><p id="fb83" class="pw-post-body-paragraph kt ku in kv b kw nd jo ky kz ne jr lb lc ni le lf lg nj li lj lk nk lm ln lo ig bi translated">首先，我们需要创建数据排序器，它将负责从数据集中的示例列表创建批处理:</p><figure class="kd ke kf kg gt kh"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="8c77" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">之后，我们需要定义我们将用来评估我们的模型的度量，这里使用的度量是准确性，因为这是图像分类任务的满意度量。</p><figure class="kd ke kf kg gt kh"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="8e70" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">现在，我们使用 transformers 中的 SwinForImageClassification 类来定义模型:</p><figure class="kd ke kf kg gt kh"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="6236" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">我们根据数据集设置标签，并使用标签列表定义 id(整数)到标签(字符串)的交换。</p><p id="66c8" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">由于该模型是在 Imagenet 1k 数据集上预先训练的，因此<code class="fe nn no np nq b">ignore_mismatched_sizes = True`</code>参数是必需的，这意味着它预期预测该数据集中 1000 个标签中的一个，而不是我们的 101 个标签，但是通过将该参数设置为<code class="fe nn no np nq b">True`</code>,我们告诉模型忽略标签数量的不匹配。</p><h2 id="a875" class="mk ml in bd mm mn mo dn mp mq mr dp ms lc mt mu mv lg mw mx my lk mz na nb nc bi translated">第三步:培训和评估。</h2><p id="efe2" class="pw-post-body-paragraph kt ku in kv b kw nd jo ky kz ne jr lb lc ni le lf lg nj li lj lk nk lm ln lo ig bi translated">下一步包括定义训练参数和训练器对象，以便我们可以训练我们的模型:</p><figure class="kd ke kf kg gt kh"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="1dde" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">我们定义了基本但非常重要的训练参数，如学习速度、批量、热身步骤等等。</p><p id="42d3" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">代码中值得注意的几行:</p><p id="483b" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated"><code class="fe nn no np nq b">remove_unused_columns = False`</code>是必要的，因为我们需要 image 列来创建模型的输入(pixel_values)，但是因为这个列本身没有被模型使用，所以我们需要确保它没有被删除。</p><p id="b2e0" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">使用<code class="fe nn no np nq b">push_to_hub = True`</code>线，在训练结束后，模型被自动推送到<a class="ae ks" href="https://huggingface.co/models" rel="noopener ugc nofollow" target="_blank"> Huggingface 的模型中枢</a>。</p><p id="91e3" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">定义参数后，我们用之前编码的函数和我们定义的参数实例化一个训练器对象。</p><p id="a93d" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">对于下一部分，我们需要训练模型并评估验证集的结果:</p><figure class="kd ke kf kg gt kh"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="cec5" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">现在剩下要做的就是等待训练结束，检查结果，并在任何你想要的时候用<a class="ae ks" href="https://huggingface.co/docs/api-inference/index" rel="noopener ugc nofollow" target="_blank">推理 API </a>来使用它！</p></div><div class="ab cl lp lq hr lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ig ih ii ij ik"><p id="a6fe" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">我希望这篇教程能帮助那些想用一种简单的方法得到好的结果的人，使用 SOTA 变换模型进行图像分类，使用非常简单的训练器 API 和 Huggingface 提供的强大的预训练模型。</p></div><div class="ab cl lp lq hr lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ig ih ii ij ik"><h2 id="5a95" class="mk ml in bd mm mn mo dn mp mq mr dp ms lc mt mu mv lg mw mx my lk mz na nb nc bi translated">参考</h2><p id="6af8" class="pw-post-body-paragraph kt ku in kv b kw nd jo ky kz ne jr lb lc ni le lf lg nj li lj lk nk lm ln lo ig bi translated">[1]<a class="ae ks" href="https://arxiv.org/abs/2103.14030" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2103.14030</a></p><p id="b4be" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">[2]<a class="ae ks" href="https://huggingface.co/transformers/v4.1.1/examples.html" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/transformers/v4.1.1/examples.html</a></p><p id="79db" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">[3]https://huggingface.co/docs<a class="ae ks" href="https://huggingface.co/docs" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>