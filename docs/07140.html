<html>
<head>
<title>DeepGlobe Road Extraction — Challenge</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">DeepGlobe 道路提取—挑战</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/deepglobe-road-extraction-challenge-1ae101966d24?source=collection_archive---------4-----------------------#2022-03-01">https://blog.devgenius.io/deepglobe-road-extraction-challenge-1ae101966d24?source=collection_archive---------4-----------------------#2022-03-01</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><p id="4599" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">端到端深度学习案例研究</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b61aa45a289497b9d813cf689a0e15a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lo1pU5ivH4Ti8qEL"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">Jaromír Kavan 在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h1 id="8725" class="kz la in bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">介绍</h1><p id="dc7a" class="pw-post-body-paragraph jk jl in jm b jn lx jp jq jr ly jt ju jv lz jx jy jz ma kb kc kd mb kf kg kh ig bi translated">地球科学和遥感学会是学习和贡献地理空间科学的知名社区之一，它赞助了 2018 年的 DeepGlobe 机器视觉挑战赛，其中包括对地球卫星图像的深度分析。</p><p id="4c1a" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">三大挑战是-</p><ul class=""><li id="8644" class="mc md in jm b jn jo jr js jv me jz mf kd mg kh mh mi mj mk bi translated">道路提取</li><li id="7ad0" class="mc md in jm b jn ml jr mm jv mn jz mo kd mp kh mh mi mj mk bi translated">建筑物检测</li><li id="2aa8" class="mc md in jm b jn ml jr mm jv mn jz mo kd mp kh mh mi mj mk bi translated">土地覆盖分类</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/03bc3ab6be2464a01744c38eb4df0339.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*SuSUo1bOEElJaBay.png"/></div></figure><p id="8af6" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">作为其中的一部分，我提出了道路提取的问题，因为道路在交通运输、交通管理、城市规划、道路监控、GPS 导航等各个方面都是至关重要的部分。</p><blockquote class="mr ms mt"><p id="6015" class="jk jl mu jm b jn jo jp jq jr js jt ju mv jw jx jy mw ka kb kc mx ke kf kg kh ig bi translated">DeepGlobe 的挑战纯粹是基于研究的，专注于真正的问题。</p></blockquote><h1 id="02a1" class="kz la in bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">DL 问题公式</h1><h2 id="d167" class="my la in bd lb mz na dn lf nb nc dp lj jv nd ne ln jz nf ng lr kd nh ni lv nj bi translated">数据概述</h2><ol class=""><li id="1370" class="mc md in jm b jn lx jr ly jv nk jz nl kd nm kh nn mi mj mk bi translated">来源→<a class="ae ky" href="https://competitions.codalab.org/competitions/18467" rel="noopener ugc nofollow" target="_blank">https://competitions.codalab.org/competitions/18467</a></li><li id="06a2" class="mc md in jm b jn ml jr mm jv mn jz mo kd mp kh nn mi mj mk bi translated">总的来说，我们有<code class="fe no np nq nr b">14796</code>张图片。其中</li></ol><ul class=""><li id="6883" class="mc md in jm b jn jo jr js jv me jz mf kd mg kh mh mi mj mk bi translated"><code class="fe no np nq nr b">6226</code> →训练卫星图像</li><li id="3d43" class="mc md in jm b jn ml jr mm jv mn jz mo kd mp kh mh mi mj mk bi translated"><code class="fe no np nq nr b">6226</code> →训练掩模图像</li><li id="a69c" class="mc md in jm b jn ml jr mm jv mn jz mo kd mp kh mh mi mj mk bi translated"><code class="fe no np nq nr b">1243</code> →验证卫星图像</li><li id="03a4" class="mc md in jm b jn ml jr mm jv mn jz mo kd mp kh mh mi mj mk bi translated"><code class="fe no np nq nr b">1101</code> →测试卫星图像</li></ul><p id="b82e" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">3.验证和测试数据集不包含各自的掩模图像。这是我们需要预测的事情。</p><h2 id="db67" class="my la in bd lb mz na dn lf nb nc dp lj jv nd ne ln jz nf ng lr kd nh ni lv nj bi translated">问题类型</h2><ol class=""><li id="692e" class="mc md in jm b jn lx jr ly jv nk jz nl kd nm kh nn mi mj mk bi translated">如果我们观察面具，有<code class="fe no np nq nr b">2</code>类。因此，这是一个二值图像分割任务。</li><li id="237a" class="mc md in jm b jn ml jr mm jv mn jz mo kd mp kh nn mi mj mk bi translated">这个任务是一个计算机视觉任务，其中我们正在处理图像(卫星图像)。</li></ol><h2 id="6666" class="my la in bd lb mz na dn lf nb nc dp lj jv nd ne ln jz nf ng lr kd nh ni lv nj bi translated">绩效指标</h2><p id="9e9e" class="pw-post-body-paragraph jk jl in jm b jn lx jp jq jr ly jt ju jv lz jx jy jz ma kb kc kd mb kf kg kh ig bi translated">因为这是一个图像分割任务，我们坚持的标准是-</p><ol class=""><li id="2517" class="mc md in jm b jn jo jr js jv me jz mf kd mg kh nn mi mj mk bi translated"><strong class="jm io"> IoU </strong>得分——预测分割和基础事实之间的重叠面积除以预测分割和基础事实之间的联合面积。</li></ol><ul class=""><li id="0f25" class="mc md in jm b jn jo jr js jv me jz mf kd mg kh mh mi mj mk bi translated"><code class="fe no np nq nr b">0</code> <strong class="jm io"> IoU </strong>表示预测分割和地面实况之间没有重叠。</li><li id="fe79" class="mc md in jm b jn ml jr mm jv mn jz mo kd mp kh mh mi mj mk bi translated"><code class="fe no np nq nr b">1</code> <strong class="jm io"> IoU </strong>表示预测分割和地面真实完全相同。</li></ul><p id="378c" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">2.<strong class="jm io">准确度</strong> —它是正确预测与输入样本总数的比率。这里的一个警告是，我们需要有相同数量的类来考虑这个度量。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/13ee29db02e9e7478e50aa2a8a7052ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*MwohreZ71Sn_ouQM.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">来源→<a class="ae ky" href="https://jovian.ai/outlink?url=http%3A%2F%2Fpyimagesearch.com" rel="noopener ugc nofollow" target="_blank">pyimagesearch.com</a></figcaption></figure><h2 id="fba9" class="my la in bd lb mz na dn lf nb nc dp lj jv nd ne ln jz nf ng lr kd nh ni lv nj bi translated">数据下载</h2><ol class=""><li id="1980" class="mc md in jm b jn lx jr ly jv nk jz nl kd nm kh nn mi mj mk bi translated">数据集内存消耗在<code class="fe no np nq nr b">4GB</code>左右。我们可以通过使用 Kaggle APIs 或 CURL WGET chrome 扩展来轻松下载这个数据集，与常规下载相比，这需要更少的时间。</li><li id="0ed1" class="mc md in jm b jn ml jr mm jv mn jz mo kd mp kh nn mi mj mk bi translated">为了方便，我已经把它下载到我的系统里了。提取文件后的数据结构如下。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/93c541ad8ce69e10d9518f3c078853c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:348/0*WQtEFw55QvI6EJdw"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</figcaption></figure><p id="6a3f" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">3.<code class="fe no np nq nr b">metadata.csv</code>文件包含所有训练、验证和测试集的图像路径。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h1 id="599f" class="kz la in bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">探索性数据分析</h1><ol class=""><li id="6f12" class="mc md in jm b jn lx jr ly jv nk jz nl kd nm kh nn mi mj mk bi translated">原来，每个图像的大小是<code class="fe no np nq nr b">(1024, 1024)</code>。如果我们考虑这个尺寸来训练模型，它将会有更多可训练的参数。我们需要确保图像尺寸小，并且具有一致性。</li><li id="578f" class="mc md in jm b jn ml jr mm jv mn jz mo kd mp kh nn mi mj mk bi translated">还提到一些训练掩模不是二进制图像。二进制图像是像素为<code class="fe no np nq nr b">0</code>或<code class="fe no np nq nr b">255</code>的图像。为了保持一致性，我们需要在<code class="fe no np nq nr b">OpenCV</code>包的帮助下对训练掩码进行二值化。</li></ol><h2 id="8183" class="my la in bd lb mz na dn lf nb nc dp lj jv nd ne ln jz nf ng lr kd nh ni lv nj bi translated">二值化</h2><p id="04fc" class="pw-post-body-paragraph jk jl in jm b jn lx jp jq jr ly jt ju jv lz jx jy jz ma kb kc kd mb kf kg kh ig bi translated">想了解更多关于图像二值化的知识，可以随时查看我的<a class="ae ky" href="https://msameeruddin.hashnode.dev/binarization-of-image-using-numpy" rel="noopener ugc nofollow" target="_blank">博客</a>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="2eea" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">输出如下。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="08b7" class="my la in bd lb mz na dn lf nb nc dp lj jv nd ne ln jz nf ng lr kd nh ni lv nj bi translated">图像大小调整</h2><p id="e764" class="pw-post-body-paragraph jk jl in jm b jn lx jp jq jr ly jt ju jv lz jx jy jz ma kb kc kd mb kf kg kh ig bi translated">我们想要的图像的理想形状是<code class="fe no np nq nr b">(256, 256)</code>。我们需要调整训练集、验证集和测试集中所有图像的大小。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><blockquote class="mr ms mt"><p id="3714" class="jk jl mu jm b jn jo jp jq jr js jt ju mv jw jx jy mw ka kb kc mx ke kf kg kh ig bi translated">一些从业者也认为图像的形状是<code class="fe no np nq nr b">(128, 128)</code>。</p></blockquote><h2 id="2d7e" class="my la in bd lb mz na dn lf nb nc dp lj jv nd ne ln jz nf ng lr kd nh ni lv nj bi translated">训练图像</h2><p id="6c1a" class="pw-post-body-paragraph jk jl in jm b jn lx jp jq jr ly jt ju jv lz jx jy jz ma kb kc kd mb kf kg kh ig bi translated">让我们设想一个训练数据的样本，它包括卫星图像及其各自的掩模图像。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="8454" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">通过观察这个样本数据，我们可以知道这个任务仅限于提取清晰可见的较大路径。</p><h2 id="a8c8" class="my la in bd lb mz na dn lf nb nc dp lj jv nd ne ln jz nf ng lr kd nh ni lv nj bi translated">验证图像</h2><p id="3df1" class="pw-post-body-paragraph jk jl in jm b jn lx jp jq jr ly jt ju jv lz jx jy jz ma kb kc kd mb kf kg kh ig bi translated">如果有验证蒙版图像就更好了，这样就可以更容易地跟踪模型的性能。不幸的是，我们没有得到掩模图像的验证数据。</p><blockquote class="mr ms mt"><p id="d6c5" class="jk jl mu jm b jn jo jp jq jr js jt ju mv jw jx jy mw ka kb kc mx ke kf kg kh ig bi translated">为了补贴这个问题，我们可以把训练数据的<code class="fe no np nq nr b">1%</code>作为验证，训练模型。</p></blockquote><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="66b9" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">这个样本集混合了较大的路径和较细的路径。</p><h2 id="fa2f" class="my la in bd lb mz na dn lf nb nc dp lj jv nd ne ln jz nf ng lr kd nh ni lv nj bi translated">测试图像</h2><p id="1a3f" class="pw-post-body-paragraph jk jl in jm b jn lx jp jq jr ly jt ju jv lz jx jy jz ma kb kc kd mb kf kg kh ig bi translated">测试数据集不包含目标或掩模图像。这是我们需要预测的事情。让我们同样想象一下。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="6613" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">这个样本集混合了较大的路径和较细的路径。</p><blockquote class="mr ms mt"><p id="f985" class="jk jl mu jm b jn jo jp jq jr js jt ju mv jw jx jy mw ka kb kc mx ke kf kg kh ig bi translated">这结束了我们的 EDA。不过，如果你想知道所有代码的完整细节，你可以查看我在 Jovian 平台上托管的<a class="ae ky" href="https://jovian.ai/msameeruddin/00-cs2-basic-eda" rel="noopener ugc nofollow" target="_blank">笔记本</a>。</p></blockquote><h1 id="c3e8" class="kz la in bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">迁移学习</h1><p id="0b87" class="pw-post-body-paragraph jk jl in jm b jn lx jp jq jr ly jt ju jv lz jx jy jz ma kb kc kd mb kf kg kh ig bi translated">迁移学习是 ML 和 DL 问题的一部分，其中在解决一个问题时训练的模型知识被存储，并进一步用于解决另一个非常相似的问题。</p><p id="5a1f" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">迁移学习的主要优点是我们不必从头开始训练模型，而是使用预先训练好的模型。Google 的 Tensorflow 是一个用于实现深度学习模型的便捷库。它还包括各种预先训练的模型，这些模型可以通过对模型架构的轻微调整来解决任何问题陈述。</p><p id="a509" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">我们把这个建模(迁移学习)部分分成<code class="fe no np nq nr b">2</code>个方面。</p><ul class=""><li id="7ceb" class="mc md in jm b jn jo jr js jv me jz mf kd mg kh mh mi mj mk bi translated"><a class="ae ky" href="https://jovian.ai/msameeruddin/01-cs2-modeling-main#C11" rel="noopener ugc nofollow" target="_blank">没有增强</a></li><li id="6921" class="mc md in jm b jn ml jr mm jv mn jz mo kd mp kh mh mi mj mk bi translated"><a class="ae ky" href="https://jovian.ai/msameeruddin/01-cs2-modeling-main#C75" rel="noopener ugc nofollow" target="_blank">增强</a></li></ul><h2 id="0305" class="my la in bd lb mz na dn lf nb nc dp lj jv nd ne ln jz nf ng lr kd nh ni lv nj bi translated">没有增加</h2><p id="e97a" class="pw-post-body-paragraph jk jl in jm b jn lx jp jq jr ly jt ju jv lz jx jy jz ma kb kc kd mb kf kg kh ig bi translated"><strong class="jm io"> ResNet34 </strong></p><p id="4ac8" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">下面的输出是验证数据预测。最右边的图像是预测遮罩，我们可以观察到，对于那些包含较大路径的图像，模型能够提取路径，但效率不如所需。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="95f9" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">下面的输出是测试数据预测。右边的图像是预测遮罩。通常，该模型只识别较大的路径，而不识别较细的路径。我们还可以看到一些已经被预测的不完整路径。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="796f" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io"> VGG16 </strong></p><p id="ebfa" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">下面的输出是验证数据预测。最右边的图像是预测掩码，我们可以观察到其性能与之前的(<code class="fe no np nq nr b">ResNet34</code>)模型非常相似。有灌木覆盖的路径的复杂模式无法正确识别。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="1359" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">下面的输出是测试数据预测。右边的图像是预测遮罩。通常，该模型只识别较大的路径，而不识别较细的路径。我们还可以看到一些已经被预测的不完整路径。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="5d33" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io">移动互联网</strong></p><p id="fc43" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">下面的输出是验证数据预测。最右边的图像是预测遮罩，我们可以观察到，对于那些包含较大路径的图像，模型能够提取路径，但效率不如所需。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="0379" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">下面的输出是测试数据预测。右边的图像是预测遮罩。与上述以前的型号相比，这种型号的性能没有达到标准。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="f894" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io">盗梦空间</strong></p><p id="6289" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">下面的输出是验证数据预测。最右边的图像是预测遮罩，我们可以观察到，对于那些包含较大路径的图像，模型能够提取路径，但效率不如所需。</p><p id="ebbb" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">对于复杂的模式，该模型表现不佳。但它在识别清晰的较薄图案方面做得很好。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="e5f0" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">下面的输出是测试数据预测。右边的图像是预测遮罩。对于某些模式来说，它做得很好，这是无法通过<code class="fe no np nq nr b">ResNet34</code>或<code class="fe no np nq nr b">VGG16</code>识别的。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="3aab" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io"> ResNet50 </strong></p><p id="bc29" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">下面的输出是验证数据预测。最右边的图像是预测遮罩。它只能提取看起来非常清晰的较大路径。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="53b9" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">测试数据预测。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="0421" class="my la in bd lb mz na dn lf nb nc dp lj jv nd ne ln jz nf ng lr kd nh ni lv nj bi translated">增大</h2><blockquote class="mr ms mt"><p id="9f4b" class="jk jl mu jm b jn jo jp jq jr js jt ju mv jw jx jy mw ka kb kc mx ke kf kg kh ig bi translated">我通过稍微增加数据来训练相同的模型列表。结果没有达到标准。</p></blockquote><h2 id="9b28" class="my la in bd lb mz na dn lf nb nc dp lj jv nd ne ln jz nf ng lr kd nh ni lv nj bi translated">模型性能</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/7e1a21bf57db690414529267fcbe991b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9W49xcQ_CC4w4jd0.png"/></div></div></figure><ol class=""><li id="9dab" class="mc md in jm b jn jo jr js jv me jz mf kd mg kh nn mi mj mk bi translated">比较结果以选择最佳模型。</li><li id="ed38" class="mc md in jm b jn ml jr mm jv mn jz mo kd mp kh nn mi mj mk bi translated">与原始数据(没有增加)相比，增加数据的结果不太好。显然，通过检查各种型号的性能，可以注意到这一点。</li><li id="a2b0" class="mc md in jm b jn ml jr mm jv mn jz mo kd mp kh nn mi mj mk bi translated">事实上，为扩充数据获得的掩码不如为原始(无扩充)数据获得的掩码清晰。</li><li id="fe2f" class="mc md in jm b jn ml jr mm jv mn jz mo kd mp kh nn mi mj mk bi translated">因此，考虑已经在扩充数据上训练的模型不是有效的决定。</li><li id="f5cd" class="mc md in jm b jn ml jr mm jv mn jz mo kd mp kh nn mi mj mk bi translated">现在剩下的唯一选择是从已经根据原始(无增强)数据训练的其他模型中选择最佳模型。</li><li id="2adc" class="mc md in jm b jn ml jr mm jv mn jz mo kd mp kh nn mi mj mk bi translated">以上所有型号中最好的型号是<code class="fe no np nq nr b">ResNet34</code>、<code class="fe no np nq nr b">VGG16</code>和<code class="fe no np nq nr b">Inception</code>。</li></ol><blockquote class="mr ms mt"><p id="0ea8" class="jk jl mu jm b jn jo jp jq jr js jt ju mv jw jx jy mw ka kb kc mx ke kf kg kh ig bi translated">请随意查看我的<a class="ae ky" href="https://jovian.ai/msameeruddin/01-cs2-modeling-main" rel="noopener ugc nofollow" target="_blank">笔记本</a>上托管在 Jovian 平台上的迁移学习。</p></blockquote><h1 id="4ce2" class="kz la in bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">u 网模型</h1><p id="8f02" class="pw-post-body-paragraph jk jl in jm b jn lx jp jq jr ly jt ju jv lz jx jy jz ma kb kc kd mb kf kg kh ig bi translated">除了实现迁移学习模型之外，我还希望通过实现一种著名的深度学习算法来交叉检查性能，这种算法称为 U-NET，主要用于图像分割任务。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/ffc9d0f88039d59f9ac7f658f4bfcb63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*FS5--4nF2F3WIjpd.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自互联网</figcaption></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="dc4b" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">U-NET 模型的性能明显优于迁移学习。像往常一样，我们将这分为<code class="fe no np nq nr b">2</code>个方面。</p><ul class=""><li id="0e71" class="mc md in jm b jn jo jr js jv me jz mf kd mg kh mh mi mj mk bi translated"><a class="ae ky" href="https://jovian.ai/msameeruddin/02-cs2-unet-scratch#C10" rel="noopener ugc nofollow" target="_blank">无增强</a></li><li id="de0c" class="mc md in jm b jn ml jr mm jv mn jz mo kd mp kh mh mi mj mk bi translated"><a class="ae ky" href="https://jovian.ai/msameeruddin/02-cs2-unet-scratch#C26" rel="noopener ugc nofollow" target="_blank">增强</a></li></ul><h2 id="fe3a" class="my la in bd lb mz na dn lf nb nc dp lj jv nd ne ln jz nf ng lr kd nh ni lv nj bi translated">没有增加</h2><p id="0def" class="pw-post-body-paragraph jk jl in jm b jn lx jp jq jr ly jt ju jv lz jx jy jz ma kb kc kd mb kf kg kh ig bi translated">下面的输出是验证数据预测。最右边的图像是预测遮罩，我们可以观察到该模型能够提取大多数路径(包括较细的路径)。</p><p id="d3ba" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">甚至在原始掩模中没有被突出显示的路径，仍然在该模型的帮助下被识别。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="db9b" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">测试数据预测。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="ed1d" class="my la in bd lb mz na dn lf nb nc dp lj jv nd ne ln jz nf ng lr kd nh ni lv nj bi translated">增大</h2><p id="f6d8" class="pw-post-body-paragraph jk jl in jm b jn lx jp jq jr ly jt ju jv lz jx jy jz ma kb kc kd mb kf kg kh ig bi translated">在数据扩充的情况下，模型仍然表现最佳。扩增有助于识别复杂的模式。验证预测的结果如下所示。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="1fc6" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">测试数据预测。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="44ab" class="my la in bd lb mz na dn lf nb nc dp lj jv nd ne ln jz nf ng lr kd nh ni lv nj bi translated">模型性能</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/ca6a4664fc1671bc71215c1558b737dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*wnmvM2CMAC-6Bbk3.png"/></div></div></figure><ol class=""><li id="6379" class="mc md in jm b jn jo jr js jv me jz mf kd mg kh nn mi mj mk bi translated">以上是从零开始开发的 U-NET 模型得到的结果。</li><li id="c464" class="mc md in jm b jn ml jr mm jv mn jz mo kd mp kh nn mi mj mk bi translated">左边的图像对应于根据原始(无增强)数据训练的模型的结果。</li><li id="930e" class="mc md in jm b jn ml jr mm jv mn jz mo kd mp kh nn mi mj mk bi translated">右侧图像对应于根据原始(扩充)数据训练的模型的结果。</li><li id="5b3e" class="mc md in jm b jn ml jr mm jv mn jz mo kd mp kh nn mi mj mk bi translated">显然，通过观察这些图表，我们可以说左边的图(模型)与右边的图(模型)相比有轻微的过度拟合。虽然，这种差别似乎可以忽略不计。</li><li id="05b2" class="mc md in jm b jn ml jr mm jv mn jz mo kd mp kh nn mi mj mk bi translated">我个人认为，根据增强数据训练的模型确实显示了一些更接近的预测。这是我们在错误分析的过程中应该观察到的。</li></ol><blockquote class="mr ms mt"><p id="b946" class="jk jl mu jm b jn jo jp jq jr js jt ju mv jw jx jy mw ka kb kc mx ke kf kg kh ig bi translated">请随意检查我的<a class="ae ky" href="https://jovian.ai/msameeruddin/02-cs2-unet-scratch" rel="noopener ugc nofollow" target="_blank">笔记本</a>上的木星平台托管的 U-NET 建模。</p></blockquote><h1 id="f329" class="kz la in bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">误差分析</h1><p id="1db5" class="pw-post-body-paragraph jk jl in jm b jn lx jp jq jr ly jt ju jv lz jx jy jz ma kb kc kd mb kf kg kh ig bi translated">误差分析非常有助于(在我们有多个模型的情况下)决定哪个模型是最好的，哪个不是。在这个阶段，我们可以知道应该如何改进模型或数据集。</p><p id="021c" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">总的来说，我们有<code class="fe no np nq nr b">6</code>个模型已经在扩充数据和非扩充数据上进行了训练。IoU 分数是我们考虑的性能指标。根据我的观察，基于非增强数据训练的 U-NET 恰好是最好的模型，因为它具有最高的 IoU 得分。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/906c30494d514fa36de2cc0670054d08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/0*4CCaDz8nt6tr36M3.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</figcaption></figure><p id="826d" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">必须对样本数据进行误差分析。但是如果你有时间和有效的系统需求，你也可以考虑整个数据集。对于这个分析，我只考虑了<code class="fe no np nq nr b">100</code>个随机图像。</p><blockquote class="mr ms mt"><p id="ef54" class="jk jl mu jm b jn jo jp jq jr js jt ju mv jw jx jy mw ka kb kc mx ke kf kg kh ig bi translated">请随意查看我的<a class="ae ky" href="https://jovian.ai/msameeruddin/03-cs2-error-analysis" rel="noopener ugc nofollow" target="_blank">笔记本</a>，获取 Jovian 平台上的深度错误分析。</p></blockquote><h1 id="110c" class="kz la in bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">单幅图像分割</h1><p id="307e" class="pw-post-body-paragraph jk jl in jm b jn lx jp jq jr ly jt ju jv lz jx jy jz ma kb kc kd mb kf kg kh ig bi translated">作为其中的一部分，我们需要在传递单幅卫星图像时提取道路路径作为模型的输入。这在现实场景中很重要，因为我们通常不会将整个测试集传递给模型。与其获取预测掩膜，不如在卫星图像本身上高亮显示道路路径。我们可以用任何颜色来突出路径。</p><p id="c227" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">一旦我们加载了模型，我们总是可以传递一个图像来获取路线。在获得预测掩码后，借助简单的图像处理技术，我们仍然可以保留背景，只突出显示路径。</p><p id="3db7" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">因此，下面的函数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="b512" class="my la in bd lb mz na dn lf nb nc dp lj jv nd ne ln jz nf ng lr kd nh ni lv nj bi translated">没有增加</h2><p id="3431" class="pw-post-body-paragraph jk jl in jm b jn lx jp jq jr ly jt ju jv lz jx jy jz ma kb kc kd mb kf kg kh ig bi translated"><strong class="jm io">100034 _ 星期六</strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="70f1" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io"> 100393_sat </strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="f350" class="my la in bd lb mz na dn lf nb nc dp lj jv nd ne ln jz nf ng lr kd nh ni lv nj bi translated">增大</h2><p id="79f1" class="pw-post-body-paragraph jk jl in jm b jn lx jp jq jr ly jt ju jv lz jx jy jz ma kb kc kd mb kf kg kh ig bi translated"><strong class="jm io"> 100034_sat </strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="c29b" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io">100393 _ 星期六</strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="88d4" class="my la in bd lb mz na dn lf nb nc dp lj jv nd ne ln jz nf ng lr kd nh ni lv nj bi translated">UI 部件</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/a4588bcf8c161c8aaf52317cdd45a452.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*vTHVH53fvVtbSwnH.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</figcaption></figure><h2 id="d67b" class="my la in bd lb mz na dn lf nb nc dp lj jv nd ne ln jz nf ng lr kd nh ni lv nj bi translated">视频演示</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa nu l"/></div></figure><div class="ob oc gp gr od oe"><a href="https://jovian.ai/msameeruddin/collections/deep-globe-road-extraction" rel="noopener  ugc nofollow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd io gy z fp oj fr fs ok fu fw im bi translated">深全球道路提取由 msameeruddin | Jovian</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">msameeruddin 的笔记本收藏。</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">jovian.ai</p></div></div><div class="on l"><div class="oo l op oq or on os ks oe"/></div></div></a></div><p id="5bb5" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><a class="ae ky" href="https://www.linkedin.com/in/mohammed-sameeruddin-596a70133/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/mohammed-sameeruddin-596a70133/</a></p><h1 id="af43" class="kz la in bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">参考</h1><ol class=""><li id="a5bb" class="mc md in jm b jn lx jr ly jv nk jz nl kd nm kh nn mi mj mk bi translated">appliedaicourse.com<a class="ae ky" href="https://www.appliedaicourse.com/" rel="noopener ugc nofollow" target="_blank"/></li><li id="fee1" class="mc md in jm b jn ml jr mm jv mn jz mo kd mp kh nn mi mj mk bi translated">【youtu.be/GAYJ81M58y8 T4】</li><li id="dd72" class="mc md in jm b jn ml jr mm jv mn jz mo kd mp kh nn mi mj mk bi translated"><a class="ae ky" href="https://www.cs.toronto.edu/~urtasun/publications/mattyus_etal_iccv17.pdf" rel="noopener ugc nofollow" target="_blank">cs.toronto.edu/~urtasun/publications/mattyu..</a></li><li id="06a0" class="mc md in jm b jn ml jr mm jv mn jz mo kd mp kh nn mi mj mk bi translated"><a class="ae ky" href="https://arxiv.org/pdf/1908.08223.pdf" rel="noopener ugc nofollow" target="_blank">arxiv.org/pdf/1908.08223.pdf</a></li><li id="3700" class="mc md in jm b jn ml jr mm jv mn jz mo kd mp kh nn mi mj mk bi translated"><a class="ae ky" href="https://www.kaggle.com/vanvalkenberg/road-maps-from-aerial-images" rel="noopener ugc nofollow" target="_blank">kaggle.com/vanvalkenberg/road-maps-from-aer..</a></li><li id="cecf" class="mc md in jm b jn ml jr mm jv mn jz mo kd mp kh nn mi mj mk bi translated"><a class="ae ky" href="https://www.kaggle.com/balraj98/road-extraction-from-satellite-images-deeplabv3" rel="noopener ugc nofollow" target="_blank">kaggle.com/balraj98/road-extraction-from-sa..</a></li></ol></div><div class="ab cl ot ou hr ov" role="separator"><span class="ow bw bk ox oy oz"/><span class="ow bw bk ox oy oz"/><span class="ow bw bk ox oy"/></div><div class="ig ih ii ij ik"><p id="f6bf" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">嗯，我这边就这样了。请务必订阅我的时事通讯，以免错过我发布的独家内容的更新。</p></div></div>    
</body>
</html>