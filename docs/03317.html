<html>
<head>
<title>Image Classifier for Oolong tea and Green tea</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">乌龙茶和绿茶的图像分类器</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/image-classifier-for-oolong-tea-and-green-tea-c06de29d834?source=collection_archive---------9-----------------------#2020-10-22">https://blog.devgenius.io/image-classifier-for-oolong-tea-and-green-tea-c06de29d834?source=collection_archive---------9-----------------------#2020-10-22</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><div class=""><h2 id="ec41" class="pw-subtitle-paragraph jk im in bd b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb dk translated"><a class="ae kc" href="https://www.tobiolabode.com/blog/2020/10/21/image-classifier-for-oolong-tea-and-green-tea" rel="noopener ugc nofollow" target="_blank">从我的网站发布</a></h2></div><figure class="ke kf kg kh gt ki gh gi paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="gh gi kd"><img src="../Images/26220a244fa62a273036803e05ad5abb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wUWvKM24YKXnnGtc"/></div></div><figcaption class="kp kq gj gh gi kr ks bd b be z dk translated">由<a class="ae kc" href="https://unsplash.com/@kimdonkey?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">万基·金</a>在<a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h1 id="7047" class="kt ku in bd kv kw kx ky kz la lb lc ld jt le ju lf jw lg jx lh jz li ka lj lk bi translated">开发数据集</h1><p id="0a22" class="pw-post-body-paragraph ll lm in ln b lo lp jo lq lr ls jr lt lu lv lw lx ly lz ma mb mc md me mf mg ig bi translated">在这个项目中，我将做一个图像分类器。我记得不久前我的尝试不起作用。为了稍微改变一下，我将使用Pytorch框架。而不是张量流。因为这是我第一次使用Pytorch。在我开始我的项目之前，我将参加一个辅导。这个项目是一个识别瓶装乌龙茶和瓶装绿茶区别的分类器。</p><p id="878c" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">我用的教程是<a class="ae kc" href="https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html" rel="noopener ugc nofollow" target="_blank"> PyTorch的60分钟闪电战</a>。(虽然我花了60多分钟才完成)。打出教程后，我习惯了使用Pytorch。所以我开始着手这个项目。因为这将是一个图像分类器。我需要将大量的图像放入我的数据集中。第一次碰到一篇中等的文章。用了一把好的刮刀。但是即使经过一些编辑，它还是不起作用。</p><figure class="ke kf kg kh gt ki gh gi paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="gh gi mm"><img src="../Images/7c86180cdacaaea656c15cf919709f15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2CiIyIgZ_ZSUh_EK4uyC3A.png"/></div></div></figure><p id="aacd" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">所以我转而使用Bing进行图片搜索。Bing有一个你可以使用的图像API。这使得它比谷歌更容易收集图像。我使用了来自<a class="ae kc" href="https://www.pyimagesearch.com/2018/04/09/how-to-quickly-build-a-deep-learning-image-dataset/" rel="noopener ugc nofollow" target="_blank"> pyimagesearch </a>的这篇文章。开始的时候，我在API上遇到了一些问题。因为微软给我的终端不适用于本教程。环顾四周和一些编辑后，我能够让它工作。</p><figure class="ke kf kg kh gt ki gh gi paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="gh gi mn"><img src="../Images/34b74adff4495efec0654d7026298d01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pgw01S2sxg3cyxRXPMncLg.png"/></div></div></figure><p id="556c" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">但是看着图像文件夹，我想到了这个:</p><figure class="ke kf kg kh gt ki gh gi paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="gh gi mo"><img src="../Images/483f2555427bddcdfda018e5c210ba0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5U3SW65gVbxYzsMkFnIvaQ.png"/></div></div></figure><p id="3492" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">看完代码后，我注意到程序没有生成新的图像。但是将图像更改为“000000”。这是因为没有从博客文章中复制最后一段代码。这更新了计数器变量。</p><figure class="ke kf kg kh gt ki gh gi paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="gh gi mp"><img src="../Images/a1b5f724c81013f6a86f9ca87f871b8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n-tn8EncJgTFbive3t5zCQ.png"/></div></div></figure><p id="9282" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">现在我有教程代码工作，我们可以尝试我的搜索词。来创建我的数据集。首先我从绿茶开始。所以我用了“瓶装绿茶”这个词。这个程序给了我这些图像:</p><figure class="ke kf kg kh gt ki gh gi paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="gh gi mq"><img src="../Images/244f1288e1e7ab1c4e29a04c177526bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JEHcufyUZLbKnDYfD_158Q.png"/></div></div></figure><p id="3a0a" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">后来，我用“瓶装乌龙茶”这个术语得到了乌龙茶。</p><figure class="ke kf kg kh gt ki gh gi paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="gh gi mr"><img src="../Images/2f3f0424e8237ea61cacb69fb01b22d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*za3Ai-k33YN-G7uzML6UbA.png"/></div></div></figure><p id="7167" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">现在我已经亲自检查了数据集。并删除任何与课程无关的图片。我删除的图像是这样的:</p><figure class="ke kf kg kh gt ki gh gi paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="gh gi ms"><img src="../Images/6645c83a5bb1e14ef145fd2202ab3992.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fvWO_AHtX7nUeZwxNNXLxw.png"/></div></div></figure><p id="6a37" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">这是因为我们希望分类器能够处理瓶装饮料。所以树叶不相关。不管它们有多好吃。</p><p id="19e3" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">它们是一些空白的图像。不用说，对于图像分类器来说是没有用的。</p><figure class="ke kf kg kh gt ki gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/27cf9f9fb2328f50046b0d25b4a91c4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/1*2EYC7hUBGeSyyQBRQhtv6Q.png"/></div></figure><figure class="ke kf kg kh gt ki gh gi paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="gh gi mu"><img src="../Images/54865ed7e8eef1c9b6bd6e3779b93090.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F5Q4ZTfI2Lr5KHxdVMEwJA.png"/></div></div></figure><p id="22f8" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">尽管这张图片中有几个绿茶瓶子。它也有一个乌龙茶瓶子，所以这将混淆模型。所以最好简化成只有几个绿茶瓶子。而不是不属于某一类的整个种类。</p><p id="6d4c" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">在我对两个数据集都做了这些之后。我准备继续创建模型。于是去Google Collab，导入Pytorch。</p><p id="0e6c" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">因为数据集的图像少于200幅。我认为应用数据增强是个好主意。我首先发现了这个使用Pytorch变换的教程。</p><p id="ba52" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">当应用转换时，它陷入了几个问题。第一，它不能正确地绘图，也不能识别我的图像。但是我能修好它</p><figure class="ke kf kg kh gt ki gh gi paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="gh gi mv"><img src="../Images/eb27e79a1439897dbae58d3f48459907.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mtXfJYlNHkSCAzounWEahw.png"/></div></div></figure><p id="b0a2" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">这些问题源于没有正确地对数据集进行切片。因为ImageFolder(Pytorch helper函数)返回一个元组，而不仅仅是图像列表。</p><h1 id="17e6" class="kt ku in bd kv kw kx ky kz la lb lc ld jt le ju lf jw lg jx lh jz li ka lj lk bi translated">开发模型</h1><p id="b324" class="pw-post-body-paragraph ll lm in ln b lo lp jo lq lr ls jr lt lu lv lw lx ly lz ma mb mc md me mf mg ig bi translated">在那之后，我开始开发这个模型。我用的是60分钟闪电战教程里用的CNN。我处理的第一个错误是数据不能正常通过网络。</p><pre class="ke kf kg kh gt mw mx my mz aw na bi"><span id="f13a" class="nb ku in mx b gy nc nd l ne nf">shape ‘[-1, 400]’ is invalid for input of size 179776</span></pre><p id="8d72" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">我可以通过将内核大小改为2 x 2来解决这个问题。并将特征图更改为64。</p><pre class="ke kf kg kh gt mw mx my mz aw na bi"><span id="049d" class="nb ku in mx b gy nc nd l ne nf">self.fc1 = nn.Linear(64 * 2 * 2, 120)</span><span id="5d81" class="nb ku in mx b gy ng nd l ne nf">x = x.view(-1, 64 * 2 * 2)</span></pre><p id="6d0c" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">紧接着，我陷入了另一个错误:</p><pre class="ke kf kg kh gt mw mx my mz aw na bi"><span id="0da1" class="nb ku in mx b gy nc nd l ne nf">ValueError: Expected input batch_size (3025) to match target batch_size (4).</span></pre><p id="a2a8" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">通过再次改变x变量的形状修复了这个问题。</p><pre class="ke kf kg kh gt mw mx my mz aw na bi"><span id="509d" class="nb ku in mx b gy nc nd l ne nf">x = x.view(-1, 64 * 55 * 55)</span></pre><p id="4078" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">利用这个<a class="ae kc" href="https://discuss.pytorch.org/t/valueerror-expected-input-batch-size-324-to-match-target-batch-size-4/24498/6" rel="noopener ugc nofollow" target="_blank">论坛的帖子</a>。</p><p id="323c" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">然后另一个错误😩。</p><pre class="ke kf kg kh gt mw mx my mz aw na bi"><span id="cbc6" class="nb ku in mx b gy nc nd l ne nf">RuntimeError: size mismatch, m1: [4 x 193600], m2: [256 x 120] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:41</span></pre><p id="8f9d" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">这是通过改变线性层再次修复。</p><pre class="ke kf kg kh gt mw mx my mz aw na bi"><span id="98cb" class="nb ku in mx b gy nc nd l ne nf">self.fc1 = nn.Linear(64 * 55 * 55, 120)</span></pre><p id="a91d" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">该死，我不知道一层厚厚的东西会让我这么头疼。</p><p id="8a65" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">经过训练。我需要测试这个模型。在制作模型之前，我没有制作测试文件夹。(菜鸟失误)。之后我用每个班的前5张图片快速制作了它。这是一件糟糕的事情。这可能会污染数据。并导致过度拟合。但我需要看看这个模型当时是否有效。</p><p id="a0d1" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">我想在测试文件夹中绘制一个图像。所以我借用了教程里的代码。这导致了一个错误。但是通过将范围改为1来修复它。而不是5。这是因为我的模型只有2个标签。(张量[0]和张量[1])不是4。</p><p id="7803" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">加载模型时。它给了我一个错误。但这是通过调整测试文件夹中的图像大小修复的。在模型运行了几次后，我注意到它没有显示损失。所以我编辑了代码。</p><pre class="ke kf kg kh gt mw mx my mz aw na bi"><span id="b2be" class="nb ku in mx b gy nc nd l ne nf">if i % 10 == 0:</span><span id="69bc" class="nb ku in mx b gy ng nd l ne nf">   print('[%d, %d] loss: %.5f' %</span><span id="c392" class="nb ku in mx b gy ng nd l ne nf">       (epoch + 1, i + 1, running_loss / 10))</span><span id="9beb" class="nb ku in mx b gy ng nd l ne nf">   running_loss = 0.0</span></pre><figure class="ke kf kg kh gt ki gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/7d4b31f1190de30d7e30d600b9c2cda9.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*TQ24IhqdkgOQvz5XigHAiw.png"/></div></figure><p id="a0df" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">正如我们所见，损失非常高。</p><p id="cc50" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">当我在测试文件夹中测试模型时，它给了我这个:</p><figure class="ke kf kg kh gt ki gh gi paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="gh gi ni"><img src="../Images/48645f94968c8ea09acfa6a1aa833ef5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q5QRxDhKOHj_DQKxWlb8IQ.png"/></div></div></figure><p id="15bc" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">也就是说最多只能猜测。后来我发现这是因为它把每张图片都当成了绿茶。有5张带有绿茶标签的图片。这导致它50%的时间是正确的。</p><p id="1ed8" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">这就把我带到了模型调试的世界。努力降低损失率，提高准确率。</p><h1 id="82bb" class="kt ku in bd kv kw kx ky kz la lb lc ld jt le ju lf jw lg jx lh jz li ka lj lk bi translated">调试模型</h1><p id="e292" class="pw-post-body-paragraph ll lm in ln b lo lp jo lq lr ls jr lt lu lv lw lx ly lz ma mb mc md me mf mg ig bi translated">当我发现这篇<a class="ae kc" href="https://blog.slavv.com/37-reasons-why-your-neural-network-is-not-working-4020854bd607" rel="noopener ugc nofollow" target="_blank">中型文章</a>时，我开始在调试我的模型方面取得一些进展</p><p id="8385" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">作者说的第一点是从一个简单的问题开始，这个问题已知适用于你的数据类型。尽管我认为我使用的是一个为处理图像数据而设计的简单模型。当我借用Pytorch教程中的模型时。但是没有用。所以选择了更简单的模型形状。这是我从一本<a class="ae kc" href="https://www.tensorflow.org/tutorials/images/cnn" rel="noopener ugc nofollow" target="_blank">张量流教程</a>中找到的。它只有3个卷积层。和两个致密层。我不得不改变最终层的参数，因为他们给了我错误。因为它是为10个目标设计的。而不是2。之后，我摆弄了一下超参数。有了这个，我就能把测试图像的准确率提高到80%😀。</p><pre class="ke kf kg kh gt mw mx my mz aw na bi"><span id="9758" class="nb ku in mx b gy nc nd l ne nf">Accuracy of the network on the 10 test images: 80 %</span><span id="ed1c" class="nb ku in mx b gy ng nd l ne nf">10</span><span id="947e" class="nb ku in mx b gy ng nd l ne nf">8</span></pre><figure class="ke kf kg kh gt ki gh gi paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="gh gi nj"><img src="../Images/16b4e48178d067e43058e110e7d91a3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0HR6FpVd8jcrLew_l61R1w.png"/></div></div></figure><h1 id="9ed4" class="kt ku in bd kv kw kx ky kz la lb lc ld jt le ju lf jw lg jx lh jz li ka lj lk bi translated">测试新模型</h1><p id="1e52" class="pw-post-body-paragraph ll lm in ln b lo lp jo lq lr ls jr lt lu lv lw lx ly lz ma mb mc md me mf mg ig bi translated">因为测试数据集被污染了，因为我使用了来自训练数据集的图像。我想用新的图像重组测试数据集。以确保准确性。</p><p id="7242" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">为了重组它，我采用了以下方式:</p><figure class="ke kf kg kh gt ki gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/a7073ff7b25a7419ffe0814045404df9.png" data-original-src="https://miro.medium.com/v2/resize:fit:922/format:webp/1*owEv6tPfHYz07oiNozaJjA.png"/></div><figcaption class="kp kq gj gh gi kr ks bd b be z dk translated">【https://stackoverflow.com/a/60333941 T4】</figcaption></figure><p id="6f4d" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">同时分别调用测试和训练数据集。</p><pre class="ke kf kg kh gt mw mx my mz aw na bi"><span id="d264" class="nb ku in mx b gy nc nd l ne nf">train_dataset = ImageFolder(root=<!-- -->'data/train'<!-- -->)</span><span id="287b" class="nb ku in mx b gy ng nd l ne nf">test_dataset  = ImageFolder(root=<!-- -->'data/test'<!-- -->)</span></pre><p id="c0da" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">有了测试图片，我决定用谷歌而不是必应。因为它给出不同的结果。之后，我在新的测试数据集上测试了这个模型。</p><pre class="ke kf kg kh gt mw mx my mz aw na bi"><span id="6b18" class="nb ku in mx b gy nc nd l ne nf">Accuracy of the network on the 10 test images: 70 %</span><span id="33a1" class="nb ku in mx b gy ng nd l ne nf">10</span><span id="53dd" class="nb ku in mx b gy ng nd l ne nf">7</span></pre><p id="6763" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">由于这不是一个明显的减少，在模型中学到了一些关于绿茶和乌龙茶。</p><p id="a388" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">使用Pytorch教程中的代码，我想进一步分析它:</p><figure class="ke kf kg kh gt ki"><div class="bz fp l di"><div class="nl nm l"/></div></figure><pre class="ke kf kg kh gt mw mx my mz aw na bi"><span id="1f09" class="nb ku in mx b gy nc nd l ne nf">Accuracy of Green_tea_test : 80 %</span><span id="bdac" class="nb ku in mx b gy ng nd l ne nf">Accuracy of oolong_tea_test : 60 %</span></pre><h1 id="cef9" class="kt ku in bd kv kw kx ky kz la lb lc ld jt le ju lf jw lg jx lh jz li ka lj lk bi translated">绘制预测图</h1><p id="bbe1" class="pw-post-body-paragraph ll lm in ln b lo lp jo lq lr ls jr lt lu lv lw lx ly lz ma mb mc md me mf mg ig bi translated">我喜欢这个。我想让程序告诉我哪些图像出错了。所以，我去工作，试图这样做。为此，我在一个独立的列表中将图像数据和标签缝合在一起。</p><pre class="ke kf kg kh gt mw mx my mz aw na bi"><span id="167f" class="nb ku in mx b gy nc nd l ne nf">for i, t, p, in zip(img_list, truth_label, predicted_label):</span><span id="bb19" class="nb ku in mx b gy ng nd l ne nf">  one_merge_dict = {'image': i, 'truth_label': t, 'predicted_label':    p}</span><span id="0efd" class="nb ku in mx b gy ng nd l ne nf">  merge_list.append(one_merge_dict)</span><span id="05f5" class="nb ku in mx b gy ng nd l ne nf">print(merge_list)</span></pre><p id="cc8f" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">在我的第一次尝试中，我得到了这个:</p><figure class="ke kf kg kh gt ki gh gi paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="gh gi nn"><img src="../Images/6888f878b8d57530d18127eeb5d0a2fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zfM10IErw_dNWgSoVQijrA.png"/></div></div></figure><p id="d40c" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">正如我们可以看到它非常杂乱，显示所有的图像。为了清除它，我删除了不需要的文字。</p><figure class="ke kf kg kh gt ki gh gi paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="gh gi nn"><img src="../Images/e64729a28943d858c96cb4fabd413fd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xN49sYjoRectv7yUuLxreA.png"/></div></div></figure><p id="061a" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">现在我可以开始区分图像的对错。</p><p id="4c18" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">我能够通过使用一个小的if语句做到这一点</p><figure class="ke kf kg kh gt ki"><div class="bz fp l di"><div class="nl nm l"/></div></figure><figure class="ke kf kg kh gt ki gh gi paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="gh gi no"><img src="../Images/3a8cbde81cab521941acc1558d3a856d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_vGQB6a0yZqn1T1jy1fDuQ.png"/></div></div></figure><p id="4912" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">我想去掉空白，所以我决定改变图片的布局。</p><pre class="ke kf kg kh gt mw mx my mz aw na bi"><span id="99e4" class="nb ku in mx b gy nc nd l ne nf">ax = plt.subplot(1, 4, i + 1)</span><span id="e4d4" class="nb ku in mx b gy ng nd l ne nf">fig = plt.figure(figsize=(15,15))</span></pre><figure class="ke kf kg kh gt ki gh gi paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="gh gi no"><img src="../Images/d440570843a64aac9173fde3cf06cbfe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vTsJJzSKd970_YvhURvJdQ.png"/></div></div></figure><p id="6779" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">现在我有一个想法，模型出了什么问题。第一个样品绿茶没有传统的绿色设计。所以这是可以理解的，这是错误的。第二个样本。是乌龙茶，但被误归类为绿茶。我的猜测是瓶子有一个非常浅的色调。与训练数据中的金色或橙色调乌龙瓶相比。然后是第三个例子，瓶子有传统的乌龙茶设计和橙色调色板。但是模型把它和绿茶混为一谈。我猜瓶子上的叶子影响了模型的判断。导致它被归类为绿茶。</p><p id="738e" class="pw-post-body-paragraph ll lm in ln b lo mh jo lq lr mi jr lt lu mj lw lx ly mk ma mb mc ml me mf mg ig bi translated">现在我已经完成了这个项目。这并不是说我可能不会回来这个项目。作为实施方面的补充。比如拥有一个可以检测乌龙茶或绿茶的手机应用程序。用你手机的摄像头。或者一个简单的网络应用程序，用户可以上传他们的瓶装茶图片。并且模型可以对你在网站上的形象进行分类。</p></div></div>    
</body>
</html>