<html>
<head>
<title>Building a data pipeline for cryptocurrency market insights</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为加密货币市场洞察构建数据管道</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/building-a-data-pipeline-for-cryptocurrency-market-insights-946f31ab511a?source=collection_archive---------9-----------------------#2022-11-27">https://blog.devgenius.io/building-a-data-pipeline-for-cryptocurrency-market-insights-946f31ab511a?source=collection_archive---------9-----------------------#2022-11-27</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><figure class="gl gn jl jm jn jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi jk"><img src="../Images/ab8a3c9dd82dc2e64ae279fb9e49d054.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DMNfCYAKZmlYBW1KFpFc-w.jpeg"/></div></div></figure><h2 id="7d96" class="jv jw in bd jx jy jz dn ka kb kc dp kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">介绍</h2><p id="c579" class="pw-post-body-paragraph kr ks in kt b ku kv kw kx ky kz la lb ke lc ld le ki lf lg lh km li lj lk ll ig bi translated">利润！这是一个非常有趣的词，但它是构成我们世界市场经济的本质。简而言之，它是一种让你投资的资金产生盈余的能力。所以，假设你投资 10 美元，赚了 15 美元，那么你就赚了 5 美元——很简单，对吧？</p><p id="809a" class="pw-post-body-paragraph kr ks in kt b ku lm kw kx ky ln la lb ke lo ld le ki lp lg lh km lq lj lk ll ig bi translated">现在…你一生中遇到的每一项服务、每一个机构都是基于这个原则，从学校、交通、娱乐到基本的生存，比如食品工业。如果这些行业的成本高于它们应该获得的利润，它们就会倒闭。</p><p id="139b" class="pw-post-body-paragraph kr ks in kt b ku lm kw kx ky ln la lb ke lo ld le ki lp lg lh km lq lj lk ll ig bi translated">让我们谈一谈交易，因为该计划旨在解决加密货币市场中的一个特定用例。</p><h2 id="18a4" class="jv jw in bd jx jy jz dn ka kb kc dp kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">那么，什么是交易？</h2><p id="3457" class="pw-post-body-paragraph kr ks in kt b ku kv kw kx ky kz la lb ke lc ld le ki lf lg lh km li lj lk ll ig bi translated">它建立在以盈利为目的的市场经济体制的同样原则基础上。但是它是如何工作的呢？</p><p id="b6d5" class="pw-post-body-paragraph kr ks in kt b ku lm kw kx ky ln la lb ke lo ld le ki lp lg lh km lq lj lk ll ig bi translated">你以某一价格买入一种货币，当这种货币升值时，你就获利了😊诶哈…但是如果当你的钱在市场上时它下跌了，你就亏了。如果你的钱不在市场上，那么这是一个低价买入的机会，这样当价格上涨时，你就获利了。交易的存在是因为价值无时无刻不在波动…<strong class="kt io"/>！它的波动基于很多因素，核心是关于市场上资产的供给和需求，更多的供给和更弱的需求推动价格下跌，相反推动价格上涨。</p><p id="3c61" class="pw-post-body-paragraph kr ks in kt b ku lm kw kx ky ln la lb ke lo ld le ki lp lg lh km lq lj lk ll ig bi translated">所以，作为一个交易者，尤其是短线交易者，你想要一个波动很大的货币，因为你想做尽可能多的盈利交易。你知道比特币不是加密货币市场中唯一的货币资产吗？🤔有很多，你要做的是确定哪些随着时间的推移波动最大，你要把你的投资分散到你已经确定的股票上。为此，您需要对市场进行分析，以了解<strong class="kt io"> <em class="lr">趋势</em> </strong>和<strong class="kt io"> <em class="lr">模式</em> </strong>，这就是下面的<strong class="kt io">数据解决方案平台</strong>发挥作用的地方。</p><p id="3687" class="pw-post-body-paragraph kr ks in kt b ku lm kw kx ky ln la lb ke lo ld le ki lp lg lh km lq lj lk ll ig bi translated">在任何给定的时间回答一些关键问题的能力在这里是至关重要的。</p><ul class=""><li id="b3ee" class="ls lt in kt b ku lm ky ln ke lu ki lv km lw ll lx ly lz ma bi translated">随着时间的推移，加密货币的平均价格是多少？一年、两年等。你想在这里抓住<strong class="kt io"> <em class="lr">模式</em></strong>……<em class="lr">我们很可能会做我们在一段时间内通常会做的事情。”</em></li><li id="b4b4" class="ls lt in kt b ku mb ky mc ke md ki me km mf ll lx ly lz ma bi translated">价格多久波动一次，波动幅度是多少？在过去 x 段时间内(一年、两年等)，该值上升或下降 1%、5%、10%等的频率</li></ul><p id="42e1" class="pw-post-body-paragraph kr ks in kt b ku lm kw kx ky ln la lb ke lo ld le ki lp lg lh km lq lj lk ll ig bi translated">作为投资者，这些问题的答案会让你处于更有利的位置。</p><p id="49f5" class="pw-post-body-paragraph kr ks in kt b ku lm kw kx ky ln la lb ke lo ld le ki lp lg lh km lq lj lk ll ig bi translated">好了，现在我们已经解决了这个问题——让我们来谈谈技术问题😋</p><p id="6dc3" class="pw-post-body-paragraph kr ks in kt b ku lm kw kx ky ln la lb ke lo ld le ki lp lg lh km lq lj lk ll ig bi translated">综合起来的解决方案是用 Python 编写的，它将数据发送到一个近乎实时的流媒体平台(<strong class="kt io"> <em class="lr">【卡夫卡】</em> </strong>)，然后该平台将数据转发到一个分析平台(<strong class="kt io"> <em class="lr"> Elasticsearch </em> </strong>)以获得可操作的见解。</p><h2 id="a1f1" class="jv jw in bd jx jy jz dn ka kb kc dp kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">摄入 Python Kafka 制作程序</h2><pre class="mg mh mi mj gt mk ml mm bn mn mo bi"><span id="0839" class="mp jw in ml b be mq mr l ms mt"><br/>################################ Get ALL cryptocurrencies (array) #######################################<br/><br/>#==============================# Import required modules for this program #==============================<br/><br/>from confluent_kafka import Producer, KafkaError<br/>import json<br/>import os<br/>import requests<br/>from time import sleep<br/>from datetime import datetime<br/>from datetime import timezone<br/>from requests.exceptions import ConnectionError, ConnectTimeout<br/>import socket<br/>import boto3<br/>import json<br/>import requests<br/>import logging<br/><br/>#==============================# This section runs our python code as a TCP server #==============================<br/><br/># Create a socket<br/>sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)<br/><br/># Ensure that you can restart your server quickly when it terminates<br/>sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)<br/><br/># Set the client socket's TCP "well-known port" number<br/>well_known_port = int(os.environ['PYTHON_PRODUCER_SERVER_PORT'])<br/>sock.bind(('localhost', well_known_port))<br/><br/># Set the number of clients waiting for connection that can be queued<br/>sock.listen(5)<br/><br/>#==============================# This section sets up Kafka Consumer world #==============================<br/><br/>#Set your kafka topic you will publishing into<br/>topic = os.environ['KAFKA_TOPIC']<br/>#Set kafka Producer settings<br/>settings = {<br/>    'bootstrap.servers': os.environ['KAFKA_BROKERS_HOST_PORT'],<br/>    'client.id': os.environ['KAFKA_PRODUCER_CLIENT_ID']<br/>}<br/><br/>#Function to check connectivity to kafka cluster<br/>def isOpen(ip,port):<br/>   s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)<br/>   try:<br/>      s.connect((ip, int(port)))<br/>      s.settimeout(30)<br/>      print("Connection successfully established with kafka cluster. We may proceed")<br/>      return True<br/>   except:<br/>      return False<br/>   finally:<br/>        s.close()<br/><br/># Check connectivity to kafka cluster before proceding any further<br/>def check_kafka():<br/>    global check_port<br/>    check_port_wait = 30<br/>    while True:<br/>        check_port =  isOpen(os.environ['KAFKA_HOST'], int(os.environ['KAFKA_BROKERS_PORT']))<br/>        if check_port == False:<br/>            for x in range(check_port_wait):<br/>                print("Retrying connection to kafka cluster...in " + str(x) + " seconds", end="\r")<br/>                sleep(1)<br/>        else:<br/>            break<br/><br/># Execute function    <br/>check_kafka()<br/><br/># Here is our Producer variable <br/>if check_port == True:<br/>    p = Producer(settings)<br/><br/># API poll interval for the dataset we're streaming<br/># We got it at every 2 minutes - you can adjust to make as real-time as possible<br/>interval = int(os.environ['KAFKA_PRODUCER_BATCH_INTERVAL'])<br/><br/>#Wait interval to retry a connection<br/>waiting = int(os.environ['KAFKA_PRODUCER_RETRIES_INTERVAL'])<br/><br/>## Functions ## <br/>#Called once for each message produced to indicate delivery result.<br/>#Triggered by poll() or flush().<br/>def delivery_report(err, msg):<br/>    if err is not None:<br/>        print('Message delivery failed: {}'.format(err))<br/>    else:<br/>        print('1 Message delivered to {} [{}]'.format(msg.topic(), msg.partition()))<br/><br/>#==================================#            AWS S3 setup            #==================================<br/><br/>#Creating Session With Boto3.<br/>session = boto3.Session(<br/>aws_access_key_id= os.environ['AWS_S3_ACCESS_KEY'],<br/>aws_secret_access_key= os.environ['AWS_S3_SECRET_KEY'],<br/>region_name= os.environ['AWS_S3_REGION']<br/>)<br/><br/>#Function for AWS S3 connectivity <br/>def send_to_s3():<br/>    try:<br/>        s3 = session.resource('s3')<br/>        run = s3.meta.client.put_object(Body=x,Bucket=os.environ['AWS_S3_BUCKET'],Key=os.environ['AWS_S3_FILENAME_PREFIX'] + str(datetime.now().strftime("%Y-%m-%dT%H-%M-%S.json")))<br/>        res = run.get('ResponseMetadata')<br/><br/>        if res.get('HTTPStatusCode') == 200:<br/>            print('Data Uploaded Succesfully to the Lake AWS S3 at ' + str(datetime.now().strftime("%Y-%m-%dT%H:%M:%S")))<br/>        else:<br/>            print('Data Not Uploaded  to the Lake AWS S3 at ' + str(datetime.now().strftime("%Y-%m-%dT%H:%M:%S"))) <br/>            print("Exiting program until fixed")<br/>            exit()<br/>    except Exception as e:<br/>        print(e)<br/><br/>#==================================# This is the Main section which runs this program - Produce to kafka #==================================<br/><br/>#a countdown variable to keep track of the amount of batches processed<br/>track = 1<br/><br/>#a continous loop to keep polling API endpoint for datasets<br/>try:<br/>    while True:<br/>        count = 0<br/>        ola = requests.get(os.environ['CRYPTO_API_ENDPOINT']).json()<br/>        #We loop throught the array<br/>        for x in ola["result"]:<br/>            #The dataset does NOT have a timestamp associated with the event, we need to add one so we can do time series analytics  <br/>            x["timestamp"] = datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%S.%f")<br/>            #Because our get call returns a type of dictionary(json), we need to convert it to a string as kafka only takes string, bytes NOT dict<br/>            x = json.dumps(x)<br/>            #Kafka producer keeps polling for new events<br/>            p.poll(0)<br/>            #Kafka producer now produces the events received to kafka topic and prints out and executes the report function<br/>            p.produce(topic,key="hello",value=x, callback=delivery_report)<br/>            #We increment our count variable to keep track of the amount of events processed<br/>            count += 1<br/>        #Then producer queue is flushed<br/>        p.flush()<br/>        #Once we run through the array, we print out message with total amount of events processed in a batch     <br/>        print("Batch number " + str(track) + " - " + str(count) + " Messages delivered to " + topic + " at " + str(datetime.now().strftime("%Y-%m-%dT%H:%M:%S")))<br/>        #Now, we're sending dataset to the lake (AWS S3)<br/>        #Creating S3 Resource From the Session.<br/>        print("Sending datasets to the Data lake AWS S3...")<br/>        send_to_s3()<br/>        #Here we pause for our next batch <br/>        for x in range(interval):<br/>            print("Pausing for next batch in ..." + str(interval) + "sec - " + str(x))<br/>            sleep(1)<br/>        #The batch count is incremented here<br/>        track += 1<br/>        #Ensure kafka is reachable <br/>        check_kafka()<br/>except ConnectionError:<br/>    while True:<br/>        print("Unable to establish connection to crypto API endpoint.Verify URL")<br/>        for x in range(waiting):<br/>            print("Retrying connection to crypto API in ... " + str(waiting) + " seconds ", str(x), end="\r")<br/>            sleep(1)<br/>except Exception as e:<br/>    print(e)<br/><br/></span></pre><p id="3e0a" class="pw-post-body-paragraph kr ks in kt b ku lm kw kx ky ln la lb ke lo ld le ki lp lg lh km lq lj lk ll ig bi translated">我已经尽力在代码中包含尽可能多的注释，这样你就可以理解了。我想在这里提到的几件事是…因为代码依赖于其他层来实现一个有效且准确的解决方案，我需要考虑到这一点，并在依赖层(<strong class="kt io"> kafka </strong>、<strong class="kt io"> aws s3 </strong>)由于某些原因不可用时停止代码执行。</p><h2 id="bf19" class="jv jw in bd jx jy jz dn ka kb kc dp kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">ETL 处理— Python Kafka 消费者</h2><pre class="mg mh mi mj gt mk ml mm bn mn mo bi"><span id="0ef4" class="mp jw in ml b be mq mr l ms mt">#Consume from kafka topic and send to ES<br/><br/>import requests<br/>import json<br/>from decimal import Decimal<br/>from confluent_kafka import Consumer, KafkaError<br/>import os<br/>import socket<br/>from time import sleep<br/><br/>from datetime import datetime<br/>from elasticsearch import Elasticsearch<br/><br/>#==============================# This section runs our python code as a TCP server #==============================<br/># Create a socket<br/>sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)<br/><br/># Ensure that you can restart your server quickly when it terminates<br/>sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)<br/><br/># Set the client socket's TCP "well-known port" number<br/>well_known_port = int(os.environ['PYTHON_CONSUMER_SERVER_PORT'])<br/>sock.bind(('localhost', well_known_port))<br/><br/># Set the number of clients waiting for connection that can be queued<br/>sock.listen(5)<br/><br/>#==============================# This section sets up Elasticsearch world #==============================<br/><br/>#Function to check connectivity to ES cluster<br/>def isOpenES(ip,port):<br/>   s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)<br/>   try:<br/>      print("Attempting connectio to ES cluster...")<br/>      s.settimeout(30)<br/>      s.connect((ip, int(port)))<br/>      print("Connection successfully established with ES cluster. We may proceed")<br/>      sleep(1)<br/>      return True<br/>   except:<br/>      return False<br/>   finally:<br/>        s.close()<br/><br/># Check connectivity to ES cluster before proceding any further<br/>def check_elastic():<br/>  global check_port_wait<br/>  check_port_wait = 30<br/>  while True:<br/>    global check_port<br/>    check_port =  isOpenES(os.environ['ES_HOST'], int(os.environ['ES_HOST_PORT']))<br/>    if check_port == False:<br/>        for x in range(check_port_wait):<br/>            print("Retrying connection to ES cluster...in " + str(x) + " seconds")<br/>            sleep(1)<br/>    else:<br/>      break<br/>    <br/># Execute elasticsearch connection check<br/>check_elastic()<br/><br/>#Only when successfull connection to ES cluster established then we can setup ES client <br/>if check_port == True:<br/>  es = Elasticsearch(<br/>      hosts= os.environ['ES_URL_ENDPOINT'],<br/>      basic_auth= (os.environ['ES_USER'], os.environ['ES_PASSWORD']),<br/>      request_timeout= 60<br/>      )<br/><br/># Set up index settings and fields mappings<br/>es_settings = {<br/>  "settings": {<br/>    "number_of_shards": 1,<br/>    "number_of_replicas": 0<br/>  },<br/>  "mappings": {<br/>    "properties": {<br/>      "next_funding_time": {<br/>        "type": "keyword"<br/>      },<br/>      "delivery_time": {<br/>        "type": "keyword"<br/>      },<br/>      "ask_price": {<br/>        "type": "float"<br/>      },<br/>      "bid_price": {<br/>        "type": "float"<br/>      },<br/>      "index_price": {<br/>        "type": "float"<br/>      },<br/>      "last_price": {<br/>        "type": "float"<br/>      },<br/>      "low_price_24h": {<br/>        "type": "float"<br/>      },<br/>      "last_price": {<br/>        "type": "float"<br/>      },<br/>      "mark_price": {<br/>        "type": "float"<br/>      },<br/>      "open_interest": {<br/>        "type": "float"<br/>      },<br/>      "prev_price_1h": {<br/>        "type": "float"<br/>      },<br/>      "prev_price_24h": {<br/>        "type": "float"<br/>      },<br/>      "price_1h_pcnt": {<br/>        "type": "float"<br/>      },<br/>      "price_24h_pcnt": {<br/>        "type": "float"<br/>      },<br/>      "total_volume": {<br/>        "type": "float"<br/>      },<br/>      "turnover_24h": {<br/>        "type": "float"<br/>      },<br/>      "volume_24h": {<br/>        "type": "float"<br/>      }<br/>    }<br/>  }<br/>}<br/><br/>#Check if if index exists before creating it:<br/>try:<br/>  check_indices = es.indices.exists(index=os.environ['ES_INDEX'])<br/>except:<br/>  while True:<br/>    if es.cluster.health()["status"] != ("green" or "yellow"):<br/>      for x in range(15):<br/>        print("ES cluster is not healthy yet, we retry in " + str(x) + " seconds")<br/>    else:<br/>      break<br/><br/><br/>#If index doesnt exist, create it<br/>if check_indices == False:<br/>  es.indices.create(index=os.environ['ES_INDEX'], body=es_settings)<br/><br/>#==============================# This section sets up Kafka Consumer world #==============================<br/><br/>#Kafka consumer settings<br/>settings = {<br/>    'bootstrap.servers': os.environ['KAFKA_BROKERS_HOST_PORT'],<br/>    'group.id': os.environ['KAFKA_CONSUMER_GROUP_ID'],<br/>    'default.topic.config': {'auto.offset.reset': os.environ['KAFKA_OFFSET_RESET']},<br/>    'auto.offset.reset': os.environ['KAFKA_OFFSET_RESET']<br/>}<br/><br/>#Function to check connectivity to Kafka cluster<br/>def isOpenKafka(ip,port):<br/>   s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)<br/>   try:<br/>      s.connect((ip, int(port)))<br/>      s.settimeout(30)<br/>      print("Connection successfully established with Kafka cluster. We may proceed, awaiting incoming events ...")<br/>      sleep(1)<br/>      return True<br/>   except:<br/>      return False<br/>   finally:<br/>        s.close()<br/><br/># Check connectivity to kafka cluster before proceding any further<br/>def check_kafka():<br/>  while True:<br/>    check_port =  isOpenKafka(os.environ['KAFKA_HOST'], int(os.environ['KAFKA_BROKERS_PORT']))<br/>    if check_port == False:<br/>        for x in range(check_port_wait):<br/>            print("Retrying connection to kafka cluster...in " + str(x) + " seconds")<br/>            sleep(1)<br/>    else:<br/>      break<br/><br/># Execute kafka check inception<br/>check_kafka()<br/><br/>#Only when successfull connection is established with kafka then we can setup Consumer <br/>if check_port == True:<br/>  c = Consumer(settings)<br/>  c.subscribe([os.environ['KAFKA_TOPIC']])<br/><br/>#==============================# This is the Main section which runs this program - Consume from kafka #==============================<br/><br/>#Set up the batch counter<br/>count = 0<br/><br/>#Kick off the consumer loop to continously consume as per poll interval.<br/>#We need to have it in a 'try' section so we can handle exceptions errors<br/>try:<br/>    while True:<br/>      #Initiates the consumer with a poll interval of milliseconds - price_nowtime poll<br/>      msg = c.poll(0.1)<br/>      #If there are no messages, continue waiting for incoming events<br/>      if msg is None:<br/>          continue<br/>      #If there are no msg.error then we've got messages and can print what we've received<br/>      elif not msg.error():<br/>          count += 1<br/>          print('Received message: {0}'.format(msg.value()))<br/>          #print('Received message: {}'.format(msg.value().decode('utf-8')))<br/>          data = msg.value().decode()<br/>          #If the message value is None, continue <br/>          if msg.value() is None:<br/>              continue<br/>          <br/>          # Handle UTF<br/>          try:<br/>              data = msg.value().decode()<br/>          except Exception:<br/>              data = msg.value()<br/>              print(data)<br/>          #At this point we have the messages so we can send them to ES cluster<br/>          try: <br/>            resp = es.index(index="elastic-index", id=datetime.now(), document=data)<br/>            print(resp['result'])<br/>          except:<br/>            check_elastic()<br/>      #Keeping track of the amount of message processed<br/>      print(str(count) + " messages received so far...at " + str(datetime.now().strftime("%Y-%m-%dT%H:%M:%S")))<br/><br/>      if msg.error():<br/>        print("Consumer error: {}".format(msg.error()))<br/>        continue<br/><br/>except Exception as e:<br/>  print(e)<br/><br/>finally:<br/>    c.close() </span></pre><p id="f1d1" class="pw-post-body-paragraph kr ks in kt b ku lm kw kx ky ln la lb ke lo ld le ki lp lg lh km lq lj lk ll ig bi translated">关于消费者需要补充的是，这个程序作为 TCP 服务器在您选择的特定 TCP 端口上运行。原因是我们想通过它的 TCP 端口知道这个应用程序是启动还是死亡。我们将作为 docker 容器运行，并通过 TCP 端口监控其健康状况。顺便说一句，同样的原则应该适用于生产者。</p><p id="0e41" class="pw-post-body-paragraph kr ks in kt b ku lm kw kx ky ln la lb ke lo ld le ki lp lg lh km lq lj lk ll ig bi translated">现在，让我们看看这两个代码运行后的样子。</p><h2 id="5dc5" class="jv jw in bd jx jy jz dn ka kb kc dp kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">Bootstrapping …代码正在运行，但会停止进一步执行，直到其依赖层(<em class="mu"> Kafka </em>)可访问</h2><figure class="mg mh mi mj gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi mv"><img src="../Images/6ab7a6b3e46e6550a3f1fd8ea93d16fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dB5GxOT9avDn3ULHYtzySw.png"/></div></div></figure><p id="7cba" class="pw-post-body-paragraph kr ks in kt b ku lm kw kx ky ln la lb ke lo ld le ki lp lg lh km lq lj lk ll ig bi translated">一旦依赖是可达的和可操作的，它就可以产生卡夫卡主题</p><figure class="mg mh mi mj gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi mw"><img src="../Images/cee3173878aa479950282bd200d3cb97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K4zxi0VZohGnm94JGn5kEA.png"/></div></div></figure><figure class="mg mh mi mj gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi mx"><img src="../Images/91ad63e2e7973be1c1db399227e989ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2-eeXiQ5xv9FzTeF7GOoqA.png"/></div></div></figure><p id="93e2" class="pw-post-body-paragraph kr ks in kt b ku lm kw kx ky ln la lb ke lo ld le ki lp lg lh km lq lj lk ll ig bi translated">我确保我们得到了事件流的实时报告，以便跟踪在这个流中发生了什么。我们正在分批摄取，作为每次摄取的一部分，我们将数据集发送到数据湖(<strong class="kt io"> AWS S3 </strong>)进行长期保存，并在需要时用于满足任何其他消费者的需求。</p><h2 id="1abf" class="jv jw in bd jx jy jz dn ka kb kc dp kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">下面是后续批处理的样子:</h2><figure class="mg mh mi mj gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi my"><img src="../Images/837a5f28bdec5ba45fb1d217343d3a02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wqUWv1rwYXo7RcZHI2R-kw.png"/></div></div></figure><h2 id="4671" class="jv jw in bd jx jy jz dn ka kb kc dp kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">是时候启动我们的 Kafka 消费者了……正如您在这里注意到的，消费者的代码执行暂停了，因为他的依赖层(<strong class="ak"><em class="mu">elastic search</em></strong>)不可达。这将循环进行，直到可以到达:</h2><figure class="mg mh mi mj gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi mz"><img src="../Images/87cdc8376542ab1436f138bcb96151c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p6UPP3dE5XHy5yw7BCZxvw.png"/></div></div></figure><p id="4c3f" class="pw-post-body-paragraph kr ks in kt b ku lm kw kx ky ln la lb ke lo ld le ki lp lg lh km lq lj lk ll ig bi translated">让我们启动 elastic search……一旦启动，代码将继续执行。</p><figure class="mg mh mi mj gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi na"><img src="../Images/3ca09093523e0f47dfc108c73654c023.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zRHhE9uJFJl_D42iTf7f5w.png"/></div></div></figure><p id="b86b" class="pw-post-body-paragraph kr ks in kt b ku lm kw kx ky ln la lb ke lo ld le ki lp lg lh km lq lj lk ll ig bi translated">解决方案中包含的一个重要注意事项是，我们<strong class="kt io">跟踪</strong>和<strong class="kt io">时间戳</strong>此工作流接收、处理的每条记录:</p><figure class="mg mh mi mj gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi nb"><img src="../Images/310c9f5628ffd04e24f1f89872db427e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xUuJ8xVyUDUWgB3lJY6kCg.png"/></div></div></figure><p id="b0a3" class="pw-post-body-paragraph kr ks in kt b ku lm kw kx ky ln la lb ke lo ld le ki lp lg lh km lq lj lk ll ig bi translated">很好，现在我们正在处理事件并将它们发布到我们的分析平台(elasticsearch)。我们去看看它是什么样子。</p><figure class="mg mh mi mj gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi nc"><img src="../Images/820e67f0e392353d1f613bd46d4e420c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-rxR4ZnXsHLkKq4j4wd5NA.png"/></div></div></figure><p id="39d1" class="pw-post-body-paragraph kr ks in kt b ku lm kw kx ky ln la lb ke lo ld le ki lp lg lh km lq lj lk ll ig bi translated">在我们开始进一步分析它之前，它看起来并不怎么样…</p><figure class="mg mh mi mj gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi nd"><img src="../Images/29b9719350d7ee281650d17cedb1340d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ERVFaOhQcd5GwhktxgAa7A.png"/></div></div></figure><p id="a316" class="pw-post-body-paragraph kr ks in kt b ku lm kw kx ky ln la lb ke lo ld le ki lp lg lh km lq lj lk ll ig bi translated">在过去的 7 天里，每种货币的价格和波动百分比是什么样的:</p><figure class="mg mh mi mj gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi ne"><img src="../Images/23a20ab4e933a0895f509e3ceb1ea9ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zu1cSno1ljUUlwRJr454NQ.png"/></div></div></figure><p id="cc0b" class="pw-post-body-paragraph kr ks in kt b ku lm kw kx ky ln la lb ke lo ld le ki lp lg lh km lq lj lk ll ig bi translated">哼🤔…我们开始了解这种情况，上涨 2.5%后又下跌的货币是什么？谁在这里经常变动？</p><p id="b574" class="pw-post-body-paragraph kr ks in kt b ku lm kw kx ky ln la lb ke lo ld le ki lp lg lh km lq lj lk ll ig bi translated">让我们获得 10 种加密货币在同一时期(7 天)的百分比变化权重:</p><pre class="mg mh mi mj gt mk ml mm bn mn mo bi"><span id="6b66" class="mp jw in ml b be mq mr l ms mt">GET elastic-index/_search<br/>{<br/>  "size": 0,<br/>  "aggs": {<br/>    "MICKA": {<br/>      "terms": {<br/>        "field": "symbol.keyword"<br/>        , "size": 10<br/>      },<br/>      "aggs": {<br/>        "NAME": {<br/>          "percentiles": {<br/>            "field": "price_24h_pcnt",<br/>            "percents": [<br/>              25,<br/>              50,<br/>              75,<br/>              95,<br/>              99<br/>            ]<br/>          }<br/>        }<br/>      }<br/>    }<br/>  }<br/>}</span></pre><pre class="nf mk ml mm bn mn mo bi"><span id="1e24" class="mp jw in ml b be mq mr l ms mt">{<br/>  "took" : 59,<br/>  "timed_out" : false,<br/>  "_shards" : {<br/>    "total" : 1,<br/>    "successful" : 1,<br/>    "skipped" : 0,<br/>    "failed" : 0<br/>  },<br/>  "hits" : {<br/>    "total" : {<br/>      "value" : 10000,<br/>      "relation" : "gte"<br/>    },<br/>    "max_score" : null,<br/>    "hits" : [ ]<br/>  },<br/>  "aggregations" : {<br/>    "MICKA" : {<br/>      "doc_count_error_upper_bound" : 0,<br/>      "sum_other_doc_count" : 72986,<br/>      "buckets" : [<br/>        {<br/>          "key" : "SKLUSDT",<br/>          "doc_count" : 397,<br/>          "NAME" : {<br/>            "values" : {<br/>              "25.0" : -0.017249249387532473,<br/>              "50.0" : 0.013384000398218632,<br/>              "75.0" : 0.02213199995458126,<br/>              "95.0" : 0.0325398001819849,<br/>              "99.0" : 0.04053437914699315<br/>            }<br/>          }<br/>        },<br/>        {<br/>          "key" : "SLPUSDT",<br/>          "doc_count" : 397,<br/>          "NAME" : {<br/>            "values" : {<br/>              "25.0" : -0.01976200006902218,<br/>              "50.0" : 0.003984000068157911,<br/>              "75.0" : 0.0206344376783818,<br/>              "95.0" : 0.041492998600006104,<br/>              "99.0" : 0.04583299905061722<br/>            }<br/>          }<br/>        },<br/>        {<br/>          "key" : "SNXUSDT",<br/>          "doc_count" : 397,<br/>          "NAME" : {<br/>            "values" : {<br/>              "25.0" : -0.04339925153180957,<br/>              "50.0" : -0.002605666678088407,<br/>              "75.0" : 0.034786999225616455,<br/>              "95.0" : 0.05091765057295561,<br/>              "99.0" : 0.056417589783668516<br/>            }<br/>          }<br/>        },<br/>        {<br/>          "key" : "SOLUSDT",<br/>          "doc_count" : 397,<br/>          "NAME" : {<br/>            "values" : {<br/>              "25.0" : -0.018149999901652336,<br/>              "50.0" : 0.020818000038464863,<br/>              "75.0" : 0.08763474971055984,<br/>              "95.0" : 0.11487374790012836,<br/>              "99.0" : 0.12104500085115433<br/>            }<br/>          }<br/>        },<br/>        {<br/>          "key" : "STGUSDT",<br/>          "doc_count" : 397,<br/>          "NAME" : {<br/>            "values" : {<br/>              "25.0" : -0.024567687651142478,<br/>              "50.0" : -0.01639300025999546,<br/>              "75.0" : 0.00449066663471361,<br/>              "95.0" : 0.025875399820506545,<br/>              "99.0" : 0.06390500068664551<br/>            }<br/>          }<br/>        },<br/>        {<br/>          "key" : "STMXUSDT",<br/>          "doc_count" : 397,<br/>          "NAME" : {<br/>            "values" : {<br/>              "25.0" : -0.03550550062209368,<br/>              "50.0" : 9.619999909773469E-4,<br/>              "75.0" : 0.03224662481807172,<br/>              "95.0" : 0.05798500031232834,<br/>              "99.0" : 0.06297794189304108<br/>            }<br/>          }<br/>        },<br/>        {<br/>          "key" : "STORJUSDT",<br/>          "doc_count" : 397,<br/>          "NAME" : {<br/>            "values" : {<br/>              "25.0" : -0.03473616577684879,<br/>              "50.0" : -0.007122000213712454,<br/>              "75.0" : 0.014991999603807926,<br/>              "95.0" : 0.033587001264095306,<br/>              "99.0" : 0.03975500166416168<br/>            }<br/>          }<br/>        },<br/>        {<br/>          "key" : "STXUSDT",<br/>          "doc_count" : 397,<br/>          "NAME" : {<br/>            "values" : {<br/>              "25.0" : 0.004346999805420637,<br/>              "50.0" : 0.013100000098347664,<br/>              "75.0" : 0.025890000785390537,<br/>              "95.0" : 0.03912999853491783,<br/>              "99.0" : 0.07264900207519531<br/>            }<br/>          }<br/>        },<br/>        {<br/>          "key" : "SUNUSDT",<br/>          "doc_count" : 397,<br/>          "NAME" : {<br/>            "values" : {<br/>              "25.0" : 0.015608999878168106,<br/>              "50.0" : 0.028155000880360603,<br/>              "75.0" : 0.042449667739371456,<br/>              "95.0" : 0.06716989986598491,<br/>              "99.0" : 0.07128699868917465<br/>            }<br/>          }<br/>        },<br/>        {<br/>          "key" : "SUSHIUSDT",<br/>          "doc_count" : 397,<br/>          "NAME" : {<br/>            "values" : {<br/>              "25.0" : -0.049969250336289406,<br/>              "50.0" : -0.020973000675439835,<br/>              "75.0" : 0.010279750218614936,<br/>              "95.0" : 0.09280899912118912,<br/>              "99.0" : 0.10080005057156086<br/>            }<br/>          }<br/>        }<br/>      ]<br/>    }<br/>  }<br/>}</span></pre><p id="8827" class="pw-post-body-paragraph kr ks in kt b ku lm kw kx ky ln la lb ke lo ld le ki lp lg lh km lq lj lk ll ig bi translated">你最喜欢的加密货币🙂</p><pre class="mg mh mi mj gt mk ml mm bn mn mo bi"><span id="108f" class="mp jw in ml b be mq mr l ms mt">GET elastic-index/_search<br/>{<br/>  "size": 0,<br/>  "query": {<br/>    "match": {<br/>      "symbol": "BTCUSD"<br/>    }<br/>  }, <br/>  "aggs": {<br/>    "MICKA": {<br/>      "terms": {<br/>        "field": "symbol.keyword"<br/>      },<br/>      "aggs": {<br/>        "NAME": {<br/>          "percentiles": {<br/>            "field": "price_24h_pcnt",<br/>            "percents": [<br/>              1,<br/>              5,<br/>              25,<br/>              50,<br/>              75,<br/>              95,<br/>              99<br/>            ]<br/>          }<br/>        }<br/>      }<br/>    }<br/>  }<br/>}</span></pre><pre class="nf mk ml mm bn mn mo bi"><span id="c5e2" class="mp jw in ml b be mq mr l ms mt">{<br/>  "took" : 740,<br/>  "timed_out" : false,<br/>  "_shards" : {<br/>    "total" : 1,<br/>    "successful" : 1,<br/>    "skipped" : 0,<br/>    "failed" : 0<br/>  },<br/>  "hits" : {<br/>    "total" : {<br/>      "value" : 398,<br/>      "relation" : "eq"<br/>    },<br/>    "max_score" : null,<br/>    "hits" : [ ]<br/>  },<br/>  "aggregations" : {<br/>    "MICKA" : {<br/>      "doc_count_error_upper_bound" : 0,<br/>      "sum_other_doc_count" : 0,<br/>      "buckets" : [<br/>        {<br/>          "key" : "BTCUSD",<br/>          "doc_count" : 398,<br/>          "NAME" : {<br/>            "values" : {<br/>              "1.0" : -0.018621680364012717,<br/>              "5.0" : -0.017968399822711947,<br/>              "25.0" : -0.013923999853432178,<br/>              "50.0" : 0.0018339999951422215,<br/>              "75.0" : 0.010238000191748142,<br/>              "95.0" : 0.022255999967455864,<br/>              "99.0" : 0.02323047965764999<br/>            }<br/>          }<br/>        }<br/>      ]<br/>    }<br/>  }<br/>}</span></pre><p id="1577" class="pw-post-body-paragraph kr ks in kt b ku lm kw kx ky ln la lb ke lo ld le ki lp lg lh km lq lj lk ll ig bi translated">这是一个<strong class="kt io"> 7 天</strong>的数据集分析！过去一两年的图像数据集…可能会让你对市场有一个更好的了解，不是吗？</p><p id="c880" class="pw-post-body-paragraph kr ks in kt b ku lm kw kx ky ln la lb ke lo ld le ki lp lg lh km lq lj lk ll ig bi translated">酷，就是这样，伙计们！在我的下一篇文章中，我们将做一些<strong class="kt io"> devops </strong>并将其存放在 docker 容器中，以便与 ansible 一起部署在<a class="ae ng" href="https://aws.amazon.com/ec2/" rel="noopener ugc nofollow" target="_blank"> <strong class="kt io"> AWS EC2 </strong> </a>工作负载上……敬请关注😉</p><h2 id="841a" class="jv jw in bd jx jy jz dn ka kb kc dp kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">哦！以下是我们的数据湖 AWS S3 中的数据集:</h2><figure class="mg mh mi mj gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi nh"><img src="../Images/b0d12ffa826b13bc71d6381e561d959e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kbQpj9K1QFIi9Ec9_drU0w.png"/></div></div></figure></div></div>    
</body>
</html>