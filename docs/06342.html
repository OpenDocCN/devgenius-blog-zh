<html>
<head>
<title>Starting with TensorFlow Datasets -part 1; An intro to tf.datasets API to start building complex data pipelines for your Machine and Deep Learning experiments.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从张量流数据集开始-第1部分；tf.datasets API简介，开始为您的机器和深度学习实验构建复杂的数据管道。</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/starting-with-tensorflow-datasets-part-1-an-intro-to-tf-datasets-9a26e2db4995?source=collection_archive---------2-----------------------#2022-01-01">https://blog.devgenius.io/starting-with-tensorflow-datasets-part-1-an-intro-to-tf-datasets-9a26e2db4995?source=collection_archive---------2-----------------------#2022-01-01</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><figure class="gl gn jl jm jn jo gh gi paragraph-image"><div class="gh gi jk"><img src="../Images/8bf7b08dec530a8f393ba84b6c971aed.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/0*tPpxUeQ45N5N0u51.jpg"/></div></figure><p id="2f89" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">TensorFlow是机器学习和深度学习的惊人生态系统，它附带了许多强大的库和工具，使工程师/研究人员能够无缝地工作，从预处理数据、创建模型等，直到将它们部署到生产中。我在工作中遇到的一个有趣的库是<a class="ae kp" href="https://www.tensorflow.org/datasets/overview" rel="noopener ugc nofollow" target="_blank"> TensorFlow数据集</a> (tfds)库。TensorFlow数据集库附带了大量研究人员想要试验的数据集。这个库最棒的地方在于它以<a class="ae kp" href="https://www.tensorflow.org/guide/data" rel="noopener ugc nofollow" target="_blank"> tf.data </a>的形式返回数据集。tf.data附带的API支持构建复杂且可重用的管道。管线被优化并且</p><p id="346f" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">在这个多部分教程系列中，我想向您介绍tf.data.Dataset及其最有趣和最重要的构建管道的方法，然后讨论tfds库，并以图像分类、自然语言处理为例。(在第2部分中)。在开始介绍TensorFlow数据集之前，我想先介绍一下tf.data api，同时也想展示一下它所具有的强大的数据转换api。</p><p id="3783" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">data是一个强大的ETL工具，它将使数据管道构建阶段变得整洁、干净和可重用。它可以与CPU、GPU和TPU一起工作，并且经过了高度优化。(啊！我还发现这让这个阶段变得轻松有趣。)</p><h1 id="8d86" class="kq kr in bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">目录</h1><ol class=""><li id="0c44" class="lo lp in jt b ju lq jy lr kc ls kg lt kk lu ko lv lw lx ly bi translated">使用tf.data的动机。</li><li id="b651" class="lo lp in jt b ju lz jy ma kc mb kg mc kk md ko lv lw lx ly bi translated">tf.data.Dataset的简要概述。</li><li id="3ab1" class="lo lp in jt b ju lz jy ma kc mb kg mc kk md ko lv lw lx ly bi translated">如何创建张量流数据集？</li><li id="9108" class="lo lp in jt b ju lz jy ma kc mb kg mc kk md ko lv lw lx ly bi translated">最重要的张量流数据集方法。</li><li id="ad7d" class="lo lp in jt b ju lz jy ma kc mb kg mc kk md ko lv lw lx ly bi translated">构建数据管道的方法链。</li></ol><h1 id="ebb2" class="kq kr in bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">1.使用tf.data的动机:-</h1><ol class=""><li id="d7c0" class="lo lp in jt b ju lq jy lr kc ls kg lt kk lu ko lv lw lx ly bi translated">可以用<strong class="jt io">的CPU，GPU，和TPU的。</strong>(您可以在您简陋的笔记本电脑上构建一个原型管道，并将其运送到强大的机器/云上)</li><li id="144b" class="lo lp in jt b ju lz jy ma kc mb kg mc kk md ko lv lw lx ly bi translated"><strong class="jt io">链接方法:</strong>各种数据转换可以表示为方法，也可以组合。</li><li id="41b6" class="lo lp in jt b ju lz jy ma kc mb kg mc kk md ko lv lw lx ly bi translated"><strong class="jt io"> Keras: </strong> tf.data与<strong class="jt io"> Keras </strong>配合得非常好，这也是将您的数据传递给<strong class="jt io"> Keras </strong>模型的推荐方式。</li><li id="e556" class="lo lp in jt b ju lz jy ma kc mb kg mc kk md ko lv lw lx ly bi translated">优化您机器的性能。更多信息请访问<a class="ae kp" href="https://www.tensorflow.org/guide/data_performance" rel="noopener ugc nofollow" target="_blank">数据性能</a>，它详细解释了tf.datasets是如何固定事物的。</li><li id="2909" class="lo lp in jt b ju lz jy ma kc mb kg mc kk md ko lv lw lx ly bi translated">使数据构建管道过程更加顺畅，代码更具可读性、可再现性和可重用性。</li></ol><h1 id="72cc" class="kq kr in bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">2.tf.data.Dataset的简要概述:</h1><p id="29d5" class="pw-post-body-paragraph jr js in jt b ju lq jw jx jy lr ka kb kc me ke kf kg mf ki kj kk mg km kn ko ig bi translated">下面是来自官方<a class="ae kp" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset" rel="noopener ugc nofollow" target="_blank">文件</a>的tf.datasets的快速浏览:</p><blockquote class="mh mi mj"><p id="c41c" class="jr js mk jt b ju jv jw jx jy jz ka kb ml kd ke kf mm kh ki kj mn kl km kn ko ig bi translated"><code class="fe mo mp mq mr b"><a class="ae kp" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset" rel="noopener ugc nofollow" target="_blank">tf.data.Dataset</a></code> API支持编写描述性的高效输入管道。<code class="fe mo mp mq mr b">Dataset</code>用法遵循一种常见模式:</p><p id="8551" class="jr js mk jt b ju jv jw jx jy jz ka kb ml kd ke kf mm kh ki kj mn kl km kn ko ig bi translated">1.根据输入数据创建源数据集。</p><p id="c317" class="jr js mk jt b ju jv jw jx jy jz ka kb ml kd ke kf mm kh ki kj mn kl km kn ko ig bi translated">2.应用数据集转换来预处理数据。</p><p id="6b72" class="jr js mk jt b ju jv jw jx jy jz ka kb ml kd ke kf mm kh ki kj mn kl km kn ko ig bi translated">3.迭代数据集并处理元素。</p><p id="35c7" class="jr js mk jt b ju jv jw jx jy jz ka kb ml kd ke kf mm kh ki kj mn kl km kn ko ig bi translated">迭代以流的方式发生，因此整个数据集不需要适合内存。</p></blockquote><h1 id="22e5" class="kq kr in bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">3.如何创建张量流数据集:</h1><p id="1386" class="pw-post-body-paragraph jr js in jt b ju lq jw jx jy lr ka kb kc me ke kf kg mf ki kj kk mg km kn ko ig bi translated">开始和理解如何创建tf.data.Dataset的最简单方法是从创建tensorflow数据集开始，最好的起点是<strong class="jt io">TF . data . dataset . from _ tensor _ slices()</strong>方法。该方法接受numpy数组/ python列表/等，并将其转换为张量数据集。</p><p id="055a" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">一旦使用这种方法创建了TensorFlow数据集，就可以使用它的<strong class="jt io"> element_spec </strong>属性来检查所创建数据集的元素规范。让我们现在就动手吧。</p><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="11ac" class="na kr in mr b gy nb nc l nd ne">import tensorflow as tf<br/>import numpy as np</span><span id="7a06" class="na kr in mr b gy nf nc l nd ne">#Creating a tensorflow dataset using a list</span><span id="4a05" class="na kr in mr b gy nf nc l nd ne">list_data = tf.data.Dataset.from_tensor_slices([1, 2, 3],)</span><span id="eb31" class="na kr in mr b gy nf nc l nd ne">#Creating a tensorflow dataset using a numpy array<br/>np_data = tf.data.Dataset.from_tensor_slices(np.array([[1, 2, 3]<br/>                                                       [4, 5, 6,],<br/>                                                       [7, 8, 9],</span><span id="8b67" class="na kr in mr b gy nf nc l nd ne">                                                       ]</span><span id="7a69" class="na kr in mr b gy nf nc l nd ne">                                               ))</span><span id="106e" class="na kr in mr b gy nf nc l nd ne">#Use the element_spec attribute to look at your data</span><span id="9a90" class="na kr in mr b gy nf nc l nd ne">list_data.element_spec</span><span id="6156" class="na kr in mr b gy nf nc l nd ne"># TensorSpec(shape=(), dtype=tf.int32, name=None)</span><span id="f390" class="na kr in mr b gy nf nc l nd ne">np_data.element_spec</span><span id="7f2b" class="na kr in mr b gy nf nc l nd ne"># TensorSpec(shape=(3,), dtype=tf.int64, name=None)</span></pre><p id="f20c" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">接下来，让我们看一个更现实的例子来创建一个张量流数据集，我们将使用mnist数据集。在下面的代码片段中，我们加载mnist数据集，并从返回的numpy数组创建TensorFlow数据集。最后，我们使用<strong class="jt io"> as_numpy_iterator() </strong>方法从TensorFlow数据集加载数据，该方法允许我们通过将张量转换为numpy数组来访问数据。在我们的例子中，它将让我们检查数据集。</p><p id="1f8a" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated"><strong class="jt io">注意</strong>:你可以传递一个以上的NumPy数组给<strong class="jt io"> from_tensor_slices </strong>方法。</p><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="1022" class="na kr in mr b gy nb nc l nd ne"># Load data the mnist data<br/>train, test = tf.keras.datasets.mnist.load_data()</span><span id="b10c" class="na kr in mr b gy nf nc l nd ne"># Read the images array's and the lables<br/>images, lables = train</span><span id="1533" class="na kr in mr b gy nf nc l nd ne"># Quick preprocess<br/>images = images/255.0</span><span id="7bd3" class="na kr in mr b gy nf nc l nd ne"># Create your dataset<br/>mnist_dataset = tf.data.Dataset.from_tensor_slices((images, lables))</span><span id="5c4a" class="na kr in mr b gy nf nc l nd ne"># Element inspection<br/>mnist_dataset.element_spec</span><span id="fa3d" class="na kr in mr b gy nf nc l nd ne"># Returns the created tensors and following is the output<br/># (TensorSpec(shape=(28, 28), dtype=tf.float64, name=None),<br/># TensorSpec(shape=(), dtype=tf.uint8, name=None))</span><span id="09f7" class="na kr in mr b gy nf nc l nd ne"><br/># X is the first input array and y is the corresponding lable</span><span id="afd8" class="na kr in mr b gy nf nc l nd ne">for X,y in mnist_dataset.as_numpy_iterator():<br/>    print("Shape of X, y")<br/>    print(X.shape, y.shape)<br/>    print(type(X), ", This number is --&gt;", y)<br/>    break # to avoid iterating over all the training examples</span><span id="7e04" class="na kr in mr b gy nf nc l nd ne"># Output is as follows:<br/># Shape of X, y<br/># (28, 28) ()<br/># &lt;class 'numpy.ndarray'&gt; , This number is --&gt; 5</span></pre><p id="ce2c" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">创建TensorFlow数据集的其他方法(使用python生成器、TFRecords、CSV、图像和文件集)将在接下来的部分中展开。如果你现在很好奇，你可以看看这些文件。</p><h1 id="2e04" class="kq kr in bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">4.可用的最重要的张量流数据集方法:</h1><p id="7440" class="pw-post-body-paragraph jr js in jt b ju lq jw jx jy lr ka kb kc me ke kf kg mf ki kj kk mg km kn ko ig bi translated">tf.data.Dataset有25种以上的可用方法，但这里我想涵盖您需要使用TensorFlow数据集的最常见方法，以及您将在文档和其他作品中看到的最常见方法。</p><ol class=""><li id="7a26" class="lo lp in jt b ju jv jy jz kc ng kg nh kk ni ko lv lw lx ly bi translated"><strong class="jt io">范围:</strong>创建一个以步长分隔的值范围的数据集。签名开始，停止步骤。下面演示了这种方法</li></ol><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="3810" class="na kr in mr b gy nb nc l nd ne">range_dataset = tf.data.Dataset.range(5)<br/>print(list(range_dataset.as_numpy_iterator()))<br/># [0, 1, 2, 3, 4]</span><span id="fdd0" class="na kr in mr b gy nf nc l nd ne">range_stepped_dataset = tf.data.Dataset.range(1, 10, 3, output_type=tf.float32)</span><span id="8054" class="na kr in mr b gy nf nc l nd ne">print(list(range_stepped_dataset.as_numpy_iterator()))<br/># [1.0, 4.0, 7.0]</span></pre><p id="3ef2" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated"><strong class="jt io"> 2。地图</strong> : <code class="fe mo mp mq mr b">map(map_func, )</code></p><p id="972c" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">这可以让你对传递给张量的每个元素应用“<strong class="jt io"> map_func </strong>”函数。下面是此方法的示例，其中我们将上面定义的range_dataset中的每个元素除以4。</p><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="b9bc" class="na kr in mr b gy nb nc l nd ne">def div_by_4(x):<br/>'''A function that will help you divide each tensor element by 4<br/>'''<br/>  return x/4</span><span id="6bff" class="na kr in mr b gy nf nc l nd ne">range_divided = range_dataset.map(div_by_4)</span><span id="cac3" class="na kr in mr b gy nf nc l nd ne">print(list(range_divided.as_numpy_iterator()))<br/>#[0.0, 0.25, 0.5, 0.75, 1.0]</span></pre><p id="54c2" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated"><strong class="jt io"> 3 .as_numpy_iterator: </strong>如上所述，此方法返回一个将数据集的所有元素转换为numpy的迭代器。</p><p id="49fd" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated"><strong class="jt io"> 4 .take: </strong> <code class="fe mo mp mq mr b">take( count, name=None)<br/></code>它创建一个新的数据集，并向其传递最大计数。下面是take方法如何工作的快速演示。它还可以处理批处理数据集，并将使用<strong class="jt io">批处理</strong>方法演示其行为。</p><p id="6521" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">在这里，我们从我们创建的<strong class="jt io"> mnist_dataset </strong>中获取前几个6个图像。</p><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="a1dd" class="na kr in mr b gy nb nc l nd ne">fist_six_images_taken = mnist_dataset.take(6)<br/>print('Lenght of the dataset',len(fist_six_images_taken))<br/># Lenght of the dataset 6</span><span id="2b7a" class="na kr in mr b gy nf nc l nd ne">print(fist_six_images_taken.element_spec)<br/># (TensorSpec(shape=(28, 28), dtype=tf.float64, name=None), #TensorSpec(shape=(), dtype=tf.uint8, name=None))</span><span id="4a4e" class="na kr in mr b gy nf nc l nd ne">for X,y in fist_six_images_taken.as_numpy_iterator():<br/>   print(X.shape, y)</span><span id="68ba" class="na kr in mr b gy nf nc l nd ne"># (28, 28) 5<br/># (28, 28) 0<br/># (28, 28) 4<br/># (28, 28) 1<br/># (28, 28) 9<br/># (28, 28) 2</span></pre><p id="7dbd" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated"><strong class="jt io"> 5 .跳过:</strong> <code class="fe mo mp mq mr b">skip( count, name=None)</code> <strong class="jt io"> <br/> </strong>它创建一个数据集，从该数据集中跳过计数元素。让我们看看这个方法是如何工作的，在下面的例子中，让我们跳过<strong class="jt io"> mnist_dataset </strong>中的前3个元素，取下一个3。如果在教程中一直跟随，我们应该依次看到标签/图像1、9和2</p><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="5f7c" class="na kr in mr b gy nb nc l nd ne">for X,y in mnist_dataset.skip(3).take(3).as_numpy_iterator():<br/>   print(X.shape, y)</span><span id="baa5" class="na kr in mr b gy nf nc l nd ne"># (28, 28) 1<br/># (28, 28) 9<br/># (28, 28) 2</span></pre><p id="2343" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated"><strong class="jt io"> 6 .重复:</strong> <code class="fe mo mp mq mr b">repeat( count=None, name=None)</code> <br/>此方法按顺序重复数据集值</p><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="5860" class="na kr in mr b gy nb nc l nd ne">dataset2 = tf.data.Dataset.range(3)<br/>repeated_dataset = dataset2.repeat(3)<br/>print(repeated_dataset.element_spec)<br/>print(list(repeated_dataset.as_numpy_iterator()))</span><span id="13fe" class="na kr in mr b gy nf nc l nd ne"># TensorSpec(shape=(), dtype=tf.int64, name=None)<br/># [0, 1, 2, 0, 1, 2, 0, 1, 2]</span></pre><p id="a53c" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated"><strong class="jt io"> 7 .洗牌:</strong> <code class="fe mo mp mq mr b">shuffle( buffer_size, seed=None, reshuffle_each_iteration=None, name=None)</code> <br/>跟随洗牌的工作取自单据TensorFlow单据</p><blockquote class="mh mi mj"><p id="387b" class="jr js mk jt b ju jv jw jx jy jz ka kb ml kd ke kf mm kh ki kj mn kl km kn ko ig bi translated">随机打乱此数据集的元素。</p><p id="b429" class="jr js mk jt b ju jv jw jx jy jz ka kb ml kd ke kf mm kh ki kj mn kl km kn ko ig bi translated">此数据集用buffer_size元素填充缓冲区，然后从此缓冲区中随机采样元素，用新元素替换所选元素。为了实现完美的混洗，需要大于或等于数据集完整大小的缓冲区大小。</p><p id="a3b1" class="jr js mk jt b ju jv jw jx jy jz ka kb ml kd ke kf mm kh ki kj mn kl km kn ko ig bi translated">例如，如果数据集包含10，000个元素，但<code class="fe mo mp mq mr b">buffer_size</code>设置为1，000，则<code class="fe mo mp mq mr b">shuffle</code>将最初仅从缓冲区中的前1，000个元素中选择一个随机元素。一旦选择了一个元素，它在缓冲区中的空间就被下一个(即1，001-st)元素替换，保持1，000个元素的缓冲区。</p></blockquote><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="e8ba" class="na kr in mr b gy nb nc l nd ne">dataset3 = tf.data.Dataset.range(3)<br/>print(list(dataset3.as_numpy_iterator()))<br/>print(list(dataset3.shuffle(3).as_numpy_iterator()))</span><span id="da82" class="na kr in mr b gy nf nc l nd ne"># [0, 1, 2]<br/># [1, 2, 0]</span></pre><p id="8969" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">注意:这种方法可用于对抗序列偏差。</p><p id="67aa" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated"><strong class="jt io"> 8 .此方法通过将给定数据集压缩在一起来创建数据集。</strong></p><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="a6f2" class="na kr in mr b gy nb nc l nd ne">np_array = np.array([[1, 2, 3],<br/>                    [4, 5, 6],<br/>                    [7, 8, 9]])<br/>labels = np.array([0, 0, 1])<br/>d_ds = tf.data.Dataset.from_tensor_slices(np_array)<br/>lab_tf = tf.data.Dataset.from_tensor_slices(labels)</span><span id="3c10" class="na kr in mr b gy nf nc l nd ne"># Zipping 2 tf datasets<br/>zipped_dataset = tf.data.Dataset.zip((d_ds, lab_tf))</span><span id="2311" class="na kr in mr b gy nf nc l nd ne">print('Array   , Label')<br/>for x,y in zipped_dataset.as_numpy_iterator():<br/>    print(x, ',' ,y)</span><span id="c1e2" class="na kr in mr b gy nf nc l nd ne"># Array   , Label<br/># [1 2 3] , 0<br/># [4 5 6] , 0<br/># [7 8 9] , 1</span></pre><p id="82d2" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated"><strong class="jt io"> 9。batch: </strong> <code class="fe mo mp mq mr b">batch( batch_size, drop_remainder=False, num_parallel_calls=None, deterministic=None,name=None)</code> <br/>该函数用于根据指定的batch_size将数据集的连续元素组合成批次。<br/><strong class="jt io">【drop _ remainder】，</strong>参数如果设置为True，将删除不符合指定批量的剩余元素。让我们来看一个例子，我们将它设置为默认值，然后将它设置为true</p><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="c4fe" class="na kr in mr b gy nb nc l nd ne"># drop_remainder = False<br/>batched_ds = zipped_dataset.batch(2)</span><span id="1ab8" class="na kr in mr b gy nf nc l nd ne">print('batched dataset, lables')<br/>for i in batched_ds:<br/>  print(i[0].shape, '        ,  ',i[1].shape)<br/>print()</span><span id="ba55" class="na kr in mr b gy nf nc l nd ne">print('Elements of the batched dataset')<br/>for X,y in batched_ds.as_numpy_iterator():<br/>  print('X= ', X)<br/>  print('y= ',y)</span><span id="cd86" class="na kr in mr b gy nf nc l nd ne"># batched dataset, lables<br/># (2, 3)         ,   (2,)<br/># (1, 3)         ,   (1,)</span><span id="6b25" class="na kr in mr b gy nf nc l nd ne"># Elements of the batched dataset<br/># X=  [[1 2 3]<br/>#     [4 5 6]]</span><span id="2fe0" class="na kr in mr b gy nf nc l nd ne"># y=  [0 0]</span><span id="716a" class="na kr in mr b gy nf nc l nd ne"># X=  [[7 8 9]]<br/># y=  [1]</span></pre><p id="7717" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">drop_remainder设置为True</p><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="c767" class="na kr in mr b gy nb nc l nd ne"># drop_remainder=True<br/>batched_ds = zipped_dataset.batch(2, drop_remainder=True)</span><span id="c6d0" class="na kr in mr b gy nf nc l nd ne">print('batched dataset, lables')<br/>for i in batched_ds:<br/>  print(i[0].shape, i[1].shape)<br/>print()</span><span id="ad71" class="na kr in mr b gy nf nc l nd ne">print('Elements of the batched dataset')<br/>for X,y in batched_ds.as_numpy_iterator():<br/>  print('X= ', X)<br/>  print('y= ',y)<br/># batched dataset, lables<br/># (2, 3) (2,)</span><span id="9965" class="na kr in mr b gy nf nc l nd ne"># Elements of the batched dataset<br/># X=  [[1 2 3]<br/>#     [4 5 6]]<br/># y=  [0 0]</span></pre><p id="fbc1" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated"><strong class="jt io"> 10。window: </strong> <code class="fe mo mp mq mr b">window( size, shift=None, stride=1, drop_remainder=False, name=None)</code> <br/>返回一个“windows”的数据集。<br/>每个“窗口”是包含输入数据集元素子集的数据集。这些数据集的大小是有限的(如果没有足够的输入元素来填充窗口，并且drop_remainder的计算结果为False，则可能更少)。</p><blockquote class="mh mi mj"><p id="2612" class="jr js mk jt b ju jv jw jx jy jz ka kb ml kd ke kf mm kh ki kj mn kl km kn ko ig bi translated"><strong class="jt io">注:</strong>处理时序数据时有用</p></blockquote><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="8f49" class="na kr in mr b gy nb nc l nd ne">data = tf.data.Dataset.range(10)<br/>print('Orginal data', list(data.as_numpy_iterator()))<br/>#  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</span><span id="9f85" class="na kr in mr b gy nf nc l nd ne">windowed_data = data.window(5, shift=1, drop_remainder=True)<br/>for window_data in windowed_data:<br/>    for val in window_data:<br/>        print(val.numpy(), end=" ")<br/>    print()</span><span id="3d39" class="na kr in mr b gy nf nc l nd ne"># Orginal data [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]<br/># 0 1 2 3 4 <br/># 1 2 3 4 5 <br/># 2 3 4 5 6 <br/># 3 4 5 6 7 <br/># 4 5 6 7 8 <br/># 5 6 7 8 9</span></pre><p id="ecd5" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">以下是设置<strong class="jt io"> shift=2 </strong>的示例</p><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="16b8" class="na kr in mr b gy nb nc l nd ne"># with shift = 2<br/>windowed_data = data.window(5, shift=2, drop_remainder=True)<br/>for window_data in windowed_data:<br/>    for val in window_data:<br/>        print(val.numpy(), end=" ")<br/>    print()</span><span id="4826" class="na kr in mr b gy nf nc l nd ne"># 0 1 2 3 4 <br/># 2 3 4 5 6 <br/># 4 5 6 7 8</span></pre><p id="d7d6" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">11。预取: <code class="fe mo mp mq mr b">prefetch( buffer_size, name=None)</code> <br/>创建一个数据集，从这个数据集中预取元素。</p><p id="b9ac" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">来自TensorFlow文档:</p><blockquote class="mh mi mj"><p id="08e6" class="jr js mk jt b ju jv jw jx jy jz ka kb ml kd ke kf mm kh ki kj mn kl km kn ko ig bi translated">大多数数据集输入管道应该以调用预取结束。这允许在处理当前元素的同时准备后面的元素。这通常会改善延迟和吞吐量，但代价是使用额外的内存来存储预取的元素。</p></blockquote><p id="789f" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">12。cache: <br/> 缓存这个数据集中的元素。第一次迭代数据集时，它的元素将被缓存在指定的文件或内存中。后续迭代将使用缓存的数据。</p><p id="fa0a" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">13。flat_map  : <code class="fe mo mp mq mr b">flat_map( map_func, name=None)</code> <br/>将<code class="fe mo mp mq mr b">map_func</code>映射到整个数据集，并将结果展平。</p><p id="351a" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">14。apply:  <code class="fe mo mp mq mr b">apply( transformation_func)<br/></code>该函数对数据集应用一个变换函数，并返回变换后的数据集。</p><h1 id="8aec" class="kq kr in bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">5.与TensorFlow数据集的方法链接:</h1><p id="8b94" class="pw-post-body-paragraph jr js in jt b ju lq jw jx jy lr ka kb kc me ke kf kg mf ki kj kk mg km kn ko ig bi translated">让我们把到目前为止我们在本教程中学到的所有东西放在一起，并链接多个TensorFlow方法来构建一个数据管道。</p><p id="ef72" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">让我们举一个简单的例子来演示如何在TensorFlow中链接方法来构建转换管道。这里我拿一个玩具的例子来演示。(真实生活中的复杂例子将在随后的部分中出现，我们将在真实数据集上使用这些方法。)</p><p id="b033" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated"><strong class="jt io">我们的任务</strong>很简单，就是创建一个数据集，用于预测序列中的下一个数字。更具体地说，假设我们有一个从1到10的序列，任务是读取前4个数字(输入)并预测第5个数字。此任务所需的数据集可能如下所示:</p><p id="f012" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">X= 1，2，3，4然后y = 5 <br/> X = 2，3，4，5然后y = 6 <br/> X = 3，4，5，6然后y = 7等等</p><p id="9f40" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">在这里，我们可以通过以下方式使用TensorFlow来完成这项任务。<br/>我们使用大小为5的窗口，前4个是X，最后一个是y。<br/>我们还打开了随机播放以避免偏差。我们使用的批量大小为3。</p><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="d80a" class="na kr in mr b gy nb nc l nd ne">ndataset = tf.data.Dataset.range(10)<br/>ndataset = ndataset.window(5, shift=1, drop_remainder=True)<br/>ndataset = ndataset.flat_map(lambda window: window.batch(5))<br/>ndataset = ndataset.map(lambda window: (window[:-1], window[-1:]))<br/>ndataset = ndataset.shuffle(buffer_size=10)<br/>ndataset = ndataset.batch(3).prefetch(1)</span><span id="75af" class="na kr in mr b gy nf nc l nd ne">for x, y in ndataset:<br/>    print("x = ", list(x.numpy()))<br/>    print("y = ", list(y.numpy()))</span><span id="e8cf" class="na kr in mr b gy nf nc l nd ne"># x =  [array([4, 5, 6, 7]), array([5, 6, 7, 8]), array([3, 4, 5, 6])]<br/># y =  [array([8]), array([9]), array([7])]<br/># x =  [array([0, 1, 2, 3]), array([2, 3, 4, 5]), array([1, 2, 3, 4])]<br/># y =  [array([4]), array([6]), array([5])]</span></pre><p id="8350" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">相同代码的更好、更易读的版本:</p><figure class="ms mt mu mv gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="nk nl di nm bf nn"><div class="gh gi nj"><img src="../Images/a914abaccd4e13f901ed6f985fc03d9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nLwxZKp7CMs0QflOxLHWXw.png"/></div></div></figure><p id="7e6e" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">我更喜欢将它们链接在一起的方式是将转换写在一个函数中，并使用apply方法。这使得代码可重用，可读性很强，并且函数可以附带文档字符串来帮助其他人理解转换的目的。</p><figure class="ms mt mu mv gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="nk nl di nm bf nn"><div class="gh gi no"><img src="../Images/a79069e26fccdbedbb47c5fb33867e4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oB9PHIRGUYsQ1l7-RGrOiQ.png"/></div></div></figure></div><div class="ab cl np nq hr nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="ig ih ii ij ik"><p id="7503" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">这就是这个教程，我们在这里经历了相当多的细节。在下一篇文章中，我想介绍TensorFlow数据集以及如何使用它，然后浏览几个流行的数据集(图像、文本、表格)，还将了解如何使用tf.dataset和<strong class="jt io"> KERAS构建预测模型。</strong></p><p id="75a5" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">下面是本文中使用的代码的链接</p><ol class=""><li id="c2ea" class="lo lp in jt b ju jv jy jz kc ng kg nh kk ni ko lv lw lx ly bi translated">github:-<a class="ae kp" href="https://github.com/Virajdatt/tensorflow_dataset_intro" rel="noopener ugc nofollow" target="_blank">https://github.com/Virajdatt/tensorflow_dataset_intro</a></li></ol><p id="177a" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">2.Google Colab:-<a class="ae kp" href="https://colab.research.google.com/drive/1LYv_JIsXTQCxxwvtedF8IKgzAE8hhBh1#scrollTo=W_592w27pPjY" rel="noopener ugc nofollow" target="_blank">https://Colab . research . Google . com/drive/1 lyv _ jisxtqcxwvtedf 8 ikgzae 8 hhbh 1 # scroll to = W _ 592 W 27 ppjy</a></p><h1 id="2d44" class="kq kr in bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated"><strong class="ak"> — — — — —敬请关注</strong> — — — —</h1><p id="0792" class="pw-post-body-paragraph jr js in jt b ju lq jw jx jy lr ka kb kc me ke kf kg mf ki kj kk mg km kn ko ig bi translated">我希望你在阅读和学习这篇文章的过程中有一段愉快的时光，就像我在写这篇文章的时候一样。如果内容对你有帮助，请鼓掌。如果你有任何问题或者(在下面的评论中提到你的问题),你可以在下面的平台上联系我并和我交谈。</p><p id="8786" class="pw-post-body-paragraph jr js in jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ig bi translated">LinkedIn:-<a class="ae kp" href="https://www.linkedin.com/in/virajdatt-kohir/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/virajdatt-kohir/</a><br/>推特:-<a class="ae kp" href="https://twitter.com/kvirajdatt" rel="noopener ugc nofollow" target="_blank">https://twitter.com/kvirajdatt</a><br/>GitHub:-<a class="ae kp" href="https://github.com/Virajdatt" rel="noopener ugc nofollow" target="_blank">https://github.com/Virajdatt</a><br/>GoodReads:-<a class="ae kp" href="https://www.goodreads.com/user/show/114768501-virajdatt-kohir" rel="noopener ugc nofollow" target="_blank">https://www . GoodReads . com/user/show/114768501-virajdatt-kohir</a></p></div></div>    
</body>
</html>