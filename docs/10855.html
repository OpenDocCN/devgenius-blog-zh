<html>
<head>
<title>Spark in a nutshell — Spark (Scala) Cheat Sheet for Data Engineers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据工程师的 Spark (Scala)备忘单</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/ultimate-spark-scala-cheat-sheet-for-data-engineers-and-scientists-9f30d2f79841?source=collection_archive---------2-----------------------#2022-12-04">https://blog.devgenius.io/ultimate-spark-scala-cheat-sheet-for-data-engineers-and-scientists-9f30d2f79841?source=collection_archive---------2-----------------------#2022-12-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="e874" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">介绍</h1><p id="7322" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">Spark 已经成为业内最基本、最广为接受的大数据编程框架之一。处理大量数据的大公司使用 Spark Scala API 或 Python API 来处理大量数据。大多数数据工程师角色要求您具备 Spark 知识，并为构建处理管道编写高效的 Spark 脚本。因此，非常有必要记住 Spark 代码片段，或者在需要时有地方参考它们。在这篇文章中，我想通过将最常用的语句和命令以备忘单的形式呈现来实现这个目标。</p></div><div class="ab cl lj lk hu ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="ij ik il im in"><h1 id="ecf7" class="jn jo iq bd jp jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk bi translated">在以下情况下，此备忘单会很有帮助</h1><ol class=""><li id="5759" class="lv lw iq kn b ko kp ks kt kw lx la ly le lz li ma mb mc md bi translated">人们需要快速更新他/她的火花知识</li><li id="eb1e" class="lv lw iq kn b ko me ks mf kw mg la mh le mi li ma mb mc md bi translated">在审查 Spark 代码片段的面试之前</li><li id="9af7" class="lv lw iq kn b ko me ks mf kw mg la mh le mi li ma mb mc md bi translated">为您的日常工作参考，以防您正在搜索特定的语法</li><li id="7314" class="lv lw iq kn b ko me ks mf kw mg la mh le mi li ma mb mc md bi translated">通过查看备忘单，保持语法活跃</li></ol></div><div class="ab cl lj lk hu ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="ij ik il im in"><h1 id="a070" class="jn jo iq bd jp jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk bi translated">本备忘单涵盖的主题包括:</h1><p id="7ae6" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">_ 在 Spark 中创建数据帧</p><p id="2fcd" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">_ 应用过滤器</p><p id="d727" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">_ 各种选择方法，包括选择、动态选择和选择表达式</p><p id="152f" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">_ Spark groupBy 和聚合函数，包括百分点、平均值、最大值、最小值和百分点</p><p id="134f" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">_ 火花窗口</p><p id="42a2" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">_ 火花旋转</p><p id="9da2" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">_ 排名和排序依据</p><p id="14bd" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">_ Spark UDF</p><p id="e0d5" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">_ Spark SQL</p><p id="daee" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">_ Spark 输入/输出拼花/CSV</p><blockquote class="mo mp mq"><p id="93c1" class="kl km mr kn b ko mj kq kr ks mk ku kv ms ml ky kz mt mm lc ld mu mn lg lh li ij bi translated">我每周都会在这个频道发表技术文章，所以请关注我，订阅我的频道。请查看我列表中与 <a class="ae mv" href="https://medium.com/@clever.tech.memes/list/internalspark-62fda9e00b36?source=my_lists---------1-------62fda9e00b36---------------------" rel="noopener"> <em class="iq"> Spark </em> </a> <em class="iq">和</em><a class="ae mv" href="https://medium.com/@clever.tech.memes/list/internalscala-40c96bf7addd?source=my_lists---------11-------40c96bf7addd---------------------" rel="noopener"><em class="iq">Scala</em></a><em class="iq"/><a class="ae mv" href="https://medium.com/@clever.tech.memes/list/internalstreamlit-8638d94cd666?source=my_lists---------8-------8638d94cd666---------------------" rel="noopener"><em class="iq">Streamlit</em></a><em class="iq"/><a class="ae mv" href="https://medium.com/@clever.tech.memes/list/internalreact-79590e57fc46?source=my_lists---------9-------79590e57fc46---------------------" rel="noopener"><em class="iq">React</em></a><em class="iq"/><a class="ae mv" href="https://medium.com/@clever.tech.memes/list/internaldjango-8eb3f062efcd?source=my_lists---------12-------8eb3f062efcd---------------------" rel="noopener"><em class="iq">Django</em></a><em class="iq"/><a class="ae mv" href="https://medium.com/@clever.tech.memes/list/internalamazonwebservices-805665b5bf42?source=my_lists---------13-------805665b5bf42---------------------" rel="noopener"><em class="iq">aw</em></a></p><p id="2488" class="kl km mr kn b ko mj kq kr ks mk ku kv ms ml ky kz mt mm lc ld mu mn lg lh li ij bi translated">请使用此链接加入 medium<a class="ae mv" href="https://medium.com/@clever.tech.memes/membership" rel="noopener"><em class="iq"/></a><em class="iq">。谢谢你的大力支持。</em></p></blockquote><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi mw"><img src="../Images/398b0338fc11d2464114dfd13a5fbc14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LqbFUuXcg0RowW_Mu-rhzQ.jpeg"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">Matheus Bertelli 摄:<a class="ae mv" href="https://www.pexels.com/photo/person-holding-sparkler-silhouette-573241/" rel="noopener ugc nofollow" target="_blank">https://www . pexels . com/photo/person-holding-sparkler-silhouette-573241/</a></figcaption></figure><h1 id="cd39" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">准备和设置</h1><p id="5aee" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">当然，这个帖子是一个备忘单，不需要设置环境；但是，您可能想测试本教程的代码片段。使用 Docker 启动 Spark 比以往任何时候都容易。你可以看看<a class="ae mv" href="https://medium.com/@clever.tech.memes/starting-with-spark-and-zeppelin-in-2-minutes-using-docker-create-your-first-data-frame-f83b65fced1c" rel="noopener">我的另一篇帖子</a>只用两分钟就能启动 Spark！</p><p id="846d" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">开始时，创建一个假的数据帧，备忘单的其余部分基于相同的数据帧。请注意，在引入代码片段之后，会显示相应的输出。</p><h1 id="6c5c" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">创建数据帧</h1><p id="b69e" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在下面，我想创建一个假的数据框架，其中包含假的股票资产买卖。</p><h2 id="8f9d" class="nm jo iq bd jp nn no dn jt np nq dp jx kw nr ns kb la nt nu kf le nv nw kj nx bi translated">创建数据帧的第一种方法—使用元组和。toDF()函数</h2><p id="c1d3" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">使用 Scala 语法在 Spark 中创建数据框的第一种方法是使用<em class="mr">Spark . implicit。</em></p><p id="ce61" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">在这种方法中，数据帧的每一行都对应于一个元组，在这个元组中，我们将。toDF()函数。让我们使用以下代码片段创建一个包含几行的数据帧:</p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="d5fc" class="od jo iq nz b be oe of l og oh">import spark.implicits._<br/>  <br/>val data = Seq(<br/>    ("Stock", "Plus500", 0.5938, "Amazon", "01/11/2021", 3368.000, 4000.0),<br/> ("Stock", "Plus500", 0.6, "Facebook", "01/11/2021", 160.0, 200.0),<br/> ("Stock", "Plus500", 0.68, "Amazon", "01/11/2021", 160.0, 200.0),<br/> ("Stock", "eToro", 1.5, "Facebook", "12/11/2021", 180.0, 250.0),<br/> ("Stock", "Plus500", 0.065, "LinkedIn", "12/11/2021", 80.0, 140.0),<br/> ("Stock", "eToro", 1.3, "Pfeizer", "01/12/2021", 34.0, 85.5),<br/> ("Stock", "Plus500", 0.01, "Bitcoin", "01/11/2021", 45000.0, 48000.0),<br/> ("Stock", "Plus500", 0.08, "Sand", "29/11/2021", 5.4, 8.9)<br/>    )<br/><br/>val firstApproachDF = data.toDF("Asset", "Platform", "Unit", "Trade Name", "Buy Date", "Buy Price", "Sell Price")<br/><br/>firstApproachDF.show()<br/><br/>firstApproachDF.printSchema </span></pre><p id="270c" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">上述代码片段的输出如下:</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi oi"><img src="../Images/88e8aec88285ad02be5bc3bba69dc7c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uBwZZwMRdXDQuSFMKIcrDg.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">创建了 8 行 7 列的数据框架</figcaption></figure><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi oj"><img src="../Images/6a0655c3baac5784430f0189431b8414.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kf-cXkTPQ9yNz-7BPlzikg.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">创建的数据帧的模式</figcaption></figure><h2 id="e8db" class="nm jo iq bd jp nn no dn jt np nq dp jx kw nr ns kb la nt nu kf le nv nw kj nx bi translated">创建数据帧的第二种方法—使用 createDataFrame()函数</h2><p id="6a4f" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在第二种方法中，我们使用 spark.createDataFrame()创建一个数据帧。数据仍然包含 Scala 中的元组序列，如下所示:</p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="b709" class="od jo iq nz b be oe of l og oh">val data = Seq(<br/>    ("Stock", "Plus500", 0.5938, "Amazon", "01/11/2021", 3368.000, 4000.0),<br/> ("Stock", "Plus500", 0.6, "Facebook", "01/11/2021", 160.0, 200.0),<br/> ("Stock", "Plus500", 0.68, "Amazon", "01/11/2021", 160.0, 200.0),<br/> ("Stock", "eToro", 1.5, "Facebook", "12/11/2021", 180.0, 250.0),<br/> ("Stock", "Plus500", 0.065, "LinkedIn", "12/11/2021", 80.0, 140.0),<br/> ("Stock", "eToro", 1.3, "Pfeizer", "01/12/2021", 34.0, 85.5),<br/> ("Stock", "Plus500", 0.01, "Bitcoin", "01/11/2021", 45000.0, 48000.0),<br/> ("Stock", "Plus500", 0.08, "Sand", "29/11/2021", 5.4, 8.9)<br/>    )<br/>    <br/> val secondApproachDF =  spark.createDataFrame(data)<br/>   <br/> <br/> secondApproachDF.show()<br/> secondApproachDF.printSchema</span></pre><p id="55b1" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">但是，在输出中有所不同，您可以看到我们不再有列名，如下面的输出所示:</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi ok"><img src="../Images/a7a8523c029f645b9a9eec4035dc5dbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xGOrmRz-QlHifAW8gWrNKQ.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">使用 CreateDataFrame()创建了 dataframe</figcaption></figure><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi ol"><img src="../Images/8879db952723ebaba57c4616839ef7a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dyFKcy_Os_DeT3dr14sVBQ.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">输出-没有列名的模式</figcaption></figure><p id="8824" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">在上述情况下，可能需要重命名列或定义一个模式。</p></div><div class="ab cl lj lk hu ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="ij ik il im in"><h1 id="9d35" class="jn jo iq bd jp jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk bi translated">数据帧的模式和列</h1><p id="0122" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在 Spark 中，始终可以使用以下方法查看数据帧的模式和列。让我们考虑前面小节中定义的 firstAppachDF，如下所示:</p><h2 id="cd31" class="nm jo iq bd jp nn no dn jt np nq dp jx kw nr ns kb la nt nu kf le nv nw kj nx bi translated"><strong class="ak">数据帧的模式</strong></h2><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="0ddb" class="od jo iq nz b be oe of l og oh">firstApproachDF.schema</span></pre><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi om"><img src="../Images/3e26de9ce66a3f037486ca5a0357b26b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WFmwSqBEX7zYkAobCKscbw.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">输出-。模式来查看数据类型方面的模式</figcaption></figure><h2 id="b007" class="nm jo iq bd jp nn no dn jt np nq dp jx kw nr ns kb la nt nu kf le nv nw kj nx bi translated"><strong class="ak">打印数据帧的模式</strong></h2><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="fa3a" class="od jo iq nz b be oe of l og oh">firstApproach.printSchema</span></pre><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi on"><img src="../Images/57489756668a0ddc42d40260cb4e4ca0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v3YuR1tAqmWSwGsrxSdJVw.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">输出—打印模式</figcaption></figure><h2 id="2e28" class="nm jo iq bd jp nn no dn jt np nq dp jx kw nr ns kb la nt nu kf le nv nw kj nx bi translated"><strong class="ak">数据帧的列</strong></h2><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="ba9d" class="od jo iq nz b be oe of l og oh">firstApproachDF.columns</span></pre><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi oo"><img src="../Images/af1aa010d84a7f63a8825c6653d3504b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pFpr2KYB7xM6ZhExBZK9uQ.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">输出 firstApproachDF 列</figcaption></figure><h2 id="5542" class="nm jo iq bd jp nn no dn jt np nq dp jx kw nr ns kb la nt nu kf le nv nw kj nx bi translated"><strong class="ak">单列</strong></h2><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="8914" class="od jo iq nz b be oe of l og oh">firstApproachDF.col("Asset")</span></pre><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi op"><img src="../Images/e97182b29e2e2eae11efe0bbfe558002.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nxx4KHqF2E2IZTmZolSRtA.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">输出—访问单个列</figcaption></figure><h2 id="8c3e" class="nm jo iq bd jp nn no dn jt np nq dp jx kw nr ns kb la nt nu kf le nv nw kj nx bi translated">使用映射函数迭代数据帧的列并追加值</h2><p id="5cda" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">有时，需要遍历数据帧的每一列并附加一个后缀。可以使用如下所示的 map()函数来实现:</p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="aa60" class="od jo iq nz b be oe of l og oh">firstApproachDF.columns.map(col =&gt; col + "_suffix")</span></pre><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi oq"><img src="../Images/82736e747c093bc80bb33d36b7179665.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OKewiKXsyvQ9vX1tdsAOBg.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">输出—_ 后缀在列名中可见</figcaption></figure><p id="f18c" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">从现在开始，让我们用<strong class="kn ir"> DF </strong>代替<strong class="kn ir"> firstApproachDF </strong>。</p></div><div class="ab cl lj lk hu ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="ij ik il im in"><h1 id="93e4" class="jn jo iq bd jp jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk bi translated">选择数据帧列的各种方法</h1><p id="39b1" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">有各种方法来选择数据帧的列。选择数据帧的列很重要，因为有两个方面:</p><ol class=""><li id="6f4e" class="lv lw iq kn b ko mj ks mk kw or la os le ot li ma mb mc md bi translated">您可能会在代码中看到各种方法，所以最好是看到这些格式。</li><li id="c0b3" class="lv lw iq kn b ko me ks mf kw mg la mh le mi li ma mb mc md bi translated">为了扩展数据帧，您可能需要在代码中添加某种动态。</li></ol><h2 id="c3de" class="nm jo iq bd jp nn no dn jt np nq dp jx kw nr ns kb la nt nu kf le nv nw kj nx bi translated"><strong class="ak">走近 1。使用选择和列名</strong></h2><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="5be3" class="od jo iq nz b be oe of l og oh">DF.select("Asset","Platform"l).show(5)</span></pre><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi ou"><img src="../Images/36e4c7689237608a2e337ac39e2675e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RhSc3u5-1MgWBOZvvF4OLQ.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">显示 5 行资产和平台列</figcaption></figure><h2 id="13c9" class="nm jo iq bd jp nn no dn jt np nq dp jx kw nr ns kb la nt nu kf le nv nw kj nx bi translated"><strong class="ak">接近 2 和 3。使用带$符号或 col( ) </strong>的选择</h2><p id="d80b" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我提出了第二种和第三种方法，因为可以像下面这样一起使用它们:</p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="3566" class="od jo iq nz b be oe of l og oh">DF.select($"Asset", $"Platform", $"Unit", col("Trade Name"), <br/>col("Buy Date")).show(5)</span></pre><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi ov"><img src="../Images/89b01d616251070d6c03485502a377b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qz5k4qEX-NWGqieLbJ3D6w.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">输出—使用$和 col 选择列</figcaption></figure><h2 id="d63f" class="nm jo iq bd jp nn no dn jt np nq dp jx kw nr ns kb la nt nu kf le nv nw kj nx bi translated"><strong class="ak">方法四。使用表达式</strong>和 spark 隐含</h2><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="bd4f" class="od jo iq nz b be oe of l og oh">DF.select(expr("Asset"), $"Trade Name").show(5)</span></pre><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi ow"><img src="../Images/7a75e011d96e13ff30359c0a4ede7f4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uKK-oozqnXyHscLb7uyU6Q.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">输出-使用表达式选择</figcaption></figure><p id="3bb1" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">也可以使用<em class="mr">表达式</em>进行计算。让我们考虑以下情况:</p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="3bbe" class="od jo iq nz b be oe of l og oh">DF.select($"Unit",expr("Unit * 2").as("Unit Multiplied by 2"), <br/>$"Trade Name").show(5)</span></pre><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi ox"><img src="../Images/e4bd80ac8589910c4caaaccff66a1b6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6Bc6xy-GkKzjt_s6fXL6rA.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">输出—使用 expr 将单位乘以 2</figcaption></figure><h2 id="1b54" class="nm jo iq bd jp nn no dn jt np nq dp jx kw nr ns kb la nt nu kf le nv nw kj nx bi translated">方法 5。使用 selectExpr</h2><p id="f0af" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">让我们考虑以下使用<em class="mr"> selectExpr </em>函数从<em class="mr">买价</em>和<em class="mr">卖价</em>的差额中计算利润的例子。请注意，对于带空格的列，我们应该使用` ':</p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="18f1" class="od jo iq nz b be oe of l og oh">DF.selectExpr("Asset", "Platform", """`Trade Name`""", """`Buy Date`""", <br/>"Unit", """ `Sell Price` - `Buy Price` as profit""" ).show(5)</span></pre><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi oy"><img src="../Images/73e45a2f576c131ebff055c0b9e959a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ICFqKYh1E5uo945AT2V6TA.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">使用 selectExpr</figcaption></figure><h2 id="6016" class="nm jo iq bd jp nn no dn jt np nq dp jx kw nr ns kb la nt nu kf le nv nw kj nx bi translated">重命名列和创建新列</h2><p id="2e06" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">可以使用<em class="mr">重命名列名。withColumnRenamed() </em>函数，所以让我们通过向带有空格的列名添加下划线(_)来看看它:</p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="0ed0" class="od jo iq nz b be oe of l og oh">val renamedColumns = DF.withColumnRenamed("Trade Name","Trade_Name")<br/>.withColumnRenamed("Buy Price","Buy_Price")<br/>.withColumnRenamed("Sell Price","Sell_Price")<br/><br/>renamedColumns.show()</span></pre><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi oz"><img src="../Images/164acf75fc0b55e2dd2be9893c73c8d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ap9yDYE02HvLfdsp7iZDdg.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">输出—重命名的列</figcaption></figure><p id="6073" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">要创建新列，我们可以使用函数<em class="mr">。withColumn() </em>在其中我们也可以指定列名。在下面的示例中，我们创建了名为“<em class="mr">利润</em>”和“<em class="mr">利润百分比</em>”的两列</p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="8acc" class="od jo iq nz b be oe of l og oh">val profitDF = DF.withColumn("Profit", col("Sell Price") - col("Buy Price"))<br/>.withColumn("Profit Percentage", col("Sell Price") / col("Buy Price"))<br/><br/>profitDF.show()</span></pre><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi pa"><img src="../Images/e5f98980cbb54a1565ed7c447e17fdcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sEtsakL96r_P-nVY_A6ouA.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">输出—添加两个名为利润和利润百分比的新列</figcaption></figure></div><div class="ab cl lj lk hu ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="ij ik il im in"><h1 id="7f92" class="jn jo iq bd jp jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk bi translated">在 Spark 中过滤行</h1><p id="af35" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">通常，需要根据某些标准过滤数据帧的行。为此，可以使用<em class="mr">过滤</em>功能，在下文中，我将回顾一些过滤功能的示例:</p><h2 id="a79a" class="nm jo iq bd jp nn no dn jt np nq dp jx kw nr ns kb la nt nu kf le nv nw kj nx bi translated">示例 1</h2><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="c38a" class="od jo iq nz b be oe of l og oh">DF.filter(col("Platform") === "Plus500").show()</span></pre><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi pb"><img src="../Images/310df8beee25e73f421c0cf00202cc50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gTnxmQM9xKpk6MVDLq_SKg.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">仅保留 Plus500 行</figcaption></figure><h2 id="e5d0" class="nm jo iq bd jp nn no dn jt np nq dp jx kw nr ns kb la nt nu kf le nv nw kj nx bi translated">例 2。使用 OR 运算符(||)</h2><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="cd77" class="od jo iq nz b be oe of l og oh">val orExampleDF = DF.filter(col("Trade Name") === "Amazon" <br/>|| col("Trade Name") ==="Facebook")<br/><br/>orExampleDF.show()</span></pre><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi pc"><img src="../Images/53a729aba3fe1a60c8de9c3830806867.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JJBGSTcX_jeQISb6urocGw.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">过滤脸书或亚马逊</figcaption></figure><h2 id="df7f" class="nm jo iq bd jp nn no dn jt np nq dp jx kw nr ns kb la nt nu kf le nv nw kj nx bi translated">例 3。使用 AND 运算符(&amp;&amp;)</h2><p id="cd7a" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">只保留<em class="mr">商品名</em>的<em class="mr">脸书</em>和<em class="mr">加 500 </em>为平台；</p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="8a09" class="od jo iq nz b be oe of l og oh">val andExampleDF = DF.filter(col("Trade Name") === "Facebook" <br/>&amp;&amp; col("Platform") ==="Plus500")<br/><br/>andExampleDF.show()</span></pre><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi pd"><img src="../Images/45b58dafcd78aed4620211ec3cbbfd52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_EkcemKgTgqPZu_5jhslBA.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">输出—和示例</figcaption></figure><h2 id="0a09" class="nm jo iq bd jp nn no dn jt np nq dp jx kw nr ns kb la nt nu kf le nv nw kj nx bi translated">例 4。不等于且大于(&gt;)</h2><p id="ba7b" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">让我们选择所有超过 0.5 单位的交易，其中商品名称不是 Amazon:</p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="6b8a" class="od jo iq nz b be oe of l og oh">val demoDF = DF.filter(col("Unit") &gt;= 0.5 &amp;&amp; col("Trade Name") =!= "Amazon")<br/><br/>demoDF.show()</span></pre><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi pe"><img src="../Images/420c336a35bd43d909403720fe7fc4c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*deEQICx5Ga2CVd56KswTMw.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">输出-不等于和大于(&gt;)的示例</figcaption></figure></div><div class="ab cl lj lk hu ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="ij ik il im in"><h1 id="515b" class="jn jo iq bd jp jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk bi translated">Spark 分组和聚合函数</h1><p id="4685" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">对多组数据计算多个统计数据是非常常见的。Spark 对此类计算有非常丰富的支持。考虑到前面章节中的 DF，让我们计算几个统计数据:</p><h2 id="c46a" class="nm jo iq bd jp nn no dn jt np nq dp jx kw nr ns kb la nt nu kf le nv nw kj nx bi translated">计数示例()</h2><p id="ad5b" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这里我们按照<em class="mr">资产</em>和<em class="mr">平台</em>分组，统计交易笔数。</p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="3e86" class="od jo iq nz b be oe of l og oh">// Calculating number of trades per platform<br/><br/>val numberOfTradesPerPlatform = DF.groupBy("Asset", "Platform")<br/>.agg(count("*").as("NumberOfTradesPerAssetPPlatForm"))<br/><br/>numberOfTradesPerPlatform.show()</span></pre><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi pf"><img src="../Images/2827168b8f76636172234904fe82ab4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TVU3FNdNFhAJfq5zP8PZew.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">输出</figcaption></figure><h2 id="2b51" class="nm jo iq bd jp nn no dn jt np nq dp jx kw nr ns kb la nt nu kf le nv nw kj nx bi translated">countDistinct()的示例</h2><p id="95aa" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在这里，我们按资产和平台分组，并计算交易项目的不同价值:</p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="287f" class="od jo iq nz b be oe of l og oh">// Count distinct of number of traded items<br/>val numberOfAssets = DF.groupBy("Asset","Platform")<br/>.agg(countDistinct("Trade Name").as("Number of Assets"))<br/><br/>numberOfAssets.show()</span></pre><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi pg"><img src="../Images/c8853b2073189acdf3ee7ffd656fc1eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DDorbotpNk2F_au4yQdMQA.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">输出—计数不同</figcaption></figure></div><div class="ab cl lj lk hu ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="ij ik il im in"><h2 id="ba77" class="nm jo iq bd jp nn no dn jt np nq dp jx kw nr ns kb la nt nu kf le nv nw kj nx bi translated">总和、AVG、中值、最小值、最大值的示例</h2><p id="8135" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在下文中，我们计算资产、平台和商品名称的买入和卖出价格的总和<em class="mr">、平均值、最小值、最大值和 P50 </em>:</p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="2ae3" class="od jo iq nz b be oe of l og oh">val agg_df = DF.groupBy("Asset", "Platform", "Trade Name").agg(<br/>    <br/>    <br/>    sum("Buy Price").as("buy_price_sum"),<br/>    sum("Sell Price").as("sell_price_Sum"),<br/>    <br/>    min("Buy Price").as("buy_price_min"),<br/>    min("Sell Price").as("sell_price_min"),<br/>    <br/>    max("Buy Price").as("buy_price_max"),<br/>    max("Sell Price").as("sell_price_max"),<br/>    <br/>    avg("Buy Price").as("buy_price_avg"),<br/>    avg("Sell Price").as("sell_price_avg"),<br/>    <br/>    expr("percentile(`Sell Price`, 0.5)").as("sell_price_P50"),<br/>    expr("percentile(`Buy Price`, 0.5)").as("buy_price_P50")<br/>    )<br/>    <br/> z.show(agg_df)  </span></pre><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi ph"><img src="../Images/67d995491b2489f7a06740456f82937f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UjCJlyuSFqFFRUvhgCRVAA.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">输出—仅显示部分列</figcaption></figure></div><div class="ab cl lj lk hu ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="ij ik il im in"><h1 id="3e09" class="jn jo iq bd jp jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk bi translated">Spark 动态分组和聚合</h1><p id="5b06" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在许多情况下，您希望对许多列执行聚合，例如 10 到 100 列，并且您希望应用不同的聚合函数，因此编写所有代码是不实际的，因此使用 map 函数使用一点语法糖会更有效。<a class="ae mv" href="https://medium.com/@clever.tech.memes/application-of-map-function-in-dynamic-spark-groupby-and-aggregations-cbe67f4ca753" rel="noopener">在另一篇教程</a>中，我已经详细解释了 Spark 动态 groupBy 聚合。我试着用一个例子来解释，但是如果你需要进一步的解释，请参考上面的链接。</p><p id="bb2d" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">现在让我们执行与上一节完全相同的 groupBy 和 aggregation，如下所示:</p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="afe9" class="od jo iq nz b be oe of l og oh">val intended_columns = List("Sell Price","Buy Price", "Unit")<br/><br/>val sumExpr = intended_columns.map(col =&gt; sum(col).as(col + "_sum"))<br/>val avgExpr = intended_columns.map(col =&gt; avg(col).as(col + "_avg"))<br/>val minExpr = intended_columns.map(col =&gt; min(col).as(col + "_min"))<br/>val maxExpr = intended_columns.map(col =&gt; max(col).as(col + "_max"))<br/><br/>val aggExpression = sumExpr ++ avgExpr ++ minExpr ++ maxExpr<br/><br/>val agg_df_v2 = DF.groupBy("Asset", "Platform", "Trade Name")<br/>.agg(aggExpression.head, aggExpression.tail: _*)<br/><br/><br/>agg_df_v2.printSchema</span></pre><p id="1c96" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">我们定义了一个对执行聚合感兴趣的列列表，即<em class="mr">卖价、买价和单位</em>。现在，我们定义表达式。一个例子是<em class="mr"> sumExpr </em>，它遍历<em class="mr"> intended_columns </em>中的所有列，对列值求和，并将其重命名。之后，我们创建一个最终的<em class="mr"> aggExpression </em>，它是所有其他表达式的串联。我们在 agg()函数中使用<em class="mr"> aggExpression.head 和 aggExpression.tail 以及“:_ *”</em>来考虑所有的表达式。</p><p id="e7df" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">输出非常大，所以我不能打印所有的列，但是下面是模式:</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi pi"><img src="../Images/792084770667439b1aad9bde91408155.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BCJ70jGRQwysIjZ9DsRlaw.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">创建的 df 的模式</figcaption></figure><p id="354c" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">所以，你可以想象如果我们有很多列，这种方法可以给我们带来多大的灵活性。我们还可以在<em class="mr"> groupBy </em>表达式中为列名列表增加同样的灵活性。</p></div><div class="ab cl lj lk hu ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="ij ik il im in"><h1 id="6dbc" class="jn jo iq bd jp jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk bi translated">火花接合</h1><p id="cb9e" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">您可以用两种方式执行联接，这由一个示例提供:</p><p id="5912" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">我们在前面的章节中看到了这两个数据帧:</p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="ebf0" class="od jo iq nz b be oe of l og oh">val numberOfTradesPerPlatform = DF.groupBy("Asset", "Platform")<br/>.agg(count("*").as("NumberOfTradesPerAssetPPlatForm"))<br/><br/><br/><br/>val numberOfAssets = DF.groupBy("Asset","Platform")<br/>.agg(countDistinct("Trade Name").as("Number of Assets"))<br/></span></pre><p id="ec0d" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">现在，让我们看看如何执行连接:</p><p id="74fe" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated"><strong class="kn ir">使用 Seq()进行连接的第一种方法</strong></p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="5fd1" class="od jo iq nz b be oe of l og oh">// First approach for join<br/><br/>val joinedDF = numberOfTradesPerPlatform<br/>.join(numberOfAssets, Seq("Asset","Platform"))<br/><br/>joinedDF.show()</span></pre><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi pj"><img src="../Images/60b2b28ee2f472476d455931a799cc1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ekiB0mIaWmZVZ9sp6-fCtQ.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">使用 Seq()联接</figcaption></figure><p id="7dbe" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated"><strong class="kn ir">第二种连接方式</strong></p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="61df" class="od jo iq nz b be oe of l og oh">// Second approach for join<br/><br/>val joinedDF2 = numberOfTradesPerPlatform.join(numberOfAssets, <br/>numberOfTradesPerPlatform.col("Asset") === numberOfAssets.col("Asset") <br/>&amp;&amp; numberOfTradesPerPlatform.col("Platform") === numberOfAssets.col("Platform"))<br/>joinedDF2.show()</span></pre><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi pk"><img src="../Images/d467200e4379c6238ba24aa817e955b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bdKMqQCxgEfWkgTo3Koi0g.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">输出—第二种方法的结果</figcaption></figure><p id="344c" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">在第二种方法中，可以看到一些列是重复的，因此建议在连接之前重命名它们。我们可以如下重复第二种方法来消除重复的列:</p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="69dc" class="od jo iq nz b be oe of l og oh">// First renaming the columns in join and creating a new DF<br/><br/>val numberOfAssets_renamed = numberOfAssets<br/>.withColumnRenamed("Asset","AssetV2")<br/>.withColumnRenamed("Platform","PlatformV2")<br/><br/>// performing the join with the new DF and dropping the renamed columns<br/><br/>val joinedDF3 = numberOfTradesPerPlatform<br/>.join(numberOfAssets_renamed, <br/>numberOfTradesPerPlatform.col("Asset") === numberOfAssets_renamed.col("AssetV2") <br/>&amp;&amp; numberOfTradesPerPlatform.col("Platform") === numberOfAssets_renamed.col("PlatformV2"))<br/>.drop("AssetV2","PlatformV2")<br/><br/>joinedDF3.show()</span></pre><p id="c681" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">在上面的例子中，可以看出首先“资产”和“平台”列被重命名为“资产 2”和“平台 2”。然后，新的数据帧用于连接，最后，删除重命名的列。现在，应该可以看到没有任何重复的输出:</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi pl"><img src="../Images/103d9461c2c21e9e2d1d85bbec3e0b53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ayQiHQNKxtsfUnoerUmjrg.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">输出—无重复</figcaption></figure></div><div class="ab cl lj lk hu ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="ij ik il im in"><h1 id="ea79" class="jn jo iq bd jp jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk bi translated">窗口函数 groupBy()的替代方法</h1><p id="9a2a" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">窗口功能允许对数据的特定维度执行某些计算，并将结果添加到数据帧中。事实上，除了执行 groupBy/aggregation 并将数据与原始数据帧联接起来之外，您还有机会通过使用 Window 函数来执行相同的操作。如果这还不清楚，让我们用一个例子来研究一下:</p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="fabe" class="od jo iq nz b be oe of l og oh">import org.apache.spark.sql.expressions.Window<br/><br/>val custom_partition = Window.partitionBy($"Asset", $"Platform", $"Trade Name")<br/><br/>val resulting_df = DF.withColumn("sum_buy_price", <br/>sum("Buy Price").over(custom_partition))<br/>.withColumn("sum_sell_price", sum("Sell Price").over(custom_partition))<br/>.withColumn("min_sell_price", min("Sell Price").over(custom_partition))<br/>.withColumn("min_buy_price", min("Buy Price").over(custom_partition))<br/>.withColumn("avg_sell_price", avg("Sell Price").over(custom_partition))<br/>.withColumn("avg_buy_price", avg("Buy Price").over(custom_partition))<br/><br/><br/>resulting_df.show()</span></pre><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi pm"><img src="../Images/5d28393bb37f2b711904dd5ec90bcbc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-aq3csDvPmNwT0wDsqyqzw.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">resulting_df 的输出—窗口函数，而不是 groupBy/aggregation 和 join back</figcaption></figure><p id="0a1e" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">从上面可以看出，它看起来像一个 groupBy/aggregation，并与原始数据帧连接在一起。让我们通过执行 groupBy/aggregation 和 joining back 来证明这一点，看看我们是否能看到相同的结果:</p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="ee71" class="od jo iq nz b be oe of l og oh"><br/>val groupBy_aggregation_df = DF.groupBy($"Asset", $"Platform", $"Trade Name")<br/>.agg(sum("Buy Price").as("sum_buy_price"), <br/>sum("Sell Price").as("sum_sell_price"), <br/>min("Buy Price").as("min_buy_price"), <br/>min("Sell Price").as("min_sell_price"), <br/>avg("Sell Price").as("avg_sell_price"),<br/>avg("Buy Price").as("avg_buy_price"))<br/><br/><br/>val joined_back_df = DF.join(groupBy_aggregation_df, <br/>Seq("Asset", "Platform","Trade Name"))<br/><br/>joined_back_df.show()</span></pre><p id="57d7" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">正如我们在下面的输出中看到的，我们得到了与使用窗口函数完全相同的结果:</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi pn"><img src="../Images/420a808e2d80134361402635181ddc86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n40MKgBkExwPrhQJ5mTZDQ.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">groupBy/aggregation 和 join back 结果</figcaption></figure></div><div class="ab cl lj lk hu ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="ij ik il im in"><h1 id="b86f" class="jn jo iq bd jp jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk bi translated">火花排序依据()</h1><p id="4c69" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">通常，在 groupBy 和聚合之后，可能需要以特定的列顺序查看结果，尽管此操作非常耗时，并且 group by 产生的数据帧不应太大。但是，也可以对原始数据帧应用 orderBy()。如上所述，如果数据帧很大，则不建议使用该操作。让我们将 orderBy()应用于 DF:</p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="9661" class="od jo iq nz b be oe of l og oh">DF.orderBy(col("Buy Price").desc).show()</span></pre><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi po"><img src="../Images/679c448bc30f075276a856336bb39b8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r3GXJIGIKT6w30WFVIWucg.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">输出-按购买价格降序排序</figcaption></figure><p id="57e1" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">也可以按多列排序，并使用<em class="mr"> $ </em>代替<em class="mr"> col() </em>，如下所示:</p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="e8cb" class="od jo iq nz b be oe of l og oh">DF.orderBy(col("Buy Price").desc, $"Sell Price".desc).show()</span></pre><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi pp"><img src="../Images/a3e50056a1a5eec0350c4b0fd98951f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*632THVkaie3xUXWubayjgg.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">输出-按多列排序</figcaption></figure></div><div class="ab cl lj lk hu ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="ij ik il im in"><blockquote class="mo mp mq"><p id="b6fa" class="kl km mr kn b ko mj kq kr ks mk ku kv ms ml ky kz mt mm lc ld mu mn lg lh li ij bi translated">请使用此链接加入 https://medium.com/@clever.tech.memes/membership<a class="ae mv" href="https://medium.com/@clever.tech.memes/membership" rel="noopener"/><em class="iq">。谢谢你的大力支持。</em></p></blockquote></div><div class="ab cl lj lk hu ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="ij ik il im in"><h1 id="19e1" class="jn jo iq bd jp jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk bi translated">等级函数</h1><p id="c510" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">Rank 函数和 Window 一起允许根据我们想要的分区中的特定列对行进行排序/分级。让我们借助<em class="mr">窗口</em>和<em class="mr"> orderBy </em>定义一个等级函数，如下所示:</p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="1eca" class="od jo iq nz b be oe of l og oh">import org.apache.spark.sql.expressions.Window<br/><br/>val custom_partition_rank = Window.partitionBy($"Asset", $"Platform")<br/>                            .orderBy($"Sell Price".desc)<br/><br/>val resulting_df = DF.withColumn("rank_col", <br/>                      row_number().over(custom_partition_rank))<br/><br/><br/>resulting_df.show()</span></pre><p id="a003" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">因此，我们可以看到，对于每个平台，我们可以在下面看到基于<em class="mr">销售价格</em>的排名:</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi pq"><img src="../Images/877d61eb6e6b6c16e64b0035f67e96a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yRLeli9trVKDUKKnHcDtkg.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">输出-等级列</figcaption></figure><p id="a289" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">您可以始终保留您想要的等级的行，如下图所示，我们使用<em class="mr">保留等级为 1 或 2 的行。filter(col(" rank _ col ")&lt;= 2)</em>:</p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="8103" class="od jo iq nz b be oe of l og oh">import org.apache.spark.sql.expressions.Window<br/><br/>val custom_partition_rank = Window.partitionBy($"Asset", $"Platform")<br/>                            .orderBy($"Sell Price".desc)<br/><br/>val resulting_df = DF.withColumn("rank_col", <br/>                  row_number().over(custom_partition_rank))<br/>                  .filter(col("rank_col")&lt;=2)<br/><br/><br/>resulting_df.show()</span></pre><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi pr"><img src="../Images/1d8d267ad1ee73ea5160e0f0ce571c1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sbFZss_XYXoIdwla4bqIuA.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">输出-仅保留等级为 1 或 2 的行</figcaption></figure><h1 id="65bd" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">火花中的旋转</h1><p id="309d" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">Spark 中的透视是一个非常有用的操作，在某些时候您可能需要透视数据。关于 Spark 中的<a class="ae mv" href="https://medium.com/@clever.tech.memes/spark-scala-pivoting-explained-a-crucial-topic-for-big-data-scientists-8e7d96733d16" rel="noopener">旋转，我已经写了一篇专门的帖子。下面，我简单地展示了一个旋转的例子:</a></p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="c54c" class="od jo iq nz b be oe of l og oh">val dfPrivot = DF.groupBy("Asset", "Trade Name").pivot("Platform",List("Plus500", "eToro"))<br/>.agg(sum("Buy Price").as("sum_buy_price"), sum("Sell Price").as("sum_sell_price"))<br/><br/>dfPrivot.show()</span></pre><p id="ad52" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">在上面的例子中，pivot 出现在<em class="mr"> groupBy() </em>之后，<em class="mr"> agg() </em>函数之前。同样，pivot 的输入是列名，即<em class="mr">平台</em>，以及列名中相应的值列表，即<em class="mr">加上 500 </em>和<em class="mr"> eToro </em>。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi ps"><img src="../Images/7697612b68dee22c7d4212a1b82f812e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hNcuyx-qAiJ4fzn4WwSyWQ.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">输出-透视示例的结果</figcaption></figure><h1 id="b626" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">火花中的 UDF</h1><p id="ce03" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">UDF 对于编写可以在 Spark 数据帧上优化应用的自定义函数非常有帮助。为了定义 udf，我们需要 a .导入"<em class="mr">org . Apache . spark . SQL . functions . UDF " b .</em>定义我们自己的函数<em class="mr"> c. </em>将我们的函数包装在<em class="mr"> udf( _) d. </em>中，并应用 UDF 来创建新列。让我们通过下面这个简单的例子来看看如何在 Spark 中使用 UDF:</p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="86ef" class="od jo iq nz b be oe of l og oh">import org.apache.spark.sql.functions._<br/><br/>// Defining a simple multiplyByTwo function<br/><br/>def multiplyByTwo(x: Float) : Float =  x*2<br/><br/>// Wrap the function inside the udf( function_name _)<br/><br/>val multiplyByTwoUDF = udf(multiplyByTwo _)<br/><br/>// Apply the UDF on our intended colum names<br/>val dfDoubled = DF.withColumn("buy_price_doubled", <br/>                  multiplyByTwoUDF(col("Buy price")) )<br/>                  .withColumn("sell_price_doubled", <br/>                    multiplyByTwoUDF(col("Sell Price")))<br/>dfDoubled.show()<br/></span></pre><p id="e0b6" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">让我们看看输出:</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi pt"><img src="../Images/b25291d807274183489b88a53441633c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RjJCdVshvp3HJ8p2l3PEYA.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">输出—应用 multiplyByTwoUDF 创建两个新列</figcaption></figure><p id="8e3e" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">让我们看一个使用多输入的更复杂的例子，稍微复杂一点的函数和使用<em class="mr"> $ </em>符号来使用 UDF:</p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="11b2" class="od jo iq nz b be oe of l og oh">def custom_function(unit: Float, buy: Float, sell: Float) : Float = {<br/>    <br/>    val diff = (sell - buy ) <br/>    <br/>    val res =  unit * diff<br/>    <br/>    res<br/>}<br/><br/>val custom_udf = udf(custom_function _)<br/><br/>val dfUDFExample = DF.withColumn("profit", <br/>custom_udf($"Unit", $"Buy Price", $"Sell Price"))<br/><br/>dfUDFExample.show()</span></pre><p id="d4cc" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">这个函数有三个输入，相应的 UDF 也接受三个参数。因此，输出如下所示:</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi pu"><img src="../Images/794fc8ceca8c59cace1f925895a34cd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v9DJo2nBWY8Uyz0f_0fT4A.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">输出——UDF 的另一个例子</figcaption></figure><h1 id="4f07" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">Spark SQL</h1><p id="61c4" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">可以编写 SQL 查询并利用 Spark 分布式计算功能。为此，需要创建一个临时视图，并在相应的视图上应用 SQL 查询。让我们使用数据帧 DF 来展示 Spark SQL 的用法:</p><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="d63a" class="od jo iq nz b be oe of l og oh">val resulting_df = spark.sql("SELECT Platform, <br/>`Trade Name`, sum(`Buy Price`) AS sum_buy_price, <br/>sum(`Sell Price`) AS sum_sell_price FROM DF_View <br/>group by Platform, `Trade Name`")<br/><br/>resulting_df.show()</span></pre><p id="bc33" class="pw-post-body-paragraph kl km iq kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">在上面的例子中，我们使用了<em class="mr"> spark.sql(…) </em>，并在里面编写了 sql 查询。我们按平台<em class="mr"> </em>和<em class="mr">商品名</em>分组，计算<em class="mr">买价</em>和<em class="mr">卖价</em>之和，输出如下所示。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi pv"><img src="../Images/bf79ea3009cc27ba2b8bfcb80d4da68c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r2FgpMBs66x_EAFr3FVtrQ.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">输出— Spark SQL</figcaption></figure></div><div class="ab cl lj lk hu ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="ij ik il im in"><h1 id="2913" class="jn jo iq bd jp jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk bi translated">火花输入和输出</h1><p id="aedb" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这里，我想介绍一下在 Spark 中读写 Parquet 和 CSV 文件的代码</p><h2 id="7175" class="nm jo iq bd jp nn no dn jt np nq dp jx kw nr ns kb la nt nu kf le nv nw kj nx bi translated">读取拼花文件的各种方法</h2><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="3224" class="od jo iq nz b be oe of l og oh"><br/>val df_ = spark.read.parquet(file_path)<br/><br/>// Reading a list of paths with Parquet Files with same schemaVarious ways of reading CSV file<br/><br/>val df = spark.read.parquet(path_list:_*)</span></pre><h2 id="b4b2" class="nm jo iq bd jp nn no dn jt np nq dp jx kw nr ns kb la nt nu kf le nv nw kj nx bi translated">读取 CSV 文件的各种方法</h2><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="d681" class="od jo iq nz b be oe of l og oh">// Reading csv files using a map of options<br/><br/>val df_csv_v1 = spark.read.options(Map("inferSchema"-&gt;"true","delimiter"-&gt;","))<br/>.csv(file_path)<br/><br/>// Reading csv file in a single folder path<br/><br/>val df_csv_v2 = spark.read.options(Map("inferSchema"-&gt;"true","delimiter"-&gt;","))<br/>.csv(folder_path)<br/><br/>// A list of file paths with same schema<br/><br/>val df_csv_v3 = spark.read.options(Map("inferSchema"-&gt;"true","delimiter"-&gt;","))<br/>.csv(file_path:_*)<br/><br/>// An example with a single option<br/><br/>val df_csv_v4 = spark.read.option("delimiter", ",").csv(file_path)<br/><br/>// Using option() sequentially<br/><br/>val df_csv_v5 = spark.read.option("delimiter", ",").option("inferSchema, "true")<br/>.csv(file_path)<br/><br/>// Reading CSV file with a specific schema<br/><br/>val df_csv_v6 = spark.read.format("csv").option("header", "true")<br/>      .schema(schema)<br/>      .load(file_path)<br/></span></pre><h2 id="6e27" class="nm jo iq bd jp nn no dn jt np nq dp jx kw nr ns kb la nt nu kf le nv nw kj nx bi translated">编写拼花和 CSV 文件</h2><pre class="mx my mz na gt ny nz oa bn ob oc bi"><span id="b18c" class="od jo iq nz b be oe of l og oh"><br/>// writes by the predefined number of partitions<br/><br/>DF.spark.write.parquet(folder_path)<br/><br/>// defining some options and number of partitions using coalesce()<br/><br/>DF.coalesce().spark.write.mode('append').parquet(folder_path)<br/><br/><br/>// Using partition by<br/><br/>DF.write.mode('append').partitionBy('col_name').parquet(folder_path)<br/><br/><br/>// writing CSV files<br/><br/>DF.write.csv(folder_path)</span></pre><h1 id="32a6" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">摘要</h1><p id="a6a9" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">Spark 在当今的大数据世界中非常重要。如果您是数据科学家或数据工程师，此备忘单可能会有所帮助:</p><ol class=""><li id="2fbd" class="lv lw iq kn b ko mj ks mk kw or la os le ot li ma mb mc md bi translated">人们需要快速更新他/她的火花知识</li><li id="365f" class="lv lw iq kn b ko me ks mf kw mg la mh le mi li ma mb mc md bi translated">在审查 Spark 代码片段的面试之前</li><li id="d615" class="lv lw iq kn b ko me ks mf kw mg la mh le mi li ma mb mc md bi translated">为您的日常工作参考，以防您正在搜索特定的语法</li><li id="d15e" class="lv lw iq kn b ko me ks mf kw mg la mh le mi li ma mb mc md bi translated">通过查看备忘单，保持语法活跃</li></ol><blockquote class="mo mp mq"><p id="dc69" class="kl km mr kn b ko mj kq kr ks mk ku kv ms ml ky kz mt mm lc ld mu mn lg lh li ij bi translated">我每周都会在这个频道发表技术文章，所以请关注我，订阅我的频道。请查看我列表中与 <a class="ae mv" href="https://medium.com/@clever.tech.memes/list/internalspark-62fda9e00b36?source=my_lists---------1-------62fda9e00b36---------------------" rel="noopener"> <em class="iq"> Spark </em> </a> <em class="iq">和</em><a class="ae mv" href="https://medium.com/@clever.tech.memes/list/internalscala-40c96bf7addd?source=my_lists---------11-------40c96bf7addd---------------------" rel="noopener"><em class="iq">Scala</em></a><em class="iq"/><a class="ae mv" href="https://medium.com/@clever.tech.memes/list/internalstreamlit-8638d94cd666?source=my_lists---------8-------8638d94cd666---------------------" rel="noopener"><em class="iq">Streamlit</em></a><em class="iq"/><a class="ae mv" href="https://medium.com/@clever.tech.memes/list/internalreact-79590e57fc46?source=my_lists---------9-------79590e57fc46---------------------" rel="noopener"><em class="iq">React</em></a><em class="iq"/><a class="ae mv" href="https://medium.com/@clever.tech.memes/list/internaldjango-8eb3f062efcd?source=my_lists---------12-------8eb3f062efcd---------------------" rel="noopener"><em class="iq">Django</em></a><em class="iq"/><a class="ae mv" href="https://medium.com/@clever.tech.memes/list/internalamazonwebservices-805665b5bf42?source=my_lists---------13-------805665b5bf42---------------------" rel="noopener"><em class="iq">aw</em></a></p><p id="22aa" class="kl km mr kn b ko mj kq kr ks mk ku kv ms ml ky kz mt mm lc ld mu mn lg lh li ij bi translated">请使用此链接加入 medium<a class="ae mv" href="https://medium.com/@clever.tech.memes/membership" rel="noopener"><em class="iq"/></a><em class="iq">。谢谢你的大力支持。</em></p></blockquote></div></div>    
</body>
</html>