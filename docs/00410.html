<html>
<head>
<title>Find Dividend Paying Stocks with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 Python 查找支付股息的股票</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/find-dividend-paying-stocks-with-python-6c7565d620f7?source=collection_archive---------10-----------------------#2020-06-06">https://blog.devgenius.io/find-dividend-paying-stocks-with-python-6c7565d620f7?source=collection_archive---------10-----------------------#2020-06-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/b517e7adc8d60ceeafda4e83850cba79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mlsEWp_MV4tAHZR1pBNrQA.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">用 python 查找支付股息的股票</figcaption></figure><p id="6e1e" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在本教程中，我们将介绍如何用 python 寻找支付股息的股票。</p><p id="7b92" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我创建这个教程和这个脚本的原因是因为我想快速获得关于股票分红的数据，而我找不到任何好的免费 API 可以使用。所以我选择的解决方案是使用网络抓取。</p><p id="7b3e" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">幸运的是，有一个很棒的 python 抓取模块，叫做 Beautiful Soup。</p><p id="1484" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们要刮的网站是:</p><p id="c2f5" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">https://www.lse.co.uk/share-fundamentals.asp?shareprice=<a class="ae lb" href="https://www.lse.co.uk/share-fundamentals.asp?shareprice=" rel="noopener ugc nofollow" target="_blank"/></p><p id="54e5" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">例如，在这个 url 的末尾，我们可以放置股票代码</p><p id="4dc4" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">【https://www.lse.co.uk/share-fundamentals.asp?shareprice=UU. T4】</p><p id="208b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在网站上，我们可以看到第二个市场数据表中的股息率和股息率:</p><figure class="ld le lf lg gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lc"><img src="../Images/b521e8d3d026c61457fad7cbe4a816ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*0y7hjuF0dW_ASABJ.png"/></div></div></figure><p id="71f7" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">所以我们想得到这些数据，但是对于任何在伦敦证交所网站上上市的股票。</p><p id="5565" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">要改变公司，我们所要做的就是把 URL 末尾的股票代码换掉。现在，你可能有自己感兴趣的股票代码列表，但如果你没有，在这个网页的底部有一个下载表格，你可以下载一个 CSV 文件，其中包含来自富时 250 指数的股票代码列表。</p><p id="5fb8" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">因为它不是关于本教程的，但是我不想错过任何次要的信息，我们将快速创建我们脚本的起点，我将在内联注释中简要解释:</p><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="b431" class="lm ln iq li b gy lo lp l lq lr"># These are our imports, external modules which <br/># will help us. <br/>from bs4 import BeautifulSoup as bs # Used for scraping data<br/>import csv # Used to get and write to CSV<br/>import requests # Used to access the external URL (the webpage)<br/><br/>'''<br/> All this function is doing is reading from our <br/> tickers.csv file (which should be saved in the <br/> same location as your python script) and returning<br/> them in a list.<br/>'''<br/>def get_tickers():<br/>    tickers = []<br/>    with open('tickers.csv') as ticker_file:<br/>        for ticker in ticker_file:<br/>            tickers.append(ticker.strip())<br/>    return tickers<br/><br/> '''<br/> This method takes a list of dictionaries <br/> and uses it to write a CSV file called <br/> dividends.csv. We will use this last.<br/> '''<br/>def to_csv(stocks):<br/>    with open('dividends.csv', 'w') as output:<br/>        writer = csv.writer(output)<br/>        writer.writerow(stocks[0].keys())<br/>        for stock in stocks:<br/>            writer.writerow(stock.values())<br/><br/>'''<br/>This method gets the webpage we want and returns<br/>the html as a beautifulsoup object which we <br/>can easily scrape for data. <br/>'''<br/>def get_soup(url):<br/>    return bs(requests.get(url).text, 'html.parser')<br/>'''<br/>This is our entry point.<br/>'''<br/>if __name__ == '__main__':<br/>    dividends = [] # Create an empty list<br/>    for ticker in get_tickers(): # Iterate over the tickers<br/>      # Add the dividend data to the dividends list<br/>        dividends.append(get_data(ticker))<br/>    # Write the dividends data to CSV.<br/>    to_csv(dividends)</span></pre><p id="1f9b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">现在我们需要找到 HTML 和表中有关股息和收益单元格的信息。</p><p id="116e" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">现在我们需要找到 HTML 和表中有关股息和收益单元格的信息。</p><p id="353a" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">为此，右键单击其中一个单元格，然后单击“检查元素”</p><figure class="ld le lf lg gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ls"><img src="../Images/a15f6dfab64001eb5b3174f20793370c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NbO6mICsY8wj2KVZ.png"/></div></div></figure><p id="bf1c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在这里，我们可以看到该表有一个“sp-fundamentals-info__table”类，该表行包含一个<th>元素和一个</th><td>元素，其中包含股息率。</td></p><p id="72a5" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">值得注意的是，在这个页面上有三个带有类“sp-fundamentals-info__table”的表格。我们想得到第二个，在代码中是[1]，因为列表从 0 开始。</p><p id="a9d5" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">还要注意，股息率在表格的第 6 行，股息率在第 7 行。所以当我们从一个列表中得到这个数据时，我们将得到元素 5 和 6。</p><p id="79b6" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">所以现在我们有了所有需要的信息。让我们开始编写 get_data 方法。</p><p id="41b1" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">首先，让我们获得由我们感兴趣的股票的网页构成的 soup 对象:</p><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="e385" class="lm ln iq li b gy lo lp l lq lr">def get_data(ticker):<br/>    url = '<a class="ae lb" href="https://www.lse.co.uk/share-fundamentals.asp?shareprice='" rel="noopener ugc nofollow" target="_blank">https://www.lse.co.uk/share-fundamentals.asp?shareprice='</a><br/>    soup = get_soup(url + ticker)</span></pre><p id="150a" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">接下来，我们应该打开一个例外尝试块。</p><p id="5f1b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">为什么？</p><p id="fb12" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这里有很多可能出错的地方，为所有可能出错的情况编写代码既无聊又容易出错。因此，我们将只做一个全面的异常。这样，如果没有红利，或者网页没有我们想要的信息，或者请求失败，我们仍然可以继续使用脚本。</p><p id="20ce" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">请注意，这种方法是懒惰的，不应该在生产中使用，因为您希望为所有可能出错的情况编写案例，并以不同的方式处理它们。但是对于本教程来说，这完全没有必要。</p><p id="9a33" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们在 try 块中要做的第一件事是找到我们感兴趣的表。为了做到这一点，我们将使用漂亮的 Soup 方法 find_all 来查找所有带有类的表元素:“sp-fundamentals-info__table”，然后我们将使用[1]选择第二个元素。</p><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="b4ee" class="lm ln iq li b gy lo lp l lq lr">try: <br/>        table = soup.find_all('table', attrs={'class', 'sp-fundamentals-info__table'})[1]</span></pre><p id="cb76" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">接下来我们需要得到股息和股息收益率信息。为此，我们将查找表中的所有<tr>元素，分别选择 5 和 6 个元素，然后使用 BeautifulSoup find 方法查找包含我们感兴趣的信息的<td>元素。最后，我们调用。text 方法，如您所料，它会返回元素中包含的文本。</td></tr></p><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="e061" class="lm ln iq li b gy lo lp l lq lr">dividend = table.find_all('tr')[5].find('td').text<br/>div_yield = table.find_all('tr')[6].find('td').text</span></pre><p id="dd9f" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">接下来，我们可以将信息打印到控制台，这样我们可以看到脚本运行时发生了什么，然后我们可以返回一个包含股票代码、股息和股息收益率的字典对象。这将在稍后形成我们的股息 CSV 文件的列。</p><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="a270" class="lm ln iq li b gy lo lp l lq lr">print(f'Dividend for {ticker} : {dividend}')</span><span id="4f06" class="lm ln iq li b gy lt lp l lq lr">return {<br/>                'ticker': ticker, <br/>                'dividend': dividend, <br/>                'yield': div_yield<br/>               }</span></pre><p id="a40d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">最后，我们需要将 except 块添加到 try 块中。在其中，我们只是简单地登录到控制台，我们找不到该特定股票的股息信息。</p><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="99dd" class="lm ln iq li b gy lo lp l lq lr">except: <br/>        print('No information available for ', ticker)</span></pre><p id="5715" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">仅此而已。现在，您可以运行代码，它将输出一个名为股息. csv 的文件。该文件将包含一个支付股息的股票及其收益率的表格。</p><p id="4152" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这个帖子最初发布在这里:<a class="ae lb" href="https://codeyogi.co.uk/2020/06/02/find-dividend-paying-stocks-with-python/" rel="noopener ugc nofollow" target="_blank">https://codeyogi . co . uk/2020/06/02/find-股息支付-股票-与-python/ </a>在这里你还可以找到一个链接，下载我们在本教程中使用的 tickers 文件。</p><p id="16ea" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我也有这个教程的视频版本，如果能让你开心的话，你可以跟着看:</p><p id="2cc5" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">【https://www.youtube.com/watch?v=b94LKGlkntM T4】</p><p id="e272" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">以下是本教程的完整代码:</p><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="b030" class="lm ln iq li b gy lo lp l lq lr">from bs4 import BeautifulSoup as bs<br/>import csv <br/>import requests</span><span id="fb1b" class="lm ln iq li b gy lt lp l lq lr">def get_tickers():<br/>    tickers = []<br/>    with open('tickers.csv') as ticker_file:<br/>        for ticker in ticker_file:<br/>            tickers.append(ticker.strip())<br/>    return tickers</span><span id="0af5" class="lm ln iq li b gy lt lp l lq lr">def to_csv(stocks):<br/>    with open('dividends.csv', 'w') as output:<br/>        writer = csv.writer(output)<br/>        writer.writerow(stocks[0].keys())<br/>        for stock in stocks:<br/>            writer.writerow(stock.values())</span><span id="5d06" class="lm ln iq li b gy lt lp l lq lr">def get_soup(url):<br/>    return bs(requests.get(url).text, 'html.parser')</span><span id="9b3c" class="lm ln iq li b gy lt lp l lq lr">def get_data(ticker):<br/>    url = '<a class="ae lb" href="https://www.lse.co.uk/share-fundamentals.asp?shareprice='" rel="noopener ugc nofollow" target="_blank">https://www.lse.co.uk/share-fundamentals.asp?shareprice='</a><br/>    soup = get_soup(url + ticker)<br/>    try: <br/>        table = soup.find_all('table', attrs={'class', 'sp-fundamentals-info__table'})[1]<br/>        dividend = table.find_all('tr')[5].find('td').text<br/>        div_yield = table.find_all('tr')[6].find('td').text</span><span id="9c57" class="lm ln iq li b gy lt lp l lq lr">print(f'Dividend for {ticker} : {dividend}')</span><span id="5785" class="lm ln iq li b gy lt lp l lq lr">return {<br/>                'ticker': ticker, <br/>                'dividend': dividend, <br/>                'yield': div_yield<br/>               }<br/>    except: <br/>        print('No information available for ', ticker)</span><span id="15ce" class="lm ln iq li b gy lt lp l lq lr">if __name__ == '__main__':<br/>    dividends = []<br/>    for ticker in get_tickers():<br/>        dividends.append(get_data(ticker))<br/>    to_csv(dividends)</span></pre></div></div>    
</body>
</html>