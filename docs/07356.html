<html>
<head>
<title>Building an analytics pipeline using StreamSets Data Collector, Apache Kafka, and Pinot</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 StreamSets 数据收集器、Apache Kafka 和 Pinot 构建分析管道</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/building-an-analytics-pipeline-using-streamsets-data-collector-apache-kafka-and-pinot-170c46f9ad2b?source=collection_archive---------2-----------------------#2022-03-18">https://blog.devgenius.io/building-an-analytics-pipeline-using-streamsets-data-collector-apache-kafka-and-pinot-170c46f9ad2b?source=collection_archive---------2-----------------------#2022-03-18</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><p id="8b80" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">使用开源工具/技术来构建您的分析堆栈非常有趣。由于是开源的，运行这样的堆栈的成本也非常便宜，而且不会影响处理数据的质量、速度和数量。</p><p id="257f" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">在本文中，我解释了如何使用以下工具在一小时内完成端到端分析堆栈的设置。</p><ul class=""><li id="f3ee" class="ki kj in jm b jn jo jr js jv kk jz kl kd km kh kn ko kp kq bi translated"><strong class="jm io"> StreamSets 数据收集器</strong> : StreamSets DataOps 平台是一个用于管理数据管道的云原生平台。使用控制中心来构建、管理和监控您的管道。将 StreamSets 引擎部署到您的公司网络，该网络可以是内部部署的，也可以是受保护的云计算平台。然后，使用引擎运行您的管道。<a class="ae kr" href="https://eu01.hub.streamsets.com/#" rel="noopener ugc nofollow" target="_blank">了解更多</a>。</li><li id="2a9c" class="ki kj in jm b jn ks jr kt jv ku jz kv kd kw kh kn ko kp kq bi translated"><strong class="jm io"> Apache Kafka </strong> : Apache Kafka 是一个开源分布式事件流平台，被数千家公司用于高性能数据管道、流分析、数据集成和关键任务应用。</li><li id="10cd" class="ki kj in jm b jn ks jr kt jv ku jz kv kd kw kh kn ko kp kq bi translated"><strong class="jm io">Apache Pinot</strong>:<a class="ae kr" href="https://pinot.apache.org/" rel="noopener ugc nofollow" target="_blank">Apache Pinot</a>是一个开源的 OLAP 数据库，能够从 Kafka 获取流数据，并在几秒钟内提供查询。</li></ul><p id="0b38" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">除了上述内容之外，我还使用了“Gretel(参考<a class="ae kr" href="https://gretel.ai/" rel="noopener ugc nofollow" target="_blank">Gretel . ai-Privacy Engineering API for every one</a>)”来生成一些我们可以用于演示的合成数据。</p><figure class="ky kz la lb gt lc gh gi paragraph-image"><div class="gh gi kx"><img src="../Images/47ff11fcfafb6085dc6e94bae1ef3279.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*Hl6JXaHj_WYDY1L4ihfnmA.png"/></div><figcaption class="lf lg gj gh gi lh li bd b be z dk translated">分析管道工作流</figcaption></figure><h1 id="a70c" class="lj lk in bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">整体数据管道架构</h1><ol class=""><li id="8728" class="ki kj in jm b jn mh jr mi jv mj jz mk kd ml kh mm ko kp kq bi translated">交易数据以 CSV 文件的形式到达 S3 存储桶。为了便于演示，我提到过事务性文件以 CSV 格式定期到达 S3。但实际上，它们总是可以作为流数据在线，也可以从任何数据仓库离线。概念保持不变。</li><li id="880d" class="ki kj in jm b jn ks jr kt jv ku jz kv kd kw kh mm ko kp kq bi translated">当数据到达时，在 StreamSets 中开发和部署的管道获取记录，将它们从 CSV 格式转换为 JSON 格式，然后发布到 Kafka。</li><li id="d223" class="ki kj in jm b jn ks jr kt jv ku jz kv kd kw kh mm ko kp kq bi translated">到达 Kafka 主题的 JSON 数据被 Apache Pinot 的 Kafka 连接器使用，以自动获取数据并将其存储在 Apache Pinot 中指定的表中。</li><li id="240e" class="ki kj in jm b jn ks jr kt jv ku jz kv kd kw kh mm ko kp kq bi translated">一旦数据输入 Pinot，就可以编写复杂的分析查询来获得即时响应。</li></ol><h1 id="386a" class="lj lk in bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">先决条件设置</h1><h2 id="68c7" class="mn lk in bd ll mo mp dn lp mq mr dp lt jv ms mt lx jz mu mv mb kd mw mx mf my bi translated">在 Docker 中设置 Apache Pinot</h2><p id="7f28" class="pw-post-body-paragraph jk jl in jm b jn mh jp jq jr mi jt ju jv mz jx jy jz na kb kc kd nb kf kg kh ig bi translated">Docker 撰写</p><p id="15fa" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">将以下内容复制并粘贴到 docker-compose.yml 文件中。</p><pre class="ky kz la lb gt nc nd ne nf aw ng bi"><span id="6f38" class="mn lk in nd b gy nh ni l nj nk">version: '3.7'<br/>services:<br/>  zookeeper:<br/>    image: zookeeper:3.5.6<br/>    hostname: zookeeper<br/>    container_name: manual-zookeeper<br/>    ports:<br/>      - "2181:2181"<br/>    environment:<br/>      ZOOKEEPER_CLIENT_PORT: 2181<br/>      ZOOKEEPER_TICK_TIME: 2000<br/>  pinot-controller:<br/>    image: apachepinot/pinot:0.9.3<br/>    command: "StartController -zkAddress manual-zookeeper:2181"<br/>    container_name: "manual-pinot-controller"<br/>    restart: unless-stopped<br/>    ports:<br/>      - "9000:9000"<br/>    environment:<br/>      JAVA_OPTS: "-Dplugins.dir=/opt/pinot/plugins -Xms1G -Xmx4G -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -Xloggc:gc-pinot-controller.log"<br/>    depends_on:<br/>      - zookeeper<br/>  pinot-broker:<br/>    image: apachepinot/pinot:0.9.3<br/>    command: "StartBroker -zkAddress manual-zookeeper:2181"<br/>    restart: unless-stopped<br/>    container_name: "manual-pinot-broker"<br/>    ports:<br/>      - "8099:8099"<br/>    environment:<br/>      JAVA_OPTS: "-Dplugins.dir=/opt/pinot/plugins -Xms4G -Xmx4G -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -Xloggc:gc-pinot-broker.log"<br/>    depends_on:<br/>      - pinot-controller<br/>  pinot-server:<br/>    image: apachepinot/pinot:0.9.3<br/>    command: "StartServer -zkAddress manual-zookeeper:2181"<br/>    restart: unless-stopped<br/>    container_name: "manual-pinot-server" <br/>    environment:<br/>      JAVA_OPTS: "-Dplugins.dir=/opt/pinot/plugins -Xms4G -Xmx16G -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -Xloggc:gc-pinot-server.log"<br/>    depends_on:<br/>      - pinot-broker</span></pre><p id="eada" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">运行以下命令启动所有组件。</p><pre class="ky kz la lb gt nc nd ne nf aw ng bi"><span id="5a47" class="mn lk in nd b gy nh ni l nj nk">docker-compose --project-name streamsets-pinot-analytics up</span></pre><p id="ac17" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">启动后，您可以运行以下命令来检查状态:</p><pre class="ky kz la lb gt nc nd ne nf aw ng bi"><span id="988d" class="mn lk in nd b gy nh ni l nj nk">docker container ls</span><span id="31ec" class="mn lk in nd b gy nl ni l nj nk">CONTAINER ID   IMAGE                          COMMAND                  CREATED         STATUS         PORTS                                                  NAMES<br/>d3dafd9e37a8   apachepinot/pinot:0.9.3        "./bin/pinot-admin.s…"   7 minutes ago   Up 7 minutes   8096-8099/tcp, 9000/tcp                                manual-pinot-server<br/>be031b0273f6   apachepinot/pinot:0.9.3        "./bin/pinot-admin.s…"   7 minutes ago   Up 7 minutes   8096-8098/tcp, 9000/tcp, 0.0.0.0:8099-&gt;8099/tcp        manual-pinot-broker<br/>34b6f63801ea   apachepinot/pinot:0.9.3        "./bin/pinot-admin.s…"   7 minutes ago   Up 7 minutes   8096-8099/tcp, 0.0.0.0:9000-&gt;9000/tcp                  manual-pinot-controller<br/>e3d8c2283e9f   zookeeper:3.5.6                "/docker-entrypoint.…"   7 minutes ago   Up 7 minutes   2888/tcp, 3888/tcp, 0.0.0.0:2181-&gt;2181/tcp, 8080/tcp   manual-zookeeper</span></pre><h1 id="1d13" class="lj lk in bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">在 Docker 中设置 Apache Kafka</h1><h2 id="bd0b" class="mn lk in bd ll mo mp dn lp mq mr dp lt jv ms mt lx jz mu mv mb kd mw mx mf my bi translated">运行卡夫卡</h2><p id="be39" class="pw-post-body-paragraph jk jl in jm b jn mh jp jq jr mi jt ju jv mz jx jy jz na kb kc kd nb kf kg kh ig bi translated">运行以下命令以:</p><pre class="ky kz la lb gt nc nd ne nf aw ng bi"><span id="3b31" class="mn lk in nd b gy nh ni l nj nk">docker run \<br/>    --network streamsets-pinot-analytics_default --name=kafka \<br/>    -e KAFKA_ZOOKEEPER_CONNECT=manual-zookeeper:2181/kafka \<br/>    -e KAFKA_BROKER_ID=0 \<br/>    -e KAFKA_ADVERTISED_HOST_NAME=kafka \<br/>    -d wurstmeister/kafka:latest</span></pre><h2 id="e5e2" class="mn lk in bd ll mo mp dn lp mq mr dp lt jv ms mt lx jz mu mv mb kd mw mx mf my bi translated">创造卡夫卡主题</h2><pre class="ky kz la lb gt nc nd ne nf aw ng bi"><span id="fc36" class="mn lk in nd b gy nh ni l nj nk">docker exec \<br/>  -t kafka \<br/>  /opt/kafka/bin/kafka-topics.sh \<br/>  --zookeeper manual-zookeeper:2181/kafka \<br/>  --partitions=1 --replication-factor=1 \<br/>  --create --topic sdc-order-topic</span></pre><h1 id="fd01" class="lj lk in bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">在 Docker 中设置流集数据收集器</h1><p id="2e14" class="pw-post-body-paragraph jk jl in jm b jn mh jp jq jr mi jt ju jv mz jx jy jz na kb kc kd nb kf kg kh ig bi translated">要设置 StreamSets，我建议你参考这个<a class="ae kr" href="https://docs.streamsets.com/portal/platform-controlhub/controlhub/UserGuide/GettingStarted/Try.html#concept_vdw_ydx_k4b" rel="noopener ugc nofollow" target="_blank">链接</a>。有足够的文献和视频可以让你在几分钟内快速上手。以下是您首次部署的入职视频。</p><p id="4628" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><a class="ae kr" href="https://streamsets.wistia.com/medias/fnru8lzq7k" rel="noopener ugc nofollow" target="_blank">如何在流集数据操作平台</a>中设置部署</p><p id="3648" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">运行“docker ps”命令，我看到下面的容器正在运行。</p><pre class="ky kz la lb gt nc nd ne nf aw ng bi"><span id="ccd5" class="mn lk in nd b gy nh ni l nj nk">[root@NL903 sdc-pinot]# docker ps<br/>CONTAINER ID   IMAGE                          COMMAND                  CREATED       STATUS       PORTS                                                  NAMES<br/>fca2fa9323bf   wurstmeister/kafka:latest      "start-kafka.sh"         9 hours ago   Up 9 hours                                                          kafka<br/>b106c08533f5   apachepinot/pinot:0.9.3        "./bin/pinot-admin.s…"   9 hours ago   Up 9 hours   8096-8099/tcp, 9000/tcp                                manual-pinot-server<br/>cca59ed38582   apachepinot/pinot:0.9.3        "./bin/pinot-admin.s…"   9 hours ago   Up 9 hours   8096-8098/tcp, 9000/tcp, 0.0.0.0:8099-&gt;8099/tcp        manual-pinot-broker<br/>ae331a604398   apachepinot/pinot:0.9.3        "./bin/pinot-admin.s…"   9 hours ago   Up 9 hours   8096-8099/tcp, 0.0.0.0:9000-&gt;9000/tcp                  manual-pinot-controller<br/>4492fe762eba   zookeeper:3.5.6                "/docker-entrypoint.…"   9 hours ago   Up 9 hours   2888/tcp, 3888/tcp, 0.0.0.0:2181-&gt;2181/tcp, 8080/tcp   manual-zookeeper<br/>d19fb61b15e5   sdc                            "/docker-entrypoint.…"   11 days ago   Up 2 days    18630/tcp, 0.0.0.0:8000-&gt;8010/tcp                      gallant_easley<br/>Setting Up Synthetic Data Using Gretel</span></pre><p id="181c" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">可以看到，上面的 StreamSets 容器是“<code class="fe nm nn no nd b">gallant_easley</code>”。</p><h2 id="78ff" class="mn lk in bd ll mo mp dn lp mq mr dp lt jv ms mt lx jz mu mv mb kd mw mx mf my bi translated">建立容器之间的桥梁</h2><p id="ce80" class="pw-post-body-paragraph jk jl in jm b jn mh jp jq jr mi jt ju jv mz jx jy jz na kb kc kd nb kf kg kh ig bi translated">运行以下命令:</p><pre class="ky kz la lb gt nc nd ne nf aw ng bi"><span id="877a" class="mn lk in nd b gy nh ni l nj nk">sudo docker network connect streamsets-pinot-analytics_default gallant_easley<br/>sudo docker network inspect streamsets-pinot-analytics_default</span></pre><p id="4bb1" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">在上面的命令之后，你会看到分配给“Kafka”的“IPv4Address”。记下它，因为在流集中构建管道时会用到它。</p><h1 id="c060" class="lj lk in bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">设置合成数据</h1><p id="4cfa" class="pw-post-body-paragraph jk jl in jm b jn mh jp jq jr mi jt ju jv mz jx jy jz na kb kc kd nb kf kg kh ig bi translated">注册<a class="ae kr" href="https://gretel.ai/" rel="noopener ugc nofollow" target="_blank">Gretel . ai——面向每个人的隐私工程 APIs】开始成为免费用户。我提供了一些示例数据的前 50 行，您可以利用它们来创建一个包含 5000 行的文件的合成数据。</a></p><h2 id="51b9" class="mn lk in bd ll mo mp dn lp mq mr dp lt jv ms mt lx jz mu mv mb kd mw mx mf my bi translated">样本合成数据</h2><p id="ba3f" class="pw-post-body-paragraph jk jl in jm b jn mh jp jq jr mi jt ju jv mz jx jy jz na kb kc kd nb kf kg kh ig bi translated">“orders_sdc.csv”文件的一些示例条目，我将用于我的数据管道演示。</p><pre class="ky kz la lb gt nc nd ne nf aw ng bi"><span id="f101" class="mn lk in nd b gy nh ni l nj nk">uniq_orderid,ort_store_id,ort_order_id,ort_date,ort_order_type,ort_deliv_now_timed,ort_time,ort_deliv_date,ort_deliv_time,ort_userid,ort_tel,ort_custid,ort_cross_street,ort_sector,ort_coupon_total,ort_grandtotal,ort_payby,ort_paid,ort_change_reason,order_storeid,order_number,order_date,order_plu,order_qty,order_amount,order_coupon,order_type<br/>cf6500531510152021,236787,151015,2021-07-01,TAKEAWAY NOW,NOW,09:46:34,2021-07-01,10:03:19,1111.0,70193673414,PANDA,NONE,,0,26.02,PANDA,Y,,236787,151015,2021-07-01,6,1,8.19,,8<br/>cf5974831510212021,654387,151021,2021-07-01,TAKEAWAY NOW,NOW,09:46:40,2021-07-01,10:03:25,1111.0,70193673414,456789,NONE,,0,26.02,CASH,Y,,654387,151021,2021-07-01,6,1,8.19,,8<br/>cf3461831510152021,236787,151015,2021-07-01,TAKEAWAY NOW,NOW,09:46:34,2021-07-01,10:03:19,1111.0,70193673414,PANDA,NONE,,0,26.02,PANDA,Y,,236787,151015,2021-07-01,6,1,8.19,,8<br/>cf5138231510212021,654387,151021,2021-07-01,TAKEAWAY NOW,NOW,09:46:40,2021-07-01,10:03:25,1111.0,70193673414,456789,NONE,,0,26.02,CASH,Y,,654387,151021,2021-07-01,6,1,8.19,,8<br/>cf3659231510152021,236787,151015,2021-07-01,TAKEAWAY NOW,NOW,09:46:34,2021-07-01,10:03:19,1111.0,70193673414,PANDA,NONE,,0,26.02,PANDA,Y,,236787,151015,2021-07-01,6,1,8.19,,8<br/>cf6350631510152021,236787,151015,2021-07-01,TAKEAWAY NOW,NOW,09:46:34,2021-07-01,10:03:19,1111.0,70193673414,PANDA,NONE,,0,26.02,PANDA,Y,,236787,151015,2021-07-01,6,1,8.19,,8<br/>cf1514431510202021,236787,151020,2021-07-01,TAKEAWAY NOW,NOW,09:46:39,2021-07-01,10:03:24,1111.0,70193673416,127865,NONE,,0,26.02,CREDITCARD,Y,,236787,151020,2021-07-01,6,1,8.19,,8<br/>cf5913831510192021,236787,151019,2021-07-01,TAKEAWAY NOW,NOW,09:46:38,2021-07-01,10:03:23,1111.0,70193673415,678543,NONE,,0,26.02,CREDITCARD,Y,,236787,151019,2021-07-01,6,1,8.19,,8<br/>cf5377731510212021,654387,151021,2021-07-01,TAKEAWAY NOW,NOW,09:46:40,2021-07-01,10:03:25,1111.0,70193673414,456789,NONE,,0,26.02,CASH,Y,,654387,151021,2021-07-01,6,1,8.19,,8<br/>cf6826831510152021,236787,151015,2021-07-01,TAKEAWAY NOW,NOW,09:46:34,2021-07-01,10:03:19,1111.0,70193673414,PANDA,NONE,,0,26.02,PANDA,Y,,236787,151015,2021-07-01,6,1,8.19,,8<br/>cf9557831510212021,654387,151021,2021-07-01,TAKEAWAY NOW,NOW,09:46:40,2021-07-01,10:03:25,1111.0,70193673414,456789,NONE,,0,26.02,CASH,Y,,654387,151021,2021-07-01,6,1,8.19,,8<br/>cf1172831510212021,654387,151021,2021-07-01,TAKEAWAY NOW,NOW,09:46:40,2021-07-01,10:03:25,1111.0,70193673414,456789,NONE,,0,26.02,CASH,Y,,654387,151021,2021-07-01,6,1,8.19,,8<br/>cf7835631510212021,654387,151021,2021-07-01,TAKEAWAY NOW,NOW,09:46:40,2021-07-01,10:03:25,1111.0,70193673414,456789,NONE,,0,26.02,CASH,Y,,654387,151021,2021-07-01,6,1,8.19,,8<br/>cf9495831510202021,236787,151020,2021-07-01,TAKEAWAY NOW,NOW,09:46:39,2021-07-01,10:03:24,1111.0,70193673416,127865,NONE,,0,26.02,CREDITCARD,Y,,236787,151020,2021-07-01,6,1,8.19,,8<br/>cf765931510172021,236787,151017,2021-07-01,TAKEAWAY NOW,NOW,09:46:36,2021-07-01,10:03:21,1111.0,70193673416,GRABFOOD,NONE,,0,26.02,GRABFOOD,Y,,236787,151017,2021-07-01,6,1,8.19,,8<br/>cf3151231510202021,236787,151020,2021-07-01,TAKEAWAY NOW,NOW,09:46:39,2021-07-01,10:03:24,1111.0,70193673416,127865,NONE,,0,26.02,CREDITCARD,Y,,236787,151020,2021-07-01,6,1,8.19,,8<br/>cf359331510162021,236787,151016,2021-07-01,TAKEAWAY NOW,NOW,09:46:37,2021-07-01,10:03:22,1111.0,70193673414,GRABFOOD,NONE,,0,26.02,GRABFOOD,Y,,236787,151016,2021-07-01,6,1,8.19,,8<br/>cf3105031510202021,236787,151020,2021-07-01,TAKEAWAY NOW,NOW,09:46:39,2021-07-01,10:03:24,1111.0,70193673416,127865,NONE,,0,26.02,CREDITCARD,Y,,236787,151020,2021-07-01,6,1,8.19,,8<br/>cf8822231510202021,236787,151020,2021-07-01,TAKEAWAY NOW,NOW,09:46:39,2021-07-01,10:03:24,1111.0,70193673416,127865,NONE,,0,26.02,CREDITCARD,Y,,236787,151020,2021-07-01,6,1,8.19,,8<br/>cf2181931510202021,236787,151020,2021-07-01,TAKEAWAY NOW,NOW,09:46:39,2021-07-01,10:03:24,1111.0,70193673416,127865,NONE,,0,26.02,CREDITCARD,Y,,236787,151020,2021-07-01,6,1,8.19,,8<br/>cf5744231510182021,236787,151018,2021-07-01,TAKEAWAY NOW,NOW,09:46:35,2021-07-01,10:03:20,1111.0,70193673415,GRABFOOD,NONE,,0,26.02,GRABFOOD,Y,,236787,151018,2021-07-01,6,1,8.19,,8<br/>cf8212631510172021,236787,151017,2021-07-01,TAKEAWAY NOW,NOW,09:46:37,2021-07-01,10:03:22,1111.0,70193673414,GRABFOOD,NONE,,0,26.02,GRABFOOD,Y,,236787,151017,2021-07-01,6,1,8.19,,8<br/>cf6223431510202021,236787,151020,2021-07-01,TAKEAWAY NOW,NOW,09:46:39,2021-07-01,10:03:24,1111.0,70193673416,127865,NONE,,0,26.02,CREDITCARD,Y,,236787,151020,2021-07-01,6,1,8.19,,8<br/>cf1786731510212021,654387,151021,2021-07-01,TAKEAWAY NOW,NOW,09:46:40,2021-07-01,10:03:25,1111.0,70193673414,456789,NONE,,0,26.02,CASH,Y,,654387,151021,2021-07-01,6,1,8.19,,8<br/>cf4811931510212021,654387,151021,2021-07-01,TAKEAWAY NOW,NOW,09:46:40,2021-07-01,10:03:25,1111.0,70193673414,456789,NONE,,0,26.02,CASH,Y,,654387,151021,2021-07-01,6,1,8.19,,8<br/>cf3465931510212021,654387,151021,2021-07-01,TAKEAWAY NOW,NOW,09:46:40,2021-07-01,10:03:25,1111.0,70193673414,456789,NONE,,0,26.02,CASH,Y,,654387,151021,2021-07-01,6,1,8.19,,8<br/>cf9248331510212021,654387,151021,2021-07-01,TAKEAWAY NOW,NOW,09:46:40,2021-07-01,10:03:25,1111.0,70193673414,456789,NONE,,0,26.02,CASH,Y,,654387,151021,2021-07-01,6,1,8.19,,8<br/>cf2635831510202021,236787,151020,2021-07-01,TAKEAWAY NOW,NOW,09:46:39,2021-07-01,10:03:24,1111.0,70193673416,127865,NONE,,0,26.02,CREDITCARD,Y,,236787,151020,2021-07-01,6,1,8.19,,8<br/>cf8620531510192021,236787,151019,2021-07-01,TAKEAWAY NOW,NOW,09:46:38,2021-07-01,10:03:23,1111.0,70193673415,678543,NONE,,0,26.02,CREDITCARD,Y,,236787,151019,2021-07-01,6,1,8.19,,8<br/>cf7102231510172021,236787,151017,2021-07-01,TAKEAWAY NOW,NOW,09:46:36,2021-07-01,10:03:21,1111.0,70193673416,GRABFOOD,NONE,,0,26.02,GRABFOOD,Y,,236787,151017,2021-07-01,6,1,8.19,,8<br/>cf9852331510202021,236787,151020,2021-07-01,TAKEAWAY NOW,NOW,09:46:39,2021-07-01,10:03:24,1111.0,70193673416,127865,NONE,,0,26.02,CREDITCARD,Y,,236787,151020,2021-07-01,6,1,8.19,,8<br/>cf9605231510202021,236787,151020,2021-07-01,TAKEAWAY NOW,NOW,09:46:39,2021-07-01,10:03:24,1111.0,70193673416,127865,NONE,,0,26.02,CREDITCARD,Y,,236787,151020,2021-07-01,6,1,8.19,,8<br/>cf1565631510182021,236787,151018,2021-07-01,TAKEAWAY NOW,NOW,09:46:37,2021-07-01,10:03:22,1111.0,70193673414,GRABFOOD,NONE,,0,26.02,GRABFOOD,Y,,236787,151018,2021-07-01,6,1,8.19,,8<br/>cf6213031510212021,654387,151021,2021-07-01,TAKEAWAY NOW,NOW,09:46:40,2021-07-01,10:03:25,1111.0,70193673414,456789,NONE,,0,26.02,CASH,Y,,654387,151021,2021-07-01,6,1,8.19,,8<br/>cf9092331510212021,654387,151021,2021-07-01,TAKEAWAY NOW,NOW,09:46:40,2021-07-01,10:03:25,1111.0,70193673414,456789,NONE,,0,26.02,CASH,Y,,654387,151021,2021-07-01,6,1,8.19,,8<br/>cf6066331510152021,236787,151015,2021-07-01,TAKEAWAY NOW,NOW,09:46:34,2021-07-01,10:03:19,1111.0,70193673414,PANDA,NONE,,0,26.02,PANDA,Y,,236787,151015,2021-07-01,6,1,8.19,,8<br/>cf6283031510212021,654387,151021,2021-07-01,TAKEAWAY NOW,NOW,09:46:40,2021-07-01,10:03:25,1111.0,70193673414,456789,NONE,,0,26.02,CASH,Y,,654387,151021,2021-07-01,6,1,8.19,,8<br/>cf7782731510212021,654387,151021,2021-07-01,TAKEAWAY NOW,NOW,09:46:40,2021-07-01,10:03:25,1111.0,70193673414,456789,NONE,,0,26.02,CASH,Y,,654387,151021,2021-07-01,6,1,8.19,,8<br/>cf1558731510192021,236787,151019,2021-07-01,TAKEAWAY NOW,NOW,09:46:38,2021-07-01,10:03:23,1111.0,70193673415,678543,NONE,,0,26.02,CREDITCARD,Y,,236787,151019,2021-07-01,6,1,8.19,,8<br/>cf1421031510202021,236787,151020,2021-07-01,TAKEAWAY NOW,NOW,09:46:39,2021-07-01,10:03:24,1111.0,70193673416,127865,NONE,,0,26.02,CREDITCARD,Y,,236787,151020,2021-07-01,6,1,8.19,,8<br/>cf2251531510202021,236787,151020,2021-07-01,TAKEAWAY NOW,NOW,09:46:39,2021-07-01,10:03:24,1111.0,70193673416,127865,NONE,,0,26.02,CREDITCARD,Y,,236787,151020,2021-07-01,6,1,8.19,,8<br/>cf1847531510162021,236787,151016,2021-07-01,TAKEAWAY NOW,NOW,09:46:37,2021-07-01,10:03:22,1111.0,70193673414,GRABFOOD,NONE,,0,26.02,GRABFOOD,Y,,236787,151016,2021-07-01,6,1,8.19,,8<br/>cf6891031510182021,236787,151018,2021-07-01,TAKEAWAY NOW,NOW,09:46:37,2021-07-01,10:03:22,1111.0,70193673414,GRABFOOD,NONE,,0,26.02,GRABFOOD,Y,,236787,151018,2021-07-01,6,1,8.19,,8<br/>cf9594731510162021,236787,151016,2021-07-01,TAKEAWAY NOW,NOW,09:46:37,2021-07-01,10:03:22,1111.0,70193673414,GRABFOOD,NONE,,0,26.02,GRABFOOD,Y,,236787,151016,2021-07-01,6,1,8.19,,8<br/>cf1788031510172021,236787,151017,2021-07-01,TAKEAWAY NOW,NOW,09:46:36,2021-07-01,10:03:21,1111.0,70193673416,GRABFOOD,NONE,,0,26.02,GRABFOOD,Y,,236787,151017,2021-07-01,6,1,8.19,,8<br/>cf7480231510202021,236787,151020,2021-07-01,TAKEAWAY NOW,NOW,09:46:39,2021-07-01,10:03:24,1111.0,70193673416,127865,NONE,,0,26.02,CREDITCARD,Y,,236787,151020,2021-07-01,6,1,8.19,,8<br/>cf7840931510202021,236787,151020,2021-07-01,TAKEAWAY NOW,NOW,09:46:39,2021-07-01,10:03:24,1111.0,70193673416,127865,NONE,,0,26.02,CREDITCARD,Y,,236787,151020,2021-07-01,6,1,8.19,,8<br/>cf8082731510202021,236787,151020,2021-07-01,TAKEAWAY NOW,NOW,09:46:39,2021-07-01,10:03:24,1111.0,70193673416,127865,NONE,,0,26.02,CREDITCARD,Y,,236787,151020,2021-07-01,6,1,8.19,,8<br/>cf2152631510192021,236787,151019,2021-07-01,TAKEAWAY NOW,NOW,09:46:38,2021-07-01,10:03:23,1111.0,70193673415,678543,NONE,,0,26.02,CREDITCARD,Y,,236787,151019,2021-07-01,6,1,8.19,,8<br/>cf2581131510182021,236787,151018,2021-07-01,TAKEAWAY NOW,NOW,09:46:36,2021-07-01,10:03:21,1111.0,70193673416,GRABFOOD,NONE,,0,26.02,GRABFOOD,Y,,236787,151018,2021-07-01,6,1,8.19,,8</span></pre><h1 id="3c76" class="lj lk in bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">在流集中设置管道</h1><h2 id="a668" class="mn lk in bd ll mo mp dn lp mq mr dp lt jv ms mt lx jz mu mv mb kd mw mx mf my bi translated">为始发地和目的地创建连接</h2><p id="97b6" class="pw-post-body-paragraph jk jl in jm b jn mh jp jq jr mi jt ju jv mz jx jy jz na kb kc kd nb kf kg kh ig bi translated">供将来参考—请参考此<a class="ae kr" href="https://docs.streamsets.com/portal/platform-controlhub/controlhub/UserGuide/Connections/GettingStarted.html#concept_fxv_rp5_4mb" rel="noopener ugc nofollow" target="_blank">链接。</a></p><h2 id="487e" class="mn lk in bd ll mo mp dn lp mq mr dp lt jv ms mt lx jz mu mv mb kd mw mx mf my bi translated">S3 连接</h2><p id="8743" class="pw-post-body-paragraph jk jl in jm b jn mh jp jq jr mi jt ju jv mz jx jy jz na kb kc kd nb kf kg kh ig bi translated">请参考 StreamSets 指南，并为存储示例文件的 S3 创建一个连接。</p><figure class="ky kz la lb gt lc gh gi paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><div class="gh gi np"><img src="../Images/01f766c4b5d7d27c2b1d98fa7a2886ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UnUnc63Mxh0uJIeN-Yi-mw.png"/></div></div><figcaption class="lf lg gj gh gi lh li bd b be z dk translated">StreamSets 数据操作中的 AWS S3 连接设置</figcaption></figure><p id="c070" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">“测试连接”——一旦您看到一个绿点，您就可以确信您的连接是成功的，并且您可以在构建管道时使用它。</p><p id="bf9a" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">保存此连接。</p><h2 id="e565" class="mn lk in bd ll mo mp dn lp mq mr dp lt jv ms mt lx jz mu mv mb kd mw mx mf my bi translated">卡夫卡连接</h2><p id="98ae" class="pw-post-body-paragraph jk jl in jm b jn mh jp jq jr mi jt ju jv mz jx jy jz na kb kc kd nb kf kg kh ig bi translated">请参考 StreamSets 指南，并为存储示例文件的 S3 创建一个连接。</p><figure class="ky kz la lb gt lc gh gi paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><div class="gh gi nu"><img src="../Images/26644aad189b36537e7823fef4dbbcaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FOjao-gjUjK_Fr9vXRLIkw.png"/></div></div><figcaption class="lf lg gj gh gi lh li bd b be z dk translated">StreamSets 数据操作中的 Kafka 连接设置</figcaption></figure><p id="edb9" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">注意“代理 URI”中的 IP 与您在“<em class="nv">设置容器之间的桥</em>”一节中收到的 IP 相同。</p><p id="90e4" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">“测试连接”——一旦您看到一个绿点，您就可以确信您的连接是成功的，并且您可以在构建管道时使用它。</p><p id="b4c2" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">保存此连接。</p><h2 id="5d7d" class="mn lk in bd ll mo mp dn lp mq mr dp lt jv ms mt lx jz mu mv mb kd mw mx mf my bi translated">创建一个片段将 CSV 转换成 JSON</h2><p id="a8db" class="pw-post-body-paragraph jk jl in jm b jn mh jp jq jr mi jt ju jv mz jx jy jz na kb kc kd nb kf kg kh ig bi translated">构建一个管道片段，将 CSV 转换为 JSON。不久前，我写了另一篇关于如何将 CSV 记录转换成 JSON 的文章——你可以参考这个链接<a class="ae kr" href="https://community.streamsets.com/how-to-51/swayam-s-micro-blogging-convert-csv-to-json-147" rel="noopener ugc nofollow" target="_blank"> Swayam 的微博:将 CSV 转换成 JSON | StreamSets 社区</a>。</p><figure class="ky kz la lb gt lc gh gi paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><div class="gh gi np"><img src="../Images/3bf89967e0163de206fc2c3f954fe6bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nT9vpd1XHadkA4tsLpjh7w.png"/></div></div><figcaption class="lf lg gj gh gi lh li bd b be z dk translated">StreamSets 数据操作管道中的片段</figcaption></figure><h2 id="4fa8" class="mn lk in bd ll mo mp dn lp mq mr dp lt jv ms mt lx jz mu mv mb kd mw mx mf my bi translated">建设管道</h2><p id="722a" class="pw-post-body-paragraph jk jl in jm b jn mh jp jq jr mi jt ju jv mz jx jy jz na kb kc kd nb kf kg kh ig bi translated">在 StreamSets DataOPs 平台中构建管道非常简单。</p><figure class="ky kz la lb gt lc gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/d9b82c10e68c1f5d0cffd329233c5da8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/format:webp/1*6cIXbAD88xhDN33TAi4lWw.png"/></div><figcaption class="lf lg gj gh gi lh li bd b be z dk translated">管道从 S3 读取 CSV 文件，并将其转换为 JSON 和发布到 Kafka</figcaption></figure><p id="b3f6" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">正如你在上面看到的，我们有 S3 起源。要配置 S3 原点，您可以使用以下提示:</p><ul class=""><li id="9068" class="ki kj in jm b jn jo jr js jv kk jz kl kd km kh kn ko kp kq bi translated">使用您之前在“连接”部分创建的相同 S3 连接。</li><li id="eae3" class="ki kj in jm b jn ks jr kt jv ku jz kv kd kw kh kn ko kp kq bi translated">提供您想要处理的 S3 存储桶和文件名(orders_sdc.csv)。</li><li id="9e1f" class="ki kj in jm b jn ks jr kt jv ku jz kv kd kw kh kn ko kp kq bi translated">确保“数据格式”选项卡用于处理文件中包含标题的标准 CSV 分隔文件。</li></ul><p id="1d4c" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">S3 源的输出连接到将 CSV 记录转换成 JSON 的 CSV2JSON 片段。</p><p id="3a40" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">最后，JSON 数据被发布给 Kafka 生产者。与起点一样，Kafka 目的地也应配置如下:</p><ul class=""><li id="a9eb" class="ki kj in jm b jn jo jr js jv kk jz kl kd km kh kn ko kp kq bi translated">使用您之前作为“连接”部分的一部分创建的相同 Kafka 连接。</li><li id="f1bb" class="ki kj in jm b jn ks jr kt jv ku jz kv kd kw kh kn ko kp kq bi translated">主题名称与我们之前创建的“<code class="fe nm nn no nd b">sdc-order-topic</code>”相同。</li><li id="dccb" class="ki kj in jm b jn ks jr kt jv ku jz kv kd kw kh kn ko kp kq bi translated">数据格式设置为 JSON。</li></ul><p id="5c80" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">一个发布到 Kafka 主题的样本 JSON 数据是:</p><pre class="ky kz la lb gt nc nd ne nf aw ng bi"><span id="98a5" class="mn lk in nd b gy nh ni l nj nk">{<br/>  "uniq_orderid": "0031510152021-07-01",<br/>  "ort_store_id": "003",<br/>  "ort_order_id": "151015",<br/>  "ort_date": "2021-07-01",<br/>  "ort_order_type": "TAKEAWAY NOW",<br/>  "ort_deliv_now_timed": "NOW",<br/>  "ort_time": "09:46:34",<br/>  "ort_deliv_date": "2021-07-01",<br/>  "ort_deliv_time": "10:03:19",<br/>  "ort_userid": "1111",<br/>  "ort_tel": "70193673415",<br/>  "ort_custid": "PANDA",<br/>  "ort_cross_street": "NONE",<br/>  "ort_sector": "",<br/>  "ort_coupon_total": "0",<br/>  "ort_grandtotal": "26.02",<br/>  "ort_payby": "PANDA",<br/>  "ort_paid": "Y",<br/>  "ort_change_reason": "NA",<br/>  "order_storeid": "003",<br/>  "order_number": "151004",<br/>  "order_date": "2021-07-01",<br/>  "order_plu": "6",<br/>  "order_qty": "1",<br/>  "order_amount": "-8.19",<br/>  "order_coupon": "NA",<br/>  "order_type": "8"<br/>}</span></pre><p id="9032" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">此时，存储在 AWS S3 存储桶中的 CSV 文件被转换成 JSON 并提交给 Kafka。</p><h1 id="a8fa" class="lj lk in bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">将数据同步到 Pinot</h1><p id="1cd3" class="pw-post-body-paragraph jk jl in jm b jn mh jp jq jr mi jt ju jv mz jx jy jz na kb kc kd nb kf kg kh ig bi translated">在将输入数据接收到 Pinot 之前，Pinot 要求您为流定义一个结构。这确保 Pinot 得到优化，以提供更快的数据分析。</p><h2 id="f2a4" class="mn lk in bd ll mo mp dn lp mq mr dp lt jv ms mt lx jz mu mv mb kd mw mx mf my bi translated">正在创建架构</h2><p id="0e7a" class="pw-post-body-paragraph jk jl in jm b jn mh jp jq jr mi jt ju jv mz jx jy jz na kb kc kd nb kf kg kh ig bi translated">创建一个文件“<strong class="jm io"> orders_sdc_schema.json </strong>，并将以下内容保存在其中。</p><pre class="ky kz la lb gt nc nd ne nf aw ng bi"><span id="b1d2" class="mn lk in nd b gy nh ni l nj nk">{<br/>    "schemaName": "orders",<br/>    "primaryKeyColumns": [<br/>      "uniq_orderid"<br/>    ],<br/>    "dimensionFieldSpecs": [<br/>      {<br/>        "name": "uniq_orderid",<br/>        "dataType": "STRING"<br/>      },<br/>      {<br/>        "name": "ort_store_id",<br/>        "dataType": "STRING"<br/>      },<br/>      {<br/>        "name": "ort_order_id",<br/>        "dataType": "INT"<br/>      },<br/>      {<br/>        "name": "ort_order_type",<br/>        "dataType": "STRING"<br/>      },<br/>      {<br/>        "name": "ort_deliv_now_timed",<br/>        "dataType": "STRING"<br/>      },<br/>      {<br/>        "name": "ort_time",<br/>        "dataType": "STRING"<br/>      },<br/>      {<br/>        "name": "ort_deliv_time",<br/>        "dataType": "STRING"<br/>      },<br/>      {<br/>        "name": "ort_userid",<br/>        "dataType": "STRING"<br/>      },<br/>      {<br/>        "name": "ort_tel",<br/>        "dataType": "STRING"<br/>      },<br/>      {<br/>        "name": "ort_custid",<br/>        "dataType": "STRING"<br/>      },<br/>      {<br/>        "name": "ort_cross_street",<br/>        "dataType": "STRING"<br/>      },<br/>      {<br/>        "name": "ort_sector",<br/>        "dataType": "STRING"<br/>      },<br/>      {<br/>        "name": "ort_coupon_total",<br/>        "dataType": "FLOAT"<br/>      },<br/>      {<br/>        "name": "ort_payby",<br/>        "dataType": "STRING"<br/>      },<br/>      {<br/>        "name": "ort_paid",<br/>        "dataType": "STRING"<br/>      },<br/>      {<br/>        "name": "ort_change_reason",<br/>        "dataType": "STRING"<br/>      },<br/>      {<br/>        "name": "order_storeid",<br/>        "dataType": "STRING"<br/>      },<br/>      {<br/>        "name": "order_number",<br/>        "dataType": "INT"<br/>      },<br/>      {<br/>        "name": "order_plu",<br/>        "dataType": "INT"<br/>      },<br/>      {<br/>        "name": "order_qty",<br/>        "dataType": "INT"<br/>      },<br/>      {<br/>        "name": "order_amount",<br/>        "dataType": "FLOAT"<br/>      },<br/>      {<br/>        "name": "order_coupon",<br/>        "dataType": "STRING"<br/>      },<br/>      {<br/>        "name": "order_type",<br/>        "dataType": "INT"<br/>      }<br/>    ],<br/>    "metricFieldSpecs": [<br/>      {<br/>        "name": "ort_grandtotal",<br/>        "dataType": "FLOAT"<br/>      }<br/>    ],<br/>    "dateTimeFieldSpecs": [{<br/>      "name": "ort_date",<br/>      "dataType": "STRING",<br/>      "format" : "1:DAYS:SIMPLE_DATE_FORMAT:yyyy-MM-dd",<br/>      "granularity": "1:DAYS"<br/>    },<br/>    {<br/>      "name": "ort_deliv_date",<br/>      "dataType": "STRING",<br/>      "format" : "1:DAYS:SIMPLE_DATE_FORMAT:yyyy-MM-dd",<br/>      "granularity": "1:DAYS"<br/>    },<br/>    {<br/>      "name": "order_date",<br/>      "dataType": "STRING",<br/>      "format" : "1:DAYS:SIMPLE_DATE_FORMAT:yyyy-MM-dd",<br/>      "granularity": "1:DAYS"<br/>    }]<br/>  }</span></pre><h2 id="81d5" class="mn lk in bd ll mo mp dn lp mq mr dp lt jv ms mt lx jz mu mv mb kd mw mx mf my bi translated">创建表格</h2><p id="341b" class="pw-post-body-paragraph jk jl in jm b jn mh jp jq jr mi jt ju jv mz jx jy jz na kb kc kd nb kf kg kh ig bi translated">创建一个文件“<strong class="jm io"> orders_sdc_table.json </strong>，并将以下内容保存在其中。</p><pre class="ky kz la lb gt nc nd ne nf aw ng bi"><span id="ffb3" class="mn lk in nd b gy nh ni l nj nk">{<br/>    "tableName": "orders",<br/>    "tableType": "REALTIME",<br/>    "segmentsConfig": {<br/>      "timeColumnName": "ort_date",<br/>      "schemaName": "orders",<br/>      "replication": "1",<br/>      "replicasPerPartition": "1"<br/>    },<br/>    "tableIndexConfig": {<br/>    "loadMode": "MMAP",<br/>    "streamConfigs": {<br/>      "streamType": "kafka",<br/>      "stream.kafka.consumer.type": "lowlevel",<br/>      "stream.kafka.topic.name": "sdc-order-topic",<br/>      "stream.kafka.decoder.class.name": "org.apache.pinot.plugin.stream.kafka.KafkaJSONMessageDecoder",<br/>      "stream.kafka.consumer.factory.class.name": "org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory",<br/>      "stream.kafka.broker.list": "kafka:9092",<br/>      "realtime.segment.flush.threshold.rows": "0",<br/>      "realtime.segment.flush.threshold.time": "24h",<br/>      "realtime.segment.flush.threshold.segment.size": "50M",<br/>      "stream.kafka.consumer.prop.auto.offset.reset": "smallest"<br/>    }<br/>  },<br/>    "tenants": {},<br/>    "metadata": {},<br/>    "routing": {<br/>      "instanceSelectorType": "strictReplicaGroup"<br/>    },<br/>    "upsertConfig": {<br/>      "mode": "FULL"<br/>    }<br/>  }</span></pre><h2 id="c293" class="mn lk in bd ll mo mp dn lp mq mr dp lt jv ms mt lx jz mu mv mb kd mw mx mf my bi translated">上传您的模式和表</h2><p id="4c0d" class="pw-post-body-paragraph jk jl in jm b jn mh jp jq jr mi jt ju jv mz jx jy jz na kb kc kd nb kf kg kh ig bi translated">将上面创建的两个 JSON 文件复制到/tmp 目录。</p><pre class="ky kz la lb gt nc nd ne nf aw ng bi"><span id="3bc1" class="mn lk in nd b gy nh ni l nj nk">mkdir -p /tmp/streamsets-pinot-analytics<br/>cp orders_sdc_schema.json orders_sdc_table.json /tmp/streamsets-pinot-analytics</span></pre><p id="23ce" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">运行以下命令:</p><pre class="ky kz la lb gt nc nd ne nf aw ng bi"><span id="5b51" class="mn lk in nd b gy nh ni l nj nk">docker run \<br/>    --network=streamsets-pinot-analytics_default \<br/>    -v /tmp/streamsets-pinot-analytics:/tmp/streamsets-pinot-analytics \<br/>    --name pinot-streaming-table-creation \<br/>    apachepinot/pinot:0.9.3 AddTable \<br/>    -schemaFile /tmp/streamsets-pinot-analytics/orders_sdc_schema.json \<br/>    -tableConfigFile /tmp/streamsets-pinot-analytics/orders_sdc_table.json \<br/>    -controllerHost manual-pinot-controller \<br/>    -controllerPort 9000 \<br/>    -exec</span></pre><p id="2f2a" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">如果一切顺利，您将在控制台中看到下面一行。这确认了该表已成功创建。</p><pre class="ky kz la lb gt nc nd ne nf aw ng bi"><span id="2be7" class="mn lk in nd b gy nh ni l nj nk">2022/03/18 08:24:02.667 INFO [AddTableCommand] [main] {"status":"Table orders_REALTIME succesfully added"}</span></pre><h1 id="cca0" class="lj lk in bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">验证 Kafka 到 Pinot 的数据摄取</h1><p id="0512" class="pw-post-body-paragraph jk jl in jm b jn mh jp jq jr mi jt ju jv mz jx jy jz na kb kc kd nb kf kg kh ig bi translated">由于 S3 桶中可用的订单数据已经作为管道的一部分被推送到 Kafka，所以一旦 Pinot 表准备好，Kafka 连接器就将所有未决记录从主题拉送到 Pinot。可以浏览到 pinot<a class="ae kr" href="http://localhost:9000/#/tables" rel="noopener ugc nofollow" target="_blank">http://localhost:9000/#/tables</a>查看表格。</p><figure class="ky kz la lb gt lc gh gi paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><div class="gh gi nx"><img src="../Images/f8120012c44d17cf9dac6987bdfe5076.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uYqxRoR3HUbQ-wCTbodIhw.png"/></div></div><figcaption class="lf lg gj gh gi lh li bd b be z dk translated">阿帕奇皮诺控制台</figcaption></figure><p id="4e1c" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">您可以转到 Pinot 查询控制台，查看表中是否已经有数据。</p><figure class="ky kz la lb gt lc gh gi paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><div class="gh gi ny"><img src="../Images/d46bdc8be54f88a763210ef5a13d91a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uOl68hCr52y268Ioa6bnvw.png"/></div></div><figcaption class="lf lg gj gh gi lh li bd b be z dk translated">Apache Pinot 查询控制台</figcaption></figure><h1 id="3cdc" class="lj lk in bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">复杂的分析查询和示例</h1><p id="b2f7" class="pw-post-body-paragraph jk jl in jm b jn mh jp jq jr mi jt ju jv mz jx jy jz na kb kc kd nb kf kg kh ig bi translated">现在您的订单事务数据已经在 Pinot 中可用，您可以使用查询控制台编写一些聚合查询来查看您得到的结果。</p><h2 id="6761" class="mn lk in bd ll mo mp dn lp mq mr dp lt jv ms mt lx jz mu mv mb kd mw mx mf my bi translated">所有商店过去 9 个月的订单总值</h2><pre class="ky kz la lb gt nc nd ne nf aw ng bi"><span id="b077" class="mn lk in nd b gy nh ni l nj nk">select sum(ort_grandtotal) as total_sales<br/>from orders<br/>where <br/>ToEpochSeconds(FromDateTime(order_date, 'YYYY-MM-dd')) &gt; ToEpochSeconds(now()- 9*30*86400000)</span></pre><h2 id="acae" class="mn lk in bd ll mo mp dn lp mq mr dp lt jv ms mt lx jz mu mv mb kd mw mx mf my bi translated">按商店 ID 和付款方式分组的所有商店过去 9 个月的订单总值</h2><pre class="ky kz la lb gt nc nd ne nf aw ng bi"><span id="66ec" class="mn lk in nd b gy nh ni l nj nk">select ort_store_id, ort_payby, sum(ort_grandtotal) as total_sales<br/>from orders<br/>where <br/>ToEpochSeconds(FromDateTime(order_date, 'YYYY-MM-dd')) &gt; ToEpochSeconds(now()- 9*30*86400000)<br/>group by ort_store_id, ort_payby<br/>order by total_sales desc</span></pre><p id="bfa3" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">Pinot 提供了 REST APIs 和驱动程序，开发人员可以利用它们来实时提取数据。此处参考阿帕奇皮诺文件<a class="ae kr" href="https://docs.pinot.apache.org/users/clients" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="76b2" class="lj lk in bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">结论</h1><p id="744e" class="pw-post-body-paragraph jk jl in jm b jn mh jp jq jr mi jt ju jv mz jx jy jz na kb kc kd nb kf kg kh ig bi translated">如您所见，使用所有开源工具，我们可以开发一个流程/工作流，通过 Apache Pinot 以低延迟处理复杂的分析查询。为了实时获取 Apache Pinot 的数据，我们可以使用 StreamSets 数据收集器，它提供了一系列连接器(<a class="ae kr" href="https://docs.streamsets.com/portal/platform-datacollector/latest/datacollector/UserGuide/Origins/Origins_title.html" rel="noopener ugc nofollow" target="_blank">起点</a>和<a class="ae kr" href="https://docs.streamsets.com/portal/platform-datacollector/latest/datacollector/UserGuide/Destinations/Destinations-title.html" rel="noopener ugc nofollow" target="_blank">终点</a>)。</p></div></div>    
</body>
</html>