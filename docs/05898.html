<html>
<head>
<title>Linear Regression- Machine Learning Algorithm</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归-机器学习算法</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/linear-regression-machine-learning-algorithm-a1d303312867?source=collection_archive---------1-----------------------#2021-11-18">https://blog.devgenius.io/linear-regression-machine-learning-algorithm-a1d303312867?source=collection_archive---------1-----------------------#2021-11-18</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><p id="bbfb" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi ki translated">线性回归一直是统计领域中研究最广泛的课题之一。通过长期建立的统计程序，线性回归模型的特性得到了很好的理解，并且可以很快地得到训练。</p><p id="2973" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">开始学习机器学习模型的踏脚石是线性回归。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/50301dfc200a170f3da7a737f80e5dc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z-P1ZDZSL8yWbShShdii_w.jpeg"/></div></div></figure><p id="5eec" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">当我们谈论线性回归时，我们需要了解ML问题的类型。以下是由不同的ML任务组成的简短总结:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ld"><img src="../Images/f14801d7e8a18710d32fb482ca1a4407.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*xDQ1fjLpV-2aoINn.png"/></div></div></figure><h1 id="8fdb" class="le lf in bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated"><strong class="ak">T3什么是线性回归？ </strong></h1><p id="1a0e" class="pw-post-body-paragraph jk jl in jm b jn md jp jq jr me jt ju jv mf jx jy jz mg kb kc kd mh kf kg kh ig bi translated">在深入线性回归之前，让我们了解这两个术语各自的含义。</p><p id="6669" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io">线性</strong>:这意味着沿着一条直线或接近直线的一系列步骤(顺序)从一个阶段前进到另一个阶段。</p><p id="3d5e" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io">回归</strong>:回归的统计术语是确定一个因变量与一系列自变量之间的关系。</p><p id="584b" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">因此，<em class="mi">线性回归</em>意味着对因变量和自变量之间的关系进行建模的线性方法。它将沿着数据点绘制一条称为最佳拟合线的直线来预测目标值。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/91040b3f62a12a5ab44fd726eb3819c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/0*Px4oHsdh9F-xYpMf.png"/></div></figure><p id="9da8" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">线性回归线有一个等式:</p><blockquote class="mk ml mm"><p id="5872" class="jk jl mi jm b jn jo jp jq jr js jt ju mn jw jx jy mo ka kb kc mp ke kf kg kh ig bi translated"><strong class="jm io">T13】Y = mX+cT15】</strong></p></blockquote><p id="9df9" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">其中Y为因变量，X为自变量，m为斜率，c为截距(当<strong class="jm io"> <em class="mi"> x </em> </strong> = 0时<strong class="jm io"> <em class="mi"> y </em> </strong>的值)</p><p id="e295" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">有两种类型的线性回归模型:</p><p id="46ab" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io"> <em class="mi">简单线性回归:</em> </strong>是一个自变量一个因变量的线性回归模型</p><blockquote class="mk ml mm"><p id="c78e" class="jk jl mi jm b jn jo jp jq jr js jt ju mn jw jx jy mo ka kb kc mp ke kf kg kh ig bi translated">y = mx + c</p></blockquote><p id="eedc" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io"> <em class="mi">多元线性回归</em> : </strong>是一个自变量多于一个因变量的线性回归模型</p><blockquote class="mk ml mm"><p id="76d6" class="jk jl mi jm b jn jo jp jq jr js jt ju mn jw jx jy mo ka kb kc mp ke kf kg kh ig bi translated">y = m1x1 + m2x2 + …+ c</p></blockquote><p id="6dd9" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io">复杂度</strong>:模型的复杂度为O(k)，其中k为数据的特征数/维数</p><h1 id="4c1a" class="le lf in bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">作为机器学习模型的线性回归</h1><ul class=""><li id="37a2" class="mq mr in jm b jn md jr me jv ms jz mt kd mu kh mv mw mx my bi translated">在机器学习中，线性回归算法需要估计数据表示中使用的系数值，以提供更好的预测值准确性。</li><li id="13c2" class="mq mr in jm b jn mz jr na jv nb jz nc kd nd kh mv mw mx my bi translated">可以使用以下方法评估系数值:</li></ul><ol class=""><li id="f021" class="mq mr in jm b jn jo jr js jv ne jz nf kd ng kh nh mw mx my bi translated"><strong class="jm io"> <em class="mi">普通最小二乘法</em> </strong>:普通最小二乘法程序寻求最小化残差平方和。这意味着给定一条穿过数据的回归线，我们计算每个数据点到回归线的距离，对其求平方，并将所有平方误差相加。这是普通最小二乘法试图最小化的量。</li><li id="dab8" class="mq mr in jm b jn mz jr na jv nb jz nc kd nd kh nh mw mx my bi translated"><strong class="jm io"> <em class="mi">梯度下降:</em> </strong>这是从每个系数的随机值开始的。计算每对输入和输出值的误差平方和。学习率被用作比例因子，并且系数朝着最小化误差的方向被更新。重复该过程，直到达到最小平方和误差，或者不可能进一步改进。<br/>使用该方法时，您必须选择一个学习率(alpha)参数，该参数决定了程序每次迭代的改进步长。</li><li id="ce6b" class="mq mr in jm b jn mz jr na jv nb jz nc kd nd kh nh mw mx my bi translated"><strong class="jm io"> <em class="mi">正则化:</em> </strong>这寻求最小化训练数据上的模型的平方误差的和(使用普通最小二乘法)，并且降低模型的复杂性(像模型中所有系数的和的数量或绝对大小)。<br/>线性回归的两种正则化<em class="mi"> </em>过程是:<br/> a. <em class="mi">套索回归</em> <br/> b. <em class="mi">岭回归</em> <br/>当输入值中存在共线性且普通最小二乘法会过度拟合训练数据时，这些方法非常有效。</li></ol><p id="ccc2" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io">线性回归模型的成本函数</strong></p><ul class=""><li id="17c6" class="mq mr in jm b jn jo jr js jv ne jz nf kd ng kh mv mw mx my bi translated">为了估计模型的性能，我们使用成本函数。</li><li id="cee3" class="mq mr in jm b jn mz jr na jv nb jz nc kd nd kh mv mw mx my bi translated">成本函数计算估计值和实际值之间的差异，并确定模型对于给定数据集的表现。</li><li id="8b6f" class="mq mr in jm b jn mz jr na jv nb jz nc kd nd kh mv mw mx my bi translated">在线性回归中，我们使用以下方法来计算成本函数:</li></ul><ol class=""><li id="9954" class="mq mr in jm b jn jo jr js jv ne jz nf kd ng kh nh mw mx my bi translated"><strong class="jm io">T22【均方根误差】T23</strong></li><li id="3614" class="mq mr in jm b jn mz jr na jv nb jz nc kd nd kh nh mw mx my bi translated"><strong class="jm io"> <em class="mi">均方差</em> </strong></li></ol><p id="bd1c" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io">为线性回归准备数据</strong></p><ul class=""><li id="0191" class="mq mr in jm b jn jo jr js jv ne jz nf kd ng kh mv mw mx my bi translated">在数据准备过程中，可以使用以下启发式方法，以便从线性回归模型中获得更好的输出</li></ul><ol class=""><li id="e1ed" class="mq mr in jm b jn jo jr js jv ne jz nf kd ng kh nh mw mx my bi translated"><strong class="jm io"> <em class="mi">剔除异常值</em> </strong>:假设你的输入输出变量没有噪声。因此，需要在数据清理阶段去除异常值。</li><li id="edc4" class="mq mr in jm b jn mz jr na jv nb jz nc kd nd kh nh mw mx my bi translated"><strong class="jm io"> <em class="mi">去除共线性</em> </strong>:当你有高度相关的输入变量时，它会过度拟合你的数据。</li><li id="a845" class="mq mr in jm b jn mz jr na jv nb jz nc kd nd kh nh mw mx my bi translated"><strong class="jm io"> <em class="mi">高斯分布:</em> </strong>如果你的输入输出变量有高斯分布，线性回归会做出更可靠的预测。</li><li id="713f" class="mq mr in jm b jn mz jr na jv nb jz nc kd nd kh nh mw mx my bi translated"><strong class="jm io"> <em class="mi">重新调整输入:</em> </strong>如果使用标准化或规范化来重新调整输入变量，通常会做出更可靠的预测。</li></ol><h1 id="2bb3" class="le lf in bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">相关和线性回归的区别</h1><p id="75c5" class="pw-post-body-paragraph jk jl in jm b jn md jp jq jr me jt ju jv mf jx jy jz mg kb kc kd mh kf kg kh ig bi translated">在理解相关和线性回归这两个术语之间的区别时，经常会出现混淆。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/2327c069cf74f9a97f03ed5324c7cccc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1018/format:webp/0*L7vtojXjUZsw-Q5B.jpg"/></div></figure><h2 id="dbda" class="nj lf in bd lg nk nl dn lk nm nn dp lo jv no np ls jz nq nr lw kd ns nt ma nu bi translated">相互关系</h2><ul class=""><li id="435a" class="mq mr in jm b jn md jr me jv ms jz mt kd mu kh mv mw mx my bi translated">相关性一词是两个词“Co”(在一起)和两个量之间的关系(联系)的组合。</li><li id="d5ee" class="mq mr in jm b jn mz jr na jv nb jz nc kd nd kh mv mw mx my bi translated">这是一种统计技术，表示变量对之间的联系强度。</li><li id="aabd" class="mq mr in jm b jn mz jr na jv nb jz nc kd nd kh mv mw mx my bi translated">相关性可以是正的，也可以是负的。当两个变量同向移动时，即一个变量的增加会导致另一个变量的相应增加，反之亦然，那么这些变量被认为是<em class="mi">正相关</em>。</li><li id="6c07" class="mq mr in jm b jn mz jr na jv nb jz nc kd nd kh mv mw mx my bi translated">相反，当两个变量朝不同的方向移动时，一个变量的增加会导致另一个变量的减少，反之亦然，这种情况被称为<em class="mi">负相关。</em></li><li id="bd0e" class="mq mr in jm b jn mz jr na jv nb jz nc kd nd kh mv mw mx my bi translated">相关性旨在找到一个表示变量之间关系的数值。</li></ul><h2 id="8467" class="nj lf in bd lg nk nl dn lk nm nn dp lo jv no np ls jz nq nr lw kd ns nt ma nu bi translated">线性回归</h2><ul class=""><li id="3957" class="mq mr in jm b jn md jr me jv ms jz mt kd mu kh mv mw mx my bi translated">它是一种统计技术，用于根据两个或多个变量之间的平均数学关系，估计由于一个或多个自变量的变化而导致的度量因变量的变化</li><li id="6e39" class="mq mr in jm b jn mz jr na jv nb jz nc kd nd kh mv mw mx my bi translated">回归描述了自变量与因变量在数字上的关系。</li><li id="0bcb" class="mq mr in jm b jn mz jr na jv nb jz nc kd nd kh mv mw mx my bi translated">回归的目标是根据固定变量的值预测随机变量的值。</li></ul><h1 id="6787" class="le lf in bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated"><strong class="ak">结论</strong></h1><p id="dde3" class="pw-post-body-paragraph jk jl in jm b jn md jp jq jr me jt ju jv mf jx jy jz mg kb kc kd mh kf kg kh ig bi translated">线性回归是机器学习的一个重要组成部分。由于其简单性和重要性，它已被广泛应用于不同的行业。</p><p id="2d00" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">它的一些应用领域是:</p><ol class=""><li id="555d" class="mq mr in jm b jn jo jr js jv ne jz nf kd ng kh nh mw mx my bi translated">企业经常使用线性回归来理解广告支出和收入之间的关系。</li><li id="46bd" class="mq mr in jm b jn mz jr na jv nb jz nc kd nd kh nh mw mx my bi translated">它可用于医学领域，以了解药物剂量和患者血压之间的关系</li><li id="d577" class="mq mr in jm b jn mz jr na jv nb jz nc kd nd kh nh mw mx my bi translated">农业科学家经常使用线性回归来观察降雨量和肥料对水果/蔬菜产量的影响。</li></ol></div><div class="ab cl nv nw hr nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="ig ih ii ij ik"><p id="10ed" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">感谢您的阅读，我希望您发现这篇文章很有见地！</p><p id="3f5d" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">非常欢迎你对这篇文章的想法。请在评论区分享。</p></div></div>    
</body>
</html>