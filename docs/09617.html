<html>
<head>
<title>Mini ML Project — Predicting Spotify Songs’ Popularity. Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">迷你 ML 项目-预测 Spotify 歌曲的受欢迎程度。第二部分</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/mini-ml-project-predicting-spotify-songs-popularity-part-2-1c8f501a109a?source=collection_archive---------5-----------------------#2022-09-01">https://blog.devgenius.io/mini-ml-project-predicting-spotify-songs-popularity-part-2-1c8f501a109a?source=collection_archive---------5-----------------------#2022-09-01</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><figure class="gl gn jl jm jn jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi jk"><img src="../Images/43c394dc019593f47085f29dde6ef995.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s_nNeWGAg_8H0ALEXcSvkw.jpeg"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk translated">*照片由 Pexels 的 Stas Knop 拍摄</figcaption></figure><p id="db09" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io">重述</strong></p><p id="d62d" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">在之前的<a class="ae kx" rel="noopener ugc nofollow" target="_blank" href="/mini-ml-project-predicting-spotify-songs-popularity-part-1-ec1c906b8ff8"> <strong class="kb io">博文</strong> </a>中，我使用了 Spotify 的歌曲数据集，试图根据各种特征预测歌曲的流行度评分。实现了三种模型——线性回归、决策树和随机森林。</p><p id="8503" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">当前的帖子将描述通过使用各种技术，如特征工程、选择和交叉验证，来提高模型准确性的尝试。在每一次改进模型精度的尝试之后，都给出了一个可视化的比较。</p><p id="df8b" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">最后一节详细介绍了实施深度学习模型的贡献以及审查该项目的领域专家的见解。</p><p id="2a70" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">非常感谢机器学习工程师 Erez Tison 和音乐制作人 Gal Petel 的专业建议和见解。</p></div><div class="ab cl ky kz hr la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ig ih ii ij ik"><p id="c819" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io">第一阶段—基线</strong></p><p id="29bb" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">在实施任何进一步的改进之前，我将评估当前模型的预测准确性。这将通过计算均方根误差(RMSE)来进行，该误差计算模型的估计预测和实际受欢迎程度得分之间的差异。</p><p id="7d89" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">较低 RMSE 代表模型对歌曲流行度得分预测准确性。下面概述了 RMSE 公式:</p><figure class="lg lh li lj gt jo gh gi paragraph-image"><div class="gh gi lf"><img src="../Images/e6012a15ad6f44a460d8063a9fda8fdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/0*z62qdPVxnK0rdTmf.jpg"/></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk translated">计算均方根误差的方式</figcaption></figure><p id="3e28" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">下图描述了实施任何更改之前模型的准确性。<strong class="kb io"> <em class="lk">随机森林</em> </strong>模型展示了最低的预测误差。</p><figure class="lg lh li lj gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi ll"><img src="../Images/9477c227ae1cf956a4de998b1275bde5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zuzuk6pMm2IxZq-MfTZ6Mg.png"/></div></div></figure></div><div class="ab cl ky kz hr la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ig ih ii ij ik"><p id="fd50" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io">第二阶段—特征工程</strong></p><p id="bc85" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">第二阶段是测试是否有可能从数据集中提取额外的有意义的数据。以前，我选择忽略一些可能对评估歌曲流行度评分至关重要的分类特征:这些特征是:歌曲的流派和时间签名。</p><p id="190b" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">看看歌曲的类型，可以看到有 22 种不同的类型。这个分类变量可以通过为每个类型创建一个虚拟变量来处理，但是这会导致相当多的特征，这会影响计算时间。因此，我选择将流派分为 6 个主要类别:舞蹈，民间，雷鬼，另类，古典和一般。</p><pre class="lg lh li lj gt lm ln lo lp aw lq bi"><span id="78b4" class="lr ls in ln b gy lt lu l lv lw"><strong class="ln io"><em class="lk"># create dummy variables - genre<br/></em></strong>genre_df=pd.get_dummies(df["genre"])<br/>df = pd.concat([df,genre_df],axis=1)</span><span id="c208" class="lr ls in ln b gy lx lu l lv lw"><strong class="ln io"><em class="lk"># create dummy variables - time signature<br/></em></strong>time_signature_df=pd.get_dummies(df["time_signature"])<br/>df = pd.concat([df,time_signature_df],axis=1)</span><span id="6c6a" class="lr ls in ln b gy lx lu l lv lw"><strong class="ln io"><em class="lk"># remove old variables <br/></em></strong>df.drop(['genre','time_signature'],axis=1, inplace=True)</span></pre><p id="8d80" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">下图显示了使用新功能重新训练模型后模型的得分。可以看出，与基线相比，这三个模型显示了改进:</p><figure class="lg lh li lj gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi ly"><img src="../Images/a8c2dc448f915a2cff9b225adecc8f11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eLD0Tsf-nnw9FQ5FxeygZw.png"/></div></div></figure></div><div class="ab cl ky kz hr la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ig ih ii ij ik"><p id="b89e" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io">阶段 3——特征选择和多元可视化</strong></p><p id="dfc9" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">作为这个阶段的一部分，我检查了基于特征与流行度分数的相关性来减少特征的数量是否会导致模型准确性的提高。为了评估它，我生成了一个热图，可视化了所有特征之间的关联矩阵。</p><pre class="lg lh li lj gt lm ln lo lp aw lq bi"><span id="280b" class="lr ls in ln b gy lt lu l lv lw"><strong class="ln io"># Visualization</strong><br/>correlation_mat = df.corr()<br/>sns.heatmap(correlation_mat)</span></pre><figure class="lg lh li lj gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi lz"><img src="../Images/949e3a29b1d8dfdab84da541f938388f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8O6l7spRTXS6kR_8lxnJ2A.png"/></div></div></figure><p id="8ae4" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">最后，所有相关性的受欢迎程度分数为 0.1 或更低的变量都被删除。这些变量包括:歌曲的时长、调式、节奏和效价。</p><pre class="lg lh li lj gt lm ln lo lp aw lq bi"><span id="0ba7" class="lr ls in ln b gy lt lu l lv lw">df.drop(['duration_s','mode','tempo','valence','5/4','Reggae'],axis=1, inplace=True)</span></pre><p id="281a" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">下图显示了修正模型的准确性:</p><figure class="lg lh li lj gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi ma"><img src="../Images/194f1eaba7f667be85bccf5bef0e1bbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*utVIIHfwqFfJojo-oCvRjQ.png"/></div></div></figure><p id="a86e" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">人们可以证明当前的特征选择没有导致显著的改进。因此，我决定研究一种称为网格搜索的替代方法，这将在下一阶段介绍。</p><p id="eae1" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io">多变量可视化突破！</strong></p><p id="b46b" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">使用成对散点图对 500 首歌曲进行采样和绘图。选择 3 对与受欢迎程度得分相关性最高的变量。</p><pre class="lg lh li lj gt lm ln lo lp aw lq bi"><span id="af14" class="lr ls in ln b gy lt lu l lv lw">sample = df.sample(500)<br/>sns.pairplot(sample[["danceability","loudness", "acousticness", "popularity"]],diag_kind="kde")</span></pre><p id="f383" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">可以看出，歌曲的颜色代表了它们的音乐类型。例如，大多数古典音乐歌曲(粉红色的点)的特点是低可舞性和流行评分。</p><figure class="lg lh li lj gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi mb"><img src="../Images/ad8bf4aba037301a159da0111e74b174.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GrOvENn9JUSiLbPVghx2zw.png"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk translated">成对散点图。圆点的颜色代表歌曲的类型</figcaption></figure></div><div class="ab cl ky kz hr la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ig ih ii ij ik"><p id="49b1" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io">第 4 阶段——网格搜索交叉验证</strong></p><p id="bf77" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">在穷尽了低挂果实后，进行网格搜索交叉验证。标准的交叉验证方法旨在通过将数据分成 K 个集合来防止过度拟合。使用迭代过程，ML 模型在 K-1 个集合上训练，然后在剩余的维持折叠上测试。人们可以认为这是一种更有效的利用数据的方式，因为所有的观察结果都用于训练和测试模型。</p><p id="e7e5" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">与标准交叉验证相比，网格搜索被认为是一种相当先进的方法，因为它利用了超参数优化。这种优化方法评估各种特征的所有可能组合，以便识别最佳组合。为了这篇文章，我应用了网格搜索来训练线性回归模型。</p><pre class="lg lh li lj gt lm ln lo lp aw lq bi"><span id="ede1" class="lr ls in ln b gy lt lu l lv lw">folds = KFold(n_splits = 10, shuffle = True)<br/>hyper_params = [{'n_features_to_select': list(range(0,X.shape[1]))}] <br/>rfe = RFE(model_regression)<br/>model_cv = GridSearchCV(estimator = rfe,<br/>                        param_grid = hyper_params,scoring= 'r2',<br/>                        cv = folds,<br/>                        verbose = 1,<br/>                        return_train_score=True)</span><span id="0a07" class="lr ls in ln b gy lx lu l lv lw"><strong class="ln io"><em class="lk"># fit the model<br/></em></strong>model_cv.fit(X_train, y_train)<br/>cv_results = pd.DataFrame(model_cv.cv_results_)</span><span id="9373" class="lr ls in ln b gy lx lu l lv lw"><strong class="ln io"># visualize the results</strong><br/>plt.figure(figsize=(10,10))<br/>plt.plot(cv_results["param_n_features_to_select"], cv_results["mean_test_score"])<br/>plt.xlabel('number of features')<br/>plt.ylabel('r-squared')<br/>plt.title("Optimal Number of Features")<br/>plt.legend(['test score'], loc='upper left')</span></pre><p id="d1f6" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">格网搜索结果的可视化方式将反映模型在越来越多的要素上的精度提高。很明显，在添加到模型中的第 10 个特征之后有一个平台。</p><figure class="lg lh li lj gt jo gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/d3b2c0af4b12a9d10e28c43760e992c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*lRE72MOp8wy3zrdV3i0nXw.png"/></div></figure><p id="1b17" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">模型的准确性。观察到轻微的改善:</p><figure class="lg lh li lj gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi md"><img src="../Images/a5dc123eadc08300bae208ee63e93693.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cjA2d1FTjX5PihjUNj5kMw.png"/></div></div></figure></div><div class="ab cl ky kz hr la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ig ih ii ij ik"><p id="3db0" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io">第 5 阶段——实施深度学习模型</strong></p><p id="a6ec" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">实现了上述改进后，我对深度学习算法的潜在性能改进感到好奇:</p><pre class="lg lh li lj gt lm ln lo lp aw lq bi"><span id="d0cf" class="lr ls in ln b gy lt lu l lv lw">def build_model():<br/>    model = keras.Sequential([<br/>        layers.Dense(64, activation=tf.nn.relu,<br/>        input_shape= [X.shape[1]]),<br/>        layers.Dense(64, activation = tf.nn.relu),<br/>        layers.Dense(1)<br/>    ])</span><span id="68ed" class="lr ls in ln b gy lx lu l lv lw">optimizer = tf.keras.optimizers.RMSprop(.001)<br/>model.compile(loss="mse",optimizer=optimizer,metrics=['mae','mse']) </span><span id="8aa3" class="lr ls in ln b gy lx lu l lv lw"><em class="lk">return</em> model</span><span id="b346" class="lr ls in ln b gy lx lu l lv lw">model = build_model()</span></pre><p id="46ba" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">随后，模型被训练，并添加了一个早期停止。早期停止是当模型的性能达到设定的特定阈值标准时自动停止模型训练的功能。</p><pre class="lg lh li lj gt lm ln lo lp aw lq bi"><span id="dabf" class="lr ls in ln b gy lt lu l lv lw"><strong class="ln io"># add dots in order to visualize the model's progress</strong><br/>class PrintDot(keras.callbacks.Callback):<br/>    def on_epoch_end(self,epoch,logs):<br/>        if epoch % 100==0: print("")<br/>        print('.',end="")</span><span id="bc47" class="lr ls in ln b gy lx lu l lv lw">EPOCHS = 500</span><span id="1943" class="lr ls in ln b gy lx lu l lv lw"><strong class="ln io"># early stop</strong><br/>early_stop = keras.callbacks.EarlyStopping(monitor='val_loss',patience=10)</span><span id="2ec1" class="lr ls in ln b gy lx lu l lv lw"><strong class="ln io"># fit the model</strong><br/>history = model.fit(X,y, epochs = EPOCHS,validation_split = 0.2, verbose = 0,callbacks = [PrintDot()])</span></pre><p id="50e9" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">下图说明了深度学习模型的预测以及它们与真实受欢迎程度分数的距离。直线下方的点代表其流行度被高估的歌曲。</p><figure class="lg lh li lj gt jo gh gi paragraph-image"><div class="gh gi me"><img src="../Images/d995dc3488223c36a89757f29c8aeb04.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/1*_SxpZly8YQZEckG7EZOVjg.png"/></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk translated">深度学习模型的预测与地面事实的比较</figcaption></figure><p id="71fa" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">深度学习 RMSE 与其他模型的比较:</p><figure class="lg lh li lj gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi md"><img src="../Images/96a0fa933b48aeb861cb2792feb51037.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YEzkb0kjHBzwR-WLE1NeIw.png"/></div></div></figure></div><div class="ab cl ky kz hr la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ig ih ii ij ik"><p id="4683" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io">领域专家评审</strong></p><figure class="lg lh li lj gt jo gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/2662faa8a32599a76b36d8d41f0a83f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/1*fiOwJu0te8cfaFPfeCH8OQ.png"/></div></figure><p id="8dfd" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">获得成功的数据科学项目的一个关键方面是理解我们工作的环境。我们可能倾向于过于关注优化我们的模型，而忽略了我们旨在实现的真正意义。</p><p id="32fc" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">最终，我们训练的 ML 模型对所表示的数据的真实含义视而不见，并且在这个过程中领域专家的参与非常重要。领域专家可以监控、解释和提供他或她的关于在训练过程中包括或排除的特性的意见。</p><p id="3b91" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">我很幸运地认识了 Gal Petel，她是一位才华横溢的音乐制作人。我感兴趣的是他对歌曲流行原因的见解，以及我添加到模型中的功能是否真的相关。</p><p id="2fda" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">根据 Gal 的说法，尽管给定的特征似乎是相关的，但是有一些特征可能有助于模型的准确性并且非常有趣，下面是一些例子:</p><p id="60fd" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">(1)这首歌有没有钩？一个音乐元素通常结合了我们无法从头脑中取出的旋律、歌词和节奏。</p><p id="c778" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">(2)歌曲结构——是经典的韵文合唱结构还是比较复杂的？</p><p id="8f1f" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">(3)歌曲的演唱者——是乐队、女歌手还是男歌手等。</p><p id="072c" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">(4)是翻唱的歌吗？</p><figure class="lg lh li lj gt jo"><div class="bz fp l di"><div class="mg mh l"/></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk translated">我所知道的最好的音乐挂钩之一</figcaption></figure><p id="9a0c" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">这种洞察力使我明白，真正有趣和有意义的不一定是财政歌曲的特点，而是歌曲的内容，这反过来又使它独特和流行。尽管一些建议的特征提取和集成起来更复杂，但是在分析过程中考虑它们仍然是有益的</p><p id="eda0" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io">结论</strong></p><p id="c9b3" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">在这篇文章中，我试图描述实现的各种改进。主要的收获是，虽然 ML 模型可以很容易地被训练，但提高它的性能是一项具有挑战性的任务。</p><p id="f194" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io"> <em class="lk">参考文献</em> </strong></p><p id="0500" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">深度学习实现—<a class="ae kx" href="https://www.youtube.com/watch?v=-vHQub0NXI4" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=-vHQub0NXI4</a></p></div></div>    
</body>
</html>