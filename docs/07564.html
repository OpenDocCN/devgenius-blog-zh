<html>
<head>
<title>Simple AI Face and emotion Recognition With React</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">简单的人工智能人脸和情感识别与反应</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/simple-ai-face-and-emotion-recognition-with-react-da2921e6075e?source=collection_archive---------0-----------------------#2022-04-06">https://blog.devgenius.io/simple-ai-face-and-emotion-recognition-with-react-da2921e6075e?source=collection_archive---------0-----------------------#2022-04-06</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><figure class="im in gp gr io ip gh gi paragraph-image"><div role="button" tabindex="0" class="iq ir di is bf it"><div class="gh gi il"><img src="../Images/853bc0edba13bdbf00d53f6e79cd2cb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x1JZIt-6lSDI5UPjP7Hdxw.jpeg"/></div></div></figure><div class=""/><p id="2aa0" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">你喜欢艾吗？因为我确实知道。今天，你将使用人工智能和面部识别来通过网络摄像头实时确定你的情绪。</p><p id="f2a3" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">为了完成这个人脸识别，您将使用一个名为<a class="ae kt" href="https://www.npmjs.com/package/face-api.js" rel="noopener ugc nofollow" target="_blank"> face-api.js </a>的库，它是 tensor-flow 的包装器，是目前最流行的机器学习库之一(截至本文发表时)。在浏览器中设置和运行它真的很容易。</p><p id="400f" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">这是本文 GitHub 库的<a class="ae kt" href="https://github.com/Exclusiveideas/ai-face-detection" rel="noopener ugc nofollow" target="_blank">链接。</a></p><p id="3b74" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">当你在我的仓库时，请留下一颗星星✨。</p><h1 id="673b" class="ku kv iy bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">我们开始吧</h1><p id="9bcd" class="pw-post-body-paragraph jv jw iy jx b jy ls ka kb kc lt ke kf kg lu ki kj kk lv km kn ko lw kq kr ks ig bi translated">Bootstrap 一个新的 react 应用程序，比如人工智能-人脸检测</p><p id="e63f" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated"><code class="fe lx ly lz ma b">npx create-react-app ai-face-detection</code></p><p id="fde2" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">运行以下命令，在 react 应用程序中下载<a class="ae kt" href="https://www.npmjs.com/package/face-api.js" rel="noopener ugc nofollow" target="_blank"> face-api.js </a>库</p><pre class="mb mc md me gt mf ma mg mh aw mi bi"><span id="da6c" class="mj kv iy ma b gy mk ml l mm mn">//using npm<br/>npm i face-api.js</span><span id="d1d7" class="mj kv iy ma b gy mo ml l mm mn">//using yarn<br/>yarn add face-api.js</span></pre><p id="1d69" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">这个项目需要的所有模型都可以在我的<a class="ae kt" href="https://github.com/Exclusiveideas/ai-face-detection/tree/main/public/models" rel="noopener ugc nofollow" target="_blank">资源库</a>中找到。</p><p id="bfa1" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">将您从我的<a class="ae kt" href="https://github.com/Exclusiveideas/ai-face-detection/tree/main/public/models" rel="noopener ugc nofollow" target="_blank">存储库</a>获得的模型文件夹放在 react 应用程序的 public 文件夹下。你的<strong class="jx iz"> app 结构</strong>应该是这样的:</p><pre class="mb mc md me gt mf ma mg mh aw mi bi"><span id="cb23" class="mj kv iy ma b gy mk ml l mm mn">AI-FACE-DETECTION<br/>|- public<br/>   |- models<br/>|- src<br/>   |- App.css<br/>   |- App.js<br/>   |- index.css<br/>   |- index.js</span></pre><p id="71bf" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">运行<code class="fe lx ly lz ma b">npm start</code>启动您的应用程序。</p><p id="20af" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">让我们给我们的<strong class="jx iz"> index.css </strong>添加一些样式:</p><pre class="mb mc md me gt mf ma mg mh aw mi bi"><span id="806b" class="mj kv iy ma b gy mk ml l mm mn">body {<br/>  margin: 0;<br/>  padding: 0;<br/>  width: 100vw;<br/>  height: 100vh;<br/>  display: flex;<br/>  justify-content: center;<br/>  align-items: center;<br/>}</span></pre><p id="c407" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">我们的 App.js 文件将是本文的重点。现在在 App 里<strong class="jx iz">。js </strong>，我们要添加一个标题和视频元素。</p><p id="cc6f" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated"><strong class="jx iz"> App.js </strong></p><pre class="mb mc md me gt mf ma mg mh aw mi bi"><span id="f3a2" class="mj kv iy ma b gy mk ml l mm mn">import { useEffect, useRef } from 'react';</span><span id="66c7" class="mj kv iy ma b gy mo ml l mm mn">const App = () =&gt; {<br/>  const videoRef = useRef();</span><span id="5ae5" class="mj kv iy ma b gy mo ml l mm mn">return (<br/>    &lt;div&gt;<br/>       &lt;video crossOrigin='anonymous' ref={videoRef} autoPlay&gt;  <br/>       &lt;/video&gt;<br/>    &lt;/div&gt;<br/>  )<br/>};</span><span id="5927" class="mj kv iy ma b gy mo ml l mm mn">export default App;</span></pre><p id="d503" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">我添加了一个<em class="mp"> useRef </em>钩子来跟踪视频流。我们需要访问网络摄像头并输出视频，为此，我们将创建一个函数<em class="mp"> startVideo </em>，它将包含访问网络摄像头并将流存储在<em class="mp"> videoRef、</em>中的语法</p><p id="7568" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated"><strong class="jx iz"> App.js </strong></p><pre class="mb mc md me gt mf ma mg mh aw mi bi"><span id="c29e" class="mj kv iy ma b gy mk ml l mm mn">useEffect(() =&gt; {<br/>  startVideo();<br/>}, []);</span><span id="0393" class="mj kv iy ma b gy mo ml l mm mn">const startVideo = () =&gt; {<br/>   navigator.mediaDevices.getUserMedia({ video: true    })<br/>   .then((currentStream) =&gt; {<br/>           videoRef.current.srcObject = currentStream;<br/>        }).catch((err) =&gt; {<br/>           console.error(err)<br/>   });<br/>}</span></pre><p id="9447" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated"><em class="mp">useeffecthhook</em>在应用安装后运行，并通过调用<em class="mp"> startVideo </em>函数初始化视频流。现在，如果你保存，你应该可以在浏览器中看到你的摄像头输出。</p><p id="8e03" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">现在让我们开始使用我们的 face-api.js 库。</p><p id="5f66" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">将 face-api.js 库导入到 index.js 中，并从 models 文件夹中加载模型</p><p id="20b9" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated"><strong class="jx iz"> App.js </strong></p><pre class="mb mc md me gt mf ma mg mh aw mi bi"><span id="b5ea" class="mj kv iy ma b gy mk ml l mm mn">useEffect(() =&gt; {<br/>   startVideo();</span><span id="eff5" class="mj kv iy ma b gy mo ml l mm mn">   videoRef &amp;&amp; loadModels();<br/>}, []);</span><span id="f675" class="mj kv iy ma b gy mo ml l mm mn">const loadModels = () =&gt; {<br/>   Promise.all([<br/>     faceapi.nets.tinyFaceDetector.loadFromUri('/models'),<br/>     faceapi.nets.faceLandmark68Net.loadFromUri('/models'),<br/>     faceapi.nets.faceRecognitionNet.loadFromUri('/models'),<br/>     faceapi.nets.faceExpressionNet.loadFromUri('/models'),<br/>   ]).then(() =&gt; {<br/>    faceDetection();<br/>   })<br/>};</span><span id="2162" class="mj kv iy ma b gy mo ml l mm mn">const faceDetection = () =&gt; {<br/>   const detections = await faceapi.detectAllFaces <br/>       (videoRef.current, new faceapi.TinyFaceDetectorOptions())<br/>        .withFaceLandmarks()<br/>        .withFaceExpressions();<br/>   console.log(detections);<br/>}</span></pre><p id="207a" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">好吧，让我解释一下，</p><ul class=""><li id="0e35" class="mq mr iy jx b jy jz kc kd kg ms kk mt ko mu ks mv mw mx my bi translated">在添加到<em class="mp"> useEffect </em>钩子的代码片段中，</li></ul><p id="b430" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated"><code class="fe lx ly lz ma b">videoRef &amp;&amp; loadModels();</code></p><p id="639e" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">只有当网络摄像头被加载时，我们才调用<em class="mp"> loadModels </em>函数</p><ul class=""><li id="b4b4" class="mq mr iy jx b jy jz kc kd kg ms kk mt ko mu ks mv mw mx my bi translated"><em class="mp"> loadModels </em>函数使用一个<em class="mp"> Promise.all 从我们的模型文件夹中加载所有需要的模型(用于运行多个承诺并返回一个包含输入承诺结果的承诺)。</em></li><li id="b8d7" class="mq mr iy jx b jy mz kc na kg nb kk nc ko nd ks mv mw mx my bi translated">加载模型后，它调用<em class="mp"> faceDetection </em>函数，该函数检测摄像头视图中的任何人脸，并将其检测值打印到控制台。</li></ul><p id="a2bf" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">现在，如果您将您的脸放在网络摄像头视图中，您应该会在浏览器控制台中看到一个日志，其中包含有关检测到的脸的信息。</p><p id="3729" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">注意:为了正确检测，你应该在一个光线充足的环境中。</p><p id="bda8" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">为了在视频输出中显示检测结果，我们将在 App.js 中添加一个 canvas 元素，以跟踪检测到的人脸的位置，并创建一个<em class="mp"> canvasRef </em>来跟踪画布。</p><p id="0288" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated"><strong class="jx iz"> App.js </strong></p><pre class="mb mc md me gt mf ma mg mh aw mi bi"><span id="229c" class="mj kv iy ma b gy mk ml l mm mn">const canvasRef = useRef();</span><span id="0187" class="mj kv iy ma b gy mo ml l mm mn">return (<br/>  &lt;div  className="app"&gt;<br/>    &lt;h1&gt; AI FACE DETECTION&lt;/h1&gt;<br/>    &lt;div className='app__video'&gt; <br/>       &lt;video crossOrigin='anonymous' ref={videoRef} autoPlay &gt;<br/>       &lt;/video&gt;<br/>    &lt;/div&gt; <br/>    &lt;canvas ref={canvasRef} width="940" height="650"<br/>     className='app__canvas' /&gt;<br/>&lt;/div&gt;<br/>);</span></pre><p id="4620" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">对于位置的样式，我们将编辑我们的 App.css</p><p id="b51c" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated"><strong class="jx iz"> App.css </strong></p><pre class="mb mc md me gt mf ma mg mh aw mi bi"><span id="b11b" class="mj kv iy ma b gy mk ml l mm mn">.app {<br/>   display: flex;<br/>   width: 100vw; <br/>   height: 100vh;<br/>   flex-direction: column;<br/>   align-items: center;<br/>   justify-content: space-between;<br/>}</span><span id="ada3" class="mj kv iy ma b gy mo ml l mm mn">.app__video {<br/>   display: flex;<br/>   align-items: center;<br/>}</span><span id="8fd6" class="mj kv iy ma b gy mo ml l mm mn">.app__canvas {<br/>   position: absolute;<br/>   top: 100px;<br/>}</span></pre><p id="33c9" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">现在，为了将来自检测的数据传输到画布上，我们将把我们的<em class="mp"> faceDetection </em>函数编辑成:</p><p id="dd02" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated"><strong class="jx iz"> App.js </strong></p><pre class="mb mc md me gt mf ma mg mh aw mi bi"><span id="ecb6" class="mj kv iy ma b gy mk ml l mm mn">const faceDetection = async () =&gt; {<br/>   setInterval(async() =&gt; {<br/>   const detections = await faceapi.detectAllFaces<br/>         (videoRef.current,new faceapi.TinyFaceDetectorOptions())<br/>          .withFaceLandmarks()<br/>          .withFaceExpressions();</span><span id="9d80" class="mj kv iy ma b gy mo ml l mm mn">canvasRef.current.innerHtml = faceapi.createCanvasFromMedia<br/>                              (videoRef.current);</span><span id="0dc9" class="mj kv iy ma b gy mo ml l mm mn">faceapi.matchDimensions(canvasRef.current, {<br/>  width: 940,<br/>  height: 650,<br/>})</span><span id="3230" class="mj kv iy ma b gy mo ml l mm mn">const resized = faceapi.resizeResults(detections, {<br/>  width: 940,<br/>  height: 650,<br/>});</span><span id="a7b5" class="mj kv iy ma b gy mo ml l mm mn">// to draw the detection onto the detected face i.e the box<br/>faceapi.draw.drawDetections(canvasRef.current, resized);</span><span id="2eb9" class="mj kv iy ma b gy mo ml l mm mn">//to draw the the points onto the detected face<br/>faceapi.draw.drawFaceLandmarks(canvasRef.current, resized);</span><span id="8d5f" class="mj kv iy ma b gy mo ml l mm mn">//to analyze and output the current expression by the detected face<br/>faceapi.draw.drawFaceExpressions(canvasRef.current, resized);</span><span id="5cfd" class="mj kv iy ma b gy mo ml l mm mn">}, 1000);</span><span id="be1b" class="mj kv iy ma b gy mo ml l mm mn">};</span></pre><p id="a98a" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">这样我们就完成了人脸和表情识别 app，你可以在<strong class="jx iz"> <em class="mp"> App.css </em> </strong>文件中修改画布的位置。</p><p id="c516" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">所以我们完整的<strong class="jx iz"> App.js </strong>文件应该是这样的:</p><pre class="mb mc md me gt mf ma mg mh aw mi bi"><span id="ca04" class="mj kv iy ma b gy mk ml l mm mn">import { useRef, useEffect } from 'react';<br/>import './App.css';<br/>import * as faceapi from "face-api.js";</span><span id="eb3d" class="mj kv iy ma b gy mo ml l mm mn">function App() {<br/>  const videoRef = useRef();<br/>  const canvasRef = useRef();<br/>  <br/>  useEffect(() =&gt; {<br/>    startVideo();</span><span id="169a" class="mj kv iy ma b gy mo ml l mm mn">    videoRef &amp;&amp; loadModels();<br/>}, []);</span><span id="ffe9" class="mj kv iy ma b gy mo ml l mm mn">  const loadModels = () =&gt; {<br/>     Promise.all([<br/>         faceapi.nets.tinyFaceDetector.loadFromUri('/models'),<br/>         faceapi.nets.faceLandmark68Net.loadFromUri('/models'),<br/>         faceapi.nets.faceRecognitionNet.loadFromUri('/models'),<br/>         faceapi.nets.faceExpressionNet.loadFromUri('/models'),<br/>     ]).then(() =&gt; {<br/>         faceDetection();<br/>        })<br/>};</span><span id="8666" class="mj kv iy ma b gy mo ml l mm mn">  const startVideo = () =&gt; {<br/>     navigator.mediaDevices.getUserMedia({ video: true })<br/>     .then((currentStream) =&gt; {<br/>          videoRef.current.srcObject = currentStream;<br/>      }).catch((err) =&gt; {<br/>         console.error(err)<br/>         });<br/>}</span><span id="da3c" class="mj kv iy ma b gy mo ml l mm mn">  const faceDetection = async () =&gt; {<br/>    setInterval(async() =&gt; {<br/>      const detections = await faceapi.detectAllFaces<br/>           (videoRef.current, new faceapi.TinyFaceDetectorOptions())<br/>           .withFaceLandmarks().withFaceExpressions();</span><span id="9e19" class="mj kv iy ma b gy mo ml l mm mn">canvasRef.current.innerHtml = faceapi.<br/>     createCanvasFromMedia(videoRef.current);</span><span id="3d17" class="mj kv iy ma b gy mo ml l mm mn">faceapi.matchDimensions(canvasRef.current, {<br/>    width: 940,<br/>    height: 650,<br/>})</span><span id="a8d8" class="mj kv iy ma b gy mo ml l mm mn">const resized = faceapi.resizeResults(detections, {<br/>    width: 940,<br/>    height: 650,<br/>});</span><span id="794d" class="mj kv iy ma b gy mo ml l mm mn">// to draw the detection onto the detected face i.e the box<br/>faceapi.draw.drawDetections(canvasRef.current, resized);</span><span id="0401" class="mj kv iy ma b gy mo ml l mm mn">//to draw the the points onto the detected face<br/>faceapi.draw.drawFaceLandmarks(canvasRef.current, resized);</span><span id="5966" class="mj kv iy ma b gy mo ml l mm mn">//to analyze and output the current expression by the detected face<br/>faceapi.draw.drawFaceExpressions(canvasRef.current, resized);</span><span id="4a47" class="mj kv iy ma b gy mo ml l mm mn">}, 1000)</span><span id="05fa" class="mj kv iy ma b gy mo ml l mm mn">}</span><span id="5d03" class="mj kv iy ma b gy mo ml l mm mn">return (<br/>  &lt;div  className="app"&gt;<br/>     &lt;h1&gt; AI FACE DETECTION&lt;/h1&gt;<br/>     &lt;div className='app__video'&gt;<br/>        &lt;video crossOrigin='anonymous' ref={videoRef} autoPlay <br/>        &lt;/video&gt;<br/>     &lt;/div&gt;<br/>     &lt;canvas ref={canvasRef} width="940" height="650"<br/>     className='app__canvas' /&gt;<br/> &lt;/div&gt;<br/>);<br/>}</span><span id="e19d" class="mj kv iy ma b gy mo ml l mm mn">export default App;</span></pre><h1 id="987c" class="ku kv iy bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">结论</h1><p id="2a1d" class="pw-post-body-paragraph jv jw iy jx b jy ls ka kb kc lt ke kf kg lu ki kj kk lv km kn ko lw kq kr ks ig bi translated">在本文中，我们看到了使用<a class="ae kt" href="https://www.npmjs.com/package/face-api.js" rel="noopener ugc nofollow" target="_blank"> face-api.js </a>库来设置人脸识别应用程序是多么容易。您可以通过阅读它们的文档来选择实现更多的特性。</p><p id="2ea8" class="pw-post-body-paragraph jv jw iy jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">感谢阅读，别忘了鼓掌👏并在我的仓库里留下一颗✨星。</p></div></div>    
</body>
</html>