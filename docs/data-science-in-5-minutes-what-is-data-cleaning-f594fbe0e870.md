# 5 分钟数据科学:什么是数据清洗？

> 原文：<https://blog.devgenius.io/data-science-in-5-minutes-what-is-data-cleaning-f594fbe0e870?source=collection_archive---------4----------------------->

![](img/c1d1c87e775e49e83d538e86f2ae758a.png)

在处理数据时，你的分析和洞察力取决于你使用的数据。如果您使用脏数据执行数据分析，您的组织将无法使用这些数据做出高效且有效的决策。数据清理是数据管理的**关键部分，它允许您验证您拥有高质量的数据。**

数据清理不仅仅包括修复拼写或语法错误。这是数据科学分析的一个**基本方面**和一个**重要的机器学习技术**。今天，我们将了解有关数据清理的更多信息、其好处、您的数据可能出现的问题以及您的后续学习步骤。

**我们将介绍**:

*   什么是数据科学清洗？
*   数据清理的好处和步骤
*   你学习的下一步

# 什么是数据科学清洗？

数据清理是纠正或删除数据集中不正确、不完整或重复数据的重要**过程。数据清理**应该是你工作流程**的第一步。当处理大型数据集和组合各种数据源时，很有可能会重复或错误标注数据。如果你有不准确或不正确的数据，它将失去其质量，你的算法和结果变得不可靠。**

数据清理**不同于数据转换，因为您实际上是删除不属于您的数据集**的数据。通过数据转换，您可以将数据转换为不同的格式或结构。数据转换过程有时被称为*数据争夺*或*数据争夺*。数据清理过程是我们今天重点关注的内容。

*那么，我如何知道我的数据是否干净？*

要确定数据质量，您可以研究其特性，并根据对您的组织和项目来说什么是重要的来权衡它们。**在评估您的数据时，有五个主要特征需要寻找**:

1.  **一致性**:你的数据在你的数据集之间是一致的吗？
2.  **准确性**:你的数据是否接近真实值？
3.  完整性:你的数据包括所有需要的信息吗？
4.  **有效性**:您的数据是否符合业务规则和/或限制？
5.  一致性:你的数据是用一致的度量单位指定的吗？现在我们知道了如何识别高质量的数据，让我们更深入地了解数据科学清理的过程，为什么它很重要，以及如何有效地进行。

# 数据清理的好处和步骤

让我们讨论一些清理步骤，您可以采取这些步骤来确保处理高质量的数据。数据科学家花费大量时间清理数据，因为一旦他们的数据清理干净，执行数据分析和构建模型就容易多了。

首先，我们将讨论您在使用数据时可能遇到的一些问题，以及如何解决这些问题。

# 处理缺失数据

大型数据集通常会缺少一些值。也许记录数据的人忘记输入它们，或者也许他们在数据收集过程的后期才开始收集那些丢失的数据变量。无论如何，在处理数据集之前，应该对缺失数据进行管理。

# 过滤不需要的异常值

离群值包含关于数据的重要信息，但同时会将您的注意力从主组上转移开。检查有无异常值的数据是一个好主意。如果您发现您想要使用它们，请确保选择一个能够处理异常值的健壮方法。如果你决定不使用它们，你可以放弃它们。

您还可以使用以下方法过滤掉不需要的异常值:

```
# Get the 98th and 2nd percentile as the limits of our outliersupper_limit = np.percentile(train_df.logerror.values, 98)lower_limit = np.percentile(train_df.logerror.values, 2) # Filter the outliers from the dataframedata[‘target’].loc[train_df[‘target’]>upper_limit] = upper_limitdata[‘target’].loc[train_df[‘target’]<lower_limit] = lower_limit
```

# 标准化您的数据

您的特征变量中的数据应该标准化。这使得数据的检查和建模变得更加容易。例如，让我们看看“动物”变量中的两个值，我们称之为“狗”和“猫”。如果您收集了数据，您可能会收到您没有预料到的不同数据值，例如:

*   狗、猫(全部大写输入)
*   狗、猫(输入时首字母大写)
*   推车自由度(作为错别字输入)

如果我们将特征变量转换成分类浮点数，我们不会得到我们想要的 0 和 1 值，我们会得到类似这样的结果:

```
{'dog': 0,'cat': 1,'DOG': 2,'CAT': 3,'Dog': 4,'Cat': 5,'dof': 6,'cart': 7}
```

为了有效地处理大小写问题并帮助标准化您的数据，您可以这样做:

```
# Make the string lowercases.lower() # Make the first letter capitalizeds.capitalize()
```

如果有打字错误的问题，您可以使用映射功能:

```
value_map = {'dof': 'dog', 'cart': 'cat'} pd_dataframe['animals'].map(value_map)
```

> ***注:*** *另一种处理错别字的方法是在 Microsoft Excel 中运行拼写和语法检查。*

# 移除不需要的观察

有时候你可能会有一些不相关的数据应该被删除。假设你想预测一本杂志的销量。您正在检查过去一年从亚马逊订购的杂志数据集，您注意到一个名为“font-type”的特征变量，它记录了书中使用的字体。

这是一个非常不相关的功能，它可能不会帮助你预测一本杂志的销量。这是一个可以像这样删除的功能:

```
df.drop('feature_variable_name', axis=1)
```

移除那些不需要的观察不仅使数据探索更容易，而且有助于训练你的机器学习模型。

# 丢弃脏数据和重复数据

脏数据包括任何错误的或不应该存在的数据点。当数据点在数据集中重复时，就会出现重复。如果你有很多副本，它会影响你的机器学习模型的训练。

要处理脏数据，您可以删除它们或者使用替换(比如将不正确的数据点转换成正确的数据点)。要处理重复问题，您可以将它们从数据中删除。

# 删除空白数据

你显然不能用空白数据进行数据分析。空白数据对分析师来说是一个主要问题，因为它削弱了数据的质量。理想情况下，您应该在数据收集阶段删除空白数据，但是您也可以编写一个程序来完成这项工作。

# 消除空白

在许多数据结构中，空白是一个很小但很常见的问题。修剪功能将帮助您消除空白。

> ***注****:TRIM 函数归类在 Excel 文本函数下。它有助于删除数据中多余的空格。可以使用* `*=TRIM(text)*` *公式。*

# 修复转换错误

有时，在导出数据时，数值会被转换为文本。价值方法是解决这一问题的好方法。

数据清理过程听起来很耗时，但它使您的数据**更容易与**一起工作，并允许您**充分利用您的数据**。拥有干净的数据可以提高您的效率，并确保您使用高质量的数据。

**数据清理的一些好处包括**:

*   有一些数据清理工具，如 DemandTools 或 Oracle Enterprise Data Quality，可以帮助您提高效率并加快决策过程。
*   您可以更好地监控您的错误，以帮助您消除不正确、损坏或不一致的数据。
*   总的来说，你会犯更少的错误。
*   您可以映射不同的函数以及您的数据应该做什么。
*   跨多个数据源删除错误很容易。
*   等等。

# 你学习的下一步

数据清理是您组织的数据管理工作流的重要组成部分。现在，您已经了解了这个过程的更多信息，您已经准备好学习机器学习中更高级的概念。以下是一些值得学习的推荐内容:

*   图像识别
*   自然语言处理
*   应用机器学习
*   等等。

*快乐学习！*