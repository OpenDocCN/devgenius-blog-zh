<html>
<head>
<title>Spark Cluster with Virtual Box, Anaconda and Jupyter — The guide</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">火花集群与虚拟盒，蟒蛇和 Jupyter 指南</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/spark-cluster-with-virtual-box-anaconda-and-jupyter-the-guide-dd0007cd5895?source=collection_archive---------3-----------------------#2022-11-03">https://blog.devgenius.io/spark-cluster-with-virtual-box-anaconda-and-jupyter-the-guide-dd0007cd5895?source=collection_archive---------3-----------------------#2022-11-03</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><figure class="gl gn jl jm jn jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi jk"><img src="../Images/957436b606a00c261a8b470543c348af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f7PNUp19qvhlL1dhHrYNyw.png"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk translated">—火花—</figcaption></figure><h1 id="511c" class="jz ka in bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">放弃</h1><blockquote class="kx ky kz"><p id="4991" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated">我不会更新这个博客，相反，我的 github 上的文档会随着我的任何改变而更新</p></blockquote><p id="675b" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated"><a class="ae mc" href="https://github.com/produdez/sparkimental" rel="noopener ugc nofollow" target="_blank"> Github </a> = &gt;转至<code class="fe md me mf mg b">docs/spark-cluster-setup.md</code>🍡</p><p id="b208" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated"><strong class="ld io"> <em class="lc">(我也认为在 markdown 上阅读更好，因为 medium 缺少这么多基本的编辑布局功能)</em> </strong></p><h1 id="165c" class="jz ka in bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">序</h1><p id="1a57" class="pw-post-body-paragraph la lb in ld b le mh lg lh li mi lk ll lz mj lo lp ma mk ls lt mb ml lw lx ly ig bi translated">如果您在进入数据科学的旅程中遇到过<code class="fe md me mf mg b">Spark</code>，那么当您第一次遇到它时，可能会有一些基本问题挥之不去，例如:</p><ul class=""><li id="bf18" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">如何设置<code class="fe md me mf mg b">Spark</code>(本地机还是虚拟机？)(集群还是只是本地进程？)</li><li id="fd24" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly mr ms mt mu bi translated">如何在上面运行代码？直接？通过 python 脚本？<code class="fe md me mf mg b">jupyter</code>？</li><li id="6af2" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly mr ms mt mu bi translated">哪个版本适用于哪个版本？<code class="fe md me mf mg b">Java</code> <code class="fe md me mf mg b">Python</code> <code class="fe md me mf mg b">Spark</code> <code class="fe md me mf mg b">Scala</code></li><li id="08e4" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly mr ms mt mu bi translated">这整件事为什么没有一个超级详细的教程？大多数教程</li></ul><ol class=""><li id="58d7" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly na ms mt mu bi translated">只要确保 Spark 能够运行(本地或分布式都没关系)</li><li id="4eaa" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly na ms mt mu bi translated">安装 Spark 集群，但没有展示如何在其上运行代码</li><li id="0815" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly na ms mt mu bi translated">不包括如何与 Spark 用户界面交互(历史、主用户界面、从用户界面、作业监控用户界面等)</li><li id="6f2f" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly na ms mt mu bi translated">没有 python 虚拟环境设置来管理 Spark 的 python 包</li><li id="431b" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly na ms mt mu bi translated">没有提到如何充分利用虚拟机(如<code class="fe md me mf mg b">VirtualBox</code>虚拟机)来帮助我们的开发过程</li></ol></div><div class="ab cl nb nc hr nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="ig ih ii ij ik"><p id="3a66" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">所以在这篇博文中，在为我的分布式数据处理任务进行研究时，我已经<em class="lc">(尽我最大的能力)</em>记录了我是如何</p><ol class=""><li id="aa23" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly na ms mt mu bi translated">在由虚拟机箱管理的虚拟机上设置我的 Spark 集群</li><li id="3110" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly na ms mt mu bi translated">使用 Anaconda 设置 python 环境(虚拟环境)来管理这些虚拟机上的 python 包</li><li id="cf70" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly na ms mt mu bi translated">运行/提交 python 代码到我正在运行 spark 集群<em class="lc">(我们不想要任何本地进程 Spark) </em></li><li id="cdfe" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly na ms mt mu bi translated">解决我一路上遇到的所有小问题/陷阱</li></ol><blockquote class="kx ky kz"><p id="c97e" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated"><em class="in">本指南旨在汇集我对该主题的所有研究参考资料，同时也旨在完全避免被愚弄🐪像我这样的人🙈</em></p></blockquote><p id="efeb" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated"><em class="lc">所以请原谅我的冗长的帖子📣我们走吧👟🪜</em></p><h1 id="d6e7" class="jz ka in bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">目录</h1><p id="7b7b" class="pw-post-body-paragraph la lb in ld b le mh lg lh li mi lk ll lz mj lo lp ma mk ls lt mb ml lw lx ly ig bi translated"><a class="ae mc" href="#165c" rel="noopener ugc nofollow">前言</a> <br/> <a class="ae mc" href="#8aba" rel="noopener ugc nofollow">虚框</a> <br/> <a class="ae mc" href="#b09e" rel="noopener ugc nofollow">创建基础 Linux </a> <br/> <a class="ae mc" href="#0761" rel="noopener ugc nofollow"> Linux 设置</a> <br/> ∘ <a class="ae mc" href="#6e30" rel="noopener ugc nofollow">规格</a> <br/> ∘ <a class="ae mc" href="#5ece" rel="noopener ugc nofollow">步骤</a> <br/> ∘ <a class="ae mc" href="#3b05" rel="noopener ugc nofollow">我们在哪里</a> <br/> ∘ <a class="ae mc" href="#fdc7" rel="noopener ugc nofollow">为什么？</a> <br/> <a class="ae mc" href="#cef6" rel="noopener ugc nofollow">安装火花</a> <br/> ∘ <a class="ae mc" href="#34b3" rel="noopener ugc nofollow">步骤</a> <br/> ∘ <a class="ae mc" href="#0ea6" rel="noopener ugc nofollow">进度如何</a> <br/> <a class="ae mc" href="#827c" rel="noopener ugc nofollow">新节点</a> <br/> ∘ <a class="ae mc" href="#024a" rel="noopener ugc nofollow">克隆</a> <br/> ∘ <a class="ae mc" href="#aad7" rel="noopener ugc nofollow">重命名机器</a> <br/> ∘ <a class="ae mc" href="#cee9" rel="noopener ugc nofollow">联网</a> <br/> <a class="ae mc" href="#90e4" rel="noopener ugc nofollow">从设置</a> <br/> <a class="ae mc" href="#58d0" rel="noopener ugc nofollow">主设置</a> <br/></p><h1 id="8aba" class="jz ka in bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">虚拟盒子</h1><blockquote class="kx ky kz"><p id="f90f" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated"><em class="in">虚拟机管理器</em></p></blockquote><ul class=""><li id="e1e3" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">6.1.38(最稳定的版本)(⁉️不要安装 7.0 以上，因为它有很多错误和不稳定)</li></ul><p id="2ae3" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated"><a class="ae mc" href="https://download.virtualbox.org/virtualbox/6.1.38/VirtualBox-6.1.38-153438-Win.exe" rel="noopener ugc nofollow" target="_blank">参考</a>，<a class="ae mc" href="https://download.virtualbox.org/virtualbox/6.1.38/VirtualBox-6.1.38-153438-Win.exe" rel="noopener ugc nofollow" target="_blank">下载</a></p><h1 id="b09e" class="jz ka in bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">创建基本 Linux</h1><blockquote class="kx ky kz"><p id="be73" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated"><em class="in">这将是我们的</em> <code class="fe md me mf mg b"><em class="in">building block</em></code> <em class="in">虚拟机，我们将对其进行克隆，然后进一步调整为我们的主节点和工作节点</em></p></blockquote><h1 id="0761" class="jz ka in bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">Linux 设置</h1><h2 id="6e30" class="ni ka in bd kb nj nk dn kf nl nm dp kj lz nn no kn ma np nq kr mb nr ns kv nt bi translated">规范</h2><ul class=""><li id="f90d" class="mm mn in ld b le mh li mi lz nu ma nv mb nw ly mr ms mt mu bi translated">Ubuntu 18.04 LTS ( <a class="ae mc" href="https://releases.ubuntu.com/18.04/" rel="noopener ugc nofollow" target="_blank"> Ref </a>，<a class="ae mc" href="https://releases.ubuntu.com/18.04/ubuntu-18.04.6-desktop-amd64.iso" rel="noopener ugc nofollow" target="_blank">下载 64 位</a>)</li><li id="978e" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly mr ms mt mu bi translated">建议的虚拟机存储大小:20GB (❗You'll 已经为所有基本软件包安装使用了大约 10GB)</li><li id="77a5" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly mr ms mt mu bi translated">RAM/CPU →你的选择，我的选择:<br/> -主节点 2 个 CPU，4GB RAM<br/>-从节点默认(workers)</li></ul><blockquote class="kx ky kz"><p id="1a79" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated">Ram/Cpu 可以很容易地改变以后，所以没什么大不了的！</p></blockquote><h2 id="5ece" class="ni ka in bd kb nj nk dn kf nl nm dp kj lz nn no kn ma np nq kr mb nr ns kv nt bi translated">步伐</h2><blockquote class="kx ky kz"><p id="ac4a" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated"><em class="in">为了方便起见，我将我的 ubuntu 机器名命名为我的虚拟机器名</em></p></blockquote><ol class=""><li id="2108" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly na ms mt mu bi translated">在 virtual box 上运行安装程序，创建一个符合上述规格的新的空虚拟机</li></ol><blockquote class="kx ky kz"><p id="fb8d" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated">注意🗒️:我给这台机器取名<code class="fe md me mf mg b">base-clean</code></p></blockquote><p id="13b1" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated"><a class="ae mc" href="https://medium.com/dfclub/create-a-virtual-machine-on-virtualbox-47e7ce10b21" rel="noopener">详细教程</a>(这个对我来说太简单了，涵盖不了)</p><blockquote class="kx ky kz"><p id="8357" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated"><em class="in">请注意，您应该使用动态分配</em></p></blockquote><p id="0e27" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">2.将虚拟机的网络设置到本地主机</p><ul class=""><li id="251a" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">右键单击机器&gt;设置&gt;网络</li><li id="0e10" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly mr ms mt mu bi translated">确保<code class="fe md me mf mg b">Adapter 2</code>有这些配置(为什么？<a class="ae mc" href="https://serverfault.com/questions/225155/virtualbox-how-to-set-up-networking-so-both-host-and-guest-can-access-internet" rel="noopener ugc nofollow" target="_blank">参考号</a></li></ul><figure class="ny nz oa ob gt jo gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/7e4d34c3aa1775322fc55a5d47d82bc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/0*Ci7uIXsuWNvkyhIj.png"/></div></figure><p id="9c3d" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">3.运行新的虚拟机，选择我们的<code class="fe md me mf mg b">Ubuntu</code> ISO 并开始安装(这一步耗时最长😷)</p><ul class=""><li id="bf89" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">请输入简单的用户名和密码🙏</li><li id="4d40" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly mr ms mt mu bi translated">不需要关心机器名，我们总是可以改变它</li></ul><blockquote class="kx ky kz"><p id="1910" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated">注意🗒️:我的设置的用户名是<code class="fe md me mf mg b">prod</code></p></blockquote><p id="9722" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">4.（⏰可选)更新内核/系统(这可能是一个屏幕 UI 提示)</p><p id="5b06" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">5.（⏰可选)安装<code class="fe md me mf mg b">Guest Addition CD Image</code></p><ul class=""><li id="b482" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">这样我们就可以在主机(<em class="lc">您的 pc) </em>和虚拟机之间使用双向剪贴板</li></ul><p id="a7d2" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated"><em class="lc">下面第 5 步的详细信息</em>🔽</p><p id="486a" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">a)安装光盘</p><figure class="ny nz oa ob gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi oc"><img src="../Images/44cc69bcb9c4bdc35f93a647ea7d14ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*V8caPyJ74nm8KEHB.png"/></div></div></figure><p id="e5e4" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">b)等待安装 CD+弹出安装窗口</p><figure class="ny nz oa ob gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi od"><img src="../Images/ca30d5cdc6156b8352e3df6089dd71b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*kWags1Y-AMdu3vSe.png"/></div></div></figure><p id="b982" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">c)点击运行，等到完成，如果你是绅士，弹出光盘🎩</p><p id="c307" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">d)重新启动虚拟机并确保共享剪贴板正常工作</p><blockquote class="kx ky kz"><p id="72fa" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated">测试前不要忘记选择共享剪贴板选项😉</p></blockquote><figure class="ny nz oa ob gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi oe"><img src="../Images/53999e14efbcb27fdf9cc0a217b175d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gHB8sX3DAzirm0lh.png"/></div></div></figure><p id="75b6" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated"><em class="lc">完成第五步</em></p></div><div class="ab cl nb nc hr nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="ig ih ii ij ik"><p id="1b1a" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">6.（⏰可选)更新包管理器<code class="fe md me mf mg b">apt-get</code></p><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="c9bd" class="ni ka in mg b gy oj ok l ol om">sudo apt-get upgrade</span></pre><p id="3a89" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">7.获取虚拟机的<code class="fe md me mf mg b">ip address</code></p><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="9be3" class="ni ka in mg b gy oj ok l ol om">ip addr</span></pre><blockquote class="kx ky kz"><p id="ca33" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated">前两个 IP 用于互联网连接，应该有第三个 IP 指示我们的主机本地网络中的虚拟机 IP(如果缺少一个条目，请重新检查适配器 2 网络设置)</p></blockquote><figure class="ny nz oa ob gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi oe"><img src="../Images/ba2f646cff3829dfcb303788847b76a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*OB6vApgEXpI1LVu0.png"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk translated">本地网络上虚拟机的 IP</figcaption></figure><p id="bdc6" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">记下本地网络上虚拟机的 IP，以便以后进行配置</p><blockquote class="kx ky kz"><p id="a48b" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated">请注意，🗒️:我的基本清理虚拟机的 IP 地址是 192.168.56.105</p></blockquote><p id="ffd9" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">8.安装<code class="fe md me mf mg b">SSH</code></p><ul class=""><li id="7eec" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">[计] 下载</li></ul><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="35dc" class="ni ka in mg b gy oj ok l ol om">sudo apt-get install openssh-server openssh-client</span></pre><ul class=""><li id="3432" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">用<code class="fe md me mf mg b">ssh-keygen</code>生成密钥</li></ul><blockquote class="kx ky kz"><p id="6088" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated">或者使用<code class="fe md me mf mg b">mkdir ~/.ssh</code>创建<code class="fe md me mf mg b">.ssh</code>文件夹，如果您不希望您的虚拟机在克隆时有重复的 SSH 密钥</p></blockquote><ul class=""><li id="7d02" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">（⏰可选)将主机的 SSH 密钥复制到虚拟机，以便以后快速进行 SSH 访问，而无需每次都重新键入密码</li></ul><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="fab5" class="ni ka in mg b gy oj ok l ol om"># assuming you already have you ssh key generated on your host machine <br/>cat C:\Users\USER\.ssh\id_rsa.pub | ssh prod@192.168.56.105 “cat &gt;&gt; .ssh/authorized_keys”</span></pre><ul class=""><li id="9af5" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">用<code class="fe md me mf mg b">ssh &lt;username&gt;@&lt;ip-addr&gt;</code>测试(不应该询问密码)</li></ul><p id="6635" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">9.安装<code class="fe md me mf mg b">curl</code>(用于以后下载文件)</p><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="42c0" class="ni ka in mg b gy oj ok l ol om">sudo apt-get install curl</span></pre><p id="ff6c" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">10.关闭机器电源，🥂</p><p id="89a0" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">11.克隆当前机器(<code class="fe md me mf mg b">base-clean</code>)作为备份，命名为<code class="fe md me mf mg b">base-installed</code>(用于下一步)</p><blockquote class="kx ky kz"><p id="a03f" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated"><em class="in"> ⚡总是克隆 MAC 地址策略设置为</em> <code class="fe md me mf mg b"><em class="in">Generate new MAC address for all network adapters</em></code> <em class="in">(避免 IP 重复)</em></p></blockquote><h2 id="3b05" class="ni ka in bd kb nj nk dn kf nl nm dp kj lz nn no kn ma np nq kr mb nr ns kv nt bi translated">我们在哪里</h2><p id="b24f" class="pw-post-body-paragraph la lb in ld b le mh lg lh li mi lk ll lz mj lo lp ma mk ls lt mb ml lw lx ly ig bi translated">我们现在有了一个<code class="fe md me mf mg b">base-clean</code> Linux 虚拟机</p><ul class=""><li id="d0ff" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">具有基本的网络设置</li><li id="7fa8" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly mr ms mt mu bi translated">安装并更新了 Ubuntu</li><li id="75e1" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly mr ms mt mu bi translated">没有额外包装的完全清洁状态</li><li id="7460" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly mr ms mt mu bi translated">SSH 设置便于从本地机器的外壳访问</li></ul></div><div class="ab cl nb nc hr nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="ig ih ii ij ik"><h2 id="fdc7" class="ni ka in bd kb nj nk dn kf nl nm dp kj lz nn no kn ma np nq kr mb nr ns kv nt bi translated">为什么？</h2><ul class=""><li id="cb8f" class="mm mn in ld b le mh li mi lz nu ma nv mb nw ly mr ms mt mu bi translated">这种干净的状态有助于回滚，以防我们后面的<code class="fe md me mf mg b">Spark/Python/Java/Scala/…</code>包安装失败💀</li><li id="0047" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly mr ms mt mu bi translated">SSH 设置允许我们稍后在<code class="fe md me mf mg b">headless</code>模式下运行这些机器(没有 UI ),并使用<code class="fe md me mf mg b">ssh</code>从本地机器 shell 中轻松访问它们</li></ul><h1 id="cef6" class="jz ka in bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">安装 Spark</h1><blockquote class="kx ky kz"><p id="f77d" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated"><em class="in">下一步我们将继续在</em> <code class="fe md me mf mg b"><em class="in">base-installed</em></code> <em class="in">虚拟机</em>上安装所需的软件包</p></blockquote><h2 id="34b3" class="ni ka in bd kb nj nk dn kf nl nm dp kj lz nn no kn ma np nq kr mb nr ns kv nt bi translated">步伐</h2><p id="d009" class="pw-post-body-paragraph la lb in ld b le mh lg lh li mi lk ll lz mj lo lp ma mk ls lt mb ml lw lx ly ig bi translated">⚠️:这些步骤需要花费相当多的时间👿</p><blockquote class="kx ky kz"><p id="3bb2" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated"><em class="in"> ⚡应该在正常启动(GUI)模式下运行您新克隆的虚拟机一次，以获取其 IP，然后使用 SSH shell 进行无头运行，以便于管理</em></p></blockquote><ol class=""><li id="d1ab" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly na ms mt mu bi translated">连接到机器<code class="fe md me mf mg b">ssh &lt;username&gt;:&lt;base-installed-VM-IP&gt;</code></li></ol><blockquote class="kx ky kz"><p id="696f" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated">注意🗒️:我的<code class="fe md me mf mg b">base-installed</code>虚拟机的 IP 是<code class="fe md me mf mg b">192.168.56.106</code></p></blockquote><p id="9d73" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">2.Java，Scala</p><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="f7bd" class="ni ka in mg b gy oj ok l ol om">sudo apt install default-jdk scala </span><span id="860d" class="ni ka in mg b gy on ok l ol om"># Verify <br/>java -version; javac -version; scala -version;</span></pre><p id="510e" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">安装的版本应该是</p><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="1b25" class="ni ka in mg b gy oj ok l ol om">openjdk version “11.0.16” 2022–07–19 OpenJDK Runtime Environment (build 11.0.16+8-post-Ubuntu-0ubuntu118.04) OpenJDK 64-Bit Server VM (build 11.0.16+8-post-Ubuntu-0ubuntu118.04, mixed mode, sharing) javac 11.0.16 Scala code runner version 2.11.12 — Copyright 2002–2017, LAMP/EPFL</span></pre><p id="0864" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">3.（⏰可选)Git</p><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="7fd3" class="ni ka in mg b gy oj ok l ol om">sudo apt-get install git </span><span id="1fd0" class="ni ka in mg b gy on ok l ol om">git — version</span></pre><blockquote class="kx ky kz"><p id="e8ec" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated">安装的⚡ Git 应该是 2.17.1，比 2.23 要旧。所以用<code class="fe md me mf mg b">checkout</code>代替<code class="fe md me mf mg b">switch</code> ( <a class="ae mc" href="https://stackoverflow.com/questions/60754571/why-does-git-switch-checkout-not-switch-branch" rel="noopener ugc nofollow" target="_blank">参考</a>)</p></blockquote><p id="0e13" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">4.蟒蛇</p><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="4d02" class="ni ka in mg b gy oj ok l ol om"># download <br/>curl -O <a class="ae mc" href="https://repo.anaconda.com/archive/Anaconda3-2022.10-Linux-x86_64.sh" rel="noopener ugc nofollow" target="_blank">https://repo.anaconda.com/archive/Anaconda3-2022.10-Linux-x86_64.sh</a> </span><span id="b64a" class="ni ka in mg b gy on ok l ol om"># validate download <br/>sha256sum Anaconda3–2022.10-Linux-x86_64.sh </span><span id="9cbb" class="ni ka in mg b gy on ok l ol om"># install (follow the instructions) <br/>bash Anaconda3–2022.10-Linux-x86_64.sh</span></pre><p id="7ed7" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">如果显示以下选项，接受它</p><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="01f7" class="ni ka in mg b gy oj ok l ol om">Do you wish the installer to initialize Anaconda3 by running conda init? </span><span id="5436" class="ni ka in mg b gy on ok l ol om"># Answer yes :v</span></pre><p id="2aa9" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">完成后，用<code class="fe md me mf mg b">source ~/.bashrc</code>重新加载 bash，并确保可以运行<code class="fe md me mf mg b">conda</code>和<code class="fe md me mf mg b">python</code></p><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="5893" class="ni ka in mg b gy oj ok l ol om">which python </span><span id="cb72" class="ni ka in mg b gy on ok l ol om">#should return <br/>/home/prod/anaconda3/bin/python</span></pre><p id="8e70" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">5.Spark ( <a class="ae mc" href="https://www.apache.org/dyn/closer.lua/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz" rel="noopener ugc nofollow" target="_blank">首页</a>，<a class="ae mc" href="https://www.apache.org/dyn/closer.lua/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz" rel="noopener ugc nofollow" target="_blank">下载站点</a>，<a class="ae mc" href="https://dlcdn.apache.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz" rel="noopener ugc nofollow" target="_blank">下载链接</a>)</p><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="545a" class="ni ka in mg b gy oj ok l ol om">curl -O <a class="ae mc" href="https://dlcdn.apache.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz" rel="noopener ugc nofollow" target="_blank">https://dlcdn.apache.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz</a> sha256sum spark-3.3.1-bin-hadoop3.tgz sudo tar xvf spark-3.3.1-bin-hadoop3.tgz</span></pre><blockquote class="kx ky kz"><p id="e5ef" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated">注意🗒️:还记得 SPARK 的安装文件夹，目前<code class="fe md me mf mg b">~/spark-3.3.1-bin-hadoop3/</code></p></blockquote><p id="a52d" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">6.创建 Anaconda 环境(管理我们的 python 包)</p><blockquote class="kx ky kz"><p id="83da" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated">参考额外部分中的“创建<code class="fe md me mf mg b">conda</code>环境”部分</p><p id="d904" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated">注意🗒️:我的<code class="fe md me mf mg b">conda</code>环境被命名为<code class="fe md me mf mg b">sparkimental</code>，它的 python 路径是<code class="fe md me mf mg b">/home/prod/anaconda3/envs/sparkimental/bin/python</code></p></blockquote><p id="5946" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">7.火花☣️的配置环境</p><ul class=""><li id="0b8e" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">打开<code class="fe md me mf mg b">bashrc</code></li></ul><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="8919" class="ni ka in mg b gy oj ok l ol om">sudo nano ~/.bashrc</span></pre><ul class=""><li id="d4b5" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">将这些附加到文件的末尾</li></ul><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="4da8" class="ni ka in mg b gy oj ok l ol om"># 1 <br/>export SPARK_HOME=~/spark-3.3.1-bin-hadoop3 <br/># 2 <br/>export PATH=$PATH:$SPARK_HOME/bin <br/>export PATH=$PATH:$SPARK_HOME/sbin <br/># 3 <br/>export PATH=$PATH:~/anaconda3/bin <br/># 4 <br/>export PATH=$PATH:$JAVA_HOME/jre/bin <br/># 5 <br/>export PYTHONPATH=&lt;path-to-python-binary-in-your-conda-env&gt; #ex: /home/prod/anaconda3/envs/sparkimental/bin/python <br/>export PYSPARK_PYTHON=$PYTHONPATH <br/>export PYSPARK_DRIVER_PYTHON=$PYTHONPATH <br/># 6 optional <br/>conda activate &lt;your-conda-env-name&gt; #ex: sparkimental</span></pre><ul class=""><li id="c336" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">重装猛击<code class="fe md me mf mg b">source ~/.bashrc</code></li></ul><blockquote class="kx ky kz"><p id="5da2" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated"><strong class="ld io">🤔为什么是这些配置？</strong> <code class="fe md me mf mg b"><strong class="ld io">Explanation</strong></code></p></blockquote><p id="7140" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">下面是我对上面每一行的简单解释</p><ol class=""><li id="2bf8" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly na ms mt mu bi translated">这就是我们安装 Spark 的地方</li><li id="bb16" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly na ms mt mu bi translated">添加 Spark 的二进制文件以便于访问</li><li id="4ff6" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly na ms mt mu bi translated">Anaconda 二进制文件</li><li id="aa79" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly na ms mt mu bi translated">JRE 二进制</li><li id="42aa" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly na ms mt mu bi translated">为<code class="fe md me mf mg b">PySpark</code>驱动程序(主)和工作程序(从)设置 python</li></ol><blockquote class="kx ky kz"><p id="0645" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated">❗Very:重要的是，驱动程序的 python 版本与工作程序的版本相同</p></blockquote><p id="6b44" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">6.这是可选的，以确保您想要的<code class="fe md me mf mg b">conda</code>虚拟环境总是在 shell 中被激活</p><p id="be53" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated"><em class="lc">完成第 7 步</em></p></div><div class="ab cl nb nc hr nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="ig ih ii ij ik"><p id="f2e2" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">8.测试火花</p><p id="24db" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">运行下面的一些命令，确保没有遇到错误<br/> <em class="lc">但是可能会有一些警告~ </em></p><ul class=""><li id="ad0a" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated"><code class="fe md me mf mg b">pyspark</code> →确保<code class="fe md me mf mg b">pyspark</code>在<code class="fe md me mf mg b">sparkimental</code>(也就是我们首选的<code class="fe md me mf mg b">conda</code>环境)中使用 python 的匹配版本</li></ul><p id="f53a" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">应该使用<code class="fe md me mf mg b">python=3.10</code>(正如我们在创建 python 环境时配置的那样- <code class="fe md me mf mg b">sparkimental</code>)</p><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="aa84" class="ni ka in mg b gy oj ok l ol om">Using Python version 3.10.6 (main, Oct 24 2022 16:07:47)</span></pre><p id="8650" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">⚠️ Ubuntu 18.04 默认预装的 python 版本是 3.6 Anaconda base python 版本是 3.9<br/>——所以如果这两个版本中的任何一个出现，你的<code class="fe md me mf mg b">.bashrc</code>很可能配置不良<br/>——<em class="lc">参考最后的陷阱部分</em></p><ul class=""><li id="05e6" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated"><code class="fe md me mf mg b">spark-shell</code> →应该没有错误</li><li id="5615" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly mr ms mt mu bi translated">运行集群测试<br/> — <code class="fe md me mf mg b">start-all.sh</code> (⚠️如果有权限错误只需更改文件夹的权限)<br/> —运行<code class="fe md me mf mg b">jps</code>并确保 worker + master 可用</li></ul><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="376a" class="ni ka in mg b gy oj ok l ol om"># Expected output <br/>3907 Jps <br/>3723 Master <br/>3851 Worker</span></pre><ul class=""><li id="fa8c" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">运行示例 python 代码(<a class="ae mc" href="https://stackoverflow.com/questions/25585194/standalone-apache-spark-what-to-put-as-slave-ip-and-port" rel="noopener ugc nofollow" target="_blank"> Ref </a>)</li></ul><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="33a0" class="ni ka in mg b gy oj ok l ol om"># run from anywhere <br/>spark-submit - master spark://base-clean:7077 /home/prod/spark-3.3.1-bin-hadoop3/examples/src/main/python/pi.py 10</span></pre><p id="84cd" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">输出预期为:<br/> — <em class="lc">运行 10 个任务(我们需要 10 个作业)</em></p><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="429d" class="ni ka in mg b gy oj ok l ol om">………… <br/>22/11/01 23:13:57 INFO TaskSchedulerImpl: Adding task set 0.0 with 10 tasks resource profile 0 <br/>22/11/01 23:14:00 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.2.15:35918) with ID 0, ResourceProfileId 0 <br/>22/11/01 23:14:00 INFO BlockManagerMasterEndpoint: Registering block manager 10.0.2.15:36705 with 413.9 MiB RAM, BlockManagerId(0, 10.0.2.15, 36705, None) <br/>22/11/01 23:14:01 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.0.2.15, executor 0, partition 0, PROCESS_LOCAL, 4437 bytes) taskResourceAssignments Map() <br/>22/11/01 23:14:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.2.15:36705 (size: 8.6 KiB, free: 413.9 MiB) <br/>22/11/01 23:14:03 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (10.0.2.15, executor 0, partition 1, PROCESS_LOCAL, 4437 bytes) taskResourceAssignments Map() <br/>…………</span></pre><p id="dcdf" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">—没有 Java 异常<br/> —获取 Pi 的结果</p><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="058a" class="ni ka in mg b gy oj ok l ol om">………… <br/>22/11/01 23:14:04 INFO DAGScheduler: Job 0 finished: reduce at /home/prod/spark-3.3.1-bin-hadoop3/examples/src/main/python/pi.py:42, took 8.446990 s Pi is roughly 3.143960 <br/>…………</span></pre><blockquote class="kx ky kz"><p id="b8e6" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated">注意🗒️: <code class="fe md me mf mg b">base-clean</code>这里是当前机器的名称(可以使用<code class="fe md me mf mg b">hostname</code>命令检查)</p></blockquote><p id="15c5" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated"><em class="lc">完成第 8 步</em></p></div><div class="ab cl nb nc hr nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="ig ih ii ij ik"><p id="9180" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">9.（⏰可选)<code class="fe md me mf mg b">gparted</code>(以防以后需要调整磁盘大小)<a class="ae mc" href="https://askubuntu.com/questions/101715/resizing-virtual-drive" rel="noopener ugc nofollow" target="_blank"> Ref </a></p><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="356e" class="ni ka in mg b gy oj ok l ol om">sudo apt-get install gparted</span></pre><p id="9f99" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">10.关机🎊</p><h2 id="0ea6" class="ni ka in bd kb nj nk dn kf nl nm dp kj lz nn no kn ma np nq kr mb nr ns kv nt bi translated">我们在哪里</h2><ul class=""><li id="2fdb" class="mm mn in ld b le mh li mi lz nu ma nv mb nw ly mr ms mt mu bi translated">在这一点上，我们应该有一个支持 spark 的 VM ( <code class="fe md me mf mg b">spark-installed</code>)，它可以:<br/> -运行<code class="fe md me mf mg b">pyspark</code> <br/> -运行<code class="fe md me mf mg b">spark-submit</code>示例<br/> -具有兼容的<code class="fe md me mf mg b">python/ java/ scala/ spark</code>版本<br/> -以及配置好的<code class="fe md me mf mg b">conda</code>环境，如果出现任何问题，可以轻松进行包管理</li><li id="0954" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly mr ms mt mu bi translated">我们现在需要做的就是向 spark 网络添加主/从节点，并完善我们的主/从设置</li></ul><h1 id="827c" class="jz ka in bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">新节点</h1><blockquote class="kx ky kz"><p id="6f44" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated"><em class="in">对于添加的每个新节点，无论是从节点还是主节点，都必须配置这些步骤</em></p></blockquote><ol class=""><li id="74bb" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly na ms mt mu bi translated">从<code class="fe md me mf mg b">base-installed</code>克隆新的虚拟机</li><li id="def6" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly na ms mt mu bi translated">（⏰可选)重命名机器</li><li id="926f" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly na ms mt mu bi translated">网络安装程序</li></ol><p id="32f6" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated"><em class="lc">下面详细介绍</em> ⬇️</p><h2 id="024a" class="ni ka in bd kb nj nk dn kf nl nm dp kj lz nn no kn ma np nq kr mb nr ns kv nt bi translated">克隆</h2><blockquote class="kx ky kz"><p id="86b2" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated"><em class="in"> ❗Every 时间您需要向我们的集群添加一台新机器(即一个新的从机)只需克隆我们全功能的</em> <code class="fe md me mf mg b"><em class="in">base-install</em></code> <em class="in">虚拟机并继续</em></p></blockquote><ol class=""><li id="76f5" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly na ms mt mu bi translated">决定是要在<code class="fe md me mf mg b">full</code>模式还是<code class="fe md me mf mg b">linked</code>模式下克隆</li></ol><blockquote class="kx ky kz"><p id="cf95" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated">⚡:就我个人而言，我会推荐链接克隆，只要确保你链接的原始虚拟存储磁盘有足够的空间</p></blockquote><p id="be25" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">2.克隆它(如果选择了<code class="fe md me mf mg b">full clone</code>，准备等待一段时间)</p><p id="643a" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">3.在 GUI 模式下启动机器，并记下机器的 IP/名称(<code class="fe md me mf mg b">ip addr</code>)</p><blockquote class="kx ky kz"><p id="5ac1" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated">请注意，🗒️:，从现在开始，您可以使用 IP 对机器进行操作</p></blockquote><p id="babc" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">4.（⏰可选)如果需要，调整存储大小<em class="lc">(参考最后的缺陷部分)</em></p><h2 id="aad7" class="ni ka in bd kb nj nk dn kf nl nm dp kj lz nn no kn ma np nq kr mb nr ns kv nt bi translated">重命名机器</h2><p id="c927" class="pw-post-body-paragraph la lb in ld b le mh lg lh li mi lk ll lz mj lo lp ma mk ls lt mb ml lw lx ly ig bi translated">重命名机器以便与<code class="fe md me mf mg b">cli</code>区分开来(因为我们将从<code class="fe md me mf mg b">shell/bash</code>通过<code class="fe md me mf mg b">ssh</code>访问它们)</p><p id="0ee0" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated"><a class="ae mc" href="https://www.cyberciti.biz/faq/ubuntu-change-hostname-command/" rel="noopener ugc nofollow" target="_blank">re f1</a>T23】re F2</p><blockquote class="kx ky kz"><p id="1c95" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated"><em class="in">显示在 bash 和网络通讯上的名字(不是 Virtua Box UI 上的名字</em></p><p id="3a94" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated"><em class="in">注意🗒️:我将使用</em> <code class="fe md me mf mg b"><em class="in">spark-master</em></code> <em class="in">作为我的主节点，使用</em> <code class="fe md me mf mg b"><em class="in">spark-slave-1 (2,3, ..)</em></code> <em class="in">作为我的从节点</em></p></blockquote><ol class=""><li id="2364" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly na ms mt mu bi translated"><code class="fe md me mf mg b">sudo nano /etc/hostname</code> →删除<code class="fe md me mf mg b">&lt;old-name&gt;</code>，换成你的<code class="fe md me mf mg b">&lt;new-name&gt;</code></li><li id="07d5" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly na ms mt mu bi translated"><code class="fe md me mf mg b">sudo nano /etc/hosts</code> →将<code class="fe md me mf mg b">127.0.1.1 &lt;old-name&gt;</code>改为<code class="fe md me mf mg b">127.0.1.1 &lt;new-name&gt;</code></li><li id="f9e2" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly na ms mt mu bi translated"><code class="fe md me mf mg b">sudo hostname &lt;new-name&gt;</code></li><li id="38aa" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly na ms mt mu bi translated">用<code class="fe md me mf mg b">hostnamectl</code>命令和<code class="fe md me mf mg b">hostname</code>命令验证</li><li id="6ef5" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly na ms mt mu bi translated">重装机器</li><li id="1695" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly na ms mt mu bi translated">现在，您应该能够使用机器的名称对其进行<code class="fe md me mf mg b">ssh</code>操作</li></ol><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="8acf" class="ni ka in mg b gy oj ok l ol om"># Ex (from local machine) <br/>ssh prod@spark-master </span><span id="f829" class="ni ka in mg b gy on ok l ol om"># Instead of <br/>ssh prod@&lt;a-long-ip-addr&gt;</span></pre><p id="17e9" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated"><code class="fe md me mf mg b">ip addr</code>还应输出与机器名称匹配的地址</p><h2 id="cee9" class="ni ka in bd kb nj nk dn kf nl nm dp kj lz nn no kn ma np nq kr mb nr ns kv nt bi translated">建立工作关系网</h2><ol class=""><li id="256f" class="mm mn in ld b le mh li mi lz nu ma nv mb nw ly na ms mt mu bi translated">配置网络/IP 列表📵</li></ol><ul class=""><li id="3323" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated"><code class="fe md me mf mg b">sudo nano /etc/hosts<br/></code>文件应包含</li></ul><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="09cb" class="ni ka in mg b gy oj ok l ol om">127.0.0.1 localhost </span><span id="8f5b" class="ni ka in mg b gy on ok l ol om"># Remove this entry below <br/>127.0.1.1 &lt;this-current-machine-name&gt; # ex: spark-master</span></pre><ul class=""><li id="7520" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">删除 IP 为<code class="fe md me mf mg b">127.0.1.1</code>的条目，因为这是一个回环，会干扰以后从浏览器对 Spark UI 的访问<em class="lc">(参考最后的陷阱部分)</em></li><li id="fe25" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly mr ms mt mu bi translated">将网络中所有机器的 IP 和名称添加到该文件中(包括当前机器的 IP 本身)</li></ul><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="adc9" class="ni ka in mg b gy oj ok l ol om"># example <br/>192.168.56.107 spark-master <br/>192.168.56.108 spark-slave-1</span></pre><blockquote class="kx ky kz"><p id="0f52" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated">‼️记得在添加新节点时更新这个列表</p></blockquote><p id="fe72" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">2.（⏰可选)您可以<code class="fe md me mf mg b">ssh</code>从当前机器到其他机器使用他们的名字以确保他们在网络上相互识别</p><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="c191" class="ni ka in mg b gy oj ok l ol om"># from the spark-master's shell <br/>ssh prod@spark-slave-1 </span><span id="93f4" class="ni ka in mg b gy on ok l ol om"># should prompt for access and password</span></pre><p id="e984" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">3.继续下一步，配置主/从细节</p><h1 id="90e4" class="jz ka in bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">从属设置</h1><blockquote class="kx ky kz"><p id="9bc1" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated"><em class="in">此时，从机已经完成配置👷‍♂️，下面的两个步骤对于一个正常工作的从节点</em>(我们已经经历过了)已经足够了</p></blockquote><ul class=""><li id="561c" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">火花安装</li><li id="eb88" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly mr ms mt mu bi translated">IP 配置</li></ul><p id="a0b4" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">只需转到主节点<em class="lc">(下一步)</em>并在那里更新 spark 的网络配置(<code class="fe md me mf mg b">spark-master</code>)</p><h1 id="58d0" class="jz ka in bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">主设置</h1><blockquote class="kx ky kz"><p id="a4d5" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated"><em class="in">在这里，我们在主设备上完善了我们的 spark 设置👑</em></p></blockquote><ol class=""><li id="6dcd" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly na ms mt mu bi translated">确保主人的<code class="fe md me mf mg b">/etc/hosts</code>中所有的奴隶都可用</li><li id="d46d" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly na ms mt mu bi translated">设置 spark master 环境</li></ol><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="f85d" class="ni ka in mg b gy oj ok l ol om">cd $SPARK_HOME/conf <br/>cp spark-env.sh.template spark-env.sh <br/>sudo nano spark-env.sh </span><span id="fd02" class="ni ka in mg b gy on ok l ol om"># Add <br/>export SPARK_MASTER_HOST= &lt;master-ip-addr&gt; # Ex: 192.168.56.107 <br/>export JAVA_HOME='/usr'</span></pre><p id="44bc" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">❓如何找到爪哇 path❓<code class="fe md me mf mg b">which java</code>复制路径前<code class="fe md me mf mg b">/bin</code></p><p id="6403" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">3.将从设备添加到 spark 配置</p><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="48bc" class="ni ka in mg b gy oj ok l ol om">cd $SPARK_HOME/conf <br/>sudo nano slaves </span><span id="56e8" class="ni ka in mg b gy on ok l ol om">#notice the 's' # add slave name from our network settings here spark-master <br/>spark-slave-1</span></pre><blockquote class="kx ky kz"><p id="5354" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated">⚡我也在我的主节点上启动了一个工作进程！(不要混淆)</p></blockquote><p id="2fdc" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">4.如果还没有生成<code class="fe md me mf mg b">ssh</code>键</p><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="372c" class="ni ka in mg b gy oj ok l ol om">ssh-keygen</span></pre><p id="a378" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">5.将<code class="fe md me mf mg b">ssh</code>钥匙复制给所有其他工人</p><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="fccd" class="ni ka in mg b gy oj ok l ol om">ssh-copy-id prod@spark-master <br/>ssh-copy-id prod@spark-slave-1</span></pre><blockquote class="kx ky kz"><p id="d9c7" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated">‼️记得在你添加新奴隶时更新<code class="fe md me mf mg b">$SPARK_HOME/conf/slaves</code>。然后把主人的<code class="fe md me mf mg b">ssh</code>钥匙抄过来</p></blockquote><p id="5741" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated"><em class="lc">同样，可以从主机到从机测试</em> <code class="fe md me mf mg b"><em class="lc">ssh</em></code> <em class="lc">以确保没有给出密码提示</em></p><p id="4aa6" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">6.（⏰可选)设置<code class="fe md me mf mg b">history-server</code>来管理所有完成的应用程序的日志</p><ul class=""><li id="c402" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">创建一个包含日志的文件夹</li></ul><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="6c62" class="ni ka in mg b gy oj ok l ol om">mkdir ~/spark-logs</span></pre><ul class=""><li id="05b7" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">配置</li></ul><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="4b3b" class="ni ka in mg b gy oj ok l ol om">cd $SPARK_HOME/conf <br/>cp spark-defaults.conf.template spark-defaults.conf sudo nano spark-defaults.conf </span><span id="92dd" class="ni ka in mg b gy on ok l ol om"># add these lines <br/>spark.eventLog.enabled true <br/>spark.eventLog.dir file://~/spark-logs <br/>spark.history.fs.logDirectory file://~/spark-logs</span></pre><ul class=""><li id="e10d" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">运行<code class="fe md me mf mg b">start-history-server.sh</code></li><li id="a4df" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly mr ms mt mu bi translated"><code class="fe md me mf mg b">jps</code>应显示<code class="fe md me mf mg b">HistoryServer</code>作为输入</li><li id="383b" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly mr ms mt mu bi translated">通过转至<code class="fe md me mf mg b">spark-master:18080</code>或<code class="fe md me mf mg b">&lt;master-ip&gt;:18080</code>进行验证</li></ul><figure class="ny nz oa ob gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi oo"><img src="../Images/52c640aa8a80be1647903b8ff3d240b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*I2lOyQhQ07_zBK5A.png"/></div></div></figure><p id="4729" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">7.测试 Spark 的集群设置</p><ul class=""><li id="27db" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">运行集群(主+所有从)</li></ul><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="7df7" class="ni ka in mg b gy oj ok l ol om">start-all.sh</span></pre><ul class=""><li id="7b91" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated"><code class="fe md me mf mg b">jps</code>输出应该有<code class="fe md me mf mg b">Worker</code>和<code class="fe md me mf mg b">Master</code>过程</li></ul><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="0199" class="ni ka in mg b gy oj ok l ol om">3645 Worker <br/>3533 Master</span></pre><ul class=""><li id="449d" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">在浏览器上验证链接<code class="fe md me mf mg b">spark-master:8080</code></li></ul><figure class="ny nz oa ob gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi op"><img src="../Images/6a040b29a2a3b033a6facb8ec13766fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rm6v6C0nR5FIRjFk.png"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk translated">请注意我们的员工各自的 IP 地址</figcaption></figure><p id="3f72" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">没有应用程序，因为现在还没有测试任何东西</p><p id="2112" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">8.运行示例并查看结果</p><blockquote class="kx ky kz"><p id="e943" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated">我们将运行 spark 安装中可用的简单 Pi 计算示例，以验证我们的集群是否正常运行</p></blockquote><ul class=""><li id="fe6e" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">确保主服务器/从服务器正在运行(如果您配置了历史服务器，它也在运行)</li></ul><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="e8c8" class="ni ka in mg b gy oj ok l ol om">jps </span><span id="c281" class="ni ka in mg b gy on ok l ol om"># expected output <br/>4658 Jps <br/>4396 HistoryServer <br/>3886 Master <br/>3999 Worker</span></pre><ul class=""><li id="1207" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">运行<code class="fe md me mf mg b">spark-submit</code>到我们正在运行的集群</li></ul><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="e409" class="ni ka in mg b gy oj ok l ol om">cd $SPARK_HOME <br/>spark-submit - master spark://spark-master:7077 ./examples/src/main/python/pi.py 10</span></pre><ul class=""><li id="5d90" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">(如果有历史服务器)转到历史服务器(<code class="fe md me mf mg b">spark-master:18080</code> ) <br/> -该日志应该存在</li></ul><figure class="ny nz oa ob gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi oq"><img src="../Images/5417d591b421c3c7abc0c164bc45c5f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KoDNP38swQVIxrLh.png"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk translated">我们的示例 PythonPi 运行日志</figcaption></figure><p id="42c6" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">深入了解工作的更多细节</p><figure class="ny nz oa ob gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi or"><img src="../Images/3d0102180314daf914cf91ff08ea5308.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*IpSENm01IB_el9_r.png"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk translated">点击 AppId 后</figcaption></figure><figure class="ny nz oa ob gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi os"><img src="../Images/be55c7adb48ce19c93c7f846a468dc16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*kxWS5imWkuKjpFuK.png"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk translated">点击职位描述后</figcaption></figure><p id="ac57" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">一路走到细节，你会看到我们的工作与 10 个任务分布在我们的两个配置工人</p><figure class="ny nz oa ob gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi ot"><img src="../Images/503030ce555e6e00ae1a3f9ec87db6ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NQlg-5H-eXX3MTd9.png"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk translated">任务日程表</figcaption></figure><figure class="ny nz oa ob gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi ou"><img src="../Images/d739670ecdacf1a5613b1009007868e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*z_spbdwRnxQemxMH.png"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk translated">任务列表及其运行进程位置(从属 ips)</figcaption></figure><p id="3414" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">您可以到其他选项卡了解更多详情<br/>执行程序选项卡显示 1 个驱动程序和 2 个工人执行程序</p><figure class="ny nz oa ob gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi ov"><img src="../Images/a7c50247410d050c87fc5a0906ff6929.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*W8AinNuz054JceOo.png"/></div></div></figure></div><div class="ab cl nb nc hr nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="ig ih ii ij ik"><p id="fc6d" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">🎉这就是我们随时可以使用的火花簇🎉</p><blockquote class="kx ky kz"><p id="9ce5" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated"><em class="in">🍖额外:如果您不想每次运行</em> <code class="fe md me mf mg b"><em class="in">spark-submit</em></code> <em class="in">时都必须指定主节点选项</em> <code class="fe md me mf mg b"><em class="in">--master spark://...</em></code> <em class="in">，只需在</em> <code class="fe md me mf mg b"><em class="in">$SPARK_HOME/conf/spark-defaults.conf</em></code>中追加<br/>  <code class="fe md me mf mg b"><em class="in">spark.master spark://spark-master:7077</em></code> <em class="in">来设置主节点即可</em></p></blockquote><h1 id="f6aa" class="jz ka in bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">如何为集群编写代码</h1><h2 id="3a02" class="ni ka in bd kb nj nk dn kf nl nm dp kj lz nn no kn ma np nq kr mb nr ns kv nt bi translated">使用 spark-提交</h2><p id="8ded" class="pw-post-body-paragraph la lb in ld b le mh lg lh li mi lk ll lz mj lo lp ma mk ls lt mb ml lw lx ly ig bi translated">简单，只是</p><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="4adc" class="ni ka in mg b gy oj ok l ol om">import pyspark</span><span id="d576" class="ni ka in mg b gy on ok l ol om"># do your code</span></pre><p id="aa19" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">并与<code class="fe md me mf mg b">spark-submit &lt;path-to-py-file&gt;</code>一起提交</p><h2 id="facb" class="ni ka in bd kb nj nk dn kf nl nm dp kj lz nn no kn ma np nq kr mb nr ns kv nt bi translated">使用 python</h2><blockquote class="kx ky kz"><p id="3bce" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated"><code class="fe md me mf mg b"><em class="in">python</em></code> <em class="in">二进制不知道我们本地安装了</em> <code class="fe md me mf mg b"><em class="in">pyspark</em></code> <em class="in">所以我们需要一个名为</em> <code class="fe md me mf mg b"><em class="in">findspark</em></code>的支持包</p></blockquote><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="dc68" class="ni ka in mg b gy oj ok l ol om"># this first<br/>import findspark<br/>findspark.init()<br/>findspark.find()</span><span id="0b5e" class="ni ka in mg b gy on ok l ol om"># then import pyspark<br/>import pyspark</span><span id="9b5e" class="ni ka in mg b gy on ok l ol om"># your codes</span></pre><p id="6892" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">用<code class="fe md me mf mg b">python &lt;path-to-py-file&gt;</code>运行</p><p id="26de" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">❗Note:记住将主节点设置为集群中当前运行的主节点，方法是</p><ul class=""><li id="a9ca" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">在<code class="fe md me mf mg b">$SPARK_HOME/config/spark-defaults.conf</code>中将<code class="fe md me mf mg b">spark.master</code>设置为默认值</li><li id="f571" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly mr ms mt mu bi translated">使用<code class="fe md me mf mg b">SparkConf</code> ( <a class="ae mc" href="https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.SparkConf.html#pyspark.SparkConf" rel="noopener ugc nofollow" target="_blank"> Ref </a>)在您的脚本(<code class="fe md me mf mg b">.py</code>)中设置它</li></ul><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="1b99" class="ni ka in mg b gy oj ok l ol om">conf = SparkConf() <br/>conf.setMaster("spark://spark-master:7077") <br/>sc = SparkContext.getOrCreate(conf)</span></pre><p id="a361" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">⚠️如果你不这样配置，你的代码将在主节点上新创建的(临时的)进程上运行，而不是被添加到你当前运行的集群中</p><h2 id="0eff" class="ni ka in bd kb nj nk dn kf nl nm dp kj lz nn no kn ma np nq kr mb nr ns kv nt bi translated">使用笔记本</h2><blockquote class="kx ky kz"><p id="12ab" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated"><code class="fe md me mf mg b"><em class="in">Jupyter</em></code> <em class="in">应仅用于开发/调试目的，实际生产代码应通过</em> <code class="fe md me mf mg b"><em class="in">spark-submit</em></code>汇总至集群</p></blockquote><ol class=""><li id="e4cc" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly na ms mt mu bi translated">确保安装了<code class="fe md me mf mg b">jupyter</code></li><li id="498d" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly na ms mt mu bi translated">从主节点(<code class="fe md me mf mg b">spark-master</code>)用<code class="fe md me mf mg b">jupyter notebook</code>启动<code class="fe md me mf mg b">jupyter</code>笔记本进程</li><li id="a7ba" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly na ms mt mu bi translated">打开从本地机器到<code class="fe md me mf mg b">spark-master</code>的<code class="fe md me mf mg b">ssh</code>隧道</li></ol><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="9805" class="ni ka in mg b gy oj ok l ol om">ssh -N -L 8888:localhost:8888 prod@spark-master <br/># this makes anyone accessing localhost:8888 be tunneled to prod@spark-master:8888</span></pre><p id="d058" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">🌀或者只需通过<code class="fe md me mf mg b">jupyter notebook --ip 0.0.0.0</code>启动<code class="fe md me mf mg b">0.0.0.0</code>上的<code class="fe md me mf mg b">jupyter</code>，并在<code class="fe md me mf mg b">spark-master:8888</code>从本地机器的浏览器直接访问它</p><p id="d250" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">4.在您的本地机器上，转到<code class="fe md me mf mg b">localhost:8888</code>并输入访问令牌/密码开始工作</p><p id="a4ed" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">5.(🗒️注)确保在笔记本中选择您想要的 python 环境作为内核(<a class="ae mc" href="https://towardsdatascience.com/get-your-conda-environment-to-show-in-jupyter-notebooks-the-easy-way-17010b76e874" rel="noopener" target="_blank"> Ref </a>)</p><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="c342" class="ni ka in mg b gy oj ok l ol om">conda activate spakimental # if not already <br/>ipython kernel install - user - name=sparkimental</span><span id="12c7" class="ni ka in mg b gy on ok l ol om"># then select "sparkimental" in notebook</span></pre><p id="4346" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">6.类似于直接使用<code class="fe md me mf mg b">python</code> bin 运行，我们的代码需要这些步骤</p><ul class=""><li id="695e" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">寻找火花</li></ul><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="f859" class="ni ka in mg b gy oj ok l ol om">import findspark <br/>findspark.init() <br/>findspark.find()</span></pre><ul class=""><li id="1c25" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">安装ˌ使成形</li></ul><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="cf84" class="ni ka in mg b gy oj ok l ol om">from pyspark import SparkConf <br/>conf = SparkConf() <br/># if not already configured in spark-defaults.conf <br/>conf.setMaster('spark://spark-master:7077') <br/># if you dont set app name, our jupyter job will be named `spark-shell` <br/>conf.setAppName('jupyter job');</span></pre><ul class=""><li id="529c" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">创造火花情境，疯狂</li></ul><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="5057" class="ni ka in mg b gy oj ok l ol om">sc = SparkContext.getOrCreate(conf)</span></pre><p id="b711" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">在执行完上面一行之后，<code class="fe md me mf mg b">spark-master:8080</code>的<code class="fe md me mf mg b">spark-master</code> web UI 应该会显示一个新的正在运行的应用程序</p><figure class="ny nz oa ob gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi ow"><img src="../Images/048f4fa3eae5599a12c7517ed7dac22f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KfiQxtwLP8qBXHJf.png"/></div></div></figure><h1 id="2243" class="jz ka in bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">临时演员</h1><h2 id="6f5f" class="ni ka in bd kb nj nk dn kf nl nm dp kj lz nn no kn ma np nq kr mb nr ns kv nt bi translated">创造<code class="fe md me mf mg b">conda</code>环境</h2><blockquote class="kx ky kz"><p id="5ec7" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated"><em class="in">来自一个</em> <code class="fe md me mf mg b"><em class="in">config.yml</em></code> <em class="in">文件</em></p></blockquote><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="3182" class="ni ka in mg b gy oj ok l ol om"># example conda.env.yml config file content<br/>name: sparkimental # this is environment name<br/>dependencies: # and the packages we need<br/>	# must have these 2<br/>	- python=3.10<br/>	- conda-forge::findspark<br/>	# NOTE! don't install pyspark and java here since we already installed them<br/>	# ones below are optional<br/>	- jupyter<br/>	- ipython<br/>	- nltk<br/>	- ipykernel<br/>	- numpy</span></pre><ul class=""><li id="20ba" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">从配置文件<br/>创建环境<code class="fe md me mf mg b">conda env create -f conda.env.yml<br/></code> ❗Careful 关于<code class="fe md me mf mg b">yml</code>文件(<a class="ae mc" href="https://stackoverflow.com/questions/57381678/how-to-create-conda-environment-with-yml-file-without-this-error" rel="noopener ugc nofollow" target="_blank"> ref </a>)</li><li id="1def" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly mr ms mt mu bi translated">请在任何其他步骤之前激活环境，始终确保您正在正确的<code class="fe md me mf mg b">conda</code>环境<br/> <code class="fe md me mf mg b">conda activate sparkimental</code>中执行代码</li><li id="ba78" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly mr ms mt mu bi translated">如果要清除环境<br/> <code class="fe md me mf mg b">conda activate base<br/>conda env remove -n sparkimental -y</code></li></ul><h1 id="9c0e" class="jz ka in bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">陷阱</h1><ul class=""><li id="bc20" class="mm mn in ld b le mh li mi lz nu ma nv mb nw ly mr ms mt mu bi translated">用尽存储空间→ <a class="ae mc" href="https://askubuntu.com/questions/101715/resizing-virtual-drive" rel="noopener ugc nofollow" target="_blank">(如何调整大小)</a></li><li id="4ac1" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly mr ms mt mu bi translated">运行 spark 时不允许创建日志→只更改被拒绝访问的文件夹的权限<code class="fe md me mf mg b">chmod -R 777 dirname</code></li><li id="b4a3" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly mr ms mt mu bi translated">spark master 监听的默认服务端口是什么？<code class="fe md me mf mg b">7077</code> ( <a class="ae mc" href="https://spark.apache.org/docs/latest/spark-standalone.html" rel="noopener ugc nofollow" target="_blank">参考 1 </a>，<a class="ae mc" href="https://stackoverflow.com/questions/25585194/standalone-apache-spark-what-to-put-as-slave-ip-and-port" rel="noopener ugc nofollow" target="_blank">参考 2 </a>)</li><li id="8241" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly mr ms mt mu bi translated">worker 和 driver 之间的 Python 不匹配→只需确保两者都设置为相同的 python(建议使用绝对路径)<br/> - <a class="ae mc" href="https://stackoverflow.com/questions/54115290/mismatch-between-python-version-in-spark-worker-and-spark-driver" rel="noopener ugc nofollow" target="_blank">不匹配 Ref</a>-<a class="ae mc" href="https://stackoverflow.com/questions/30464980/how-to-check-all-versions-of-python-installed-on-osx-and-centos" rel="noopener ugc nofollow" target="_blank">如何在 Linux 上检查所有 python 版本</a></li><li id="f3cd" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly mr ms mt mu bi translated">火花回送 IP 问题(<a class="ae mc" href="https://support.datastax.com/s/article/Spark-hostname-resolving-to-loopback-address-warning-in-spark-worker-logs" rel="noopener ugc nofollow" target="_blank">问题描述</a>)</li></ul><pre class="ny nz oa ob gt of mg og oh aw oi bi"><span id="70cf" class="ni ka in mg b gy oj ok l ol om">Your hostname, … resolves to a loopback address: 127.0.0.1; using 10.1.2.1 instead</span></pre><p id="fbe8" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">通过从<code class="fe md me mf mg b">/etc/hosts</code>中删除<code class="fe md me mf mg b">127.0.1.1</code>条目来解决</p><h1 id="ddc2" class="jz ka in bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">参考</h1><blockquote class="kx ky kz"><p id="0287" class="la lb lc ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ig bi translated"><em class="in">本文主要基于以下观点/指导🙇，我感谢所有其他作者❣️ </em></p></blockquote><ul class=""><li id="2466" class="mm mn in ld b le lf li lj lz mo ma mp mb mq ly mr ms mt mu bi translated">基础【https://www.guru99.com/pyspark-tutorial.html#4】教程:<a class="ae mc" href="https://www.guru99.com/pyspark-tutorial.html#4" rel="noopener ugc nofollow" target="_blank">基础</a></li><li id="9510" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly mr ms mt mu bi translated">如何设置<code class="fe md me mf mg b">Spark</code>集群:<a class="ae mc" href="https://medium.com/@jootorres_11979/how-to-install-and-set-up-an-apache-spark-cluster-on-hadoop-18-04-b4d70650ed42" rel="noopener">https://medium . com/@ joo Torres _ 11979/how-to-install-and-setup-an-Apache-spark-cluster-on-Hadoop-18-04-b4d 70650 ed 42</a></li><li id="6c34" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly mr ms mt mu bi translated">带着<code class="fe md me mf mg b">Jupyter</code>笔记本跑<code class="fe md me mf mg b">PySpark</code>:<a class="ae mc" rel="noopener ugc nofollow" target="_blank" href="/a-convenient-way-to-run-pyspark-4e84a32f00b7">https://blog . dev genius . io/a-convenient-way-to-run-py spark-4e 84 a 32 f 00 b 7</a></li><li id="8ae6" class="mm mn in ld b le mv li mw lz mx ma my mb mz ly mr ms mt mu bi translated">Spark 历史服务器设置:<a class="ae mc" href="https://sparkbyexamples.com/spark/spark-history-server-to-monitor-applications/" rel="noopener ugc nofollow" target="_blank">https://sparkbyexamples . com/spark/spark-History-Server-to-monitor-applications/</a></li></ul><h1 id="2ae5" class="jz ka in bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">结论</h1><p id="b763" class="pw-post-body-paragraph la lb in ld b le mh lg lh li mi lk ll lz mj lo lp ma mk ls lt mb ml lw lx ly ig bi translated">我们有 it 🥳，一个运行 spark 的全功能虚拟机集群，您可以从本地计算机管理它，并以任何方式运行代码。</p><p id="3607" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">请对我的话题发表你的看法，如果有任何帮助，请鼓掌。很乐意收到你的来信😸</p><p id="b350" class="pw-post-body-paragraph la lb in ld b le lf lg lh li lj lk ll lz ln lo lp ma lr ls lt mb lv lw lx ly ig bi translated">感谢阅读🖤，继续闪耀😉💫</p></div></div>    
</body>
</html>