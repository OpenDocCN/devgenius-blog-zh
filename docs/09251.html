<html>
<head>
<title>Building a Streaming Data Pipeline With Kafka And Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 Kafka 和 Spark 构建流数据管道</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/building-a-streaming-data-pipeline-on-ubuntu-20-04-8fa9e6f9cced?source=collection_archive---------7-----------------------#2022-08-09">https://blog.devgenius.io/building-a-streaming-data-pipeline-on-ubuntu-20-04-8fa9e6f9cced?source=collection_archive---------7-----------------------#2022-08-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/90d8a9debc1a9f40cf2ca4062dae5e64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xMdcnrdGraUxtAFv"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">康尼·施耐德在<a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="3e7d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">学习大数据可能很容易，但应用知识却不太容易。这就是为什么在本教程中，我将向您展示如何建立端到端的实时数据管道。</em></p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h2 id="95ac" class="lj lk iq bd ll lm ln dn lo lp lq dp lr ko ls lt lu ks lv lw lx kw ly lz ma mb bi translated">开始之前</h2><p id="3175" class="pw-post-body-paragraph kd ke iq kf b kg mc ki kj kk md km kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated">在本教程中，我将介绍如何创建一个数据流管道，但我不会深入研究每一项技术。因此，如果您对 Spark、Kafka 和非关系数据库不太熟悉，我建议您在开始这个数据流管道之前先看看这些主题。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h2 id="91f1" class="lj lk iq bd ll lm ln dn lo lp lq dp lr ko ls lt lu ks lv lw lx kw ly lz ma mb bi translated">让我们开始吧…架构</h2><p id="5807" class="pw-post-body-paragraph kd ke iq kf b kg mc ki kj kk md km kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated">真实世界环境中的数据管道可能会变得非常复杂，有大量的技术可能会让你感到困惑。在本教程中，我将介绍流数据管道的基本逻辑。我将使用 Spotify 播放列表作为源数据，Kafka 作为摄取工具，Spark SQL 用于数据处理，MongoDB 用于存储处理后的数据。</p><figure class="mi mj mk ml gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mh"><img src="../Images/9c5e247ea2817392576fd9856dd5d94a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2rdYiLNu0JTlJzE7e6fjEQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">Javier Gr 的流水线架构</figcaption></figure><p id="71b9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">逻辑很简单，但功能强大且可扩展。让我们快速回顾一下管道中使用的每项技术及其用途。</p><p id="8c7a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Spotify: 这是一项数字音乐流媒体服务。它可以让你即时访问在线音乐和播客库，让你随时收听你选择的任何内容。既合法又好用。在这条数据流管道中，Spotify 将提供源数据。我们将从基本播放列表开始，并处理这些歌曲的数据。一旦一首新歌被添加到播放列表中，这些细节将在我们的管道中传输和处理。</p><p id="89b8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> Kafka: </strong>它是一个基于发布-订阅(生产者-消费者)消息传递系统(在进程、应用程序和服务器之间交换数据)的分布式消息传递和流数据平台。Kafka 用于构建实时流数据管道和适应数据流的应用程序。在这个数据流管道中，Kafka 将被用作摄取工具，将歌曲细节从 Spotify 播放列表发送到 Spark 应用程序。</p><p id="eb38" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> Spark: </strong>它是一个开源的数据处理框架，用于计算机集群上的并行数据处理。Spark 将是用于处理该数据流管道中的数据的引擎。</p><p id="1c3c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">MongoDB: 这是一个面向文档的 NoSQL 数据库，用于大容量数据存储。MongoDB 不像传统的关系数据库那样使用表和行，而是使用集合和文档。基本上，这是我们数据的最终目的地。数据处理完成后，数据将存储在这里。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h2 id="318f" class="lj lk iq bd ll lm ln dn lo lp lq dp lr ko ls lt lu ks lv lw lx kw ly lz ma mb bi translated">先决条件</h2><p id="c40c" class="pw-post-body-paragraph kd ke iq kf b kg mc ki kj kk md km kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated">在本教程中，我们不会介绍每种技术的安装。我们将专注于数据流管道，但请确保您已经启动并运行了一切！</p><ul class=""><li id="f1ae" class="mo mp iq kf b kg kh kk kl ko mq ks mr kw ms la mt mu mv mw bi translated">Spotify:这里我们需要重要的东西。首先，您需要选择一个播放列表，并确保您可以将歌曲添加到该播放列表中(您创建的任何播放列表都可以完成这项工作)。第二，你需要注册 Spotify 开发者，创建一个应用(不用担心，你可以用你的普通 Spotify 账号登录 Spotify 开发者)。如果你需要这方面的指导，你可以关注 Spotify 的官方教程<a class="ae kc" href="https://developer.spotify.com/documentation/general/guides/authorization/app-settings/" rel="noopener ugc nofollow" target="_blank">。</a></li><li id="eff7" class="mo mp iq kf b kg mx kk my ko mz ks na kw nb la mt mu mv mw bi translated">Ubuntu:我在 Windows 上使用的是从<a class="ae kc" href="https://www.microsoft.com/store/productId/9MTTCL66CPXJ" rel="noopener ugc nofollow" target="_blank">微软商店</a>下载的 WSL2 上的 Ubuntu 20.04，但是任何发行版都可以完成这项工作。</li><li id="9bef" class="mo mp iq kf b kg mx kk my ko mz ks na kw nb la mt mu mv mw bi translated">Kafka:我用的是 Kafka 3.0.0，不过任何更新的版本应该都可以。如果你想知道如何安装它，我跟随<a class="ae kc" href="https://kontext.tech/article/1047/install-and-run-kafka-320-on-wsl" rel="noopener ugc nofollow" target="_blank">这个</a>教程。</li><li id="f197" class="mo mp iq kf b kg mx kk my ko mz ks na kw nb la mt mu mv mw bi translated">Spark:我用的是 Spark 3.1.3 搭配 Hadoop 3.2，万一你没有，可以去看看<a class="ae kc" href="https://www.osradar.com/how-to-install-apache-spark-on-ubuntu-20-04/" rel="noopener ugc nofollow" target="_blank">这个</a>教程。</li><li id="0267" class="mo mp iq kf b kg mx kk my ko mz ks na kw nb la mt mu mv mw bi translated">MongoDB:我使用的是 MongoDB 5.0.9，我按照微软的官方文档<a class="ae kc" href="https://www.osradar.com/how-to-install-apache-spark-on-ubuntu-20-04/" rel="noopener ugc nofollow" target="_blank">将其安装在 WSL2 上。</a></li><li id="e89b" class="mo mp iq kf b kg mx kk my ko mz ks na kw nb la mt mu mv mw bi translated">Python/Spotipy:我在用 Python 3.8.10 (sudo apt 安装 Python 3.8)和 Spotipy (pip 安装 spotipy —升级)。</li></ul></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h2 id="4ab6" class="lj lk iq bd ll lm ln dn lo lp lq dp lr ko ls lt lu ks lv lw lx kw ly lz ma mb bi translated">代码时间到了！</h2><p id="9a97" class="pw-post-body-paragraph kd ke iq kf b kg mc ki kj kk md km kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated">我们将创建两个脚本来完成我们的流数据管道。第一个脚本是生产者，第二个脚本是消费者。</p><p id="1e0f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先让我们创建我们的生产者(生产者. py)。它会将 Spotify 播放列表中的数据发送到 Spark 应用程序。</p><p id="149c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们添加实现这一目标所需的所有库:</p><figure class="mi mj mk ml gt jr"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="99c7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，我们需要在默认端口 9092 上创建我们的 Kakfa 生产者，并使用 utf-8 编码数据。</p><figure class="mi mj mk ml gt jr"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="6f53" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将打印一条消息，以确保我们的生产者已经开始。</p><figure class="mi mj mk ml gt jr"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="377c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，让我们使用客户端 id 和客户端密钥来设置我们的 Spotify 开发者帐户，这些信息可以在您的 Spotify 开发者仪表板上找到。</p><figure class="mi mj mk ml gt jr"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="6e6e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在是时候创建一个方法来返回包含所有歌曲 id 的列表了。这将有助于使用歌曲的 id 获得每首歌曲的更多细节。</p><figure class="mi mj mk ml gt jr"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="7b5d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">是时候获取歌曲细节了，也就是元数据。使用 getTrackFeatures 方法，我们将获得歌曲，专辑和艺术家的名字，每首歌曲使用其 id。Spotify 还增加了一些功能，比如 danceability，我们也将检索这些功能。所有这些细节都将存储在一个列表中并返回。</p><figure class="mi mj mk ml gt jr"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="4613" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在是时候传输我们的数据了。我们将使用 while 循环，因为我们希望它总是检查是否有新歌被添加到 getTrackID(user，playlistID)方法指定的播放列表中。每次添加歌曲时，它都会检查前面提到的所有歌曲的详细信息，我们将使用 Kafka 建立我们的消息流。</p><figure class="mi mj mk ml gt jr"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="cde2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在让我们创建我们的消费者(consumer.py)。它将接收、处理和存储流数据。</p><p id="fd31" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先让我们导入所有需要的库。</p><figure class="mi mj mk ml gt jr"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="0cab" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在让我们创建一个方法，帮助我们将流数据写入 MongoDB。</p><figure class="mi mj mk ml gt jr"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="1f89" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们指定我们在生成器中使用的主题和端口。</p><figure class="mi mj mk ml gt jr"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="edab" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们可以创建我们的 Spark 应用程序，我们需要提供设置 MongoDB 连接的细节。在本例中，我的数据库名是 spotifydb，集合名是 spotifycoll。</p><figure class="mi mj mk ml gt jr"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="019f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦创建了 Spark 应用程序，我们就可以开始读取流数据了。</p><figure class="mi mj mk ml gt jr"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="5cf1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为我们正在接收流数据，所以我们必须格式化它，并根据源数据提供模式。如果你对流式数据帧的工作方式感兴趣，并想深入理解下面的代码，我推荐你阅读这篇文章。</p><figure class="mi mj mk ml gt jr"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="02da" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们来做一些小的处理，只是为了好玩。基本上，我们增加了一个基于跳舞率的新栏目。</p><figure class="mi mj mk ml gt jr"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="2550" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后是向 MongoDB 发送数据的时候了。在这一步中，我们在控制台中显示发送到 MongoDB 的数据，然后调用 writeToMongoDB 方法将每条记录写入 MongoDB。</p><figure class="mi mj mk ml gt jr"><div class="bz fp l di"><div class="nc nd l"/></div></figure></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h2 id="6fb1" class="lj lk iq bd ll lm ln dn lo lp lq dp lr ko ls lt lu ks lv lw lx kw ly lz ma mb bi translated">测试时间到了！</h2><p id="eadc" class="pw-post-body-paragraph kd ke iq kf b kg mc ki kj kk md km kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated">现在我们已经准备好了要测试的代码，我们需要启动 Kafka 服务。让我们开始触发动物园管理员服务:</p><pre class="mi mj mk ml gt ne nf ng nh aw ni bi"><span id="d70b" class="lj lk iq nf b gy nj nk l nl nm">$KAFKA_HOME/bin/zookeeper-server-start.sh $KAFKA_HOME/config/zookeeper.properties</span></pre><p id="f59b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在又在一个新的终端触发 Kafka 服务:</p><pre class="mi mj mk ml gt ne nf ng nh aw ni bi"><span id="b77c" class="lj lk iq nf b gy nj nk l nl nm">$KAFKA_HOME/bin/kafka-server-start.sh $KAFKA_HOME/config/server.properties</span></pre><p id="bca8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">注意:</strong>如果你没有在 WSL2 上使用 Ubuntu 20.4，你应该使用下面的命令来启动 ZoooKeeper 和 Kafka 服务。</p><pre class="mi mj mk ml gt ne nf ng nh aw ni bi"><span id="bfaf" class="lj lk iq nf b gy nj nk l nl nm">sudo systemctl enable zookeeper<br/>sudo systemctl enable kafka</span></pre><p id="e08b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我们继续执行我们的消费者和生产者之前，我们应该检查 MongoDB 是否正在运行。首先我们检查它的状态，如果 MongoDB 没有运行，我们应该启动它。下面是检查、启动和停止 MongoDB 的命令。</p><pre class="mi mj mk ml gt ne nf ng nh aw ni bi"><span id="8865" class="lj lk iq nf b gy nj nk l nl nm">sudo service mongodb status<br/>sudo service mongodb stop<br/>sudo service mongodb start</span></pre><p id="e99c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">注意:</strong>如果你没有在 WSL2 上使用 Ubuntu 20.4，你应该使用下面的命令来检查和启动 MongoDB。</p><pre class="mi mj mk ml gt ne nf ng nh aw ni bi"><span id="cd91" class="lj lk iq nf b gy nj nk l nl nm">systemctl status mongod<br/>sudo systemctl restart mongod</span></pre><p id="e793" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在 Kafka 和 MongoDB 正在运行，我们将首先开始执行消费者，因为我们希望在发送流数据之前进行监听。为了触发消费者，我们将使用下面的命令。</p><pre class="mi mj mk ml gt ne nf ng nh aw ni bi"><span id="7bc1" class="lj lk iq nf b gy nj nk l nl nm">spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.3,org.mongodb.spark:mongo-spark-connector_2.12:3.0.1 consumer.py</span></pre><p id="fc1e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦 Spark 应用程序被提交，我们将看到它是如何等待数据的。</p><figure class="mi mj mk ml gt jr gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/19232ee9d51d62b272725a422e19c1e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1102/format:webp/1*fMGanjZiyIoBHst0GonUEA.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">消费者等待数据</figcaption></figure><p id="0cd9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们现在处决制片人。由于生产者只是一个 Python 脚本，我们可以像执行任何其他 Python 脚本一样执行它。</p><pre class="mi mj mk ml gt ne nf ng nh aw ni bi"><span id="8cc5" class="lj lk iq nf b gy nj nk l nl nm">python3 producer.py</span></pre><p id="791d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">制作人将开始从我们的<a class="ae kc" href="https://open.spotify.com/playlist/15XvyZ84e5tXUVoWd15Eqm?si=cf914550483b4c28" rel="noopener ugc nofollow" target="_blank"> Spotify 播放列表</a>中读取数据，并将其发送给消费者。如果没有更多的数据要发送，它将等待，直到我们停止它或新的数据到来。</p><figure class="mi mj mk ml gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi no"><img src="../Images/fddab47dea3d52e7a7401499da03921d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DO9kTP32rO5FtMmQG8Ce8g.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">生产者读取和发送的数据</figcaption></figure><p id="8ede" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">消费者将读取生产者发送的数据，并处理和存储到 MongoDB</p><figure class="mi mj mk ml gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi np"><img src="../Images/2480fe23024d36d933e4ed406d8f551a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hynckCT0vY0BaAyoVTxUcw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">消费者读取和处理的数据</figcaption></figure><figure class="mi mj mk ml gt jr gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/2507b9e17ec4ae7149b3a9d9338e2e53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*GwrQtuqdFICYEl_cKFCH8A.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">存储在 MongoDB 中的数据</figcaption></figure><p id="a148" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们已经发送和存储了 5 首歌曲，我们可以向 Spotify 播放列表添加一首新歌，制作人将读取并发送它。</p><figure class="mi mj mk ml gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nr"><img src="../Images/357308223f3c66772f671f39bb551576.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GWXsOM9-i9IpY6eJBA4HvA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">新歌曲被添加到播放列表并被制作人阅读。</figcaption></figure><p id="278c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">消费者将阅读添加的新歌，并将它处理和存储到 MongoDB。</p><figure class="mi mj mk ml gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ns"><img src="../Images/4f4b6cff867a501cd71918c5c8867139.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o2ISC73ieGflR-eLCC68Og.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">消费者阅读的新歌。</figcaption></figure><figure class="mi mj mk ml gt jr gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/9c3fd1f7e64e44fa3e68e2052866c232.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/format:webp/1*RKh-2YvajomIiFwGot2HUw.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">存储在 MongoDB 中的歌曲。</figcaption></figure><p id="3738" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我希望你和我一样喜欢这个教程。这是一个简单的数据流管道，但是相同的逻辑适用于更大的管道。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><p id="76fc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你像我一样喜欢写这篇文章，别忘了👏。</p><div class="nu nv gp gr nw nx"><a href="https://medium.com/@JavierGr/membership" rel="noopener follow" target="_blank"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd ir gy z fp oc fr fs od fu fw ip bi translated">通过我的推荐链接加入媒体</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">阅读哈维尔和媒体上成千上万其他作家的每一个故事。</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">medium.com</p></div></div><div class="og l"><div class="oh l oi oj ok og ol jw nx"/></div></div></a></div></div></div>    
</body>
</html>