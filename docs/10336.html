<html>
<head>
<title>Data Processing and Analysis using Spark | Spark Project-1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Spark | Spark 项目-1 进行数据处理和分析</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/data-processing-and-analysis-using-spark-spark-project-1-3f52516272a7?source=collection_archive---------1-----------------------#2022-10-25">https://blog.devgenius.io/data-processing-and-analysis-using-spark-spark-project-1-3f52516272a7?source=collection_archive---------1-----------------------#2022-10-25</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><figure class="gl gn jl jm jn jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi jk"><img src="../Images/d6340e9cabaf92b94bfeee5ee2069666.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rOe5v0px2ooR-uS1jMksTg.png"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk translated">设计概述</figcaption></figure><p id="8434" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi kx translated">在这篇博文中，我们将了解如何使用 Apache Spark 在关系数据库上执行简单的操作，以获得有价值的见解。</p></div><div class="ab cl lg lh hr li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ig ih ii ij ik"><h2 id="65f8" class="ln lo in bd lp lq lr dn ls lt lu dp lv kk lw lx ly ko lz ma mb ks mc md me mf bi translated">问题陈述:</h2><p id="851c" class="pw-post-body-paragraph jz ka in kb b kc mg ke kf kg mh ki kj kk mi km kn ko mj kq kr ks mk ku kv kw ig bi translated">我们有三个 CSV 类型的数据表。我们在这些表中执行基本的连接，并创建一个不完整的数据框架，这样我们就可以在数据的基础上执行一些处理和分析。</p><h2 id="d543" class="ln lo in bd lp lq lr dn ls lt lu dp lv kk lw lx ly ko lz ma mb ks mc md me mf bi translated">数据集:</h2><p id="aa8a" class="pw-post-body-paragraph jz ka in kb b kc mg ke kf kg mh ki kj kk mi km kn ko mj kq kr ks mk ku kv kw ig bi translated">对于这个项目，我们将使用<a class="ae ml" href="https://github.com/sidharth1805/Data-Processing-and-Analysis-using-Spark-Spark-Project-1/tree/main/Data" rel="noopener ugc nofollow" target="_blank">零售数据集</a>。这些数据集由三个表组成:customer、orders 和 order_items。</p><h2 id="7654" class="ln lo in bd lp lq lr dn ls lt lu dp lv kk lw lx ly ko lz ma mb ks mc md me mf bi translated">使用的技术组合/技能:</h2><ol class=""><li id="edb0" class="mm mn in kb b kc mg kg mh kk mo ko mp ks mq kw mr ms mt mu bi translated">火花</li><li id="661a" class="mm mn in kb b kc mv kg mw kk mx ko my ks mz kw mr ms mt mu bi translated">结构化查询语言</li></ol><h2 id="227e" class="ln lo in bd lp lq lr dn ls lt lu dp lv kk lw lx ly ko lz ma mb ks mc md me mf bi translated">设置工作空间:</h2><p id="6373" class="pw-post-body-paragraph jz ka in kb b kc mg ke kf kg mh ki kj kk mi km kn ko mj kq kr ks mk ku kv kw ig bi translated">我们将使用免费的 Databricks Community Edition 来执行 spark 操作，如果您更喜欢在本地或 Hadoop 集群中使用 Spark，也没问题。</p><p id="1165" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">参考:【https://www.databricks.com/product/faq/community-edition】T4</p><p id="6018" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">设置工作区后，创建一个集群并打开一个工作簿。你已经准备好出发了。</p><h2 id="a75c" class="ln lo in bd lp lq lr dn ls lt lu dp lv kk lw lx ly ko lz ma mb ks mc md me mf bi translated">项目:</h2><p id="952a" class="pw-post-body-paragraph jz ka in kb b kc mg ke kf kg mh ki kj kk mi km kn ko mj kq kr ks mk ku kv kw ig bi translated">现在是时候将我们的数据添加到数据块中了。</p><figure class="nb nc nd ne gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi na"><img src="../Images/ebd5fda10f0ca59787ce0cb3d23535c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3luM6g9xUS6mSd8LrM6Grg.png"/></div></div></figure><p id="d3a2" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">通过创建适当的文件夹上传数据在下面的例子中，我创建了一个文件夹数据，在它下面我创建了一个文件夹订单并上传了数据文件。</p><figure class="nb nc nd ne gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi nf"><img src="../Images/5081c298ebffa898227f4c48db139f93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q1y2jq4HCyl3G6DzXwVcQA.png"/></div></div></figure><figure class="nb nc nd ne gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi ng"><img src="../Images/0ad578f0224f3071c9b3eb6645ed3351.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*03P0lXF0JXsLNO6sMzd0nA.png"/></div></div></figure><p id="2219" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">既然我们已经完成了在数据块中设置数据，现在是时候写一些代码了。</p><p id="9283" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io">步骤 1: </strong>检查是否所有需要的文件都已放置</p><pre class="nb nc nd ne gt nh ni nj nk aw nl bi"><span id="1ec9" class="ln lo in ni b gy nm nn l no np">%fs ls dbfs:/FileStore/tables/Data</span></pre><figure class="nb nc nd ne gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi nq"><img src="../Images/717a7cf95bbc5024946493f2f4e4dbc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O4S_5uileBxtBJEG6XShww.png"/></div></div></figure><p id="87e1" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io">步骤 2: </strong>为订单、order_items 和客户创建数据框架。我们使用的 CSV 文件没有模式，因此在创建数据框时我们定义了模式。</p><figure class="nb nc nd ne gt jo"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="f254" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io">第三步:</strong>查看数据帧</p><pre class="nb nc nd ne gt nh ni nj nk aw nl bi"><span id="874f" class="ln lo in ni b gy nm nn l no np">order_items_df.show(2)</span></pre><figure class="nb nc nd ne gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi nt"><img src="../Images/9d8b548e9571e07ffeb3ebb177c63a3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fLwzJ0n53JYNF_HvJ95TOg.png"/></div></div></figure><p id="7ab6" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io">步骤 4: </strong>将我们的表连接到一个新的数据框架(oreder_details)中，以创建一个非规范化的数据框架。</p><ul class=""><li id="b153" class="mm mn in kb b kc kd kg kh kk nu ko nv ks nw kw nx ms mt mu bi translated">最初连接客户和订单表。</li></ul><pre class="nb nc nd ne gt nh ni nj nk aw nl bi"><span id="ef2b" class="ln lo in ni b gy nm nn l no np">customers_orders_df=customer_df.join(orders_df,customer_df['customer_id']==orders_df['order_customer_id'])</span></pre><ul class=""><li id="7106" class="mm mn in kb b kc kd kg kh kk nu ko nv ks nw kw nx ms mt mu bi translated">使用 SELECT 子句投影所需的数据。</li></ul><pre class="nb nc nd ne gt nh ni nj nk aw nl bi"><span id="4ace" class="ln lo in ni b gy nm nn l no np">customers_orders_df.select('customer_id','order_id','order_date','order_status').orderBy('customer_id').show(10)</span></pre><figure class="nb nc nd ne gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi ny"><img src="../Images/f110ca2b157b34bd5777238ba9964e48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ld6Tas61Cx_n5zjXYAoEew.png"/></div></div></figure><ul class=""><li id="c702" class="mm mn in kb b kc kd kg kh kk nu ko nv ks nw kw nx ms mt mu bi translated">将 order_id、order_date 和 order_status 合并为结构化数据类型。</li></ul><pre class="nb nc nd ne gt nh ni nj nk aw nl bi"><span id="0a4c" class="ln lo in ni b gy nm nn l no np">from pyspark.sql.functions import struct</span><span id="0f00" class="ln lo in ni b gy nz nn l no np">customers_orders_df.select('customer_id',struct('order_id','order_date','order_status').alias('order_details')).orderBy('customer_id').show(10)</span></pre><figure class="nb nc nd ne gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi oa"><img src="../Images/a780022bcb45b970529cdc49d217c35a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dsrz0kso_cnF3hg8NEttNA.png"/></div></div></figure><ul class=""><li id="bb10" class="mm mn in kb b kc kd kg kh kk nu ko nv ks nw kw nx ms mt mu bi translated">生成一个结构数组。使用 order_details 字段。这里我们将 customer_id 分组，并以数组的形式存储 order_details。</li></ul><pre class="nb nc nd ne gt nh ni nj nk aw nl bi"><span id="f9f6" class="ln lo in ni b gy nm nn l no np">customer_order_struct=customers_orders_df.select('customer_id',struct('order_id','order_date','order_status').alias('order_details'))</span><span id="5390" class="ln lo in ni b gy nz nn l no np">from pyspark.sql.functions import collect_list</span><span id="cc56" class="ln lo in ni b gy nz nn l no np">final_df=customer_order_struct.groupBy('customer_id').agg(collect_list('order_details').alias('order_details')).orderBy('customer_id')</span></pre><figure class="nb nc nd ne gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi ob"><img src="../Images/fc20108fd7cd88452e6e7c7d029503fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PHJ6r19u5SVJXtMxmfgkWg.png"/></div></div></figure><p id="bdb6" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated"><strong class="kb io">第五步:</strong>将数据帧导出到 JSON 文件中。</p><pre class="nb nc nd ne gt nh ni nj nk aw nl bi"><span id="450f" class="ln lo in ni b gy nm nn l no np">final_df.coalesce(1).write.json('dbfs:/FileStore/tables/Data/final')</span></pre><figure class="nb nc nd ne gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi oc"><img src="../Images/4dee7cce4db6c5c28fcaf0feea8f029c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*opuVNdwkT9jE2fkByiQu2g.png"/></div></div></figure><p id="7d0f" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">之前，我们已经对订单和客户进行了反规范化。现在我们将为三张桌子表演。</p><figure class="nb nc nd ne gt jo"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="e760" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">将数据框导出到 JSON 文件中。</p><pre class="nb nc nd ne gt nh ni nj nk aw nl bi"><span id="682c" class="ln lo in ni b gy nm nn l no np">denorm_df.coalesce(1).write.json('dbfs:/FileStore/tables/Data/denorm')</span></pre></div><div class="ab cl lg lh hr li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ig ih ii ij ik"><p id="9e0d" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">现在我们有了进行分析所需的数据。现在是使用 Spark 分析反规范化数据的时候了。</p><p id="e5a4" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">我们将对我们的数据进行以下分析</p><ol class=""><li id="ddd9" class="mm mn in kb b kc kd kg kh kk nu ko nv ks nw kw mr ms mt mu bi translated">获取客户在 2014 年 1 月 1 日下的订单的详细信息</li><li id="70e2" class="mm mn in kb b kc mv kg mw kk mx ko my ks mz kw mr ms mt mu bi translated">计算每月客户收入</li></ol><h2 id="d9cf" class="ln lo in bd lp lq lr dn ls lt lu dp lv kk lw lx ly ko lz ma mb ks mc md me mf bi translated">问题陈述— 1:</h2><p id="57e4" class="pw-post-body-paragraph jz ka in kb b kc mg ke kf kg mh ki kj kk mi km kn ko mj kq kr ks mk ku kv kw ig bi translated">读取数据帧。</p><pre class="nb nc nd ne gt nh ni nj nk aw nl bi"><span id="e8f9" class="ln lo in ni b gy nm nn l no np">json_df=spark.read.json('dbfs:/FileStore/tables/Data/denorm/part-00000-tid-4357456608139543307-49cdb4fe-37a2-4435-be01-b6711f29eb3d-211-1-c000.json')</span><span id="76e8" class="ln lo in ni b gy nz nn l no np">json_df.show(2)</span></pre><figure class="nb nc nd ne gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi od"><img src="../Images/9ffeecd88e4752fb233402087272cb3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dlMPVpTiJx4wGwB2BX7kGQ.png"/></div></div></figure><pre class="nb nc nd ne gt nh ni nj nk aw nl bi"><span id="db99" class="ln lo in ni b gy nm nn l no np">json_df.select('customer_id','customer_fname',explode('order_details').alias('order_details')). \<br/>filter('order_details.order_date LIKE "2014-01-01%"'). \<br/>orderBy('customer_id'). \<br/>select('customer_id','customer_fname','order_details.order_id','order_details.order_date','order_details.order_status'). \<br/>show(10)</span></pre><figure class="nb nc nd ne gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi oe"><img src="../Images/d10d2377dfc327b8c9c48401f27a90df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BoRk9EEsk3zj68o5G8gfcA.png"/></div></div></figure><h2 id="d511" class="ln lo in bd lp lq lr dn ls lt lu dp lv kk lw lx ly ko lz ma mb ks mc md me mf bi translated">问题陈述— 2:</h2><ul class=""><li id="c9fd" class="mm mn in kb b kc mg kg mh kk mo ko mp ks mq kw nx ms mt mu bi translated">为了计算每月的客户收入，我们需要对 order_items 表中的 order_item_subtotal 执行聚合(SUM)。</li><li id="e4fe" class="mm mn in kb b kc mv kg mw kk mx ko my ks mz kw nx ms mt mu bi translated">在我们的输入数据中，我们已经将所有的细节包装到一个 struct 数据类型中，因此是时候展平所有的细节了。</li></ul><figure class="nb nc nd ne gt jo"><div class="bz fp l di"><div class="nr ns l"/></div></figure><figure class="nb nc nd ne gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi of"><img src="../Images/1ef6ac27abacb3869374628de3f3e501.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ccilDd7dyxW3Cp44lk7COw.png"/></div></div></figure><ul class=""><li id="21da" class="mm mn in kb b kc kd kg kh kk nu ko nv ks nw kw nx ms mt mu bi translated">展平数据后，让我们编写逻辑来获得月收入</li></ul><figure class="nb nc nd ne gt jo"><div class="bz fp l di"><div class="nr ns l"/></div></figure><figure class="nb nc nd ne gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi og"><img src="../Images/d1f7641b43d2bcbf1f46aaf01e67cdc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2WssNX_in6Yy_JwDSeBvNA.png"/></div></div></figure></div><div class="ab cl lg lh hr li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ig ih ii ij ik"><p id="6109" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi kx translated">这个项目将让你了解如何去规格化数据表，并使用 Spark 在数据上执行分析。这里请参考<a class="ae ml" href="https://github.com/sidharth1805/Data-Processing-and-Analysis-using-Spark-Spark-Project-1" rel="noopener ugc nofollow" target="_blank"/>。</p></div></div>    
</body>
</html>