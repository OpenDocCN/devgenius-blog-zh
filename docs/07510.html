<html>
<head>
<title>Investigating Machine Learning Techniques to Improve Spec Tests — II</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">研究机器学习技术以改进规格测试— II</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/investigating-machine-learning-techniques-to-improve-spec-tests-ii-5ad2837bad8f?source=collection_archive---------10-----------------------#2022-03-31">https://blog.devgenius.io/investigating-machine-learning-techniques-to-improve-spec-tests-ii-5ad2837bad8f?source=collection_archive---------10-----------------------#2022-03-31</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><figure class="gl gn jl jm jn jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi jk"><img src="../Images/a2d40aa40b526170e2f4a4471c7f9fa5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_c2jKJmRRkAu7pu4.jpg"/></div></div></figure><h1 id="b621" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">介绍</h1><p id="2e86" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">这是与人工智能实现相关的系列博文的一部分。如果你对故事的背景或情节感兴趣:</p><p id="4077" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated"><a class="ae lw" href="https://serpapi.com/blog/how-to-scrape-google-local-results-with-artificial-intelligence/" rel="noopener ugc nofollow" target="_blank"> #1)如何用人工智能抓取 Google 本地结果？</a><br/><a class="ae lw" href="https://serpapi.com/blog/real-world-example-of-machine-learning-on-rails/" rel="noopener ugc nofollow" target="_blank"># 2)Rails 上机器学习的真实世界示例</a> <br/> <a class="ae lw" href="https://serpapi.com/blog/better-training-tips-and-comparisons/" rel="noopener ugc nofollow" target="_blank"> #3) AI 训练技巧和比较</a><br/><a class="ae lw" href="https://serpapi.com/blog/machine-learning-in-scraping-with-rails/" rel="noopener ugc nofollow" target="_blank"># 4)Rails 刮刮中的机器学习</a> <br/> <a class="ae lw" href="https://serpapi.com/blog/implementing-onnx-models-to-rails/" rel="noopener ugc nofollow" target="_blank"> #5)在 Rails 中实现 ONNX 模型</a><br/><a class="ae lw" href="https://serpapi.com/blog/how-ml-hybrid-parser-beats-tradition/" rel="noopener ugc nofollow" target="_blank"># 6)ML 混合解析器如何击败传统解析器</a> <br/> <a class="ae lw" href="https://serpapi.com/blog/ml-hybrid-benchmarks/" rel="noopener ugc nofollow" target="_blank"> #7)如何在 Rails 上对 ML 实现进行基准测试</a> <br/> <a class="ae lw" href="https://serpapi.com/blog/use-machine-learning-to-improve-spec-tests/" rel="noopener ugc nofollow" target="_blank"> #8)研究机器学习技术</a></p><p id="d45e" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated">本周，我们将展示为一般测试目的实现机器学习模型的数据库创建过程。我们将使用<a class="ae lw" href="https://serpapi.com/organic-results" rel="noopener ugc nofollow" target="_blank"> SerpApi 的 Google Organic Results Scraper API</a>进行数据收集。此外，这里有一个<a class="ae lw" href="https://serpapi.com/playground?q=Coffee&amp;location=Austin%2C+Texas%2C+United+States&amp;gl=us&amp;hl=en&amp;no_cache=true&amp;newPara=lr+async+as_qdr" rel="noopener ugc nofollow" target="_blank">链接</a>，包含我们将使用的数据的详细视图。</p><figure class="ly lz ma mb gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi lx"><img src="../Images/d4a71a412dfb6ba98ebffb17ea199cbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*DZRS9qkiSi459_H1.png"/></div></div></figure><p id="200f" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi">— — — — — — — — — — — — — — — — — — — — — — — — — — — — — —</p><h1 id="5a1a" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">I —从哈希中创建线性 CSV</h1><p id="c466" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">让我们初始化类变量<code class="fe mc md me mf b">@@pattern_data</code>并在<code class="fe mc md me mf b">Database</code>类中定义<code class="fe mc md me mf b">@@vocab</code>。我们将用来矢量化单词和句子的默认词汇表应该是<code class="fe mc md me mf b">{ "&lt;unk&gt;" =&gt; 0, " " =&gt; 1 }</code>。</p><pre class="ly lz ma mb gt mg mf mh mi aw mj bi"><span id="ed49" class="mk jw in mf b gy ml mm l mn mo">class Database<br/>  def initialize json_data, vocab = { "&lt;unk&gt;" =&gt; 0, " " =&gt; 1 }<br/>    super()<br/>    @@pattern_data = []<br/>    @@vocab = vocab<br/>  end</span></pre><p id="d1b5" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated">接下来，我们需要一种递归的方法来将散列转换成由值及其键类型组成的可理解的比特行。</p><p id="e624" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated">例如，我们需要翻译这个:</p><pre class="ly lz ma mb gt mg mf mh mi aw mj bi"><span id="032f" class="mk jw in mf b gy ml mm l mn mo">{<br/>      "position": 1,<br/>      "title": "Coffee - Wikipedia",<br/>      "link": "https://en.wikipedia.org/wiki/Coffee",<br/>      "displayed_link": "https://en.wikipedia.org › wiki › Coffee",<br/>      "thumbnail": "https://serpapi.com/searches/62436d12e7d08a5a74994e0f/images/ed8bda76b255c4dc4634911fb134de5319e08af7e374d3ea998b50f738d9f3d2.jpeg",<br/>      "snippet": "Coffee is a brewed drink prepared from roasted coffee beans, the seeds of berries from certain flowering plants in the Coffea genus. From the coffee fruit, ...",<br/>	  ...<br/>    }</span></pre><p id="fda5" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated">对此:</p><figure class="ly lz ma mb gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi mp"><img src="../Images/d220665ba979554d7187d6cf27511960.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i56LBhH8Qcpd3iJD19gBcQ.png"/></div></div></figure><p id="4844" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated">注意，对于某些元素来说，位置并不重要。所以我们用<code class="fe mc md me mf b">n</code>来称呼它们，内部按键用<code class="fe mc md me mf b">__</code>来分隔。</p><p id="7595" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated">现在让我们定义填充<code class="fe mc md me mf b">@@pattern_data</code> (master_array)的主函数，并将其写入一个 CSV 文件供将来使用。</p><pre class="ly lz ma mb gt mg mf mh mi aw mj bi"><span id="f454" class="mk jw in mf b gy ml mm l mn mo">def self.add_new_data_to_database json_data, csv_path = nil<br/>    json_data.each do |result|<br/>      recursive_hash_pattern result, ""<br/>    end</span><span id="8c67" class="mk jw in mf b gy mq mm l mn mo">    @@pattern_data = @@pattern_data.reject { |pattern| pattern.include? nil }.uniq.compact</span><span id="4760" class="mk jw in mf b gy mq mm l mn mo">    path = "#{csv_path}master_database.csv"<br/>    File.write(path, @@pattern_data.map(&amp;:to_csv).join)<br/>  end</span></pre><p id="6202" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated">我们来分解一下<code class="fe mc md me mf b">recursive_hash_pattern</code>及其相关功能:</p><pre class="ly lz ma mb gt mg mf mh mi aw mj bi"><span id="167f" class="mk jw in mf b gy ml mm l mn mo">## For keys that directly contain String, Integer, Float etc.<br/>  def self.element_pattern result, pattern<br/>    @@pattern_data.append([result, pattern].flatten)<br/>  end </span><span id="1e57" class="mk jw in mf b gy mq mm l mn mo">  ## For Arrays that contain String, Integer, Float etc.<br/>  def self.element_array_pattern result, pattern<br/>    result.each do |element|<br/>      element_pattern element, pattern<br/>    end<br/>  end</span><span id="e505" class="mk jw in mf b gy mq mm l mn mo">  ## Main Process<br/>  def self.assign hash, key, pattern</span><span id="cbbe" class="mk jw in mf b gy mq mm l mn mo">    ## If the key contains a hash, it has to be recursed until all<br/>    ## child components are collected.<br/>    if hash[key].is_a?(Hash)<br/>      if pattern.present?<br/>        pattern = "#{pattern}__#{key}"<br/>      else<br/>        pattern = "#{key}"<br/>      end</span><span id="a22f" class="mk jw in mf b gy mq mm l mn mo">      recursive_hash_pattern hash[key], pattern</span><span id="0c40" class="mk jw in mf b gy mq mm l mn mo">    ## If the key contains an array, containing multiple hashes,           ## all the hashes should be recursed to their components<br/>    elsif hash[key].present? &amp;&amp; hash[key].is_a?(Array) &amp;&amp; hash[key].first.is_a?(Hash)<br/>      if pattern.present?<br/>        pattern = "#{pattern}__#{key}__n"<br/>      else<br/>        pattern = "#{key}"<br/>      end</span><span id="4d16" class="mk jw in mf b gy mq mm l mn mo">      hash[key].each do |hash_inside_array|<br/>        recursive_hash_pattern hash_inside_array, pattern<br/>      end<br/>    ## If the key contains an array consisting of base elements,<br/>    ## each element should be added with the right key pattern.<br/>    elsif hash[key].present? &amp;&amp; hash[key].is_a?(Array)<br/>      if pattern.present?<br/>        pattern = "#{pattern}__n"<br/>      else<br/>        pattern = "#{key}"<br/>      end</span><span id="6e34" class="mk jw in mf b gy mq mm l mn mo">      element_array_pattern hash[key], pattern<br/>    ## If the element contains String, Float, etc.<br/>    else<br/>      if pattern.present?<br/>        pattern = "#{pattern}__#{key}"<br/>      else<br/>        pattern = "#{key}"<br/>      end</span><span id="c890" class="mk jw in mf b gy mq mm l mn mo">      element_pattern hash[key], pattern<br/>    end<br/>  end<br/> <br/>  def self.recursive_hash_pattern hash, pattern<br/>    hash.keys.each do |key|<br/>      assign hash, key, pattern<br/>    end<br/>  end</span></pre><p id="188d" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated">请注意，每个递归操作都将其模式带到下一次迭代中，以使键分类不同。</p><p id="448c" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated">现在，如果我们应用这些命令，它将在<code class="fe mc md me mf b">organic_results</code>文件夹中创建一个名为<code class="fe mc md me mf b">master.csv</code>的 csv 文件。<br/> <code class="fe mc md me mf b">json_data</code>表示包含所有<code class="fe mc md me mf b">organic_result</code>散列的<code class="fe mc md me mf b">organic_results</code>数组。</p><pre class="ly lz ma mb gt mg mf mh mi aw mj bi"><span id="3576" class="mk jw in mf b gy ml mm l mn mo">Database.new json_data Database.add_new_data_to_database json_data, csv_path = "organic_results/"</span></pre><p id="85ea" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated">最终结果如您所愿:</p><figure class="ly lz ma mb gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi mp"><img src="../Images/d220665ba979554d7187d6cf27511960.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i56LBhH8Qcpd3iJD19gBcQ.png"/></div></div></figure><p id="6df7" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi">— — — — — — — — — — — — — — — — — — — — — — — — — — — — — —</p><h1 id="47cd" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">II——标记化和词汇创造</h1><p id="63f0" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">在我们开始创建要用<code class="fe mc md me mf b">ngram iterator</code>标记的<code class="fe mc md me mf b">hash specific tables</code>之前，让我们定义负责标记的函数:</p><pre class="ly lz ma mb gt mg mf mh mi aw mj bi"><span id="2e80" class="mk jw in mf b gy ml mm l mn mo">def self.default_dictionary_hash<br/>    {<br/>      /\"/ =&gt; "",<br/>      /\'/ =&gt; " \'  ",<br/>      /\./ =&gt; " . ",<br/>      /,/ =&gt; ", ",<br/>      /\!/ =&gt; " ! ",<br/>      /\?/ =&gt; " ? ",<br/>      /\;/ =&gt; " ",<br/>      /\:/ =&gt; " ",<br/>      /\(/ =&gt; " ( ",<br/>      /\)/ =&gt; " ) ",<br/>      /\// =&gt; " / ",<br/>      /\s+/ =&gt; " ",<br/>      /&lt;br \/&gt;/ =&gt; " , ",<br/>      /http/ =&gt; "http",<br/>      /https/ =&gt; " https ",<br/>    }<br/>  end</span></pre><p id="14f7" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated">该函数负责为<code class="fe mc md me mf b">tokenizer</code>中输入的拆分单词创建默认的字典哈希，以及它们将被替换成什么。我们将能够从这些分裂点创建可理解的向量。请注意，我将<code class="fe mc md me mf b">http</code>和<code class="fe mc md me mf b">https</code>包含在其中，因为它们在<code class="fe mc md me mf b">organic_results</code>中被广泛使用。</p><p id="79a8" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi">— — — — — — — — — — — — — — — — — — — — — — — — — — — — — —</p><pre class="ly lz ma mb gt mg mf mh mi aw mj bi"><span id="f42a" class="mk jw in mf b gy ml mm l mn mo">def self.tokenizer word, dictionary_hash = default_dictionary_hash word = word.downcase dictionary_hash.keys.each do |key| word.sub!(key, dictionary_hash[key]) end word.split end</span></pre><p id="d0f8" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated">这是我们主要的记号赋予器。举个例子，如果我们应用这样的命令:</p><pre class="ly lz ma mb gt mg mf mh mi aw mj bi"><span id="9f93" class="mk jw in mf b gy ml mm l mn mo">Database.tokenizer "SerpApi, to. the: Moon"</span></pre><p id="66ce" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated">我们得到这样的输出:</p><pre class="ly lz ma mb gt mg mf mh mi aw mj bi"><span id="d227" class="mk jw in mf b gy ml mm l mn mo">["serpapi,", "to", ".", "the", "moon"]</span></pre><p id="df52" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi">— — — — — — — — — — — — — — — — — — — — — — — — — — — — — — -</p><pre class="ly lz ma mb gt mg mf mh mi aw mj bi"><span id="c8a7" class="mk jw in mf b gy ml mm l mn mo">def self.iterate_ngrams token_list, ngrams = 1<br/>    token_list.each do |token|<br/>      1.upto(ngrams) do |n|<br/>        permutations = (token_list.size - n + 1).times.map { |i| token_list[i...(i + n)] }<br/>        <br/>        permutations.each do |perm|<br/>          key = perm.join(" ")</span><span id="c859" class="mk jw in mf b gy mq mm l mn mo">          unless @@vocab.keys.include? key<br/>            @@vocab[key] = @@vocab.size<br/>          end<br/>        end<br/>      end<br/>    end<br/>  end</span></pre><p id="14cb" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated">这是我们的<code class="fe mc md me mf b">ngram iterator</code>。<code class="fe mc md me mf b">token_list</code>这里是 tokenizer 函数的输出。通过这个函数，我们可以从不同的切割点创建置换。<code class="fe mc md me mf b">ngrams</code>定义排列的宽度。</p><p id="1c53" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated">举个例子，如果我们应用这样的命令:</p><pre class="ly lz ma mb gt mg mf mh mi aw mj bi"><span id="8c77" class="mk jw in mf b gy ml mm l mn mo">Database.iterate_ngrams ["serpapi,", "to", ".", "the", "moon"], ngrams=3</span></pre><p id="ce8a" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated">我们的词汇(<code class="fe mc md me mf b">@@vocab</code>)将更新如下:</p><pre class="ly lz ma mb gt mg mf mh mi aw mj bi"><span id="d2c1" class="mk jw in mf b gy ml mm l mn mo">{<br/>  "&lt;unk&gt;"=&gt;0,<br/>  " "=&gt;1,<br/>  "serpapi,"=&gt;2,<br/>  "to"=&gt;3,<br/>  "."=&gt;4,<br/>  "the"=&gt;5,<br/>  "moon"=&gt;6,<br/>  "serpapi, to"=&gt;7,<br/>  "to ."=&gt;8,<br/>  ". the"=&gt;9,<br/>  "the moon"=&gt;10,<br/>  "serpapi, to ."=&gt;11,<br/>  "to . the"=&gt;12,<br/>  ". the moon"=&gt;13<br/>}</span></pre><p id="a31e" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi">— — — — — — — — — — — — — — — — — — — — — — — — — — — — — —</p><p id="4abc" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated">我们将在下周的博客文章中讨论如何使用向量进行分类。但是为了给出一个大概的样子，负责的函数是:</p><pre class="ly lz ma mb gt mg mf mh mi aw mj bi"><span id="e668" class="mk jw in mf b gy ml mm l mn mo">def self.word_to_tensor word<br/>    token_list = tokenizer word<br/>    token_list.map {|token| @@vocab[token]}<br/>  end</span></pre><p id="21ae" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated">所以，如果我们把我们的句子:</p><pre class="ly lz ma mb gt mg mf mh mi aw mj bi"><span id="b93c" class="mk jw in mf b gy ml mm l mn mo">Database.word_to_tensor "SerpApi, to. the: Moon"</span></pre><p id="88f3" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated">我们得到相应的令牌:</p><pre class="ly lz ma mb gt mg mf mh mi aw mj bi"><span id="1eb2" class="mk jw in mf b gy ml mm l mn mo">[2, 3, 4, 5, 6]</span></pre><p id="03cc" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated">这样我们就可以用数学的方式来表达字符串。</p><p id="6877" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi">— — — — — — — — — — — — — — — — — — — — — — — — — — — — — —</p><h1 id="74fe" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">III —关键的特定 CSV 创建</h1><p id="f1e4" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">让我们定义一些函数，它们将有助于创建关键的特定数据库，并供以后使用。<br/>首先，我们需要定义一个函数来保存我们的词汇表的最终结果，该词汇表将由输入到关键特定数据库的每个单词创建:</p><pre class="ly lz ma mb gt mg mf mh mi aw mj bi"><span id="1cfd" class="mk jw in mf b gy ml mm l mn mo">def self.save_vocab vocab_path = ""<br/>    path = "#{vocab_path}vocab.json"<br/>    vocab = JSON.parse(@@vocab.to_json)<br/>    File.write(path, JSON.pretty_generate(vocab))<br/>  end</span></pre><p id="6d0e" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated">最终结果将是:</p><pre class="ly lz ma mb gt mg mf mh mi aw mj bi"><span id="92d5" class="mk jw in mf b gy ml mm l mn mo">{<br/>  "&lt;unk&gt;": 0,<br/>  " ": 1,<br/>  "1": 2,<br/>  "coffee": 3,<br/>  "-": 4,<br/>  "wikipedia": 5,<br/>  "coffee -": 6,<br/>  ...<br/>}</span></pre><p id="e315" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi">— — — — — — — — — — — — — — — — — — — — — — — — — — — — — —</p><p id="4ef4" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated">只是为了检查字符串是否仅由数值组成:</p><pre class="ly lz ma mb gt mg mf mh mi aw mj bi"><span id="8903" class="mk jw in mf b gy ml mm l mn mo">def self.is_numeric?<br/>    return true if self =~ /\A\d+\Z/<br/>    true if Float(self) rescue false<br/>  end</span></pre><p id="691f" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi">— — — — — — — — — — — — — — — — — — — — — — — — — — — — — —</p><p id="e86a" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated">要为每种键类型创建示例键-值对:</p><pre class="ly lz ma mb gt mg mf mh mi aw mj bi"><span id="5374" class="mk jw in mf b gy ml mm l mn mo">def self.create_keys_and_examples<br/>    keys = @@pattern_data.map { |pattern| pattern.second }.uniq</span><span id="9fc8" class="mk jw in mf b gy mq mm l mn mo">    examples = {}<br/>    keys.each do |key|<br/>      examples[key] = @@pattern_data.find { |pattern| pattern.first.to_s if pattern.second == key }<br/>    end</span><span id="4b76" class="mk jw in mf b gy mq mm l mn mo">    [keys, examples]<br/>  end</span></pre><p id="f931" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated">最终结果将是一个惟一键的集合和一个散列，其中包含一个消除条件错误的示例。</p><p id="25c0" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi">— — — — — — — — — — — — — — — — — — — — — — — — — — — — — —</p><pre class="ly lz ma mb gt mg mf mh mi aw mj bi"><span id="f2cc" class="mk jw in mf b gy ml mm l mn mo">def self.create_key_specific_databases result_type = "organic_results", csv_path = nil, dictionary = nil, ngrams = nil, vocab_path = nil<br/>    keys, examples = create_keys_and_examples</span><span id="260c" class="mk jw in mf b gy mq mm l mn mo">    keys.each do |key|<br/>      specific_pattern_data = []<br/>      @@pattern_data.each_with_index do |pattern, index|<br/>        word = pattern.first.to_s<br/>        <br/>        next if word.blank?</span><span id="0a38" class="mk jw in mf b gy mq mm l mn mo">        if dictionary.present?<br/>          token_list = tokenizer word, dictionary<br/>        else<br/>          token_list = tokenizer word<br/>        end</span><span id="b75d" class="mk jw in mf b gy mq mm l mn mo">        if ngrams.present?<br/>          iterate_ngrams token_list, ngrams<br/>        else<br/>          iterate_ngrams token_list<br/>        end</span><span id="b24a" class="mk jw in mf b gy mq mm l mn mo">        if key == pattern.second<br/>          specific_pattern_data &lt;&lt; [ 1, word ]<br/>        elsif (examples[key].to_s.to_i == examples[key]) &amp;&amp; word.to_i == word<br/>          next<br/>        elsif (examples[key].to_s.to_i == examples[key]) &amp;&amp; word.numeric?<br/>          specific_pattern_data &lt;&lt; [ 0, word ]<br/>        elsif examples[key].numeric? &amp;&amp; word.numeric?<br/>          next<br/>        elsif key.split("__").last == pattern.second.to_s.split("__").last<br/>          specific_pattern_data &lt;&lt; [ 1, word ]<br/>        else<br/>          specific_pattern_data &lt;&lt; [ 0, word ]<br/>        end<br/>      end</span><span id="d309" class="mk jw in mf b gy mq mm l mn mo">      path = "#{csv_path}#{result_type}__#{key}.csv"<br/>      File.write(path, specific_pattern_data.map(&amp;:to_csv).join)<br/>    end</span><span id="a964" class="mk jw in mf b gy mq mm l mn mo">    if vocab_path.present?<br/>      save_vocab vocab_path<br/>    else<br/>      save_vocab<br/>    end<br/>  end</span></pre><p id="384f" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated">这是负责为每个键创建数据库的主要函数。请注意，对于包含整数的键，csv 将省略表中的整数键。这样，我们可以消除像<code class="fe mc md me mf b">rating:"5"</code>这样可能与<code class="fe mc md me mf b">reviews:"5"</code>混淆的情况。我们还推广了最后的内部键相同的情况，以避免同类元素的混淆。例子是在主散列和它的一个键中的<code class="fe mc md me mf b">position</code>。它们代表同一个键，所以用<code class="fe mc md me mf b">1</code>标记它们会很方便。我们还将每个单词添加到我们的词汇表中以扩充它，稍后保存到 csv 中。</p><p id="48c1" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated">创建的一个 CSV 文件的最终结果(<code class="fe mc md me mf b">organic_results__about_page_link</code>):</p><figure class="ly lz ma mb gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi mr"><img src="../Images/52c67bc9e3c3570e98400b9deb44509e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*chgkOefCHNqr2_IWQ2lHjg.png"/></div></div></figure><p id="b7dc" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated"><code class="fe mc md me mf b">1</code>代表这是我们对这样一个键想要的那种结果，<code class="fe mc md me mf b">0</code>代表相反。</p><p id="d158" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi">— — — — — — — — — — — — — — — — — — — — — — — — — — — — — —</p><h1 id="054f" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">IV —整个代码</h1><p id="1a46" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">这是整个过程的思维导图:</p><figure class="ly lz ma mb gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi jk"><img src="../Images/33551a9aa4d7f2b58e83c49a2f5f8e93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*x84LPcMdWC4vvI4C.png"/></div></div></figure><p id="2344" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated">下面是该类的完整代码:</p><pre class="ly lz ma mb gt mg mf mh mi aw mj bi"><span id="31ce" class="mk jw in mf b gy ml mm l mn mo">class Database<br/>  def initialize json_data, vocab = { "&lt;unk&gt;" =&gt; 0, " " =&gt; 1 }<br/>    super()<br/>    @@pattern_data = []<br/>    @@vocab = vocab<br/>  end</span><span id="55e5" class="mk jw in mf b gy mq mm l mn mo">  ## Related to creating main database<br/>  def self.add_new_data_to_database json_data, csv_path = nil<br/>    json_data.each do |result|<br/>      recursive_hash_pattern result, ""<br/>    end</span><span id="aa31" class="mk jw in mf b gy mq mm l mn mo">    @@pattern_data = @@pattern_data.reject { |pattern| pattern.include? nil }.uniq.compact</span><span id="390a" class="mk jw in mf b gy mq mm l mn mo">    path = "#{csv_path}master_database.csv"<br/>    File.write(path, @@pattern_data.map(&amp;:to_csv).join)<br/>  end</span><span id="2470" class="mk jw in mf b gy mq mm l mn mo">  def self.element_pattern result, pattern<br/>    @@pattern_data.append([result, pattern].flatten)<br/>  end </span><span id="bc3c" class="mk jw in mf b gy mq mm l mn mo">  def self.element_array_pattern result, pattern<br/>    result.each do |element|<br/>      element_pattern element, pattern<br/>    end<br/>  end</span><span id="70e1" class="mk jw in mf b gy mq mm l mn mo">  def self.assign hash, key, pattern<br/>    if hash[key].is_a?(Hash)<br/>      if pattern.present?<br/>        pattern = "#{pattern}__#{key}"<br/>      else<br/>        pattern = "#{key}"<br/>      end</span><span id="bfdc" class="mk jw in mf b gy mq mm l mn mo">      recursive_hash_pattern hash[key], pattern<br/>    elsif hash[key].present? &amp;&amp; hash[key].is_a?(Array) &amp;&amp; hash[key].first.is_a?(Hash)<br/>      if pattern.present?<br/>        pattern = "#{pattern}__#{key}__n"<br/>      else<br/>        pattern = "#{key}"<br/>      end</span><span id="6306" class="mk jw in mf b gy mq mm l mn mo">      hash[key].each do |hash_inside_array|<br/>        recursive_hash_pattern hash_inside_array, pattern<br/>      end<br/>    elsif hash[key].present? &amp;&amp; hash[key].is_a?(Array)<br/>      if pattern.present?<br/>        pattern = "#{pattern}__n"<br/>      else<br/>        pattern = "#{key}"<br/>      end</span><span id="bd7e" class="mk jw in mf b gy mq mm l mn mo">      element_array_pattern hash[key], pattern<br/>    else<br/>      if pattern.present?<br/>        pattern = "#{pattern}__#{key}"<br/>      else<br/>        pattern = "#{key}"<br/>      end</span><span id="53c0" class="mk jw in mf b gy mq mm l mn mo">      element_pattern hash[key], pattern<br/>    end<br/>  end<br/> <br/>  def self.recursive_hash_pattern hash, pattern<br/>    hash.keys.each do |key|<br/>      assign hash, key, pattern<br/>    end<br/>  end</span><span id="9241" class="mk jw in mf b gy mq mm l mn mo">  ## Related to tokenizing<br/>  def self.default_dictionary_hash<br/>    {<br/>      /\"/ =&gt; "",<br/>      /\'/ =&gt; " \'  ",<br/>      /\./ =&gt; " . ",<br/>      /,/ =&gt; ", ",<br/>      /\!/ =&gt; " ! ",<br/>      /\?/ =&gt; " ? ",<br/>      /\;/ =&gt; " ",<br/>      /\:/ =&gt; " ",<br/>      /\(/ =&gt; " ( ",<br/>      /\)/ =&gt; " ) ",<br/>      /\// =&gt; " / ",<br/>      /\s+/ =&gt; " ",<br/>      /&lt;br \/&gt;/ =&gt; " , ",<br/>      /http/ =&gt; "http",<br/>      /https/ =&gt; " https ",<br/>    }<br/>  end</span><span id="7562" class="mk jw in mf b gy mq mm l mn mo">  def self.tokenizer word, dictionary_hash = default_dictionary_hash<br/>    word = word.downcase</span><span id="20c1" class="mk jw in mf b gy mq mm l mn mo">    dictionary_hash.keys.each do |key|<br/>      word.sub!(key, dictionary_hash[key])<br/>    end</span><span id="7cf2" class="mk jw in mf b gy mq mm l mn mo">    word.split<br/>  end</span><span id="484a" class="mk jw in mf b gy mq mm l mn mo">  def self.iterate_ngrams token_list, ngrams = 1<br/>    token_list.each do |token|<br/>      1.upto(ngrams) do |n|<br/>        permutations = (token_list.size - n + 1).times.map { |i| token_list[i...(i + n)] }<br/>        <br/>        permutations.each do |perm|<br/>          key = perm.join(" ")</span><span id="8d83" class="mk jw in mf b gy mq mm l mn mo">          unless @@vocab.keys.include? key<br/>            @@vocab[key] = @@vocab.size<br/>          end<br/>        end<br/>      end<br/>    end<br/>  end</span><span id="2b86" class="mk jw in mf b gy mq mm l mn mo">  def self.word_to_tensor word<br/>    token_list = tokenizer word<br/>    token_list.map {|token| @@vocab[token]}<br/>  end</span><span id="fa1b" class="mk jw in mf b gy mq mm l mn mo">  ## Related to creating key-specific databases <br/>  def self.create_key_specific_databases result_type = "organic_results", csv_path = nil, dictionary = nil, ngrams = nil, vocab_path = nil<br/>    keys, examples = create_keys_and_examples</span><span id="82ba" class="mk jw in mf b gy mq mm l mn mo">    keys.each do |key|<br/>      specific_pattern_data = []<br/>      @@pattern_data.each_with_index do |pattern, index|<br/>        word = pattern.first.to_s<br/>        <br/>        next if word.blank?</span><span id="1233" class="mk jw in mf b gy mq mm l mn mo">        if dictionary.present?<br/>          token_list = tokenizer word, dictionary<br/>        else<br/>          token_list = tokenizer word<br/>        end</span><span id="a961" class="mk jw in mf b gy mq mm l mn mo">        if ngrams.present?<br/>          iterate_ngrams token_list, ngrams<br/>        else<br/>          iterate_ngrams token_list<br/>        end</span><span id="869a" class="mk jw in mf b gy mq mm l mn mo">        if key == pattern.second<br/>          specific_pattern_data &lt;&lt; [ 1, word ]<br/>        elsif (examples[key].to_s.to_i == examples[key]) &amp;&amp; word.to_i == word<br/>          next<br/>        elsif (examples[key].to_s.to_i == examples[key]) &amp;&amp; word.numeric?<br/>          specific_pattern_data &lt;&lt; [ 0, word ]<br/>        elsif examples[key].numeric? &amp;&amp; word.numeric?<br/>          next<br/>        elsif key.split("__").last == pattern.second.to_s.split("__").last<br/>          specific_pattern_data &lt;&lt; [ 1, word ]<br/>        else<br/>          specific_pattern_data &lt;&lt; [ 0, word ]<br/>        end<br/>      end</span><span id="54a1" class="mk jw in mf b gy mq mm l mn mo">      path = "#{csv_path}#{result_type}__#{key}.csv"<br/>      File.write(path, specific_pattern_data.map(&amp;:to_csv).join)<br/>    end</span><span id="5f2d" class="mk jw in mf b gy mq mm l mn mo">    if vocab_path.present?<br/>      save_vocab vocab_path<br/>    else<br/>      save_vocab<br/>    end<br/>  end</span><span id="9d9a" class="mk jw in mf b gy mq mm l mn mo">  def self.create_keys_and_examples<br/>    keys = @@pattern_data.map { |pattern| pattern.second }.uniq</span><span id="ac6f" class="mk jw in mf b gy mq mm l mn mo">    examples = {}<br/>    keys.each do |key|<br/>      examples[key] = @@pattern_data.find { |pattern| pattern.first.to_s if pattern.second == key }<br/>    end</span><span id="b439" class="mk jw in mf b gy mq mm l mn mo">    [keys, examples]<br/>  end</span><span id="853f" class="mk jw in mf b gy mq mm l mn mo">  def self.is_numeric?<br/>    return true if self =~ /\A\d+\Z/<br/>    true if Float(self) rescue false<br/>  end</span><span id="22e9" class="mk jw in mf b gy mq mm l mn mo">  def self.save_vocab vocab_path = ""<br/>    path = "#{vocab_path}vocab.json"<br/>    vocab = JSON.parse(@@vocab.to_json)<br/>    File.write(path, JSON.pretty_generate(vocab))<br/>  end<br/>end</span></pre><p id="d8c7" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi">— — — — — — — — — — — — — — — — — — — — — — — — — — — — — —</p><h1 id="2f98" class="jv jw in bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">五、结论</h1><p id="fefe" class="pw-post-body-paragraph kt ku in kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ig bi translated">下周我们将利用这些 csv 文件通过<code class="fe mc md me mf b">tokenizer</code>来<code class="fe mc md me mf b">vectorize</code>它们，并为每个键创建<code class="fe mc md me mf b">key-specific models</code>。这个项目的最终目标是创建一个<code class="fe mc md me mf b">open-source gem</code>，每个人都可以在代码中使用 JSON 数据结构来实现它。我要感谢读者的关注，感谢才华横溢的塞尔帕皮人在艰难时期创造奇迹，感谢他们的支持。</p></div><div class="ab cl ms mt hr mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ig ih ii ij ik"><p id="755a" class="pw-post-body-paragraph kt ku in kv b kw lr ky kz la ls lc ld le lt lg lh li lu lk ll lm lv lo lp lq ig bi translated"><em class="mz">原载于 2022 年 3 月 30 日 https://serpapi.com</em><a class="ae lw" href="https://serpapi.com/blog/investigating-machine-learning-techniques-to-improve-spec-tests-ii/" rel="noopener ugc nofollow" target="_blank"><em class="mz"/></a><em class="mz">。</em></p></div></div>    
</body>
</html>