<html>
<head>
<title>Implementing K Nearest Neighbors from scratch in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 Python 中从头开始实现 K 近邻</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/implementing-k-nearest-neighbors-from-scratch-in-python-d5eaaf558d49?source=collection_archive---------2-----------------------#2022-02-03">https://blog.devgenius.io/implementing-k-nearest-neighbors-from-scratch-in-python-d5eaaf558d49?source=collection_archive---------2-----------------------#2022-02-03</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><div class=""><h2 id="13cc" class="pw-subtitle-paragraph jk im in bd b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb dk translated">并将我们的模型性能与 Scikit-learn 实现进行比较</h2></div><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi kc"><img src="../Images/1abc841a6862c6a2669f1720c506ffa2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BSSy9Hmjni2LpQzI"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">由<a class="ae ks" href="https://unsplash.com/@derickray?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">吴镇男·麦金尼</a>在<a class="ae ks" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="0c10" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi lp translated"><span class="l lq lr ls bm lt lu lv lw lx di"> K </span>最近邻(KNN)是最简单的监督机器学习算法之一。该算法最初是为分类任务开发的，但后来也扩展到执行回归任务。</p><p id="6fbf" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">与其他有监督的机器学习算法不同，<strong class="kv io"> KNN 没有底层模型，算法只对存储的训练数据进行处理。</strong></p><p id="1c54" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">KNN 试图根据每个测试数据点与训练数据集的距离来预测这些值。因此，该算法不会对数据的特征或输出做出任何假设。</p><p id="777f" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">由于算法的这种性质，它只在引入测试数据后才开始工作并做出预测，因此也被称为<strong class="kv io">懒惰学习者</strong>。</p><p id="763a" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">除了分类和回归任务，KNN 算法还用于缺失值插补、数据集重采样、异常值检测等。KNN 的一些工业应用包括建立推荐系统、手写识别、图像识别等。</p><p id="6f88" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">有几种寻找 K 个最近邻居的方法，如使用矩形判定边界来分类数据点的 K 维树、使用球形判定边界的球树<strong class="kv io">等。在本文中，我们将从头开始使用 Python 实现 KNN 的强力方法。</strong></p><h1 id="2ee5" class="ly lz in bd ma mb mc md me mf mg mh mi jt mj ju mk jw ml jx mm jz mn ka mo mp bi translated">该算法</h1><p id="71ff" class="pw-post-body-paragraph kt ku in kv b kw mq jo ky kz mr jr lb lc ms le lf lg mt li lj lk mu lm ln lo ig bi translated">因此，创建 KNN 模型的步骤如下:</p><ol class=""><li id="ed15" class="mv mw in kv b kw kx kz la lc mx lg my lk mz lo na nb nc nd bi translated">我们首先需要一个 K 的最优值。</li><li id="7301" class="mv mw in kv b kw ne kz nf lc ng lg nh lk ni lo na nb nc nd bi translated">计算测试集中每个数据点与训练集中每个点的距离。</li><li id="1f08" class="mv mw in kv b kw ne kz nf lc ng lg nh lk ni lo na nb nc nd bi translated">按照升序对计算出的距离以及训练数据中相应的目标值进行排序。</li><li id="5431" class="mv mw in kv b kw ne kz nf lc ng lg nh lk ni lo na nb nc nd bi translated">从这些排序的值中，选择 K 个最高值。</li><li id="e9c7" class="mv mw in kv b kw ne kz nf lc ng lg nh lk ni lo na nb nc nd bi translated">对于<strong class="kv io">分类任务</strong>，对应于 K 顶行的数据点的模式将是预测输出，对于<strong class="kv io">回归任务</strong>，均值/中值将是预测输出。</li></ol></div><div class="ab cl nj nk hr nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="ig ih ii ij ik"><h1 id="0811" class="ly lz in bd ma mb nq md me mf nr mh mi jt ns ju mk jw nt jx mm jz nu ka mo mp bi translated">从头开始实施</h1><p id="3323" class="pw-post-body-paragraph kt ku in kv b kw mq jo ky kz mr jr lb lc ms le lf lg mt li lj lk mu lm ln lo ig bi translated">让我们创建我们的 KNN 算法的基本结构。我们将遵循 Scikit-learn 方法，并用 fit 和 predict 方法定义一个类。</p><figure class="kd ke kf kg gt kh"><div class="bz fp l di"><div class="nv nw l"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">图片作者<a class="ae ks" href="https://retinpkumar.medium.com/" rel="noopener">作者</a></figcaption></figure><p id="1e6c" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">我们将使用邻居数量、问题类型和评估标准来初始化我们的类实例。</p><p id="eb7a" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">问题类型将决定它是回归任务还是分类任务，而度量将决定应该使用哪个距离度量来计算距离。</p><p id="6ca8" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">现在，我们将问题类型 0 指定给回归，1 指定给分类。欧几里德距离的度量值为 0，曼哈顿距离的度量值为 1。</p><figure class="kd ke kf kg gt kh"><div class="bz fp l di"><div class="nv nw l"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">图片作者<a class="ae ks" href="https://retinpkumar.medium.com/" rel="noopener">作者</a></figcaption></figure><p id="631a" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">在我们的拟合方法中，我们将用训练数据特征和目标来拟合算法。</p><figure class="kd ke kf kg gt kh"><div class="bz fp l di"><div class="nv nw l"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">图片由<a class="ae ks" href="https://retinpkumar.medium.com/" rel="noopener">作者</a></figcaption></figure><p id="387c" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">在以测试特性数据作为参数的预测方法中，我们有 3 个额外的步骤要执行。</p><ul class=""><li id="0345" class="mv mw in kv b kw kx kz la lc mx lg my lk mz lo nx nb nc nd bi translated">首先，我们计算距离。</li><li id="c841" class="mv mw in kv b kw ne kz nf lc ng lg nh lk ni lo nx nb nc nd bi translated">然后我们计算邻居。</li><li id="f637" class="mv mw in kv b kw ne kz nf lc ng lg nh lk ni lo nx nb nc nd bi translated">最后，我们做出预测。</li></ul><p id="9cc1" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">代码是不言自明的。</p><figure class="kd ke kf kg gt kh"><div class="bz fp l di"><div class="nv nw l"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">图片由<a class="ae ks" href="https://retinpkumar.medium.com/" rel="noopener">作者</a></figcaption></figure><p id="2d95" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">把这些放在一起，我们就有了 BruteForceKNN 算法。</p><figure class="kd ke kf kg gt kh"><div class="bz fp l di"><div class="nv nw l"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">图片作者<a class="ae ks" href="https://retinpkumar.medium.com/" rel="noopener">作者</a></figcaption></figure><p id="54c4" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">现在让我们尝试使用 Scikit learn 库实现 KNN，并计算分类指标。然后，我们将在相同的数据上实现我们的 BruteForceKNN，并比较它相对于 Scikit learn 实现的性能。</p></div><div class="ab cl nj nk hr nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="ig ih ii ij ik"><h1 id="b6e7" class="ly lz in bd ma mb nq md me mf nr mh mi jt ns ju mk jw nt jx mm jz nu ka mo mp bi translated">使用 Scikit 测试-学习实现</h1><p id="aefb" class="pw-post-body-paragraph kt ku in kv b kw mq jo ky kz mr jr lb lc ms le lf lg mt li lj lk mu lm ln lo ig bi translated">让我们导入必要的库和依赖项。</p><figure class="kd ke kf kg gt kh"><div class="bz fp l di"><div class="nv nw l"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">图片作者<a class="ae ks" href="https://retinpkumar.medium.com/" rel="noopener">作者</a></figcaption></figure><p id="5946" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">现在，让我们从 Scikit learn 数据集加载虹膜数据。然后，我们将拆分数据，并使用标准缩放来缩放我们的数据。</p><figure class="kd ke kf kg gt kh"><div class="bz fp l di"><div class="nv nw l"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">图片由<a class="ae ks" href="https://retinpkumar.medium.com/" rel="noopener">作者</a></figcaption></figure><p id="9492" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">现在，我们需要找到'<strong class="kv io"> k </strong>'的最佳值。</p><p id="0c1d" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">为此，我们将使用默认设置实例化一个基本 KNN 分类器，并对范围从 1 到 31 的“k”值进行预测。</p><p id="2726" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">然后我们将计算训练和测试误差，并绘制出<strong class="kv io">误差曲线</strong>。借助于误差曲线，我们将找到‘k’的最佳值。</p><figure class="kd ke kf kg gt kh"><div class="bz fp l di"><div class="nv nw l"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">图片作者<a class="ae ks" href="https://retinpkumar.medium.com/" rel="noopener">作者</a></figcaption></figure><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div class="ab gu cl ny"><img src="../Images/585d9401ca6c5a4a5b3dc538c00843d6.png" data-original-src="https://miro.medium.com/v2/format:webp/1*YyTQYKUWuBDuCMT5YCb41w.png"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">图片作者<a class="ae ks" href="https://retinpkumar.medium.com/" rel="noopener">作者</a></figcaption></figure><p id="19ff" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">从误差曲线中，我们发现 k=14 非常适合我们的数据。因此，我们实例化一个 k=14 的 KNN 对象，拟合训练数据，并使用测试数据进行预测。</p><figure class="kd ke kf kg gt kh"><div class="bz fp l di"><div class="nv nw l"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">图片由<a class="ae ks" href="https://retinpkumar.medium.com/" rel="noopener">作者</a></figcaption></figure><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/a54e94bf570e4c54a1d4080e243599a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*wUaqVfsyUv7KWUm_hdvazA.png"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">图片作者<a class="ae ks" href="https://retinpkumar.medium.com/" rel="noopener">作者</a></figcaption></figure><p id="5008" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">现在，让我们绘制混淆矩阵并检查其他分类指标。</p><figure class="kd ke kf kg gt kh"><div class="bz fp l di"><div class="nv nw l"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">图片由<a class="ae ks" href="https://retinpkumar.medium.com/" rel="noopener">作者</a></figcaption></figure><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div class="ab gu cl ny"><img src="../Images/f0722849527c519ef9349ae506629791.png" data-original-src="https://miro.medium.com/v2/format:webp/1*0pAEvYyalchEhAhswx3M9w.png"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">图片由<a class="ae ks" href="https://retinpkumar.medium.com/" rel="noopener">作者</a></figcaption></figure><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/bf1d9b878e7de4bf135433c2529d93f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*0uqvcJKRFu12EcSfg5ed4w.png"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">图片由<a class="ae ks" href="https://retinpkumar.medium.com/" rel="noopener">作者</a></figcaption></figure></div><div class="ab cl nj nk hr nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="ig ih ii ij ik"><h1 id="0d7c" class="ly lz in bd ma mb nq md me mf nr mh mi jt ns ju mk jw nt jx mm jz nu ka mo mp bi translated">使用我们的强力 KNN 进行测试</h1><p id="3021" class="pw-post-body-paragraph kt ku in kv b kw mq jo ky kz mr jr lb lc ms le lf lg mt li lj lk mu lm ln lo ig bi translated">现在，我们将实例化我们的 BruteForceKNN 类，并用相同的数据进行预测。</p><figure class="kd ke kf kg gt kh"><div class="bz fp l di"><div class="nv nw l"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">图片作者<a class="ae ks" href="https://retinpkumar.medium.com/" rel="noopener">作者</a></figcaption></figure><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi ob"><img src="../Images/d2c7822f79b226d0d6d2743a31fed848.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*tpFV9LwaW4S5cVIh5b_EVA.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">图片由<a class="ae ks" href="https://retinpkumar.medium.com/" rel="noopener">作者</a></figcaption></figure><p id="fbac" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">这太棒了。我们的模型精度与 Scikit-learn 实现相匹配。现在让我们检查混淆矩阵。</p><figure class="kd ke kf kg gt kh"><div class="bz fp l di"><div class="nv nw l"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">图片由<a class="ae ks" href="https://retinpkumar.medium.com/" rel="noopener">作者</a></figcaption></figure><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div class="ab gu cl ny"><img src="../Images/d10320d48d2dc251fe151decf5e8c377.png" data-original-src="https://miro.medium.com/v2/format:webp/1*_uyWskc5ARynpq516cTndQ.png"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">图片作者<a class="ae ks" href="https://retinpkumar.medium.com/" rel="noopener">作者</a></figcaption></figure><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi oc"><img src="../Images/806f6248a70a6001ad67a73b97c82a16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/1*sLd-RKzYJQPv7s2uhzyogQ.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">图片作者<a class="ae ks" href="https://retinpkumar.medium.com/" rel="noopener">作者</a></figcaption></figure><p id="462e" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">我们发现我们的 BruteForceKNN 模型性能与 KNN 分类器的 Scikit-learn 实现完全匹配。</p><p id="1695" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">至此，我们已经到了这篇文章的结尾。</p><p id="6797" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">我希望您喜欢用 Python 从头开始学习和实现 KNN 算法，并比较模型性能和 Scikit-learn API。</p><p id="db93" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">如果你喜欢这篇文章，请<a class="ae ks" href="https://retinpkumar.medium.com/" rel="noopener">关注我</a>以获得更多有趣且可行的帖子。</p></div></div>    
</body>
</html>