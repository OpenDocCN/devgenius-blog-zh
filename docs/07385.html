<html>
<head>
<title>Unit Testing Spark Structured Streaming Application using Memory Stream.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用内存流对 Spark 结构化流应用程序进行单元测试。</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/unit-testing-spark-structured-streaming-application-using-memory-stream-fbaebfd39791?source=collection_archive---------3-----------------------#2022-03-21">https://blog.devgenius.io/unit-testing-spark-structured-streaming-application-using-memory-stream-fbaebfd39791?source=collection_archive---------3-----------------------#2022-03-21</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><figure class="gl gn jl jm jn jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi jk"><img src="../Images/35e04723770dd28087383a43dbe30212.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eQh3bnMUN3sLG9G9vVnwmw.png"/></div></div></figure><p id="8bd6" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">Spark 结构化流提供了强大的 API 来构建连续的应用程序。然而，当谈到流式应用程序的单元测试时，我发现互联网上的可用信息非常有限。</p><h2 id="2f6e" class="kt ku in bd kv kw kx dn ky kz la dp lb kg lc ld le kk lf lg lh ko li lj lk ll bi translated">概观</h2><p id="fbc5" class="pw-post-body-paragraph jv jw in jx b jy lm ka kb kc ln ke kf kg lo ki kj kk lp km kn ko lq kq kr ks ig bi translated">在这篇文章中，我们将探讨如何用<a class="ae lr" href="https://github.com/MayuriD18/MDSparkStreamingUnitTest/tree/master/src/test/java/com/md/spark/sql/streaming" rel="noopener ugc nofollow" target="_blank"> java </a>和<a class="ae lr" href="https://github.com/MayuriD18/MDSparkStreamingUnitTest/tree/master/src/test/scala/com/md/spark/sql/streaming" rel="noopener ugc nofollow" target="_blank"> scala </a>为结构化流应用编写简单的单元测试代码。我们将使用<a class="ae lr" href="https://junit.org/junit5/docs/current/user-guide/" rel="noopener ugc nofollow" target="_blank"> junit </a>框架来编写单元测试用例。我们将利用 apache spark 的<a class="ae lr" href="https://www.javadoc.io/doc/org.apache.spark/spark-sql_2.12/latest/org/apache/spark/sql/execution/streaming/MemoryStream.html" rel="noopener ugc nofollow" target="_blank">内存流</a>。</p><p id="b9f5" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">Spark 的内存流是一个流源，当用户添加值时，它产生存储在内存中的值。此源旨在用于单元测试，因为它只能在对象仍然可用时重放数据。一旦我们创建了内存流，我们必须将测试数据添加到内存流中，我们将应用一些转换，并将实际结果与预期结果进行比较。因此，内存流是在微批处理流处理中支持读取的数据流。</p><p id="843b" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">让我们理解简单的流式作业，我们将使用它进行单元测试和单元测试代码。</p><p id="c0a5" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated"><em class="ls">注意——我们在这篇博客中使用了 Scala API。可以在</em> <a class="ae lr" href="https://github.com/MayuriD18/MDSparkStreamingUnitTest/tree/master/src/test/java/com/md/spark/sql/streaming" rel="noopener ugc nofollow" target="_blank"> <strong class="jx io"> GitHub </strong> </a>上找到 Java API 代码。</p><p id="6591" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated"><strong class="jx io"> Spark 结构化流作业</strong></p><blockquote class="lt lu lv"><p id="c192" class="jv jw ls jx b jy jz ka kb kc kd ke kf lw kh ki kj lx kl km kn ly kp kq kr ks ig bi translated">在我们的流应用程序中，我们过滤了部门为“营销”的人员。这只是我们写的简单的过滤查询。</p></blockquote><figure class="ma mb mc md gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi lz"><img src="../Images/fafc1b13f935b267074b36b4ba2fe372.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TE9on8zRua9wH2e1SDaIVw.png"/></div></div><figcaption class="me mf gj gh gi mg mh bd b be z dk translated">scala 中的过滤方法</figcaption></figure><p id="5c75" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">在上面的代码中，</p><ul class=""><li id="34ce" class="mi mj in jx b jy jz kc kd kg mk kk ml ko mm ks mn mo mp mq bi translated">我们有 Person case 类，定义了人的属性。</li><li id="f54c" class="mi mj in jx b jy mr kc ms kg mt kk mu ko mv ks mn mo mp mq bi translated">我们将为其编写单元测试的流过滤方法。</li></ul><h2 id="af04" class="kt ku in bd kv kw kx dn ky kz la dp lb kg lc ld le kk lf lg lh ko li lj lk ll bi translated"><strong class="ak">使用内存流的单元测试代码</strong></h2><blockquote class="lt lu lv"><p id="b1cd" class="jv jw ls jx b jy jz ka kb kc kd ke kf lw kh ki kj lx kl km kn ly kp kq kr ks ig bi translated">创建内存流-</p></blockquote><pre class="ma mb mc md gt mw mx my mz aw na bi"><span id="b5bd" class="kt ku in mx b gy nb nc l nd ne">import org.apache.spark.sql.{Encoder, Encoders}<br/>implicit val personEncoder: Encoder[Person] = Encoders.<em class="ls">product</em>[Person]<br/><br/>val inputStream: MemoryStream[Person] = new MemoryStream[Person](1, <em class="ls">spark</em>.<em class="ls">sqlContext</em>,<em class="ls">Some</em>(5))<br/>implicit val sqlCtx: SQLContext = <em class="ls">spark</em>.<em class="ls">sqlContext<br/></em>val sessions = inputStream.toDF</span></pre><p id="9b02" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">我们已经创建了 Person 类的内存流，并使用 toDF 将内存流转换为 Dataframe[Person]</p><blockquote class="lt lu lv"><p id="c163" class="jv jw ls jx b jy jz ka kb kc kd ke kf lw kh ki kj lx kl km kn ly kp kq kr ks ig bi translated">调用转换(业务逻辑或者我们为之编写单元测试的方法)</p></blockquote><pre class="ma mb mc md gt mw mx my mz aw na bi"><span id="b053" class="kt ku in mx b gy nb nc l nd ne">val filteredDF = DataframeFilter.<em class="ls">streamFiltering</em>(sessions)</span></pre><p id="9fb8" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">我们调用我们的过滤方法，如上图所示。此方法筛选部门为“营销”的人员。</p><blockquote class="lt lu lv"><p id="692d" class="jv jw ls jx b jy jz ka kb kc kd ke kf lw kh ki kj lx kl km kn ly kp kq kr ks ig bi translated">将输出写入内存表</p></blockquote><pre class="ma mb mc md gt mw mx my mz aw na bi"><span id="f7f6" class="kt ku in mx b gy nb nc l nd ne">val streamingQuery = filteredDF.writeStream.format("memory").queryName("person").outputMode("append").start</span></pre><p id="27dd" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">现在，我们将把过滤后的流写入内存表“person ”,保持输出模式 append。这将启动我们的流式查询。但是到目前为止，查询正在处理 0 行，因为我们还没有向内存流添加数据。</p><blockquote class="lt lu lv"><p id="9643" class="jv jw ls jx b jy jz ka kb kc kd ke kf lw kh ki kj lx kl km kn ly kp kq kr ks ig bi translated">将数据添加到内存流并处理它</p></blockquote><pre class="ma mb mc md gt mw mx my mz aw na bi"><span id="dabf" class="kt ku in mx b gy nb nc l nd ne">val inputData = <em class="ls">Seq</em>(<em class="ls">Person</em>("donna","india","finance"), <em class="ls">Person</em>("dora","india","marketing"), <em class="ls">Person</em>("dina","india","marketing"))</span><span id="8ae2" class="kt ku in mx b gy nf nc l nd ne">inputStream.addData(inputData)</span><span id="05d5" class="kt ku in mx b gy nf nc l nd ne">streamingQuery.processAllAvailable()</span></pre><p id="3320" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">我们通过直接在代码中添加数据，创建了 Seq[Person]。我们可以使用 json 来读取(github java 测试代码中提供了示例)。</p><blockquote class="lt lu lv"><p id="509b" class="jv jw ls jx b jy jz ka kb kc kd ke kf lw kh ki kj lx kl km kn ly kp kq kr ks ig bi translated">主张</p></blockquote><pre class="ma mb mc md gt mw mx my mz aw na bi"><span id="69e2" class="kt ku in mx b gy nb nc l nd ne">val result = <em class="ls">spark</em>.sql("select * from person").collectAsList<br/><br/><em class="ls">assertEquals</em>("Filtering the Input Stream should get filtered correctly", 2, result.size)<br/><br/><em class="ls">assertEquals</em>(RowFactory.<em class="ls">create</em>("dora", "india", "marketing"), result.get(0))</span></pre><p id="d3a0" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">使用写流，我们将数据保存到内存表 person 中，现在我们从 person 表中读取数据，将其收集为列表，并使用它来比较实际结果和预期结果。我们可以使用各种 spark sql 命令，并获得特定的记录用于输出比较。</p><blockquote class="lt lu lv"><p id="f345" class="jv jw ls jx b jy jz ka kb kc kd ke kf lw kh ki kj lx kl km kn ly kp kq kr ks ig bi translated">将新数据添加到相同的流中并处理它</p></blockquote><pre class="ma mb mc md gt mw mx my mz aw na bi"><span id="9d24" class="kt ku in mx b gy nb nc l nd ne">val inputData1 = <em class="ls">Seq</em>(<em class="ls">Person</em>("sam","india","marketing"), <em class="ls">Person</em>("sara","india","marketing"))</span><span id="4b6e" class="kt ku in mx b gy nf nc l nd ne">inputStream.addData(inputData1)</span><span id="2231" class="kt ku in mx b gy nf nc l nd ne">streamingQuery.processAllAvailable()</span></pre><p id="06de" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">我们已经将新的两个事件添加到流中，并对其进行了处理。这将使用新数据更新内存表。</p><blockquote class="lt lu lv"><p id="d5bb" class="jv jw ls jx b jy jz ka kb kc kd ke kf lw kh ki kj lx kl km kn ly kp kq kr ks ig bi translated">对更新数据的断言</p></blockquote><pre class="ma mb mc md gt mw mx my mz aw na bi"><span id="ae0b" class="kt ku in mx b gy nb nc l nd ne">result = <em class="ls">spark</em>.sql("select * from person").collectAsList<br/><br/><em class="ls">assertEquals</em>("Filtering the Input Stream should get filtered correctly", 4, result.size)</span></pre><p id="cf9b" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">最后，根据更新的数据，我们写了更多的断言。现在结果大小为 4，因为我们与部门有 4 个事件。</p><p id="33a2" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">至此，我们已经成功地为 spark 流应用程序编写了单元测试！！</p></div><div class="ab cl ng nh hr ni" role="separator"><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl"/></div><div class="ig ih ii ij ik"><p id="d076" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">我希望这个概述对您有所帮助！<br/>为了便于参考，可以在<strong class="jx io"> </strong> <a class="ae lr" href="https://github.com/MayuriD18/MDSparkStreamingUnitTest/tree/master/src/test/java/com/md/spark/sql/streaming" rel="noopener ugc nofollow" target="_blank"> <strong class="jx io"> GitHub </strong> </a>上找到完整的代码。它将涵盖 scala 和 java API 中的单元测试用例。</p></div></div>    
</body>
</html>