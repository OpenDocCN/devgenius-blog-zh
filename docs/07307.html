<html>
<head>
<title>Coreference Resolution [NLP, Python]</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">共指消解[NLP，Python]</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/coreference-resolution-nlp-python-584c2ec50f5d?source=collection_archive---------3-----------------------#2022-03-14">https://blog.devgenius.io/coreference-resolution-nlp-python-584c2ec50f5d?source=collection_archive---------3-----------------------#2022-03-14</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><figure class="gl gn jl jm jn jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi jk"><img src="../Images/93d0846cb76a4000e350987e4efa34dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*l4b8FQIemOyFcNKe.png"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk translated">来源:https://nlp.stanford.edu/projects/coref.shtml</figcaption></figure><p id="2ada" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">共指消解的任务是找出所有指称的表达，如—(他、我、那个、这个……或任何主语或名词)所指的是哪个实体(指称物，如任何人、事物、主语等)...)</p><p id="06e4" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated"><strong class="kc io">某些类型的证明人</strong></p><ul class=""><li id="5c6f" class="ky kz in kc b kd ke kh ki kl la kp lb kt lc kx ld le lf lg bi translated"><strong class="kc io">回指</strong> — acc。在维基百科中→ <strong class="kc io"> " </strong> <em class="lh">回指是一个表达式的使用，其解释具体取决于另一个(先行)表达式</em> <strong class="kc io"> " </strong>或者当所指表达式(回指)指向后 <strong class="kc io"> " </strong>时，你可以说<strong class="kc io"> " </strong> <em class="lh"/></li></ul><blockquote class="li lj lk"><p id="99a1" class="ka kb lh kc b kd ke kf kg kh ki kj kk ll km kn ko lm kq kr ks ln ku kv kw kx ig bi translated">例子:- <strong class="kc io">音乐太吵了，以至于<strong class="kc io">T21 无法欣赏</strong></strong></p><p id="2108" class="ka kb lh kc b kd ke kf kg kh ki kj kk ll km kn ko lm kq kr ks ln ku kv kw kx ig bi translated"><strong class="kc io"> it </strong> →这里指的是<strong class="kc io">音乐，</strong>这里的“it”出现在句子中“The music”之后。</p></blockquote><ul class=""><li id="22a8" class="ky kz in kc b kd ke kh ki kl la kp lb kt lc kx ld le lf lg bi translated"><strong class="kc io">下指</strong>——据说正好是前指的反义词→<strong class="kc io"/><em class="lh">使用一个依赖于后置表达式</em><strong class="kc io"/>的表达式，或者当所指表达式指向前方<strong class="kc io"/>时，你可以说<strong class="kc io"/><em class="lh"/></li></ul><blockquote class="li lj lk"><p id="b8ed" class="ka kb lh kc b kd ke kf kg kh ki kj kk ll km kn ko lm kq kr ks ln ku kv kw kx ig bi translated">例句:<strong class="kc io">他</strong>到家时，<strong class="kc io">约翰</strong>就去睡觉了。</p><p id="40f9" class="ka kb lh kc b kd ke kf kg kh ki kj kk ll km kn ko lm kq kr ks ln ku kv kw kx ig bi translated"><strong class="kc io">何</strong>是指<strong class="kc io">约翰，</strong>句中“他”在“约翰”之前。</p></blockquote><p id="aafb" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">分裂先行词这是一种回指表达，代词(2)指代不止一个先行词(1)。</p><figure class="lp lq lr ls gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi lo"><img src="../Images/0eb58f16270b7ecc562b708aaa36e2a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*zg2Sn-NJrOvUla3O.jpg"/></div></div></figure><figure class="lp lq lr ls gt jo gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/1af11e43504c93edad27ca03a658feef.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/0*4SxdBYADUWSyh6jq.jpg"/></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk translated">资料来源:ScienceDirect.com</figcaption></figure><p id="392c" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">我们将关注<strong class="kc io">共指解析</strong>——它的任务是确定是否有两个或更多的提及<em class="lh">共指(意思是它们是指同一个实体……)</em></p><p id="4388" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">一个共指表达只有在它的解释依赖于文本中的前一个表达(即它的先行词)时才是回指</p><blockquote class="li lj lk"><p id="3e0c" class="ka kb lh kc b kd ke kf kg kh ki kj kk ll km kn ko lm kq kr ks ln ku kv kw kx ig bi translated">命名提及代替代词的例子:- <br/> 1。<strong class="kc io">国际商业机器</strong>向亚马逊寻求专利赔偿；IBM 之前曾起诉过其他公司。你可以看到 IBM 指的是国际商用机器公司。这些类型参考也在那里..</p><p id="004f" class="ka kb lh kc b kd ke kf kg kh ki kj kk ll km kn ko lm kq kr ks ln ku kv kw kx ig bi translated"><strong class="kc io"> 2。巴拉克·奥巴马</strong>前往…<strong class="kc io">奥巴马</strong>……<br/>所以我们可以看到“奥巴马”和“巴拉克·奥巴马”指的是同一个人。</p></blockquote><p id="7f79" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">因此，共指消解包括两个任务(尽管它们通常是联合执行的):(1)识别提及，以及(2)将它们聚类成共指链/话语实体</p><p id="6899" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">让我们看另一个例子</p><blockquote class="li lj lk"><p id="5b44" class="ka kb lh kc b kd ke kf kg kh ki kj kk ll km kn ko lm kq kr ks ln ku kv kw kx ig bi translated">Megabucks Banking 的首席财务官维多利亚·陈(Victoria Chen)在 38 岁成为公司总裁后，薪酬跃升至 230 万美元。众所周知，她是从竞争对手变成百万富翁的</p></blockquote><p id="3636" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">让我们把上面的例子组合起来:</p><ol class=""><li id="5c42" class="ky kz in kc b kd ke kh ki kl la kp lb kt lc kx lu le lf lg bi translated">维多利亚·陈，她，38 岁，她</li><li id="90c7" class="ky kz in kc b kd lv kh lw kl lx kp ly kt lz kx lu le lf lg bi translated">银行，公司，巨款</li><li id="8270" class="ky kz in kc b kd lv kh lw kl lx kp ly kt lz kx lu le lf lg bi translated">她的工资</li><li id="275f" class="ky kz in kc b kd lv kh lw kl lx kp ly kt lz kx lu le lf lg bi translated">Lotsabucks</li></ol><p id="594c" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">一个在文本中只有一次提及的实体(比如 Lotsabucks 和她的工资)被称为<strong class="kc io">单身</strong>。</p><h2 id="f84a" class="ma mb in bd mc md me dn mf mg mh dp mi kl mj mk ml kp mm mn mo kt mp mq mr ms bi translated">应用:</h2><ul class=""><li id="1d09" class="ky kz in kc b kd mt kh mu kl mv kp mw kt mx kx ld le lf lg bi translated">文本摘要</li><li id="c07d" class="ky kz in kc b kd lv kh lw kl lx kp ly kt lz kx ld le lf lg bi translated">机器翻译</li><li id="3cc6" class="ky kz in kc b kd lv kh lw kl lx kp ly kt lz kx ld le lf lg bi translated">信息提取</li><li id="9fc9" class="ky kz in kc b kd lv kh lw kl lx kp ly kt lz kx ld le lf lg bi translated">聊天机器人/问答系统</li></ul><blockquote class="my"><p id="b910" class="mz na in bd nb nc nd ne nf ng nh kx dk translated">让我们举一个问答引擎的真实例子:-</p></blockquote><p id="a7fd" class="pw-post-body-paragraph ka kb in kc b kd ni kf kg kh nj kj kk kl nk kn ko kp nl kr ks kt nm kv kw kx ig bi translated"><strong class="kc io">提供给 QnA 引擎的内容</strong>→<br/><em class="lh">小约瑟夫·罗比内特·拜登</em> <strong class="kc io">。</strong>是美国政治家，美国第 46 任、现任总统。作为民主党成员，他在 2009 年至 2017 年期间担任巴拉克·奥巴马的第 47 任副总统，并在 1973 年至 2009 年期间代表特拉华州参加美国参议院。</p><p id="8620" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated"><strong class="kc io">现在如果我们问问题</strong>→“2009 年至 2017 年谁担任第 47 任副总统？”</p><p id="d05e" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">在 QnA 引擎<strong class="kc io">中，如果没有参考分辨率</strong>，它会给出→<strong class="kc io">he</strong>但这不是我们想要的答案，对吗？我们在这里知道“<strong class="kc io">何</strong>”指的是<strong class="kc io">约瑟夫·罗比内特·拜登。</strong>我们想要他的名字作为正确答案..？这就是共指消解的用武之地。它让我们知道，他是指约瑟夫罗比内特拜登，以便我们工作的东西，并取代“他”或任何其他提及，在幕后。以便我们得到适当的答案。</p><h1 id="14d8" class="nn mb in bd mc no np nq mf nr ns nt mi nu nv nw ml nx ny nz mo oa ob oc mr od bi translated">履行</h1><h2 id="8094" class="ma mb in bd mc md me dn mf mg mh dp mi kl mj mk ml kp mm mn mo kt mp mq mr ms bi translated">spaCy-hugging face(neural oref)共指消解</h2><p id="4c66" class="pw-post-body-paragraph ka kb in kc b kd mt kf kg kh mu kj kk kl oe kn ko kp of kr ks kt og kv kw kx ig bi translated">NeuralCoref 是 spaCy 2.1+的管道扩展，它使用神经网络标注和解析共指聚类。NeuralCoref 是生产就绪的，集成在 spaCy 的 NLP 管道中，并可扩展到新的训练数据集。</p><figure class="lp lq lr ls gt jo"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="1ce0" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">除了<code class="fe oj ok ol om b">coref_clusters</code>、<code class="fe oj ok ol om b">coref_resolved</code>之外，你还可以在 github <a class="ae jz" href="https://github.com/huggingface/neuralcoref" rel="noopener ugc nofollow" target="_blank">这里</a>查看更多属性。</p><p id="435f" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated"><em class="lh">要训练神经共指模型你可以在这里查看博客</em> <a class="ae jz" href="https://medium.com/huggingface/how-to-train-a-neural-coreference-model-neuralcoref-2-7bb30c1abdfe" rel="noopener">。</a></p><h2 id="0745" class="ma mb in bd mc md me dn mf mg mh dp mi kl mj mk ml kp mm mn mo kt mp mq mr ms bi translated">Allennlp 共指消解</h2><p id="44a2" class="pw-post-body-paragraph ka kb in kc b kd mt kf kg kh mu kj kk kl oe kn ko kp of kr ks kt og kv kw kx ig bi translated"><code class="fe oj ok ol om b">pip install allennlp<br/>pip install allennlp-models</code></p><figure class="lp lq lr ls gt jo"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="7373" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">如果你注意到上面的输出集群形成的是[0 到 3 和 26 到 26]和[34 到 34 和 56 到 56]这些是给令牌的索引。请看下面，这些是什么</p><pre class="lp lq lr ls gt on om oo op aw oq bi"><span id="422e" class="ma mb in om b gy or os l ot ou">print(prediction['document'])</span></pre><p id="c7ab" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">输出:</p><pre class="lp lq lr ls gt on om oo op aw oq bi"><span id="4233" class="ma mb in om b gy or os l ot ou">[<strong class="om io">'Joseph', 'Robinette', 'Biden', 'Jr.'</strong>, 'is', 'an', 'American', 'politician', 'who', 'is', 'the', '46th', 'andcurrent', 'president', 'of', 'the', 'United', 'States', '.', 'A', 'member', 'of', 'the', 'Democratic', 'Party', ',', <strong class="om io">'he'</strong>, 'served', 'as', 'the', '47th', 'vice', 'president', 'from', <strong class="om io">'2009'</strong>, 'to', '2017', 'under', 'Barack', 'Obama', 'andrepresented', 'Delaware', 'in', 'the', 'United', 'States', 'Senate', 'from', '1973', 'to', <strong class="om io">'2009'</strong>, '.']</span></pre><p id="3064" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">如果你注意到代表<code class="fe oj ok ol om b">Joseph Robinette Biden Jr.</code> (0，1，2，3)的索引 0–3 和索引 26 ( <code class="fe oj ok ol om b">‘he’</code>)这是一个集群。另一个是<code class="fe oj ok ol om b">2009</code>本身，所以我们可以忽略它。</p><p id="25f4" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">阅读<a class="ae jz" href="https://towardsdatascience.com/how-to-make-an-effective-coreference-resolution-model-55875d2b5f19" rel="noopener" target="_blank">博客</a>关于如何建立有效的共指消解模型。<br/>它还解释了<strong class="kc io"> Allennlp 似乎比 Huggingface neural corf</strong>找到了更多的聚类，并且 hugging face 在检测下指时存在一些问题，Allennlp 在句子中检测下指，但它在聚类中用它的第一次提及替换，因为它认为第一次提及是它的头。在这篇解释优美的博客<a class="ae jz" href="https://medium.com/@m.maslankowska" rel="noopener">中，玛莎</a>解释了如何克服这个问题并做出一些改进。你可以在这里查看博客<a class="ae jz" href="https://towardsdatascience.com/how-to-make-an-effective-coreference-resolution-model-55875d2b5f19" rel="noopener" target="_blank"><strong class="kc io"/></a>，在这里查看代码<a class="ae jz" href="https://github.com/NeuroSYS-pl/coreference-resolution/blob/main/improvements_to_allennlp_cr.ipynb" rel="noopener ugc nofollow" target="_blank"><strong class="kc io"/></a>……这些经过改进的库仍然会给我们很好但并不完美的结果。关于如何制作更好的共指消解模型的研究仍在继续。</p></div></div>    
</body>
</html>