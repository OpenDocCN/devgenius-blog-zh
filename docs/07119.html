<html>
<head>
<title>Paper Explained — NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">论文解释——NeRF:将场景表示为用于视图合成的神经辐射场</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/paper-explained-nerf-representing-scenes-as-neural-radiance-fields-for-view-synthesis-e16567180531?source=collection_archive---------0-----------------------#2022-02-28">https://blog.devgenius.io/paper-explained-nerf-representing-scenes-as-neural-radiance-fields-for-view-synthesis-e16567180531?source=collection_archive---------0-----------------------#2022-02-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/b53a41990df86c236f4d10bbf230411e.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/1*TMVO-IsZNM0kl-2xDQqW6A.gif"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk translated">GIF 图片来自官方 GitHub repo </figcaption></figure><h1 id="4fc6" class="jz ka iq bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">介绍</h1><p id="6de4" class="pw-post-body-paragraph kx ky iq kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated">当它问世时，<a class="ae jy" href="https://arxiv.org/abs/2003.08934" rel="noopener ugc nofollow" target="_blank"> NeRF:将场景表示为用于视图合成的神经辐射场</a>论文彻底改变了它的领域，产生了大量受其启发的后续作品。尽管如此，我还没能在网上找到一个对这个领域的新手来说容易理解的解释，并且解释得足够详细以至于能真正理解它到底是怎么回事。有了这篇文章，希望能填补这个空白。</p><p id="9b7b" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">在接下来的内容中，我将引导你阅读这篇文章，澄清第一次阅读时可能会模糊的部分。对于那些想进一步探索这些主题的人，他们可以在本文末尾找到更多的资料。</p><h1 id="b578" class="jz ka iq bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">新视图合成</h1><p id="3652" class="pw-post-body-paragraph kx ky iq kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated"><strong class="kz ir">神经辐射场</strong> ( <strong class="kz ir"> NeRF </strong>)试图解决的问题被称为<strong class="kz ir">新颖视图合成</strong>，如<a class="ae jy" href="https://paperswithcode.com/task/novel-view-synthesis" rel="noopener ugc nofollow" target="_blank">论文中所描述的代码</a>其在于:</p><blockquote class="ma mb mc"><p id="2d2a" class="kx ky md kz b la lv lc ld le lw lg lh me lx lk ll mf ly lo lp mg lz ls lt lu ij bi translated">从给定的源图像和它们的相机姿态合成具有任意目标相机姿态的目标图像。</p></blockquote><p id="819f" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">这项技术很重要，因为它可以实现从<strong class="kz ir">电影摄影</strong>到<strong class="kz ir">虚拟现实</strong>等广泛的应用。</p><h1 id="dded" class="jz ka iq bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">为什么这篇论文是相关的</h1><p id="17be" class="pw-post-body-paragraph kx ky iq kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated">尤其是在计算机视觉领域，一张图片(或者更好的是一段视频)胜过千言万语:</p><figure class="mi mj mk ml gt jr gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/7e283554d5185f1d410d55b36bccc684.png" data-original-src="https://miro.medium.com/v2/resize:fit:1088/format:webp/1*lt8FkeNEAn2NGecn-bTHNw.png"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk translated">经<a class="ae jy" href="https://arxiv.org/abs/2003.08934" rel="noopener ugc nofollow" target="_blank">原稿</a>许可拍摄的图像</figcaption></figure><p id="fb9b" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">从上面可以清楚地看到，NeRF 通过启动一个可与 GANs 相媲美的新研究系列，极大地提高了技术水平，例如参见 Hassan Abu Alhaija 的推文:</p><figure class="mi mj mk ml gt jr"><div class="bz fp l di"><div class="mm mn l"/></div></figure><h1 id="ded5" class="jz ka iq bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">神经辐射场场景表示</h1><h2 id="ad7d" class="mo ka iq bd kb mp mq dn kf mr ms dp kj li mt mu kn lm mv mw kr lq mx my kv mz bi translated">输入和输出</h2><figure class="mi mj mk ml gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="nb nc di nd bf ne"><div class="gh gi na"><img src="../Images/9ef776cdcdbcb0d053e0a9108ca6696b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jUC3Ta_Dsuhs17reDHxS6A.png"/></div></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk translated">图片经<a class="ae jy" href="https://arxiv.org/abs/2003.08934" rel="noopener ugc nofollow" target="_blank">原文</a>许可拍摄</figcaption></figure><p id="5d6e" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">让我们先来理解一个场景是如何被 NeRF 表示的:</p><blockquote class="ma mb mc"><p id="dd55" class="kx ky md kz b la lv lc ld le lw lg lh me lx lk ll mf ly lo lp mg lz ls lt lu ij bi translated">我们将连续场景表示为 5D 向量值函数，其输入是 3D 位置 x = (x，y，z)和 2D 观察方向(θ，φ)的<br/>，其输出是发射的颜色 c = (r，g，b)和体积密度σ。</p></blockquote><p id="a1dd" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">在实践中，<strong class="kz ir">观察方向</strong>被表示为 3D 笛卡尔单位向量<strong class="kz ir"> d </strong>，所以让我们想象一个单位长度的向量，它从我们相机的光学中心开始，指向我们正在取景的方向。</p><p id="082a" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated"><em class="md">光学中心对你来说是一个晦涩难懂的词吗？没听说过针孔摄像头模型？看看我的另一篇文章:</em></p><div class="nf ng gp gr nh ni"><a href="https://medium.com/analytics-vidhya/simple-camera-models-with-numpy-and-matplotlib-92281f15f9b2" rel="noopener follow" target="_blank"><div class="nj ab fo"><div class="nk ab nl cl cj nm"><h2 class="bd ir gy z fp nn fr fs no fu fw ip bi translated">使用 NumPy 和 Matplotlib 的简单相机模型</h2><div class="np l"><h3 class="bd b gy z fp nn fr fs no fu fw dk translated">几何学乍一看很难理解。为了更好地吸收这些概念，最好的方法是在…</h3></div><div class="nq l"><p class="bd b dl z fp nn fr fs no fu fw dk translated">medium.com</p></div></div><div class="nr l"><div class="ns l nt nu nv nr nw js ni"/></div></div></a></div><p id="588d" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">但不管这些，为什么知道方向对预测特定点发出的颜色很重要呢？事实上，这并不总是必要的。在完全<strong class="kz ir">朗伯</strong>表面的情况下(想象一个像陶土花瓶一样的理想“无光泽”表面)，当光线击中一个点时，光线稍微进入物体的表面，并向各个方向散射。在这种情况下，我可以从任何方向看这个点，它的颜色都是一样的。在另一个极端，我们有一面<strong class="kz ir">完美的镜子</strong>:在这种情况下，每条光线只向一个方向反射，这使得，例如，当我们看着一面镜子时，我们看到的东西会根据我们的观察位置而变化。该论文的图 3 显示了观察方向的影响:</p><figure class="mi mj mk ml gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="nb nc di nd bf ne"><div class="gh gi nx"><img src="../Images/b31f5aa3f6f6e2be459db4eeb7272d5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AImjrPGKViZqhyc7TT_PWw.png"/></div></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk translated">经<a class="ae jy" href="https://arxiv.org/abs/2003.08934" rel="noopener ugc nofollow" target="_blank">原稿</a>许可拍摄的图像</figcaption></figure><p id="dec4" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">最后，<strong class="kz ir">体积密度</strong>模拟物体的不透明程度。让我们想象一下，我们戴上太阳镜。因为它们不是完全不透明的，我们可以透过它们看东西，我们看到的颜色受我们使用的镜头的颜色影响。因此，从理论上讲，要确定在给定像素中观察到的颜色，我们必须分析一条线或“<strong class="kz ir">相机</strong> <strong class="kz ir">光线</strong>”中所有点的特征，这条线或光线从我们相机的光学中心发出，并沿着我们的观察方向无限延伸。</p><h2 id="d0fb" class="mo ka iq bd kb mp mq dn kf mr ms dp kj li mt mu kn lm mv mw kr lq mx my kv mz bi translated">模型架构</h2><figure class="mi mj mk ml gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="nb nc di nd bf ne"><div class="gh gi ny"><img src="../Images/f303da730a6cbd79406c102477167471.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cYENpNGA1hkUJcpRYlkbmQ.png"/></div></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk translated">经<a class="ae jy" href="https://arxiv.org/abs/2003.08934" rel="noopener ugc nofollow" target="_blank">原稿</a>许可拍摄的图像</figcaption></figure><p id="667d" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">为了将输入映射到期望的输出，NeRF 使用一个简单的<strong class="kz ir">多层感知器</strong>(<strong class="kz ir">MLP</strong>)fθ:(<strong class="kz ir">x</strong>，<strong class="kz ir"> d </strong> ) → ( <strong class="kz ir"> c </strong>，σ)，其中θ是其要优化的权重。</p><p id="7d8e" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">暂时忽略位置编码γ( <strong class="kz ir"> x </strong>)，我们将在后面讨论它，并且假设它仅仅是输入坐标<strong class="kz ir"> x </strong>，从图 7 中我们可以看到，仅从这些坐标预测体积密度σ，同时预测颜色也考虑输入观察方向γ( <strong class="kz ir"> d </strong>)的(位置编码)。由于点的密度不依赖于观察点的位置，因此使用观察方向来预测它会使多视图表示不一致。</p><h1 id="93ba" class="jz ka iq bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">辐射场体绘制</h1><p id="db74" class="pw-post-body-paragraph kx ky iq kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated">假设我们有一个系统，它为沿着<strong class="kz ir">相机光线</strong><strong class="kz ir">r</strong>(<em class="md">t</em>)=<strong class="kz ir">o</strong>+<em class="md">t</em><strong class="kz ir">d</strong>的每个 3D 点提供密度和颜色，我们如何计算给定像素的<strong class="kz ir">预期颜色</strong>？为此，作者使用了<a class="ae jy" href="https://dl.acm.org/doi/10.1145/964965.808594" rel="noopener ugc nofollow" target="_blank">经典的体绘制原理</a>:</p><figure class="mi mj mk ml gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="nb nc di nd bf ne"><div class="gh gi nz"><img src="../Images/843ddfe6572504fee0ecf880c450dc47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vccYGsEwhWq78_89QPA1-w.png"/></div></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk translated">经<a class="ae jy" href="https://arxiv.org/abs/2003.08934" rel="noopener ugc nofollow" target="_blank">原稿</a>许可拍摄的图像</figcaption></figure><p id="103d" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">在上面的公式中，<em class="md"> tn </em>和<em class="md"> tf </em>是相机光线的近的<strong class="kz ir">和远<strong class="kz ir">的</strong>和<strong class="kz ir">边界</strong>，也就是我们忽略这个范围之外的一切，<em class="md"> T(t) </em>表示光线从<em class="md"> tn </em>行进到<em class="md"> t </em>而没有碰到任何其他粒子的概率。注意，由于σ总是非负的，<em class="md"> T(t) </em>只能随着<em class="md"> t </em>的增加而减少或保持不变；如果我们想象几个部分透明的物体在彼此前面，这在直觉上是有意义的，在某个点上，最远的物体的影响将几乎为零。为了进一步帮助直观，我们注意到沿着光线<strong class="kz ir"> r </strong> ( <em class="md"> t </em>)的一个点如何基于其发出的颜色<strong class="kz ir">C</strong>(<strong class="kz ir">r</strong>(<em class="md">T</em>)、<strong class="kz ir"> d </strong>)对最终颜色<em class="md"> C </em> ( <strong class="kz ir"> r </strong>)做出贡献，这也取决于观察方向<strong class="kz ir"> d </strong>，并且</strong></p><p id="57d1" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">上面的公式是连续的，为了估计<em class="md"> C </em> ( <strong class="kz ir"> r </strong>)我们需要<strong class="kz ir">将其离散化</strong>，使用<a class="ae jy" href="https://en.wikipedia.org/wiki/Quadrature_(mathematics)" rel="noopener ugc nofollow" target="_blank">求积</a>。作者更喜欢使用<strong class="kz ir">分层抽样方法</strong>，而不是使用确定性正交，限制 MLP 的空间分辨率，然后只在固定的离散位置集进行查询。在实践中，他们将[ <em class="md"> tn </em>，<em class="md"> t </em> f]分成<em class="md"> N </em>个均匀间隔的箱，然后从每个箱内随机抽取一个样本，这导致在优化过程中在连续位置评估 MLP:</p><figure class="mi mj mk ml gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="nb nc di nd bf ne"><div class="gh gi oa"><img src="../Images/566560a057eb08ecc1cd5fdee4e669c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rA45WWejOfDECndSqCh3CA.png"/></div></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk translated">经<a class="ae jy" href="https://arxiv.org/abs/2003.08934" rel="noopener ugc nofollow" target="_blank">原稿</a>许可拍摄的图像</figcaption></figure><p id="6bf4" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">然后，使用 Max 在<a class="ae jy" href="https://ieeexplore.ieee.org/document/468400" rel="noopener ugc nofollow" target="_blank">体积渲染审查中讨论的<strong class="kz ir">求积规则</strong>，将得到的样本用于估计<em class="md"> C </em> ( <strong class="kz ir"> r </strong>):</a></p><figure class="mi mj mk ml gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="nb nc di nd bf ne"><div class="gh gi ob"><img src="../Images/bacf9b81b0a4ec09f689fe7b19914fc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fQUB7G5nHGFmIGXpxQU_4Q.png"/></div></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk translated">经<a class="ae jy" href="https://arxiv.org/abs/2003.08934" rel="noopener ugc nofollow" target="_blank">原稿</a>许可拍摄的图像</figcaption></figure><p id="c9f2" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">其中<em class="md">δI</em>=<em class="md">ti</em>+1<em class="md">ti</em>为相邻样本之间的距离。</p><p id="2e59" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">这样定义的函数是<strong class="kz ir">可微的</strong>，这是一个关键属性，因为我们想使用<strong class="kz ir">梯度下降</strong>来优化我们的参数！</p><h1 id="68c1" class="jz ka iq bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated"><strong class="ak">优化神经辐射场</strong></h1><p id="7284" class="pw-post-body-paragraph kx ky iq kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated">到目前为止，提出的核心组件不足以实现最先进的结果。这里我们引入另外两个组件:<strong class="kz ir">位置编码、</strong>以更好地模拟高频函数，以及<strong class="kz ir">分层采样</strong>过程，以有效地对这种高频表示进行采样。</p><h2 id="38a4" class="mo ka iq bd kb mp mq dn kf mr ms dp kj li mt mu kn lm mv mw kr lq mx my kv mz bi translated">位置编码</h2><figure class="mi mj mk ml gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="nb nc di nd bf ne"><div class="gh gi oc"><img src="../Images/b4b04c1fe5e4e5ae443eb8a3e114e91c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PJw56h8ZP-9owlQPyHnkrQ.png"/></div></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk translated">经<a class="ae jy" href="https://arxiv.org/abs/2003.08934" rel="noopener ugc nofollow" target="_blank">原稿</a>许可拍摄的图像</figcaption></figure><p id="0dbf" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">上面你可以看到使用位置编码的好处。没有这些，高频率的几何图形和纹理实际上是模糊的。但是什么是位置编码呢？在论文中，他们使用了以下<strong class="kz ir">编码函数</strong>:</p><figure class="mi mj mk ml gt jr gh gi paragraph-image"><div class="gh gi od"><img src="../Images/51a994fe70f92c01670e486ad8dfd5c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*W1KPxm7XIF3y7c37vY-ydw.png"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk translated">经<a class="ae jy" href="https://arxiv.org/abs/2003.08934" rel="noopener ugc nofollow" target="_blank">原稿</a>许可拍摄的图像</figcaption></figure><p id="a1aa" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">其中<em class="md"> p </em>是一个标量。该函数γ()分别应用于<strong class="kz ir"> x </strong>中的三个坐标值以及观察方向<strong class="kz ir"> d </strong>的坐标值。</p><p id="4c56" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">位置编码并不是一个新概念，这种映射的一个非常相似的版本被用在流行的<a class="ae jy" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank"> Transformer 架构</a>中。然而，目的是不同的:如果对于<strong class="kz ir">变压器</strong>来说，这是一种提供序列中记号的离散位置的方式，在这种情况下，目的是将输入映射到更高维度的空间中，在该空间中，MLP 可以更容易地逼近更高频率的函数。</p><h2 id="3139" class="mo ka iq bd kb mp mq dn kf mr ms dp kj li mt mu kn lm mv mw kr lq mx my kv mz bi translated">分层体积取样</h2><p id="6417" class="pw-post-body-paragraph kx ky iq kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated">想想看，沿相机光线均匀采样点不是很有效，许多点会落入自由空间或遮挡区域，对渲染图像没有贡献。</p><p id="91a4" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">为了解决这个问题，NeRF 使用了<strong class="kz ir">两个网络</strong>:一个<strong class="kz ir">粗</strong>和一个<strong class="kz ir">细</strong>。该策略可分为<strong class="kz ir">两步</strong>:</p><ol class=""><li id="b17d" class="oe of iq kz b la lv le lw li og lm oh lq oi lu oj ok ol om bi translated">使用分层抽样对一组<em class="md"> Nc </em>位置进行抽样，并评估这些位置的“粗略”网络</li><li id="54b4" class="oe of iq kz b la on le oo li op lm oq lq or lu oj ok ol om bi translated">给定第一步的输出，产生一个更加明智的采样，它倾向于对最终图像做出真正贡献的点</li></ol><p id="d53f" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">重写等式(3)我们有:</p><figure class="mi mj mk ml gt jr gh gi paragraph-image"><div class="gh gi os"><img src="../Images/0b529a133aaa30bd8c8d58860c4bbf23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*zIytoY3O5eMm6c-VHtZYnQ.png"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk translated">经<a class="ae jy" href="https://arxiv.org/abs/2003.08934" rel="noopener ugc nofollow" target="_blank">原稿</a>许可拍摄的图像</figcaption></figure><p id="d48b" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">如果我们用归一化权重<em class="md">，这将产生一个沿射线的概率密度函数<strong class="kz ir"> </strong> (PDF)。然后，我们可以使用<a class="ae jy" href="https://en.wikipedia.org/wiki/Inverse_transform_sampling" rel="noopener ugc nofollow" target="_blank">逆变换采样</a>从该分布中采样第二组<em class="md"> Nf </em>位置，在第一组和第二组样本的联合处评估我们的“精细”网络，并使用(3)但使用所有<em class="md"> Nc </em> + <em class="md"> Nf </em>样本计算光线<em class="md">ĉf</em>(<strong class="kz ir">r</strong>)的最终渲染颜色。</em></p><p id="02cf" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">如前所述，该过程将更多的样本分配给我们期望包含可视内容的区域。</p><p id="c500" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated"><strong class="kz ir">实施细节</strong></p><p id="d7bb" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">对于机器学习专家来说，可能导致违反直觉的结果是，迄今为止描述的程序<strong class="kz ir">为每个场景优化了单独的神经连续体表示网络</strong>。换句话说，网络不是为了预测其他场景而在场景数据集上训练的，而是在我们想要合成新视图的单个场景上训练的。</p><p id="aff1" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">训练 NeRF 只需要一组捕获的场景的 RGB 图像、相应的相机姿态和内在参数以及场景边界(还记得等式(1)中的<em class="md"> tn </em>、<em class="md"> t </em> f 吗？).对于<strong class="kz ir">合成数据</strong>，作者使用地面真实值，而对于<strong class="kz ir">真实数据</strong>，他们使用<a class="ae jy" href="https://colmap.github.io/" rel="noopener ugc nofollow" target="_blank"> COLMAP </a> <strong class="kz ir">运动结构</strong>软件包来估计这些参数。</p><p id="dca4" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">然后，在每个<strong class="kz ir">优化迭代</strong>中，训练网络的过程是:</p><ol class=""><li id="b598" class="oe of iq kz b la lv le lw li og lm oh lq oi lu oj ok ol om bi translated">从数据集中所有像素的集合中采样一批相机光线</li><li id="22e4" class="oe of iq kz b la on le oo li op lm oq lq or lu oj ok ol om bi translated">按照分层抽样程序从粗网络中查询<em class="md"> Nc </em>样本，从细网络中查询<em class="md"> Nc </em> + <em class="md"> Nf </em>样本</li><li id="967a" class="oe of iq kz b la on le oo li op lm oq lq or lu oj ok ol om bi translated">使用前面描述的渲染过程来渲染两组样本的每条光线的颜色</li><li id="3770" class="oe of iq kz b la on le oo li op lm oq lq or lu oj ok ol om bi translated">计算损失</li><li id="ebfd" class="oe of iq kz b la on le oo li op lm oq lq or lu oj ok ol om bi translated">使用优化器更新参数</li></ol><p id="e5ca" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">在论文中,<strong class="kz ir">损失函数</strong>简单地是粗略渲染和精细渲染的<br/>渲染和真实像素颜色之间的<strong class="kz ir">总平方误差</strong>:</p><figure class="mi mj mk ml gt jr gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/8c8ffda2ee565df376f1d7efdd5ce8f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*2VXn2oBvvCa4sfKUhDX7PQ.png"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk translated">经<a class="ae jy" href="https://arxiv.org/abs/2003.08934" rel="noopener ugc nofollow" target="_blank">原稿</a>许可拍摄的图像</figcaption></figure><p id="ae31" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">作为一个<strong class="kz ir">优化器</strong>，作者使用<a class="ae jy" href="https://arxiv.org/abs/1412.6980" rel="noopener ugc nofollow" target="_blank"> Adam </a>，其<strong class="kz ir">学习率</strong>从 5×104 开始，<strong class="kz ir">以指数方式从</strong>衰减到 5×105。</p><h1 id="261b" class="jz ka iq bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">局限性和后续步骤</h1><p id="1447" class="pw-post-body-paragraph kx ky iq kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated">好了，我们已经走了很长一段路，那么可以说小说视图合成任务完全由 NeRF 解决了吗？不完全是。这里列出了一些最重要的<strong class="kz ir">限制</strong>:</p><ul class=""><li id="72e9" class="oe of iq kz b la lv le lw li og lm oh lq oi lu ou ok ol om bi translated">最初的 NeRF 旨在表现一个<strong class="kz ir">静态场景</strong>；这一限制随后被未来的作品解决，如<a class="ae jy" href="https://arxiv.org/abs/2011.13961" rel="noopener ugc nofollow" target="_blank"> D-NeRF:动态场景的神经辐射场</a></li><li id="3d0b" class="oe of iq kz b la on le oo li op lm oq lq or lu ou ok ol om bi translated">为了对单个场景进行<strong class="kz ir">优化，作者报告了大约 100-300k 的多次迭代以达到收敛，这类似于在单个 NVIDIA V100 GPU 上<strong class="kz ir">1-2 天</strong>的时间，而不是实时的。已经提出了许多改进来加速训练和推理(参见“附加材料”)</strong></li><li id="451e" class="oe of iq kz b la on le oo li op lm oq lq or lu ou ok ol om bi translated">如前所述，一个训练好的 NeRF 不能推广到其他场景/物体</li><li id="db76" class="oe of iq kz b la on le oo li op lm oq lq or lu ou ok ol om bi translated">最初的 NeRF 无法渲染<strong class="kz ir">大规模环境</strong>，这个问题由<a class="ae jy" href="https://waymo.com/research/block-nerf/" rel="noopener ugc nofollow" target="_blank"> Block-NeRF 解决:可扩展的大场景神经视图合成</a></li></ul><p id="b3f6" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">虽然这个列表可能继续与其他点，这项开创性工作的重要性不能低估。NeRF 的论文革新了它的领域，在过去的两年里，研究继续沿着它的方向进行。</p><h1 id="009e" class="jz ka iq bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">附加材料</h1><p id="fc26" class="pw-post-body-paragraph kx ky iq kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated">鉴于 NeRF 的流行，网上有很多关于这个主题的资料，下面是其中的一小部分:</p><ul class=""><li id="d446" class="oe of iq kz b la lv le lw li og lm oh lq oi lu ou ok ol om bi translated">马修·坦西克的 NeRF 网站</li><li id="db62" class="oe of iq kz b la on le oo li op lm oq lq or lu ou ok ol om bi translated">官方<a class="ae jy" href="https://github.com/bmild/nerf" rel="noopener ugc nofollow" target="_blank"> GitHub 页面</a></li><li id="f8d3" class="oe of iq kz b la on le oo li op lm oq lq or lu ou ok ol om bi translated"><a class="ae jy" href="https://github.com/yenchenlin/awesome-NeRF" rel="noopener ugc nofollow" target="_blank">令人敬畏的神经辐射场</a></li><li id="2049" class="oe of iq kz b la on le oo li op lm oq lq or lu ou ok ol om bi translated">弗兰克·德拉雷特的《2020 年的 NeRF 爆炸》</li><li id="a754" class="oe of iq kz b la on le oo li op lm oq lq or lu ou ok ol om bi translated"><a class="ae jy" href="https://www.youtube.com/watch?v=CRlN-cYFxTk" rel="noopener ugc nofollow" target="_blank"> ML 研究论文由 Yannic Kilcher 解释</a>(YouTube 视频)</li></ul><p id="c08d" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">显然，你可以在搜索栏中键入“神经辐射场<strong class="kz ir">”</strong>找到其他关于这个主题的文章。</p><h1 id="4400" class="jz ka iq bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">结论</h1><p id="7af3" class="pw-post-body-paragraph kx ky iq kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated">我希望这个 NeRF 演示能够击中目标:对于新手来说，比原始论文更容易理解，但又不会丢失重要的细节。</p><p id="8de4" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">如果你喜欢这篇文章，并希望我写更多类似的文章，你可以做几件事来支持我:开始在 Medium 上关注我，在社交媒体上分享这篇文章，并使用下面的鼓掌按钮，这样我就知道你对这种类型的内容感兴趣。</p><p id="27c2" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">最后，如果您还不是中等会员，您可以使用我的推荐链接成为中等会员:</p><div class="nf ng gp gr nh ni"><a href="https://mnslarcher.medium.com/membership" rel="noopener follow" target="_blank"><div class="nj ab fo"><div class="nk ab nl cl cj nm"><h2 class="bd ir gy z fp nn fr fs no fu fw ip bi translated">通过我的推荐链接加入 Medium-Mario Nam Tao shian ti Larcher</h2><div class="np l"><h3 class="bd b gy z fp nn fr fs no fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="nq l"><p class="bd b dl z fp nn fr fs no fu fw dk translated">mnslarcher.medium.com</p></div></div><div class="nr l"><div class="ov l nt nu nv nr nw js ni"/></div></div></a></div><p id="73d8" class="pw-post-body-paragraph kx ky iq kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu ij bi translated">想保持联系吗？在<a class="ae jy" href="https://www.linkedin.com/in/mnslarcher/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或<a class="ae jy" href="https://twitter.com/mnslarcher" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上关注我！</p></div></div>    
</body>
</html>