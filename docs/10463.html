<html>
<head>
<title>How to connect Kafka to Hasura GraphQL</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何将卡夫卡与哈苏拉·格拉福 QL 联系起来</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/how-to-connect-kafka-to-hasura-graphql-560335c9bc66?source=collection_archive---------5-----------------------#2022-11-03">https://blog.devgenius.io/how-to-connect-kafka-to-hasura-graphql-560335c9bc66?source=collection_archive---------5-----------------------#2022-11-03</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><h1 id="e104" class="jk jl in bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">使用这种管道方法将您的事件流转化为健壮的实时 API</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/a42c35659721f13fcdfcdbe4bab82c16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*Eyso1OtaUSXRGaU9doW3Qg.png"/></div></figure><h1 id="d7f1" class="jk jl in bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">介绍</h1><p id="8c09" class="pw-post-body-paragraph kq kr in ks b kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln ig bi translated">在本教程中，您将学习如何使用 Hasura 和河口流将 Apache Kafka 与实时 GraphQL API 集成。</p><p id="9d58" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated"><em class="lt">注意:我们为这个练习改编的源项目是由河口的工程师 Will Baker 创建的。如果你宁愿跳过详细的演练或以不同的方式处理事情，</em> <a class="ae lu" href="https://github.com/williamhbaker/kafka-graphql/" rel="noopener ugc nofollow" target="_blank"> <em class="lt">前往 GitHub </em> </a> <em class="lt">和 at！</em></p><p id="3072" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated"><strong class="ks io"> Kafka </strong>是一个流行的开源事件流媒体平台。它功能多样，但也没有个性化，使用起来很有挑战性。将 Kafka 连接到您的应用程序或项目的前端，不仅是功能性的，而且是<em class="lt">高效的，</em>是一个主要的挑战。</p><p id="a083" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated">这听起来像是 GraphQL 的工作。Graphql 是 API 的服务器端查询语言。它是 REST 的一个<a class="ae lu" href="https://www.apollographql.com/blog/graphql/basics/why-use-graphql/" rel="noopener ugc nofollow" target="_blank">替代品，正在迅速普及，并且可以为您的应用程序或项目提供一个健壮、高效的 API 层。</a></p><p id="1073" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated">然而，一个明显的问题是<strong class="ks io">如何连接这两个</strong>。有没有可能以一种合理的、平易近人的方式做到这一点？同时又不会失去 Kafka 集群近乎实时的特性？</p><p id="1f91" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated">确实是。让我们看看我们将构建什么。</p><h1 id="1484" class="jk jl in bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">卡夫卡到 GraphQL 的管道</h1><p id="8f8c" class="pw-post-body-paragraph kq kr in ks b kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln ig bi translated">当我们在这里完成时，我们将有一个这样的管道:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi lv"><img src="../Images/03010c53de0a317fd354039edb88b0a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vRWIBIvBm-mvgVjJ"/></div></div></figure><p id="20bc" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated">每一个组成部分都是有原因的。我们已经介绍了 Kafka 和 GraphQL。</p><p id="a68b" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated"><strong class="ks io">河口流</strong>是为实时数据流设计的 DataOps 平台。它将 ETL 供应商的熟悉程度与事件驱动的运行时相结合。它的优点包括:</p><ul class=""><li id="ea45" class="ma mb in ks b kt lo kx lp lb mc lf md lj me ln mf mg mh mi bi translated">与作为数据源<a class="ae lu" href="https://www.estuary.dev/sources/" rel="noopener ugc nofollow" target="_blank">的 Kafka</a>和作为目的地<a class="ae lu" href="https://www.estuary.dev/destinations/" rel="noopener ugc nofollow" target="_blank">的 Postgres</a>的开箱即用集成。</li><li id="a53d" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mf mg mh mi bi translated">对 SaaS 产品的直观 CLI 和 UI 支持，以及一个开源选项。</li><li id="2d07" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mf mg mh mi bi translated">通过验证和一次性语义实时传输文档。</li></ul><p id="fd68" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated"><a class="ae lu" href="https://hasura.io/blog/what-is-hasura-ce3b5c6e80e8/" rel="noopener ugc nofollow" target="_blank"><strong class="ks io">Hasura</strong></a><strong class="ks io">graph QL Engine</strong>是一项服务，您可以使用它从任何风格的 Postgres 生成实时 GraphQL APIs。在众多促进 GraphQL 的服务中，Hasura 的优势包括:</p><ul class=""><li id="a520" class="ma mb in ks b kt lo kx lp lb mc lf md lj me ln mf mg mh mi bi translated">易用性。</li><li id="5c44" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mf mg mh mi bi translated">选择自托管开源版本，以及一个具有大量免费层的云平台。</li><li id="fb3b" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mf mg mh mi bi translated">Hasura 是为 Postgres 设计的，Postgres 是世界上最流行的开源 SQL 数据库之一。为了我们这里的目的，Postgres 也与河口流连接。</li></ul><p id="9651" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated">今天，我们将使用除 Kafka 之外的每个管道组件的云版本或 SaaS 版本。我们将只使用<strong class="ks io">免费试用版或免费等级来做到这一点。</strong></p><p id="fdac" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated">要运行此工作流，您不必是开发人员。我将把事情详细分解，这样只要你是一个熟练的技术使用者，你就能跟上。</p><p id="5ed5" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated">最后，请记住，这是<em class="lt">远离</em>建设这条管道的唯一途径。将其用作您自己的定制工作流的起点。</p><h1 id="eca8" class="jk jl in bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">先决条件和设置</h1><p id="4fde" class="pw-post-body-paragraph kq kr in ks b kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln ig bi translated">我们需要所有这些东西:</p><ul class=""><li id="8c4a" class="ma mb in ks b kt lo kx lp lb mc lf md lj me ln mf mg mh mi bi translated"><strong class="ks io">本地开发环境。</strong>我推荐用 Visual Studio 代码工作，但是你想用什么都可以。</li><li id="0af2" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mf mg mh mi bi translated"><strong class="ks io">一个带有数据</strong>的卡夫卡集群。我们将使用本地托管的项目回购附带的版本。如果你有自己的集群，你可以自由地使用它。</li><li id="21b4" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mf mg mh mi bi translated"><strong class="ks io">码头工人</strong>。Kafka 集群和数据生成器是在一个容器化的环境中出现的。如果你以前没有用过 Docker，你需要下载一些东西。</li><li id="01dd" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mf mg mh mi bi translated"><strong class="ks io">代理</strong>允许流访问本地机器上的 Kafka 集群。我们将使用<strong class="ks io"> ngrok。</strong></li><li id="35b0" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mf mg mh mi bi translated"><strong class="ks io">一个河口流量免费试账。</strong></li><li id="d35d" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mf mg mh mi bi translated">一个 Postgres 数据库。我们将通过 Google Cloud SQL 使用托管版本。新账户有 300 美元的免费信用额度，这对我们的需求来说绰绰有余。</li><li id="405c" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mf mg mh mi bi translated"><strong class="ks io">一个哈苏拉云的账号。</strong>免费层是供个人使用的，这再次满足了我们今天的需求。</li></ul><p id="a3e3" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated">以下是获得所有东西的方法:</p><ol class=""><li id="3617" class="ma mb in ks b kt lo kx lp lb mc lf md lj me ln mo mg mh mi bi translated">如有必要，下载并安装以下软件:<br/> 1。<a class="ae lu" href="https://code.visualstudio.com" rel="noopener ugc nofollow" target="_blank"> VS 代码</a>T25】2。<a class="ae lu" href="https://www.docker.com/get-started/" rel="noopener ugc nofollow" target="_blank"> Docker 桌面</a> <br/> 3。<a class="ae lu" href="https://code.visualstudio.com/docs/devcontainers/containers" rel="noopener ugc nofollow" target="_blank"> VS 代码远程容器扩展</a>T31】4。<a class="ae lu" href="https://docs.github.com/en/desktop/installing-and-configuring-github-desktop/overview/getting-started-with-github-desktop" rel="noopener ugc nofollow" target="_blank"> GitHub 桌面</a>(如果你不是开发人员，也从未使用过 Git 或 GitHub，这是最快的入门方式)。</li><li id="7c31" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">在本地克隆项目。<br/> 1。去<a class="ae lu" href="https://github.com/williamhbaker/kafka-graphql/" rel="noopener ugc nofollow" target="_blank"> GitHub 回购</a>。<br/> 2。点击<strong class="ks io">代码</strong>，选择<strong class="ks io">用 GitHub 桌面打开。</strong>GitHub 桌面<strong class="ks io">克隆存储库</strong>对话框打开。<br/> 3。将<strong class="ks io">本地路径</strong>设置为您想要将源文件保存到本地的位置，然后点击<strong class="ks io">克隆。</strong>这将创建一个名为<strong class="ks io"> kafka-graphql 的新文件夹。</strong></li><li id="d9fd" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">下载并安装<a class="ae lu" href="https://ngrok.com/" rel="noopener ugc nofollow" target="_blank"> ngrok </a>。</li><li id="7f15" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">通过在<a class="ae lu" href="http://dashboard.estuary.dev" rel="noopener ugc nofollow" target="_blank"> Flow web app </a>中填写您的凭证来注册河口免费试用。<br/> <em class="lt">注:截至发稿时，流量处于私下测试阶段。我们将在 24 小时内为您提供一个试用帐户。</em></li><li id="56ce" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">在 Google Cloud SQL 中创建您的 Postgres 数据库。<br/> 1。开始您的试用。2<br/>2。创建一个新的 Postgres 实例。记下用户名和密码。<br/> 3。<a class="ae lu" href="https://cloud.google.com/sql/docs/mysql/configure-ip#add" rel="noopener ugc nofollow" target="_blank">为实例</a>启用公共 IP，将河口的 IP 34.121.207.128 添加为授权 IP 地址。</li><li id="1396" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">注册<a class="ae lu" href="http://cloud.hasura.io" rel="noopener ugc nofollow" target="_blank"> Hasura Cloud </a>并在免费层创建一个新项目。</li></ol><p id="05da" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated">现在，开始有趣的部分。</p><h1 id="e06c" class="jk jl in bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">启动 Kafka 集群和数据生成器</h1><p id="469f" class="pw-post-body-paragraph kq kr in ks b kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln ig bi translated">我们从 GitHub 克隆的项目包括一个 Docker 网络，可以用来旋转数据管道的不同部分:</p><ul class=""><li id="7ae4" class="ma mb in ks b kt lo kx lp lb mc lf md lj me ln mf mg mh mi bi translated">卡夫卡集群。</li><li id="c0fc" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mf mg mh mi bi translated">向 Kafka 发送虚构的股票交易数据的数据生成器。这条信息流将在一个名为<strong class="ks io">交易的 Kafka 主题中发送。</strong></li></ul><p id="73fd" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated">首先，让我们启用这两个服务，并确保它们通过 ngrok 代理可见。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi mp"><img src="../Images/cc1901e473f75b29e06349efc804d771.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*b1Dg51kG3lpmDHd3"/></div></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk translated">该图像对应于下面的步骤 5。</figcaption></figure><ol class=""><li id="33bd" class="ma mb in ks b kt lo kx lp lb mc lf md lj me ln mo mg mh mi bi translated"><a class="ae lu" href="https://docs.docker.com/desktop/install/windows-install/#start-docker-desktop" rel="noopener ugc nofollow" target="_blank">启动 Docker 桌面。</a></li><li id="1426" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">在 VS 代码中，打开<strong class="ks io"> kafka-graphql </strong>文件夹。<br/>它包含几个文件，包括一个名为<strong class="ks io"> data_gen </strong>的文件夹(数据生成器的源代码)和一个名为<strong class="ks io"> docker-compose.yaml </strong>的文件，其中包含了 docker 网络的详细信息。</li><li id="0fe0" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">点击<strong class="ks io"> docker-compose.yaml </strong>打开文件。<br/>该文件包含多个 docker 容器的规范。(对于本教程，由于我们使用云托管的 Postgres 和 Hasura，我们可以忽略被注释掉的容器。)</li><li id="1cd6" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">请注意，Kafka 被配置为在端口 9092 上运行。<br/>我们将为此端口设置一个代理。</li><li id="d9ae" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">在终端窗口中，运行:<code class="fe mu mv mw mx b">ngrok tcp 9092</code> <br/>该窗口显示您的代理的详细信息。在整个练习过程中，您将让它一直运行，但完成后一定要将其移除。</li><li id="3820" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">复制转发地址，省略协议。它会像<code class="fe mu mv mw mx b">0.tcp.ngrok.io:00000</code>一样被格式化。<br/>您将把它设置为 Kafka 主机的环境变量。</li><li id="a8fa" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">找到名为<strong class="ks io">的文件。环境模板</strong>。制作一个副本，并将其名称更改为<code class="fe mu mv mw mx b">.env</code>。</li><li id="86af" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">打开<code class="fe mu mv mw mx b">.env</code>，将<code class="fe mu mv mw mx b">KAFKA_HOST</code>设置为您的 ngrok 地址，(如<code class="fe mu mv mw mx b">KAFKA_HOST=0.tcp.ngrok.io:00000</code>)。保存文件。</li><li id="ea77" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">打开一个新的终端窗口，构建 docker 网络、数据生成器和 Kafka 集群:<br/> <code class="fe mu mv mw mx b">docker compose -f “docker-compose.yaml” up -d --build --remove-orphans<br/></code>进程退出，表示网络已成功构建并启动，但数据生成器和 Kafka 集群可能需要一段时间才能开始相互对话。让我们监视数据生成器日志。</li><li id="809b" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">运行<code class="fe mu mv mw mx b">docker logs --follow data_gen<br/></code>新的日志条目不断出现，每一两秒钟一次。当它们停止显示错误并开始看起来像:<br/> <code class="fe mu mv mw mx b">data_gen | 2022/10/28 16:00:15 Producing record of trade: {“ID”:616,”Symbol”:”GOOG”,”Price”:44.35,”Size”:25,”Timestamp”:”2022–10–28T16:00:15.241172378Z”}<br/></code> …您可以继续下一部分。</li></ol><p id="c3a6" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated">提示:如果日志似乎在几分钟后停止，你可能没有正确设置你的代理。检查 ngrok 是否仍在运行，以及是否在 Docker 合成文件中放入了正确的地址。如有必要，运行 <code class="fe mu mv mw mx b">docker compose down</code> <em class="lt">并再次开始该部分。</em></p><h1 id="c5df" class="jk jl in bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">用河口流捕捉卡夫卡主题</h1><p id="03c5" class="pw-post-body-paragraph kq kr in ks b kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln ig bi translated">我们现在有一个带有数据流的功能性 Kafka 集群，但是它没有连接到任何东西。下一步是利用河口流获取数据。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi my"><img src="../Images/4f0e15d1dc42021945acffd19f50bad5.png" data-original-src="https://miro.medium.com/v2/resize:fit:586/format:webp/1*ODS73PLc5_yvsuDYLZ0FgA.png"/></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk translated">此图像对应于下面的步骤 3。</figcaption></figure><ol class=""><li id="032f" class="ma mb in ks b kt lo kx lp lb mc lf md lj me ln mo mg mh mi bi translated">登录<a class="ae lu" href="http://dashboard.estuary.dev" rel="noopener ugc nofollow" target="_blank">流程 web 应用</a>。</li><li id="07a3" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">点击<strong class="ks io">捕捉</strong>选项卡，然后点击<strong class="ks io">新建捕捉</strong>按钮。</li><li id="b4ef" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">找到阿帕奇卡夫卡卡，点击<strong class="ks io">捕获。<br/> </strong>出现一个表单，其中包含设置从 Kafka 捕获所需的属性。我们将从给任务命名开始。</li><li id="4f4d" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">在<strong class="ks io">名称</strong>框内点击。<br/>您将看到一个或多个前缀，代表您有权访问的<em class="lt">名称空间</em>。很有可能，你的会说<code class="fe mu mv mw mx b">trial/</code>。</li><li id="e7e6" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">单击前缀并为其附加唯一的名称。比如<code class="fe mu mv mw mx b">trial/yourname/kafka-graphql</code>。</li><li id="3519" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">在<strong class="ks io">端点配置下，</strong>找到<strong class="ks io">引导服务器</strong>部分。单击加号按钮添加服务器。在出现的字段中，粘贴您的 ngrok 代理地址，例如<code class="fe mu mv mw mx b">0.tcp.ngrok.io:00000</code>。</li><li id="498c" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">展开<strong class="ks io">认证</strong>部分。<br/>由于这只是一个演示，我们的 Kafka 集群没有认证。(对于您的生产用例，请确保<a class="ae lu" href="https://docs.estuary.dev/reference/Connectors/capture-connectors/apache-kafka/#authentication-and-connection-security" rel="noopener ugc nofollow" target="_blank">在您的集群</a>上设置身份验证)。</li><li id="1fc6" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">点击<strong class="ks io">禁用。</strong></li><li id="16b3" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">点击<strong class="ks io">下一个</strong>按钮。Flow 启动与您的 Kafka 集群的连接，并为数据<em class="lt">捕获</em>任务以及它将写入的数据<em class="lt">集合</em>生成 JSON 规范。</li><li id="43aa" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">在规范编辑器中，单击带有集合名称的选项卡(类似于<code class="fe mu mv mw mx b">trial/yourname/kafka-graphql/trades</code>)。JSON 模式本质上是空的。因为 Kafka 没有对其存储的消息实施模式，所以 Flow 无法推断出模式。你会给它一个。</li><li id="eb21" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">将以下内容粘贴到编辑器中，删除之前的内容:</li></ol><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="37db" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated"><em class="lt">注意:该方案的 YAML 版本包含在项目回购协议中。然而，web 应用程序目前只接受 JSON，所以我为你重新格式化了它，使事情变得更快。</em></p><p id="be11" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated">12.点击<strong class="ks io">保存并发布</strong>按钮。</p><p id="ac3d" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated">流部署数据捕获。虽然我们还没有在任何地方实现它，但是 Flow 在云支持的集合中保留了每个文档的副本。我们可以在 web 应用程序中预览这些数据。</p><p id="5bf8" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated">13.当截图成功发布后，在显示日志的弹出窗口中点击<strong class="ks io">关闭</strong>。</p><p id="3e3e" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated">14.单击<strong class="ks io">收藏</strong>选项卡，然后单击您的收藏名称旁边的<strong class="ks io">详细信息</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi nb"><img src="../Images/44c451499cb51a2102b012648f65e4a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8ifCBe3aOJvQDGqw"/></div></div></figure><p id="21f8" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated">数据存储时显示:按键。我们提供的模式使用股票符号作为键。</p><p id="9936" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated">对于每个符号，Flow 每次从 Kafka 接收到一条新消息时都会覆盖价格。在 Postgres 中，这将转化为当前股票价格的紧凑表格。</p><p id="ea62" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated">我们现在将数据加载到 Postgres 中。</p><h1 id="bc90" class="jk jl in bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">将数据具体化到 Postgres 数据库中</h1><p id="3248" class="pw-post-body-paragraph kq kr in ks b kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln ig bi translated">让我们继续将流中的数据连接到您之前设置的 Google Cloud SQL Postgres 实例。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi nc"><img src="../Images/54522f0f7c7c8bb2f953e65bc1cbe23a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5uMDasKkWd_CnaUy"/></div></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk translated">此图像对应于下面的步骤 7。</figcaption></figure><ol class=""><li id="ca3a" class="ma mb in ks b kt lo kx lp lb mc lf md lj me ln mo mg mh mi bi translated">在 Flow web app 中，点击<strong class="ks io">物化</strong>选项卡，然后点击<strong class="ks io">新建物化</strong>按钮。</li><li id="3c26" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">找到 PostgreSQL 卡，点击<strong class="ks io">物化。<br/> </strong>出现一个表单，其中包含设置 Postgres 物化所需的属性。同样，我们先给它一个名字。</li><li id="b7ac" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">在<strong class="ks io">名称</strong>框内单击，选择您的前缀，并添加一个唯一的名称，如<code class="fe mu mv mw mx b">trial/yourname/postgres-graphql</code>。</li><li id="ef3d" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">要填写<strong class="ks io">地址</strong>字段，您需要实例的公共 IP。<br/> 1。去<a class="ae lu" href="https://console.cloud.google.com/sql" rel="noopener ugc nofollow" target="_blank">谷歌云控制台</a>选择你的实例。<br/> 2。从实例的<strong class="ks io">概述</strong>页面，在<strong class="ks io">连接到该实例下，</strong>复制公共 IP 地址。</li><li id="447a" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">回归流动。在<strong class="ks io">地址</strong>字段中，粘贴公共 IP 地址并附加端口<code class="fe mu mv mw mx b">:5432</code>，给出地址的完整格式<code class="fe mu mv mw mx b">XX.XX.XXX.XXX:5432</code>。</li><li id="ea0b" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">填写<strong class="ks io">用户</strong>和<strong class="ks io">密码</strong>字段。除非您在设置过程中更改了用户名，否则用户名为<code class="fe mu mv mw mx b">postgres</code>。如果您在设置过程中没有设置密码，请将该字段留空。您可以在 Google Cloud Console 中实例页面的<strong class="ks io">用户</strong>选项卡上查看您的用户信息。</li><li id="a28d" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">将数据库<strong class="ks io">留空。流将具体化到默认数据库，也称为<code class="fe mu mv mw mx b">postgres.<br/></code>。接下来，我们将指定 trades 集合作为要具体化的数据，并命名将在数据库中创建的相应表。</strong></li><li id="34d6" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">向下滚动到<strong class="ks io">集合选择器。</strong>使用<strong class="ks io">可用收藏</strong>框搜索您的收藏(例如<code class="fe mu mv mw mx b">trial/yourname/kafka-graphql/trades</code>)。</li><li id="dd31" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">在<strong class="ks io">表</strong>字段中，输入<code class="fe mu mv mw mx b">trades</code>。</li><li id="01f8" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">点击<strong class="ks io">下一步</strong>测试连接，然后点击<strong class="ks io">保存并发布。<br/> </strong>当动作成功完成，这意味着你从 Kafka 到 Postgres 的数据流完成。本地 Kafka 集群上的交易事件以毫秒为单位反映在 Postgres 表中。</li></ol><p id="4df3" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated">剩下要做的就是将数据库连接到 Hasura，并开始使用 GraphQL API。</p><h1 id="1592" class="jk jl in bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">将 Postgres 数据库连接到 Hasura GraphQL</h1><ol class=""><li id="9259" class="ma mb in ks b kt ku kx ky lb nd lf ne lj nf ln mo mg mh mi bi translated">在<a class="ae lu" href="https://cloud.hasura.io/projects" rel="noopener ugc nofollow" target="_blank"> Hasura 控制台</a>中打开你的项目。</li><li id="59b7" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">将你的 Hasura 项目连接到你的 Postgres。按照 Hasura 文档中的<a class="ae lu" href="https://hasura.io/docs/latest/databases/connect-db/cloud-databases/gcp/" rel="noopener ugc nofollow" target="_blank">步骤</a>来做这件事(从<strong class="ks io">步骤 4:允许从 Hasura Cloud </strong>连接到你的 DB 开始)。<br/>一旦连接，数据库名称将显示在<strong class="ks io">数据</strong>选项卡的侧边栏上。它包含默认的数据库模式，<strong class="ks io"> Public。</strong></li><li id="2a4f" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">点击侧边栏中的<strong class="ks io"> Public </strong>显示数据库表列表。找到 trades 表并单击<strong class="ks io"> Track </strong>向 GraphQL API 公开该表。</li><li id="eca1" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">点击<strong class="ks io"> API </strong>标签。<br/>我们将设置一个订阅—一个实时查询—并直观地验证我们的管道是否按预期工作。</li><li id="aa3f" class="ma mb in ks b kt mj kx mk lb ml lf mm lj mn ln mo mg mh mi bi translated">在查询框中，粘贴以下内容，然后按播放按钮:</li></ol><pre class="kj kk kl km gt ng mx nh ni aw nj bi"><span id="c92c" class="nk jl in mx b gy nl nm l nn no">subscription {<br/>  trades {<br/>    price<br/>    symbol<br/>    Size<br/>  }<br/>}</span></pre><p id="004c" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated">在右边的查看器中，您会看到来自 Postgres 的实时交易更新。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/a23fd365c1cce9ed6b44384cea8f76f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*0WACoBq3sQU2eIRaTKy3qw.gif"/></div></figure><h1 id="b1f9" class="jk jl in bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">下一步是什么？</h1><p id="19f2" class="pw-post-body-paragraph kq kr in ks b kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln ig bi translated">从这里开始，路就打开了，但我只能走到这里。您有一个高性能的 API，可以随时随地使用。</p><p id="b16d" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated">使用我们在这里使用的样本数据集，您可以创建一个应用程序，该应用程序提供定制的警报，或者根据当前的股票价格代表您自动进行交易(当然，您必须首先将您的集群与真实的股票数据联系起来)。</p><p id="dc9a" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated">真正强大的地方是，如果您在自己的 Kafka 集群中有数据，并且您很难将其与应用程序的前端集成。尤其是随着您的数据量和复杂性的增长，拥有一个在验证和重塑数据的同时保持快速规模的管道非常重要。</p></div><div class="ab cl nq nr hr ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="ig ih ii ij ik"><p id="c16e" class="pw-post-body-paragraph kq kr in ks b kt lo kv kw kx lp kz la lb lq ld le lf lr lh li lj ls ll lm ln ig bi translated"><em class="lt">本文原载于</em> <a class="ae lu" href="https://www.estuary.dev/how-to-connect-kafka-to-hasura-graphql/" rel="noopener ugc nofollow" target="_blank"> <em class="lt">河口博客</em> </a> <em class="lt">。</em></p></div></div>    
</body>
</html>