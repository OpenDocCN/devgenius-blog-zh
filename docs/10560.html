<html>
<head>
<title>How to Use the New Google Infinite Nature “3D images generator”</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用新的谷歌无限自然“三维图像生成器”</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/how-to-use-the-new-google-infinite-nature-3d-images-generator-ac0261f43563?source=collection_archive---------3-----------------------#2022-11-11">https://blog.devgenius.io/how-to-use-the-new-google-infinite-nature-3d-images-generator-ac0261f43563?source=collection_archive---------3-----------------------#2022-11-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7429" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">循序渐进的 Python 指南</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/eb0de64565d6cfec362a81b1c2980d6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*as-wLiDiGaBNi5xfQzNvfQ.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">《创世纪》中的“LightBeUponUS”由 Philippe Bouaziz (Pele_B)制作的人造对抗 NFT <a class="ae kv" href="https://www.redbubble.com/i/t-shirt/LightBeUponUS-by-PeleB/131378947.WFLAH" rel="noopener ugc nofollow" target="_blank">系列</a>使用<a class="ae kv" href="https://www.midjourney.com/showcase/" rel="noopener ugc nofollow" target="_blank">中途</a>制作(图片由作者提供)</figcaption></figure><p id="5478" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi ls translated"><span class="l lt lu lv bm lw lx ly lz ma di">人工智能是一种强有力的工具，可用于许多领域，如图像识别和机器翻译。但新一代人工智能工具可以更进一步，创造出从未存在过的图像。这些“想象的”图像是由人工智能创建的，人工智能在大量真实图像上进行训练，学习创建逼真且与原始数据一致的新图像。新图像可以用于各种目的，例如创建逼真的假图像，填充图片中的空白，甚至根据文本描述生成新图像。</span></p><p id="c482" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这项技术被称为生成对抗网络(GAN)，它是由多伦多大学的一名研究人员在 2014 年首次提出的。GAN 由两部分组成:发生器和鉴别器。生成器是创建新图像的神经网络，而鉴别器是将图像分类为真或假的神经网络。两个网络一起训练，生成器试图欺骗鉴别器，鉴别器试图捕捉假图像。在训练过程中，生成器学习创建真实的图像，而鉴别器学习变得越来越精确。结果是一个系统可以生成难以与真实图像区分的真实图像。来源:</p><p id="e0ef" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">甘已经被用来生成各种各样的图像，包括脸，风景，甚至动漫人物。它还可以用于从文本描述中生成图像，例如来自《圣经》的以下文本:</p><p id="3cf0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">“起初，上帝创造了天地。那时，地是空虚混沌的，黑暗笼罩着深渊的表面，上帝的灵在水面上盘旋。”</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mb"><img src="../Images/8a94d68fb6eb0241cde2340bec6e5418.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NNGCVixykpkuUVdP24GI1g.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">《创世纪》中的天使 NFT <a class="ae kv" href="https://www.redbubble.com/i/t-shirt/Genesis-Angel-of-G-by-PeleB/130468375.WFLAH?asc=u" rel="noopener ugc nofollow" target="_blank">系列</a>由 Philippe Bouaziz (Pele_B)利用<a class="ae kv" href="https://www.midjourney.com/showcase/" rel="noopener ugc nofollow" target="_blank">中途</a>创造(图片由作者提供)</figcaption></figure><p id="dc8b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这个名为“创世纪人工对抗网络”( GAAN)的数字展示中，我试图理解人工智能机器人(中途)是如何解释《圣经》文本的。使用深度学习技术，如生成对抗网络(GAN)和图像处理。</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><p id="3580" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本教程中，我们将讨论如何从视频 2D 图像生成 3D 人工智能图像。我们将使用新的无限自然 GAN 模型在视频 2D 图像数据集上训练该模型，并从中生成 3D 图像。python 代码可以在<a class="ae kv" href="https://infinite-nature-zero.github.io/" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上免费获得。我们将使用名为<a class="ae kv" href="https://infinite-nature.github.io/" rel="noopener ugc nofollow" target="_blank">空中海岸线影像数据集</a> (ACID)的在线视频数据集，并从中生成 3D 图像。我们将为这个 GAN 模型使用 TensorFlow 后端，这里是 collab <a class="ae kv" href="https://colab.research.google.com/github/google-research/google-research/blob/master/infinite_nature/infinite_nature_demo.ipynb" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><p id="9af9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">更准确地说，我们将分析从视频 2D 图像生成 3D AI 图像的方法。首先，我们下载一个深度卷积神经网络来从视频 2D 图像中提取 3D 信息。接下来，我们使用生成对抗网络从提取的 3D 信息生成 3D AI 图像。最后，我们使用渲染算法来渲染 3D AI 图像。该方法可以从视频 2D 图像中生成逼真的三维人工智能图像。</p><p id="ab7e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，我们需要安装 numpy 版本 1.19.5:</p><pre class="kg kh ki kj gt mj mk ml bn mm mn bi"><span id="7d53" class="mo mp iq mk b be mq mr l ms mt">import numpy as np<br/>import os<br/><br/>if np.__version__ != '1.19.5':<br/>  print("Installing correct numpy library...")<br/>  os.system('pip install numpy==1.19.5')<br/>  print("Numpy installed, please press run all again.", flush=True)<br/>  os.kill(os.getpid(), 9)</span></pre><p id="4ef0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">之后，我们需要安装:</p><ul class=""><li id="8e54" class="mu mv iq ky b kz la lc ld lf mw lj mx ln my lr mz na nb nc bi translated"><strong class="ky ir">数据集</strong>:infinite _ nature _ public Google API</li><li id="a36a" class="mu mv iq ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated"><strong class="ky ir">依赖关系</strong>:infinite _ nature/requirements . txt</li><li id="91b2" class="mu mv iq ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated"><strong class="ky ir"> 3D 网格渲染</strong>:将图像从 2D 转换为 3D</li></ul><pre class="kg kh ki kj gt mj mk ml bn mm mn bi"><span id="a51e" class="mo mp iq mk b be mq mr l ms mt">%%shell<br/>echo Fetching code from github...<br/><br/>apt install subversion<br/>svn export --force https://github.com/google-research/google-research/trunk/infinite_nature<br/><br/>echo<br/>echo Fetching trained model weights...<br/>rm -f autocruise_input*.pkl<br/>rm -f ckpt.tar.gz<br/>rm -rf ckpt<br/>wget https://storage.googleapis.com/gresearch/infinite_nature_public/autocruise_input1.pkl<br/>wget https://storage.googleapis.com/gresearch/infinite_nature_public/autocruise_input2.pkl<br/>wget https://storage.googleapis.com/gresearch/infinite_nature_public/autocruise_input3.pkl<br/>wget https://storage.googleapis.com/gresearch/infinite_nature_public/ckpt.tar.gz<br/>tar -xf ckpt.tar.gz<br/><br/>echo<br/>echo Installing required dependencies...<br/>pip install -r infinite_nature/requirements.txt<br/><br/>echo<br/>echo Fetching tf_mesh_renderer and compiling kernels...<br/>cd infinite_nature<br/>rm -rf tf_mesh_renderer<br/>source download_tf_mesh_renderer.sh<br/><br/>echo Done.</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/a624400193b0a3581288c286d0f8a88a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b5qs9_wRylMAUKmRGb31og.png"/></div></div></figure><p id="c228" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在下一步中，我们需要通过安装以下组件来激活神经网络模型:</p><ul class=""><li id="f7f9" class="mu mv iq ky b kz la lc ld lf mw lj mx ln my lr mz na nb nc bi translated"><strong class="ky ir"> Tensorflow 库</strong>:创建张量(将彩色图像转换为灰度 0/1 矢量)</li><li id="db6a" class="mu mv iq ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated"><strong class="ky ir"> Numpy 库</strong>:使用矩阵</li><li id="4ad2" class="mu mv iq ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated"><strong class="ky ir"> ImageIO 库</strong>:用滤镜变换 2D 图像</li><li id="2028" class="mu mv iq ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated"><strong class="ky ir">火车模型</strong>:来自谷歌网站名称“ckpt/model.ckpt-6935893”</li><li id="9b72" class="mu mv iq ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated">定义<strong class="ky ir"> RGBD 颜色</strong>的功能 01:“input _ RGBD”</li><li id="8fed" class="mu mv iq ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated">函数 02 将<strong class="ky ir"> RGBD 图像定义为矩阵</strong> : "current_image_as_png "</li><li id="d5aa" class="mu mv iq ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated">函数 03 到<strong class="ky ir">将图像</strong>的高/重比调整为【160，256】，函数名为:“reset(rgbd=None)”。此外，这个函数定义了人工智能无人机图像集:方向 _ 偏移，下一个 _ 姿态 _ 功能，姿态，转弯 _ 功能</li><li id="1fa3" class="mu mv iq ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated">功能 04 至<strong class="ky ir">定义下一个图像视图</strong>:步骤(offsetx，offsety)</li><li id="b088" class="mu mv iq ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated"><strong class="ky ir"> MiDaS V2 模型</strong> <strong class="ky ir">获取 fom 2D 图像估计 3D 渲染</strong>:“预测=(预测—显示 _ 最小)/(显示 _ 最大—显示 _ 最小)”</li><li id="d342" class="mu mv iq ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated">功能 05 至<strong class="ky ir">加载 2D 图像</strong></li></ul><p id="778b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可以看到下面的代码:</p><pre class="kg kh ki kj gt mj mk ml bn mm mn bi"><span id="5ab0" class="mo mp iq mk b be mq mr l ms mt">import tensorflow as tf<br/>import os<br/>import sys<br/><br/># Make sure dynamic linking can find tensorflow libraries.<br/>os.system('ldconfig ' + tf.sysconfig.get_lib())<br/><br/># Make sure python can find our libraries.<br/>sys.path.append('infinite_nature')<br/>sys.path.append('infinite_nature/tf_mesh_renderer/mesh_renderer')<br/><br/># Make sure the mesh renderer library knows where to load its .so file from.<br/>os.environ['TEST_SRCDIR'] = 'infinite_nature'</span></pre><pre class="nj mj mk ml bn mm mn bi"><span id="46ab" class="mo mp iq mk b be mq mr l ms mt">import imageio<br/>import IPython<br/>import numpy as np<br/>import pickle<br/>import tensorflow as tf<br/>import tensorflow_hub as hub<br/><br/>import config<br/>import fly_camera<br/>import infinite_nature_lib<br/><br/># Build model and restore checkpoint.<br/>config.set_training(False)<br/>model_path = "ckpt/model.ckpt-6935893"<br/>render_refine, style_encoding = infinite_nature_lib.load_model(model_path)<br/>initial_rgbds = [<br/>    pickle.load(open("autocruise_input1.pkl", "rb"))['input_rgbd'],<br/>    pickle.load(open("autocruise_input2.pkl", "rb"))['input_rgbd'],<br/>    pickle.load(open("autocruise_input3.pkl", "rb"))['input_rgbd']]<br/><br/># Code for an autopilot demo. We expose two functions that will be invoked<br/># from an HTML/JS frontend: reset and step.<br/><br/># The state that we need to remember while flying:<br/>state = {<br/>  'intrinsics': None,<br/>  'pose': None,<br/>  'rgbd': None,<br/>  'start_rgbd': None,<br/>  'style_noise': None,<br/>  'next_pose_function': None,<br/>  'direction_offset': None,  # Direction controlled by user's mouse clicks.<br/>}<br/><br/>def current_image_as_png():<br/>  imgdata = tf.image.encode_png(<br/>      tf.image.convert_image_dtype(state['rgbd'][..., :3], dtype=tf.uint8))<br/>  return IPython.display.Image(data=imgdata.numpy())<br/><br/>def reset(rgbd=None):<br/>  if rgbd is None:<br/>    rgbd = state['start_rgbd']<br/><br/>  height, width, _ = rgbd.shape<br/>  aspect_ratio = width / float(height)<br/><br/>  rgbd = tf.image.resize(rgbd, [160, 256])<br/>  state['rgbd'] = rgbd<br/>  state['start_rgbd'] = rgbd<br/>  state['pose'] = np.array(<br/>      [[1.0, 0.0, 0.0, 0.0],<br/>       [0.0, 1.0, 0.0, 0.0],<br/>       [0.0, 0.0, 1.0, 0.0]],<br/>      dtype=np.float32)<br/>  # 0.8 focal_x corresponds to a FOV of ~64 degrees.<br/>  state['intrinsics'] = np.array(<br/>      [0.8, 0.8 * aspect_ratio, .5, .5],<br/>      dtype=np.float32)<br/>  state['direction_offset'] = (0.0, 0.0)<br/>  state['style_noise'] = style_encoding(rgbd)<br/>  state['next_pose_function'] = fly_camera.fly_dynamic(<br/>    state['intrinsics'],<br/>    state['pose'],<br/>    turn_function=(lambda _: state['direction_offset']))<br/>  return current_image_as_png()<br/><br/><br/>def step(offsetx, offsety):<br/>  state['direction_offset'] = (offsetx, offsety)<br/>  next_pose = state['next_pose_function'](state['rgbd'])<br/>  next_rgbd = render_refine(<br/>       state['rgbd'], state['style_noise'],<br/>       state['pose'], state['intrinsics'],<br/>       next_pose, state['intrinsics'])<br/>  state['pose'] = next_pose<br/>  state['rgbd'] = next_rgbd<br/>  return current_image_as_png()<br/><br/><br/># To run on user-supplied images, we use MiDaS V2 to obtain initial disparity.<br/>midas_model = hub.load('https://tfhub.dev/intel/midas/v2/2', tags=['serve'])<br/><br/>def midas_disparity(rgb):<br/>  """Computes MiDaS v2 disparity on an RGB input image.<br/><br/>  Args:<br/>    rgb: [H, W, 3] Range [0.0, 1.0].<br/>  Returns:<br/>    [H, W, 1] MiDaS disparity resized to the input size and in the range<br/>    [0.0, 1.0]<br/>  """<br/>  size = rgb.shape[:2]<br/>  resized = tf.image.resize(rgb, [384, 384], tf.image.ResizeMethod.BICUBIC)<br/>  # MiDaS networks wants [1, C, H, W]<br/>  midas_input = tf.transpose(resized, [2, 0, 1])[tf.newaxis]<br/>  prediction = midas_model.signatures['serving_default'](midas_input)['default'][0]<br/>  disp_min = tf.reduce_min(prediction)<br/>  disp_max = tf.reduce_max(prediction)<br/>  prediction = (prediction - disp_min) / (disp_max - disp_min)<br/>  return tf.image.resize(<br/>      prediction[..., tf.newaxis], size,  method=tf.image.ResizeMethod.AREA)<br/><br/><br/>def load_initial(i):<br/>  return reset(rgbd=initial_rgbds[i])<br/><br/><br/>def load_image(data):<br/>  # Data converted from JS ends up as a string, needs to be converted to<br/>  # bytes using Latin-1 encoding (which just maps 0-255 to 0-255).<br/>  data = data.encode('Latin-1')<br/>  rgb = tf.image.decode_image(data, channels=3, dtype=tf.float32)<br/>  resized = tf.image.resize(rgb, [160, 256], tf.image.ResizeMethod.AREA)<br/>  rgbd = tf.concat([resized, midas_disparity(resized)], axis=-1)<br/>  return reset(rgbd=rgbd)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/f9650403b7bd2acb46021e2373762375.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aqTcIGpHi914MyOf8cJSxQ.png"/></div></div></figure><p id="01c6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，我们需要运行一个 html 代码来玩<strong class="ky ir">交互演示</strong>。</p><pre class="kg kh ki kj gt mj mk ml bn mm mn bi"><span id="27a4" class="mo mp iq mk b be mq mr l ms mt">import IPython<br/>from google.colab import output<br/><br/># The front-end for our interactive demo.<br/><br/>html='''<br/>&lt;style&gt;<br/>#view {<br/>  width: 512px;<br/>  height: 320px;<br/>  background-color: #aaa;<br/>  background-size: 100% 100%;<br/>  border: 1px solid #000;<br/>  margin: 20px;<br/>  position: relative;<br/>}<br/>#rgb {<br/>  height: 100%;<br/>}<br/>#cursor {<br/>  position: absolute;<br/>  height: 0; width: 0;<br/>  left: 50%; top: 50%;<br/>  opacity: .5;<br/>}<br/>#cursor::before, #cursor::after {<br/>  content: '';<br/>  position: absolute;<br/>  background: #f04;<br/>  pointer-events: none;<br/>}<br/>#cursor::before {<br/>  left: -10px; top: -1px; width: 20px; height: 2px;<br/>}<br/>#cursor::after {<br/>  left: -1px; top: -10px; width: 2px; height: 20px;<br/>}<br/>.buttons {<br/>  margin: 20px;<br/>}<br/>.buttons div {<br/>  display: inline-block;<br/>  cursor: pointer;<br/>  padding: 20px;<br/>  background: #eee;<br/>  border: 2px solid #aaa;<br/>  border-radius: 3px;<br/>  margin-right: 10px;<br/>  font-weight: bold;<br/>  text-transform: uppercase;<br/>  letter-spacing: 1px;<br/>  color: #444;<br/>}<br/>.buttons div:active {<br/>  background: #444;<br/>  color: #fff;<br/>}<br/>h3 {<br/>  margin-left: 20px;<br/>}<br/>&lt;/style&gt;<br/>&lt;h3&gt;Infinite Nature interactive demo&lt;/h3&gt;<br/>&lt;div id=view&gt;&lt;img id=rgb&gt;&lt;div id=cursor&gt;&lt;/div&gt;&lt;/div&gt;<br/>&lt;div class=buttons&gt;<br/>Click &lt;b&gt;Play&lt;/b&gt; to run or &lt;b&gt;Step&lt;/b&gt; to advance frame by frame.<br/>Click mouse over image to steer.&lt;br&gt;&lt;br&gt;<br/>&lt;div id=restart&gt;Restart&lt;/div&gt;&lt;div id=play&gt;Play&lt;/div&gt;&lt;div id=pause&gt;Pause&lt;/div&gt;&lt;div id=step&gt;Step&lt;/div&gt;<br/>&lt;br&gt;&lt;br&gt;<br/>Select starting image (be patient…):&lt;br&gt;&lt;br&gt;<br/>&lt;div id=image1&gt;Image 1&lt;/div&gt;&lt;div id=image2&gt;Image 2&lt;/div&gt;&lt;div id=image3&gt;Image 3&lt;/div&gt;&lt;div id=upload&gt;Upload…&lt;/div&gt;&lt;br&gt;<br/>&lt;input style="display:none" type=file id=chooser accept=".png,.jpg"&gt;<br/>&lt;/div&gt;<br/>&lt;script&gt;<br/>let playing = true;<br/>let pending = false;<br/>let x = 0.5;<br/>let y = 0.5;<br/>let cursor_count = 0;<br/><br/>async function call(name, ...parms) {<br/>  pending = true;<br/>  const result = await google.colab.kernel.invokeFunction(name, parms, {});<br/>  pending = false;<br/>  const url = `data:image/png;base64,${result.data['image/png']}`;<br/>  document.querySelector('#rgb').src = url;<br/>  if (!playing) { return; }<br/>  step();<br/>}<br/><br/>async function reset() {<br/>  playing = false;<br/>  await call('reset');<br/>}<br/><br/>async function selectImage(i) {<br/>  playing = false;<br/>  await call('load_initial', i);<br/>}<br/><br/>function upload() {<br/>  playing = false;<br/>  document.querySelector('#chooser').click();<br/>}<br/><br/>function uploadFile(file) {<br/>  if (file.type != 'image/png' &amp;&amp; file.type != 'image/jpeg') {<br/>    error('Only PNG or JPEG files accepted.');<br/>    return;<br/>  }<br/>  console.log(file);<br/>  const reader = new FileReader();<br/>  reader.onload = (e) =&gt; {<br/>    const imagebytes = e.target.result;<br/>    call('load_image', imagebytes);<br/>  }<br/>  document.querySelector('#rgb').src = '';<br/>  reader.readAsBinaryString(file);<br/>}<br/><br/>async function step() {<br/>  if (pending) { return; }<br/>  await call('step', 2*x - 1, 2*y - 1);<br/>  // Cursor moves back towards center.<br/>  if (cursor_count) {<br/>    cursor_count--;<br/>  } else {<br/>    x = 0.5 + (x - 0.5) * .9;<br/>    y = 0.5 + (y - 0.5) * .9;<br/>    update_cursor();<br/>  }<br/>}<br/><br/>async function play() {<br/>  playing = true;<br/>  await step();<br/>}<br/><br/>async function pause() {<br/>  playing = false;<br/>}<br/><br/>function update_cursor() {<br/>  let cursor = document.querySelector('#cursor');<br/>  cursor.style.left = `${(100 * x).toFixed(2)}%`;<br/>  cursor.style.top = `${(100 * y).toFixed(2)}%`;<br/>}<br/><br/>function cursor(e) {<br/>  console.log(e);<br/>  x = e.offsetX / e.target.clientWidth;<br/>  y = e.offsetY / e.target.clientHeight;<br/>  cursor_count = 1;<br/>  update_cursor();<br/>}<br/><br/>document.querySelector('#restart').addEventListener('click', reset);<br/>document.querySelector('#image1').addEventListener('click', () =&gt; selectImage(0));<br/>document.querySelector('#image2').addEventListener('click', () =&gt; selectImage(1));<br/>document.querySelector('#image3').addEventListener('click', () =&gt; selectImage(2));<br/>document.querySelector('#upload').addEventListener('click', upload);<br/>document.querySelector('#play').addEventListener('click', play);<br/>document.querySelector('#pause').addEventListener('click', pause);<br/>document.querySelector('#step').addEventListener('click', () =&gt; { playing = false; step(); });<br/>document.querySelector('#view').addEventListener('click', cursor);<br/>document.querySelector('#chooser').addEventListener('change', (e) =&gt; {<br/>  if (e.target.files.length &gt; 0) {<br/>    uploadFile(e.target.files[0]);<br/>  }<br/>});<br/>selectImage(0);<br/>&lt;/script&gt;<br/>'''<br/><br/>display(IPython.display.HTML(html))<br/><br/>output.register_callback('load_initial', load_initial)<br/>output.register_callback('load_image', load_image)<br/>output.register_callback('reset', reset)<br/>output.register_callback('step', step)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/45ec1d4be0749a75c1699773242b04a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sO2uv15HtmdIUh1D50fp5A.png"/></div></div></figure><p id="0f4d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你也可以在他们的官方网站上找到完整的 2D 影像 3D 电影:</p><p id="cbf3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://infinite-nature-zero.github.io/static/videos/InfNatZeroResults.mp4" rel="noopener ugc nofollow" target="_blank">https://infinite-nature-zero . github . io/static/videos/infnatzeroresults . MP4</a></p><p id="417d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里有一个分两步走的例子:</p><ul class=""><li id="6e85" class="mu mv iq ky b kz la lc ld lf mw lj mx ln my lr mz na nb nc bi translated"><strong class="ky ir">一帧</strong></li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nl"><img src="../Images/fecc7c805368055f90301fff882e1622.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gUdIbjvadHKFhufi-Xu93Q.jpeg"/></div></div></figure><ul class=""><li id="054e" class="mu mv iq ky b kz la lc ld lf mw lj mx ln my lr mz na nb nc bi translated"><strong class="ky ir">第二帧</strong></li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nl"><img src="../Images/33b53013f61ed9313d6429ce42334c67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oyqMVAoLt3kXd2HTt3HGLA.jpeg"/></div></div></figure></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><p id="e56d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">总结</strong></p><p id="a3b9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">新的 2022 谷歌研究甘图像生成器是一个伟大的工具，创造现实的三维图像。它也是一个强大的工具，用于创建用传统方法无法创建的图像。在不久的将来，这种工具可以用来为娱乐或广告制作逼真的图像或视频。此外，它可以用于生成新的数据来训练机器学习模型，这可以提高这些模型的准确性。</p><p id="0492" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如有任何问题，欢迎在下方留言，继续探索:-)</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nm"><img src="../Images/13be7a431c0349ba51329468671d7962.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eTLV__ZZGIO13DNwXQqQMw.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">Philippe Bouaziz 设计的巴黎“la madeleine”街</figcaption></figure></div></div>    
</body>
</html>