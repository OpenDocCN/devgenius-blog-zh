<html>
<head>
<title>ResNet50</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ResNet50</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/resnet50-6b42934db431?source=collection_archive---------0-----------------------#2022-03-14">https://blog.devgenius.io/resnet50-6b42934db431?source=collection_archive---------0-----------------------#2022-03-14</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><p id="6b34" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">ResNet-50 是一个 50 层深的卷积神经网络。ResNet 是残差网络的缩写，是一种经典的神经网络，用作许多计算机视觉任务的主干。ResNet 的根本突破是它允许我们训练具有 150+层的非常深的神经网络。这是一种创新的神经网络，何，，任，在他们 2015 年的计算机视觉研究论文中首次提出，论文名为<strong class="jm io">‘图像识别的深度残差学习’</strong>。</p><p id="af4b" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">卷积神经网络有一个主要的缺点——<strong class="jm io">消失梯度问题</strong>。在反向传播过程中，梯度值显著减小，因此权重几乎没有变化。为了克服这一点，使用了 ResNet。它利用<strong class="jm io">“跳过连接”。</strong></p><h2 id="4001" class="ki kj in bd kk kl km dn kn ko kp dp kq jv kr ks kt jz ku kv kw kd kx ky kz la bi translated">ResNet-50 架构</h2><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/1f23a7a8c82ab28aa64127fc97e27e30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9LqUp7XyEx1QNc6A.png"/></div></div></figure><p id="5ca5" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io">跳过连接</strong> — <em class="ln">将原始输入添加到卷积块的输出。</em></p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lo"><img src="../Images/96f2a319c871d5732dd253291f076377.png" data-original-src="https://miro.medium.com/v2/resize:fit:1020/format:webp/1*TlcuN-PjLbXYSYQKqpTIzw.png"/></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk translated">跳过连接</figcaption></figure><p id="8a57" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">所有算法都在输出‘Y’上训练，但是 ResNet 在 F(X)上训练。更简单地说，ResNet 试图使 F(X)=0，使 Y=X。</p><p id="c737" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io">跳过连接</strong>是跳过模型某些层的直接连接。由于这种跳过连接，输出是不同的。如果没有跳过连接，输入 X 将乘以图层的权重，然后添加一个偏差项。</p><p id="703d" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">然后是激活函数 F()，我们得到的输出是:</p><p id="32cb" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io"> F( w*x + b ) (=F(X)) </strong></p><p id="0860" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">但是使用跳过连接技术，输出是:</p><p id="495c" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io"> F(X)+x </strong></p><p id="417e" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">在 ResNet-50 中，有两种类型的块</p><ol class=""><li id="ddce" class="lt lu in jm b jn jo jr js jv lv jz lw kd lx kh ly lz ma mb bi translated">身份块</li><li id="6a66" class="lt lu in jm b jn mc jr md jv me jz mf kd mg kh ly lz ma mb bi translated">卷积块</li></ol><p id="2d5f" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">当且仅当,“x”的值被添加到输出层</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/6e0e00896f5c96bb2247eecd4424b34a.png" data-original-src="https://miro.medium.com/v2/resize:fit:482/format:webp/1*wwmasNpGzolM0FswrY0h3A.png"/></div></figure><p id="d395" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">如果不是这样，我们在快捷路径中添加一个<strong class="jm io">‘卷积块’</strong>，使输入大小等于输出大小。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/419c0a4b028fc5ac240aee2dc96a793b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/0*2f4GK4NXT8w3svqg.JPG"/></div></figure><p id="4109" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">有两种方法可以使输入大小等于输出大小-</p><ol class=""><li id="0ad3" class="lt lu in jm b jn jo jr js jv lv jz lw kd lx kh ly lz ma mb bi translated">填充输入音量，</li><li id="2c1a" class="lt lu in jm b jn mc jr md jv me jz mf kd mg kh ly lz ma mb bi translated">执行 1*1 卷积。</li></ol><p id="4f82" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">输出层的大小通过以下公式计算—</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/d231ac9d6bfb5af77cfd06d664ddef6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:340/format:webp/1*MF8XgxXzK8wzDwzNHYuT4Q.png"/></div></figure><p id="6be5" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">在哪里，</p><p id="94bb" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">n=输入图像大小，</p><p id="7b8c" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">p =填充，</p><p id="9d58" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">s =步幅，</p><p id="c8e9" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">f =过滤器数量。</p><p id="b052" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">对于 1*1 卷积层，输出层的大小=</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/49238da9bdf3028d9ef2728e057ee1b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:254/format:webp/1*czgYO_l_WyNvf7ytZrCa9g.png"/></div></figure><p id="9319" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">给定输入大小为“n”。</p><p id="1718" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">在 CNN 中，为了减小图像的大小，使用了池。这里，我们使用 stride=2 来代替。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ml"><img src="../Images/726bba10660f3df4245377c2b5b413ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mdh0V22fZIuq2XJw.png"/></div></div></figure></div><div class="ab cl mm mn hr mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ig ih ii ij ik"><p id="1771" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><em class="ln">感谢阅读！如有任何疑问，请随时联系我的</em><a class="ae mt" href="http://aditi2507rastogi@gmail.com/" rel="noopener ugc nofollow" target="_blank"><strong class="jm io"><em class="ln">Gmail</em></strong></a><strong class="jm io"><em class="ln"/></strong><em class="ln">或我的</em> <a class="ae mt" href="https://www.linkedin.com/in/aditi-rastogi-961789191/" rel="noopener ugc nofollow" target="_blank"> <strong class="jm io"> <em class="ln"> LinkedIn 个人资料</em></strong></a><strong class="jm io"><em class="ln"/></strong><em class="ln">或</em><a class="ae mt" href="https://github.com/AditiRastogi250701" rel="noopener ugc nofollow" target="_blank"><strong class="jm io"><em class="ln">GitHub</em></strong></a><em class="ln">个人资料。</em></p></div></div>    
</body>
</html>