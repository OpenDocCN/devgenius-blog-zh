<html>
<head>
<title>Football webscraping: Data collection from a top european league — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">足球网络搜集:来自欧洲顶级联赛的数据收集——第一部分</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/football-webscraping-data-collection-from-a-top-european-league-e433dedb5d48?source=collection_archive---------6-----------------------#2022-12-06">https://blog.devgenius.io/football-webscraping-data-collection-from-a-top-european-league-e433dedb5d48?source=collection_archive---------6-----------------------#2022-12-06</a></blockquote><div><div class="fc if ig ih ii ij"/><div class="ik il im in io"><div class=""/><p id="6bcd" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated"><em class="km">“预测模型的好坏取决于提供给它的数据”</em> —保罗·科克兰，又名作者。但是我相信很多其他人以前也说过这句话。:)</p><p id="8802" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">今天，我将通过第一阶段为足球做一个预测模型。当然，有许多免费的开源网站提供了不错的足球统计数据。但当我浏览欧洲主要足球联赛时，法国法甲联赛的官方网站提供了许多经 Opta 验证的有趣统计数据。</p><p id="a87b" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">从下面的截图中可以看到一些其他地方没有的统计数据，包括传球准确性，对手半场的传球准确性，禁区内的射门以及与传中有关的统计数据。如果你在每个标签中循环，大约有 25 个字段可用。这是一个很好的起点。</p><figure class="ko kp kq kr gu ks gi gj paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gi gj kn"><img src="../Images/d555e5702ce6a1eb2e501b03ef6fd1a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*65gLy0gmfdQbaG3n5c6J0Q.png"/></div></div><figcaption class="kz la gk gi gj lb lc bd b be z dk translated">图 1:法国法甲官方网站。</figcaption></figure><h1 id="9891" class="ld le ir bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated"><strong class="ak">数据</strong></h1><p id="91fb" class="pw-post-body-paragraph jo jp ir jq b jr mb jt ju jv mc jx jy jz md kb kc kd me kf kg kh mf kj kk kl ik bi translated">csv 格式的最终数据帧如下所示。为了达到这一点，在熊猫中除了一些清洁工作之外，还有网页清扫。</p><figure class="ko kp kq kr gu ks gi gj paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gi gj mg"><img src="../Images/a823b160210c8a0d338c23a0403488d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1iAxy5N_cMeTfS_zqWQxBA.png"/></div></div><figcaption class="kz la gk gi gj lb lc bd b be z dk translated">图 2:最终数据帧。</figcaption></figure><p id="8b5a" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">所以让我们从数据收集方法开始。</p><h1 id="abd0" class="ld le ir bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated"><strong class="ak">网页抓取</strong></h1><p id="2d53" class="pw-post-body-paragraph jo jp ir jq b jr mb jt ju jv mc jx jy jz md kb kc kd me kf kg kh mf kj kk kl ik bi translated">Python 是这里使用的语言，我发现它是最容易使用的，尽管这可以通过一些 r 知识来实现。与您选择的浏览器兼容的 web 驱动程序是一项要求，它的可执行路径存储在您的计算机上。你可以在这里下载 chrome 的 webdriver】。其他浏览器可下载的文件很容易通过在线搜索找到。</p><p id="9340" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">其他值得注意的库有:</p><p id="1055" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">熊猫:用于清洁。</p><p id="75f6" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">时间:用于输入睡眠值，以确保 chrome 驱动程序在抓取游戏之间有一个喘息的时间。这允许加载所有数据，也有助于避免从网站上抓取软件。我首先导入库，然后建立一个空列表，用于存储循环中的所有游戏。</p><pre class="ko kp kq kr gu mi mj mk bn ml mm bi"><span id="2fa2" class="mn le ir mj b be mo mp l mq mr">from selenium import webdriver<br/>from selenium.webdriver.chrome.options import Options<br/>from selenium.webdriver.support.ui import WebDriverWait<br/>from selenium.webdriver.support import expected_conditions as EC<br/>from selenium.webdriver import ActionChains<br/>from selenium.webdriver.common.by import By<br/>from time import sleep, time<br/>import pandas as pd<br/>import warnings<br/><br/>warnings.filterwarnings('ignore')<br/><br/># set up empty dataframe in a list for storage.<br/>dataframe = []</span></pre><p id="979b" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">法国法甲网站有一个很好的功能，所有的游戏网址都用一个数字 ID 存储，比如:<a class="ae mh" href="https://www.ligue1.com/match?matchId=70899" rel="noopener ugc nofollow" target="_blank">https://www.ligue1.com/match?matchId=70899</a></p><p id="9207" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">这使得(如果你读过我的其他文章，你会注意到这是不可能的)我可以一次自动抓取几个游戏，而不必手动粘贴 URL。根据一点研究，本赛季的第一场比赛的 ID 是 70760，而最后一场比赛，也就是世界杯开始前的最后一场比赛的 ID 是 70909。<code class="fe ms mt mu mj b">range()</code>函数最多可以有三个参数:</p><pre class="ko kp kq kr gu mi mj mk bn ml mm bi"><span id="0851" class="mn le ir mj b be mo mp l mq mr">range(start, stop, step)</span></pre><p id="e402" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">start 参数包含了我们设置的 ID，但 stop 没有，这意味着我必须在 ID 上加 1，以确保赛季结束前的所有 150 场比赛都被取消。</p><p id="e641" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">我在 f 字符串中的变量 base_url 中提供了基本 url，这允许循环在每次迭代中使用 ID。其他参数是设置 chromedriver。Option.headless = False 让我们可以看到 chrome 驱动在做什么。传递你的可执行路径，你曾经存储你的 chromedriver 或其他浏览器的下载。Maximize_window 确实像它听起来的那样，只是最大化自动化浏览器的屏幕。每场比赛都会弹出一个 cookie，所以我将它设置为被接受，这样我们就可以继续了。</p><pre class="ko kp kq kr gu mi mj mk bn ml mm bi"><span id="5610" class="mn le ir mj b be mo mp l mq mr">for id in range(70760,70910):<br/><br/>    base_url = f'https://www.ligue1.com/match?matchId={id}'<br/><br/>    option = Options()<br/>    option.headless = False<br/>    driver = webdriver.Chrome("C:/Users/paulc/Documents/Football Data project/DroppingOddsScraper/chromedriver.exe",options=option)<br/>    driver.get(base_url)<br/><br/>    driver.maximize_window()<br/><br/># click the cookie pop up<br/>    WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, "/html/body/div/div/div/div/div/div/div[3]/button[2]/span"))).click()</span></pre><p id="de2e" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">当 chromedriver 导航到该 URL 时，默认的着陆位置是这个页面，其中 live 选项卡是打开的。统计数据不在这里，除非我们告诉 chromedriver 点击统计选项卡打开页面，否则我们无法抓取。</p><figure class="ko kp kq kr gu ks gi gj paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gi gj mv"><img src="../Images/31c0b1808d4d44958574793d3fd9d559.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tGCw1TObzGHXZGDlgQOXyg.png"/></div></div><figcaption class="kz la gk gi gj lb lc bd b be z dk translated">图 3:默认着陆。</figcaption></figure><p id="af0a" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">像下面这样传递 stats 选项卡的 xpath，并使用 actions.move_to_element 单击选项卡，得到我们需要的驱动程序。如果你保留 option.headless = False，你会看到 chrome 实时这样做，这很酷，至少第一次是这样的:)。</p><p id="0668" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">然后，我遍历感兴趣的信息，收集它的 xpath，并使用文本检索值，并将它们存储到一个变量中。因为这个页面在一个单独的类中存储更高的统计数据，所以分组不是一个选项，但是如果类都是这样的话，代码会少得多。</p><figure class="ko kp kq kr gu ks gi gj paragraph-image"><div class="gi gj mw"><img src="../Images/d52f4d7abf6e4bc41273b1322abb71a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*G9VDj9iE6HuPRJoAfNu82Q.png"/></div><figcaption class="kz la gk gi gj lb lc bd b be z dk translated">图 4:类。</figcaption></figure><pre class="ko kp kq kr gu mi mj mk bn ml mm bi"><span id="349a" class="mn le ir mj b be mo mp l mq mr"># navigate to the stats - general tab.<br/>    element = WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, "//a[text()='Stats']")))<br/>    actions = ActionChains(driver)<br/>    actions.move_to_element(element).click().perform()<br/><br/><br/># scraping the general stats page.<br/><br/><br/>    sleep(1)<br/><br/>    date = driver.find_element("xpath",<br/>            '/html/body/main/div[1]/div/div/div[2]/div[1]/p[1]').text<br/><br/>    Round = driver.find_element("xpath",<br/>            '/html/body/main/div[1]/div/div/div[2]/div[1]/h2').text<br/><br/><br/>    home_team = driver.find_element("xpath",<br/>            '/html/body/main/div[1]/div/div/div[2]/div[2]/div[1]/a/h2').text<br/><br/>    away_team = driver.find_element("xpath",<br/>            '/html/body/main/div[1]/div/div/div[2]/div[2]/div[3]/a/h2').text<br/><br/>    home_possesion = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[1]/div/table/tbody/tr[2]/td[1]').text<br/><br/>    away_possesion = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[1]/div/table/tbody/tr[2]/td[3]').text<br/><br/>    home_duel_success_rate = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[1]/div/table/tbody/tr[4]/td[1]').text<br/><br/>    away_duel_success_rate = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[1]/div/table/tbody/tr[4]/td[3]').text<br/><br/>    home_aerial_success_rate = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[1]/div/table/tbody/tr[6]/td[1]').text<br/><br/>    away_aerial_success_rate = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[1]/div/table/tbody/tr[6]/td[3]').text<br/><br/>    home_interceptions = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[1]/div/table/tbody/tr[8]/td[1]').text<br/><br/>    away_interceptions = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[1]/div/table/tbody/tr[8]/td[3]').text<br/><br/><br/>    home_offsides = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[1]/div/table/tbody/tr[10]/td[1]').text<br/><br/>    away_offsides = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[1]/div/table/tbody/tr[10]/td[3]').text<br/><br/>    home_corners = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[1]/div/table/tbody/tr[12]/td[1]').text<br/><br/>    away_corners = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[1]/div/table/tbody/tr[12]/td[3]').text</span></pre><p id="fd5d" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">接下来的阶段重复导航每个选项卡和收集统计数据的过程。</p><pre class="ko kp kq kr gu mi mj mk bn ml mm bi"><span id="5463" class="mn le ir mj b be mo mp l mq mr">sleep(1)<br/># move to distribution tab.<br/><br/><br/>    element = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, "//a[text()='Distribution']")))<br/>    actions = ActionChains(driver)<br/>    actions.move_to_element(element).click().perform()<br/><br/><br/>    home_passes = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[2]/div/table/tbody/tr[2]/td[1]').text<br/><br/>    away_passes = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[2]/div/table/tbody/tr[2]/td[3]').text<br/><br/><br/>    home_long_passes = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[2]/div/table/tbody/tr[4]/td[1]').text<br/><br/>    away_long_passes = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[2]/div/table/tbody/tr[4]/td[3]').text<br/><br/>    home_pass_acc = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[2]/div/table/tbody/tr[6]/td[1]').text<br/><br/>    away_pass_acc = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[2]/div/table/tbody/tr[6]/td[3]').text<br/><br/>    home_pass_acc_opp_half = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[2]/div/table/tbody/tr[8]/td[1]').text<br/><br/>    away_pass_acc_opp_half = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[2]/div/table/tbody/tr[8]/td[3]').text<br/><br/>    home_crossing = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[2]/div/table/tbody/tr[10]/td[1]').text<br/><br/>    away_crossing = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[2]/div/table/tbody/tr[10]/td[3]').text<br/><br/>    home_crossing_acc = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[2]/div/table/tbody/tr[12]/td[1]').text<br/><br/>    away_crossing_acc = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[2]/div/table/tbody/tr[12]/td[3]').text<br/><br/><br/><br/><br/>    sleep(1)<br/># move to attack tab.<br/><br/>    element = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, "//a[text()='Attack']")))<br/>    actions = ActionChains(driver)<br/>    actions.move_to_element(element).click().perform()<br/><br/><br/>    home_goals = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[3]/div/table/tbody/tr[2]/td[1]').text<br/><br/>    away_goals = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[3]/div/table/tbody/tr[2]/td[3]').text<br/><br/>    home_shots = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[3]/div/table/tbody/tr[4]/td[1]').text<br/><br/>    away_shots = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[3]/div/table/tbody/tr[4]/td[3]').text<br/><br/>    home_shots_on_target = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[3]/div/table/tbody/tr[6]/td[1]').text<br/><br/>    away_shots_on_target = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[3]/div/table/tbody/tr[6]/td[3]').text<br/><br/>    home_blocked_shots = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[3]/div/table/tbody/tr[8]/td[1]').text<br/><br/>    away_blocked_shots = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[3]/div/table/tbody/tr[8]/td[3]').text<br/><br/>    home_shots_os_box = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[3]/div/table/tbody/tr[10]/td[1]').text<br/><br/>    away_shots_os_box = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[3]/div/table/tbody/tr[10]/td[3]').text<br/><br/>    home_shots_is_box = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[3]/div/table/tbody/tr[12]/td[1]').text<br/><br/>    away_shots_is_box = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[3]/div/table/tbody/tr[12]/td[3]').text<br/><br/>    home_shooting_acc = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[3]/div/table/tbody/tr[14]/td[1]').text<br/><br/>    away_shooting_acc = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[3]/div/table/tbody/tr[14]/td[3]').text<br/><br/><br/>    sleep(1)<br/><br/># move to defence tab.<br/><br/>    element = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, "//a[text()='Defence']")))<br/>    actions = ActionChains(driver)<br/>    actions.move_to_element(element).click().perform()<br/><br/>    home_tackles = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[4]/div/table/tbody/tr[2]/td[1]').text<br/><br/>    away_tackles = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[4]/div/table/tbody/tr[2]/td[3]').text<br/><br/>    home_tackles_success_rate = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[4]/div/table/tbody/tr[4]/td[1]').text<br/><br/>    away_tackles_success_rate = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[4]/div/table/tbody/tr[4]/td[3]').text<br/><br/>    home_clearances = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[4]/div/table/tbody/tr[6]/td[1]').text<br/><br/>    away_clearances = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[4]/div/table/tbody/tr[6]/td[3]').text<br/><br/><br/>    sleep(1)<br/><br/># move to discipline tab.<br/><br/>    element = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, "//a[text()='Discipline']")))<br/>    actions = ActionChains(driver)<br/>    actions.move_to_element(element).click().perform()<br/><br/>    home_fouls = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[5]/div/table/tbody/tr[2]/td[1]').text<br/><br/>    away_fouls = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[5]/div/table/tbody/tr[2]/td[3]').text<br/><br/>    home_yellows = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[5]/div/table/tbody/tr[4]/td[1]').text<br/><br/>    away_yellows = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[5]/div/table/tbody/tr[4]/td[3]').text<br/><br/>    home_reds = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[5]/div/table/tbody/tr[6]/td[1]').text<br/><br/>    away_reds = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[3]/div/div/div/div/div/ul/li[5]/div/table/tbody/tr[6]/td[3]').text<br/><br/><br/>    sleep(1)<br/><br/># move to lineups tab to get referee.<br/><br/><br/>    element = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, "//a[text()='Line-ups']")))<br/>    actions = ActionChains(driver)<br/>    actions.move_to_element(element).click().perform()<br/><br/>    referee = driver.find_element("xpath",<br/>            '/html/body/main/div[2]/div/div/div[2]/div[4]/div/div/div[3]/div/div/div[2]/ul/li[1]/span[2]').text</span></pre><p id="3016" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">这使得大量信息存储在变量中。还记得我在开始时设置的空列表吗？此时，我可以将每个匹配变量存储到一个名为 scraped_data 的列表中，并将其附加到 dataframe 中。continue 行告诉 webdriver 循环到下一个匹配，最后当它通过提供的范围时，它将退出。</p><pre class="ko kp kq kr gu mi mj mk bn ml mm bi"><span id="8a30" class="mn le ir mj b be mo mp l mq mr">scraped_data = [date,Round,home_team,away_team,home_possesion,away_possesion,home_duel_success_rate,away_duel_success_rate,home_aerial_success_rate,away_aerial_success_rate,<br/>            home_interceptions,away_interceptions,home_offsides,away_offsides,home_corners,away_corners,home_passes,away_passes,home_long_passes,away_long_passes,home_pass_acc,away_pass_acc,home_pass_acc_opp_half,away_pass_acc_opp_half,home_crossing,away_crossing,home_crossing_acc,away_crossing_acc,home_goals,away_goals,<br/>            home_shots,away_shots,home_shots_on_target,away_shots_on_target,home_blocked_shots,away_blocked_shots,home_shots_os_box,away_shots_os_box,home_shots_is_box,<br/>            away_shots_is_box,home_shooting_acc,away_shooting_acc,home_tackles,away_tackles,home_tackles_success_rate,away_tackles_success_rate,home_clearances,away_clearances,<br/>            home_fouls,away_fouls,home_yellows,away_yellows,home_reds,away_reds,referee]<br/><br/><br/>dataframe.append(scraped_data)<br/><br/>continue<br/><br/>driver.quit()</span></pre><h1 id="683e" class="ld le ir bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated"><strong class="ak">清洁</strong></h1><p id="8ed7" class="pw-post-body-paragraph jo jp ir jq b jr mb jt ju jv mc jx jy jz md kb kc kd me kf kg kh mf kj kk kl ik bi translated">所以现在我们所有的比赛数据都是一个非常脏的形式，需要进行清理，这样我才能让数据帧正常工作。我设置了一个包含所有列名的空列表，每个队一个，并将存储每个匹配数据的列表转换为 pandas 数据帧，为其提供列名。</p><pre class="ko kp kq kr gu mi mj mk bn ml mm bi"><span id="b700" class="mn le ir mj b be mo mp l mq mr">columns = ['Date','Round','HomeTeam','AwayTeam','Possession_Home','Possession_Away','Home_duels_success_rate','Away_duels_success_rate','Home_aerials_success_rate','Away_aerials_success_rate','Home_interceptions','Away_interceptions','Home_offsides','Away_offsides','Home_corners','Away_corners','Home_passes','Away_passes',<br/> 'Home_long_passes','Away_long_passes','Home_passing_acc','Away_passing_acc','Home_passing_acc_opp_half','Away_passing_acc_opp_half','Home_crosses','Away_crosses',<br/> 'Home_crossing_acc','Away_crossing_acc','HomeGoals','AwayGoals','HomeShots','AwayShots','HomeSOT','AwaySOT','Home_blocked_shots','Away_blocked_shots','Home_Shots_OB','Away_Shots_OB','Home_Shots_IB','Away_shots_IB','Home_shooting_acc','Away_shooting_acc','HomeTackles','AwayTackles','Home_Tackle_success_rate','Away_Tackle_success_rate',<br/>  'HomeClearances','AwayClearances','HomeFouls','AwayFouls','HomeYellows','AwayYellows','HomeReds','AwayReds','Referee']<br/><br/><br/>final_df = pd.DataFrame(dataframe)<br/>final_df.columns = columns</span></pre><p id="8677" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">接下来的几行清理了数据，提供的注释解释了我为什么这么做以及我在做什么。球队的名字也很有趣，这就是为什么我用字典给他们重新命名，让他们更好看。</p><pre class="ko kp kq kr gu mi mj mk bn ml mm bi"><span id="ab77" class="mn le ir mj b be mo mp l mq mr">#cleaning<br/><br/># strip ROUND from round<br/><br/>final_df['Round'] = final_df['Round'].str.strip('ROUND')<br/><br/><br/># extract time from date<br/><br/>final_df['Time'] = [i.split("-")[1] for i in final_df['Date']]<br/><br/># turn date column into datetime.<br/><br/>final_df['Date'] = pd.to_datetime(final_df['Date'])<br/>final_df['Date'] = final_df['Date'].dt.date<br/><br/><br/># fix capitalisation of string columns<br/><br/>final_df['HomeTeam'] = final_df['HomeTeam'].str.title()<br/>final_df['AwayTeam'] = final_df['AwayTeam'].str.title()<br/>final_df['Referee'] = final_df['Referee'].str.title()<br/><br/><br/># remove % sign<br/><br/>final_df = final_df.replace('\%','',regex=True)<br/><br/># turn columns into float.<br/><br/>final_df[['Round','Possession_Home','Possession_Away','Home_duels_success_rate','Away_duels_success_rate','Home_aerials_success_rate','Away_aerials_success_rate','Home_interceptions','Away_interceptions','Home_offsides','Away_offsides','Home_corners','Away_corners','Home_passes','Away_passes',<br/> 'Home_long_passes','Away_long_passes','Home_passing_acc','Away_passing_acc','Home_passing_acc_opp_half','Away_passing_acc_opp_half','Home_crosses','Away_crosses',<br/> 'Home_crossing_acc','Away_crossing_acc','HomeGoals','AwayGoals','HomeShots','AwayShots','HomeSOT','AwaySOT','Home_blocked_shots','Away_blocked_shots','Home_Shots_OB','Away_Shots_OB','Home_Shots_IB','Away_shots_IB','Home_shooting_acc','Away_shooting_acc','HomeTackles','AwayTackles','Home_Tackle_success_rate','Away_Tackle_success_rate',<br/>  'HomeClearances','AwayClearances','HomeFouls','AwayFouls','HomeYellows','AwayYellows','HomeReds','AwayReds']] = final_df[['Round','Possession_Home','Possession_Away','Home_duels_success_rate','Away_duels_success_rate','Home_aerials_success_rate','Away_aerials_success_rate','Home_interceptions','Away_interceptions','Home_offsides','Away_offsides','Home_corners','Away_corners','Home_passes','Away_passes','Home_long_passes','Away_long_passes','Home_passing_acc','Away_passing_acc','Home_passing_acc_opp_half','Away_passing_acc_opp_half','Home_crosses','Away_crosses','Home_crossing_acc','Away_crossing_acc','HomeGoals','AwayGoals','HomeShots','AwayShots','HomeSOT','AwaySOT','Home_blocked_shots','Away_blocked_shots','Home_Shots_OB','Away_Shots_OB','Home_Shots_IB','Away_shots_IB','Home_shooting_acc','Away_shooting_acc','HomeTackles','AwayTackles','Home_Tackle_success_rate','Away_Tackle_success_rate','HomeClearances','AwayClearances','HomeFouls','AwayFouls','HomeYellows','AwayYellows','HomeReds','AwayReds']].astype(float)<br/><br/><br/># reformat % columns by dividing by 100.<br/><br/><br/>final_df[['Possession_Home','Possession_Away','Home_duels_success_rate','Away_duels_success_rate','Home_aerials_success_rate','Away_aerials_success_rate','Home_passing_acc','Away_passing_acc','Home_passing_acc_opp_half','Away_passing_acc_opp_half','Home_crossing_acc','Away_crossing_acc','Home_shooting_acc','Away_shooting_acc','Home_Tackle_success_rate','Away_Tackle_success_rate']] = final_df[['Possession_Home','Possession_Away','Home_duels_success_rate','Away_duels_success_rate','Home_aerials_success_rate','Away_aerials_success_rate','Home_passing_acc','Away_passing_acc','Home_passing_acc_opp_half','Away_passing_acc_opp_half','Home_crossing_acc','Away_crossing_acc','Home_shooting_acc','Away_shooting_acc','Home_Tackle_success_rate','Away_Tackle_success_rate']].div(100).round(2)<br/><br/><br/># apply dictionary to remap names.<br/><br/><br/>teams_dict = {"Rc Lens":"Lens",<br/>              "Angers Sco":"Angers",<br/>              "Fc Nantes":"Nantes",<br/>              "Losc":"Lille",<br/>              "Ol":"Lyon",<br/>              "Ogc Nice":"Nice",<br/>              "Om":"Marseille",<br/>              "As Monaco":"Monaco",<br/>              "Ac Ajaccio":"Ajaccio",<br/>              "Aj Auxerre":"Auxerre",<br/>              "Toulouse Fc":"Toulouse",<br/>              "Fc Lorient":"Lorient"}<br/><br/>for key, value in final_df['HomeTeam'].iteritems():<br/>    final_df['HomeTeam'] = final_df['HomeTeam'].apply(lambda x: teams_dict.get(x,x))<br/><br/>for key, value in final_df['AwayTeam'].iteritems():<br/>    final_df['AwayTeam'] = final_df['AwayTeam'].apply(lambda x: teams_dict.get(x,x))<br/><br/><br/>final_df</span></pre><p id="aceb" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">然后我可以使用 final _ df . to _ CSV(' Ligue 1 _ 2223 . CSV '，index=False)将它本地存储在我的 PC 上。下面是我加载的一个 youtube 视频，展示了 webscraper 的运行。</p><figure class="ko kp kq kr gu ks"><div class="bz fq l di"><div class="mx my l"/></div><figcaption class="kz la gk gi gj lb lc bd b be z dk translated">视频演示。</figcaption></figure><h1 id="6011" class="ld le ir bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated"><strong class="ak">可能的改进</strong></h1><p id="ebac" class="pw-post-body-paragraph jo jp ir jq b jr mb jt ju jv mc jx jy jz md kb kc kd me kf kg kh mf kj kk kl ik bi translated">错误处理是一个大问题。目前，webscraper 能够处理将近半个赛季的数据，但如果它在某个特定的游戏中出错，那么失去进展将是一种耻辱。将这些实例存储到一个列表中，并允许 webscraper 继续前进，这是我将做的事情，并在未来的编辑中更新。</p><p id="8f37" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">我的<a class="ae mh" href="https://github.com/socrstats/webscraping" rel="noopener ugc nofollow" target="_blank"> github </a>上提供了完整的代码和数据，以节省您的时间。</p><h1 id="ca31" class="ld le ir bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated"><strong class="ak">编辑</strong></h1><p id="4837" class="pw-post-body-paragraph jo jp ir jq b jr mb jt ju jv mc jx jy jz md kb kc kd me kf kg kh mf kj kk kl ik bi translated">为了考虑可能的错误处理，我在 try 块中重新格式化了 scraper。我创建了一个空列表来存储潜在的错误。这将允许刮刀在遇到任何错误时继续工作。匹配的 id 将在你的笔记本/IDE 中打印出来。更新的刮刀在 github 中，取代了原来的刮刀。它是为了刮 21/22 赛季而设立的。</p><figure class="ko kp kq kr gu ks gi gj paragraph-image"><div class="gi gj mz"><img src="../Images/c5d4163938bb8ebd0c850dc34409668e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*9ap5xBzk43E0cFsfECi4Wg.png"/></div></figure><p id="930b" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">网络抓取的计算成本很高，当我尝试做一个完整的赛季时，我遇到了 chrome 驱动程序问题，我一直到第 34 轮都没有问题，所以可能值得将 21/22 的结束范围设置为 69238，以将抓取分成两次运行。</p><p id="fdc0" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">希望你喜欢，在不久的将来，我将在这篇文章的基础上进行一个基于这些数据(和前几年)的建模项目，所以请跟我来保持更新。</p><p id="c492" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated"><strong class="jq is">进一步编辑:我已经编辑了这里使用的代码，以自动进行每周数据的抓取。更新的 scraper 在 GitHub 链接上。它会查找结果页面上显示的所有 id，默认着陆是最近一轮。它通过漂亮的 soup 将这些 id 存储到一个列表中，for 循环遍历存储的 id，而不是 range 函数。</strong></p><p id="6fa1" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">第 2 部分现在可用了，我从这里的<a class="ae mh" href="https://leftsidedcentrehalf.medium.com/football-webscraping-data-collection-from-a-top-european-league-part-2-dashboard-creation-6352b13ced78" rel="noopener">创建了一个 Rshiny 仪表板。</a></p><p id="3eb7" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">谢谢，</p><p id="56ec" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">保罗</p></div></div>    
</body>
</html>