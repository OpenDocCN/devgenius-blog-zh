<html>
<head>
<title>You will never believe how machines can learn like humans: Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你永远不会相信机器如何像人类一样学习:第二部分</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/you-will-never-believe-how-machines-can-learn-like-humans-part-2-d62e080fe0f5?source=collection_archive---------33-----------------------#2020-07-07">https://blog.devgenius.io/you-will-never-believe-how-machines-can-learn-like-humans-part-2-d62e080fe0f5?source=collection_archive---------33-----------------------#2020-07-07</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><p id="f2a7" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">在我之前的文章中，我写了一些人工智能的基础知识。如果你还没有读过，请点击下面的链接。</p><p id="a95c" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><a class="ae ki" href="https://medium.com/dev-genius/you-will-never-believe-how-machine-can-learn-like-humans-b67faf26bf9c" rel="noopener">https://medium . com/dev-genius/you-will-would-been-have-you-believe-how-machine-learn-like-humans-b 67 faf 26 BF 9 c</a></p><p id="e588" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">今天让我们深入一点人工智能的概念。</p><p id="3347" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">你知道吗<strong class="jm io">“机器学习的结果取决于你输入的数据来训练它”</strong></p><p id="8218" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">我们都知道，没有大脑，人就无法正常运作。我们的身体部位和大脑之间必须有联系。这种联系是由神经网络建立的。同类型的神经网络负责机器学习！</p><h2 id="0a80" class="kj kk in bd kl km kn dn ko kp kq dp kr jv ks kt ku jz kv kw kx kd ky kz la lb bi translated">神经网络</h2><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi lc"><img src="../Images/29706baa3520c4e9c0a591826fb238bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*MQ3VgFWfSx-w_a4y"/></div></div><figcaption class="lo lp gj gh gi lq lr bd b be z dk translated">照片由<a class="ae ki" href="https://unsplash.com/@franckinjapan?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">法兰克诉</a>在<a class="ae ki" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</figcaption></figure><p id="6009" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">深度学习使用多层非线性处理单元进行特征提取和转换，称为神经网络。所有神经网络中最简单的是<strong class="jm io">感知器</strong>。<strong class="jm io">感知器</strong>使用单层神经网络，该网络使用输入特征列表。让我们看看这个例子，比如 x1 到 xn，其中 x1 可能是成本，x2 可能是数量等等。这些 x1 到 xn 被称为特征向量。在本例中，我们需要通过查看输入特性来确定客户是否会购买该产品。除了输入特征，在线性回归模型中还有一个偏差项，如截距。该输入特征、空间以及截距形成给出输出的线性特征。为了获得输出，我们需要为线性模型提供激活函数。这个激活函数基本上是非线性的，并且取决于我们试图解决的问题的类型。这里激活函数是 sigmoid 函数。在我们的例子中，我们需要确定客户是否会购买我们的产品。为此，输出是二进制形式。要么是，要么不是！</p><p id="9c0a" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">感知器非常简单，只有一层，由输入特征和产生输出的激活函数的总和组成。很久以前，感知器的概念很流行。加班的人给感知器增加了许多层。现在我们有一个输入层，原始层和隐藏层。一旦我们有了多层，感知器就变成了神经网络。神经网络非常复杂，在一层中有多层。它们甚至很难理解、解释和训练。由于深度学习的革命，我们有不同的框架来设计、训练和实现神经网络。这导致了多层的开发，因此我们可以拥有比以前更多的输入数据。深度学习框架有 Mxnet、TensorFlow、Cafe、PyTorch 等。这些是从不同的来源开发的，但是可以使用 Python 访问。是的，我们可以使用 python 来设计、训练和拟合神经网络。</p><h2 id="cd98" class="kj kk in bd kl km kn dn ko kp kq dp kr jv ks kt ku jz kv kw kx kd ky kz la lb bi translated">理解机器学习算法</h2><p id="b3b1" class="pw-post-body-paragraph jk jl in jm b jn ls jp jq jr lt jt ju jv lu jx jy jz lv kb kc kd lw kf kg kh ig bi translated">任何表现出智能行为的机器都需要具备两个基本特征。知识获取:机器获取周围知识并利用所获取的知识进行预测的能力是机器学习的一个非常重要的方面。<br/> <strong class="jm io"> 2。推断</strong>:机器推断以前经验的知识来做出现在预测的能力是机器学习的一个基本方面。<br/>我们在之前的文章中已经看到了机器学习的类型。它们是被监督的、非监督的和强化的。现在让我们看看这些类型的算法是如何设计出来的。</p><h2 id="00e9" class="kj kk in bd kl km kn dn ko kp kq dp kr jv ks kt ku jz kv kw kx kd ky kz la lb bi translated">1.监督学习算法</h2><p id="6d42" class="pw-post-body-paragraph jk jl in jm b jn ls jp jq jr lt jt ju jv lu jx jy jz lv kb kc kd lw kf kg kh ig bi translated">在监督学习的情况下，在用许多例子展示一台机器，并由老师解释机器是什么之后，就会生成算法。这也被称为训练机器学习模型。经过训练后，机器能够识别示例中未显示的其他类似事物。这简直就像一个新生儿在给它看了一个橘子并告诉它是什么之后，试图去辨别苹果和香蕉一样！有数百种监督学习算法。没有必要一一提及。所以我们可以按照某些家庭来分类。我们在上一篇文章中也看到了关于预测的类型。其中，回归是一种基于给定输入预测未知值的预测。为了根据类或类别分离对象，我们需要一个超平面，也称为分离两个对象的决策边界。如果存在一个线性曲面将两个类分开，那么它们被称为线性可分的。这些都很简单，而且有误差。所以我们需要将 logistic 函数应用于模型的线性组合的输出。这形成了逻辑回归算法的基础。这方面的一个例子是<em class="lx">亚马逊鼠尾草制造商</em></p><h2 id="93b5" class="kj kk in bd kl km kn dn ko kp kq dp kr jv ks kt ku jz kv kw kx kd ky kz la lb bi translated">2.无监督算法</h2><p id="4f69" class="pw-post-body-paragraph jk jl in jm b jn ls jp jq jr lt jt ju jv lu jx jy jz lv kb kc kd lw kf kg kh ig bi translated">在无监督学习的情况下，与有监督学习的情况一样，算法将不是线性的。这意味着必须有圆形甚至方形的边界。这些边界形成了树。这些来自树族的树形成许多树并给出预测，而不是构造一棵单独的树。像<em class="lx">随机森林</em>、<em class="lx"> XGBoost </em>这样的算法就是基于这些方法。事实上，<em class="lx">亚马逊 Sagemaker </em>也利用了<em class="lx"> XGBoost </em>。想法是从许多弱分类器中建立一个强分类器。这种方法被称为助推。<em class="lx"> XGBoost </em>是一个通用的监督算法。<em class="lx">factorization Machines</em>也是一种算法，当我们需要查看大量稀疏数据时使用，如在线广告中的点击预测。</p><h2 id="107d" class="kj kk in bd kl km kn dn ko kp kq dp kr jv ks kt ku jz kv kw kx kd ky kz la lb bi translated">使聚集</h2><p id="87cc" class="pw-post-body-paragraph jk jl in jm b jn ls jp jq jr lt jt ju jv lu jx jy jz lv kb kc kd lw kf kg kh ig bi translated">在无监督学习的情况下，<strong class="jm io">聚类</strong>是非常重要的。给定大量的数据点，它们被分成组和簇。聚类的问题是我们不知道要建立多少个聚类。如果我们请求算法生成两个聚类，那么得到的答案与请求生成四个聚类时得到的答案是不同的。</p><h2 id="41cc" class="kj kk in bd kl km kn dn ko kp kq dp kr jv ks kt ku jz kv kw kx kd ky kz la lb bi translated">异常检测</h2><p id="56c0" class="pw-post-body-paragraph jk jl in jm b jn ls jp jq jr lt jt ju jv lu jx jy jz lv kb kc kd lw kf kg kh ig bi translated">另一个非常流行的不同系列的无监督算法试图检测异常或试图找到数据的异常值。没有明确的老师将历史数据标记为异常，相反，该算法通过简单地观察数据来学习正常情况。一种异常检测算法是由在亚马逊工作的科学家开发的。它被称为乱砍森林。该算法通过构建所谓的随机切割树的森林来工作。每个树都是通过递归过程构建的，首先用边界框包围数据点，然后通过随机选取切割点沿坐标轴切割或分割。重复该过程，直到每个点都被分类到树的特定叶子中。</p><h2 id="33f7" class="kj kk in bd kl km kn dn ko kp kq dp kr jv ks kt ku jz kv kw kx kd ky kz la lb bi translated">主题建模</h2><p id="1198" class="pw-post-body-paragraph jk jl in jm b jn ls jp jq jr lt jt ju jv lu jx jy jz lv kb kc kd lw kf kg kh ig bi translated">无监督算法的另一个例子是用于具有文本内容的文档的所谓主题建模。该算法是亚马逊理解服务中同名功能的基础。给定一组文档(例如新闻文章)和我们想要发现的主题数量，该算法会产生定义该主题的最热门单词，以及这些单词中的每个单词相对于该主题的权重。与一般的聚类一样，这种方法对请求的主题数量很敏感，它仍然需要我们为发现的主题(如健康、体育或政治)指定含义。</p><p id="2355" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">总而言之，Amazon SageMaker 包含了一个流行的聚类算法，叫做<strong class="jm io"> k-means </strong>。这是亚马逊对著名的可扩展算法 Web-scale k-means 的改进。无监督家族的另一个成员被称为主成分分析或简称 PCA。同样在 SageMaker 有售。它在减少数据集的维度方面特别有用，并且通常在将数据传递给监督算法之前用作特征工程步骤。潜在狄利克雷分配或 LDA 是特定主题建模算法的名称。Amazon understand 的主题建模功能使用了一个变体，该算法在 sage maker 中也可用。SageMaker 和 Amazon Kinesis 数据分析中提供了用于异常检测的随机切割森林算法，以便轻松应用于流数据。Kinesis 数据分析还具有热点检测功能，这是无监督学习算法的另一个例子，可用于识别数据中相对密集的区域。</p><h2 id="f513" class="kj kk in bd kl km kn dn ko kp kq dp kr jv ks kt ku jz kv kw kx kd ky kz la lb bi translated">卷积神经网络</h2><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi ly"><img src="../Images/b860153ee06b3ecc3cba58a0ea205a96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7Xk87ABgM_Zqoq_M"/></div></div><figcaption class="lo lp gj gh gi lq lr bd b be z dk translated"><a class="ae ki" href="https://unsplash.com/@alinnnaaaa?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">阿丽娜·格鲁布尼亚</a>在<a class="ae ki" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="3d43" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">深度学习的一个重要突破是所谓的卷积神经网络(简称 CNN)的发明，它对图像处理特别有用。CNN 背后的主要思想是，它能够将图像中的邻近像素相关联，而不是像 CNN 出现之前那样，将它们视为完全独立的输入。一种称为卷积的特殊操作被应用于图像的整个子部分，更重要的是，这些卷积的参数也在这个过程中被学习。如果几个卷积层一个接一个地堆叠，随着我们在各层之间移动，每个卷积层都学会识别复杂度增加的模式。例如，它们可以用于语义分割或者将单个像素分类为属于或者不属于检测到的对象。</p><p id="3419" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">如果我们获取一个神经元的输出，并将其作为输入提供给自身或来自前几层的神经元，我们就创建了所谓的递归神经网络。这就好像神经元记得前一次迭代的输出，从而产生了一种记忆。在右手边，你可以看到一个更复杂的网络中的一个单元，叫做 LSTM，代表长短期记忆。它通常用于语音识别和翻译。事实上，LSTMs 被用作神经机器翻译中使用的序列对序列建模的构件。亚马逊发布了一个名为<strong class="jm io"> Sockeye </strong>的完整库，用于排序客户可以在他们的项目中使用的建模任务。</p><p id="47f3" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">Amazon SageMaker 方便地提供了一个基于 Resnet(一种 CNN)的内置图像分类算法，但它也提供了一个序列到序列算法，一个神经主题建模算法来补充潜在的 Dirichlet 分配，以及时间序列的 DeepAR 预测算法</p><p id="edca" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">写这篇文章真的很有趣。我希望你能像我喜欢写作一样喜欢阅读这篇文章…..！</p><p id="5ac8" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">谢谢你</p></div></div>    
</body>
</html>