# 基于 DolphinScheduler 的金融科技数据中心应用转型

> 原文：<https://blog.devgenius.io/application-transformation-of-the-fintech-data-center-based-on-dolphinscheduler-473359d94184?source=collection_archive---------23----------------------->

![](img/79cb282fb17c10bae00446a57360573a.png)

在上周的 Apache DolphinScheduler Meetup 上，来自方成 FinTech 的大数据工程师冯明霞为我们带来了 DolphinScheduler 在 FinTech 领域的应用实践。以下是演示文稿。

![](img/ca2fe38a758cd10ec960bed8b96890bc.png)

**冯明霞，方成金融科技大数据工程师**

专注于大数据领域的实时和离线数据处理与分析，目前主要负责数据中间平台的研发。

**演讲摘要:**

使用背景

基于 DolphinScheduler 的二次转换

DolphinScheduler 插件扩展

未来和展望

# **使用背景**

## **01 数据中心建设**

目前，大数据技术广泛应用于金融领域，大数据平台已经成为金融基础设施。在大数据平台的建设中，数据中心是最闪亮的明星，是业务系统使用大数据的入口和接口，当各种业务系统连接到数据中心时，数据中台需要提供统一管理和统一接入，以保证服务的安全、可靠、高效和可靠。

如下图所示，**数据中台**处于业务系统和大数据平台的中间环节，各业务系统通过数据中心提供的服务访问大数据平台。

![](img/ab5df30361b2321f7e9a3f568856ef9c.png)

数据中台的核心理念是实现**四化，**即**业务数据、数据资产、资产服务、服务业务**。从业务到数据，再回到业务形成的完整闭环，支撑企业数字化转型。

![](img/cfdc1661f6964cd0ce5c78de5a855646.png)

数据中间站逻辑架构图

数据中心的逻辑架构如上图所示，自下而上分析，首先，**底层**是数据资源层，是各种业务系统产生的原始数据；下一层是**数据集成**，数据集成的方法有离线采集和实时采集，其中使用的技术有 Flume、CDC 实时采集等。

下一层是**数据湖，**通过数据集成将数据放入湖中，存储在 Hadoop 分布式存储或 MPP 架构数据库中。

下一层是**数据引擎层**，通过 Flink、Spark 等实时和离线计算引擎对数据湖中的数据进行处理和分析，形成服务数据供上层使用。

下一层是数据中心需要提供的**数据服务**。目前，数据服务包括数据开发服务和数据共享服务，为上层业务系统提供数据开发和共享能力。

**数据应用层**是数据的具体应用，包括数据异常检测、数据治理、AI 决策、BI 分析。

在整个数据中间平台的建设中，调度引擎是数据引擎层的核心位置，也是数据中间平台建设中的重要功能。

# 数据中心面临的问题和挑战

数据中台将面临一些问题和挑战。

首先，数据任务的执行和调度是数据中心提供数据开发服务的核心和关键。

其次，数据中心提供统一的数据服务管理、服务开发、服务调用和服务监控。

第三，保证金融数据的安全是 FinTech 的首要任务，数据中台需要保证数据服务的安全性和可靠性。

在上述问题和挑战下，我们研究了一些开源的调度引擎。

![](img/f3b46c2fc183c8047f5ee81ddaf622a4.png)

目前，我们在生产过程中使用了多种调度引擎，如 oozie、XXL job、DolphinScheduler，这些都是我们在 2022 年通过研究和分析推出的，在整个数据中心的建设中起着非常重要的作用。

首先， **DolphinScheduler 部分解决了我们对统一服务管理、服务开发、服务调用和服务管理的需求**。

其次，**在任务容错方面有自己独特的设计，支持 HA、弹性扩展、容错，基本保证任务的安全运行**。

第三，**支持任务和节点监控**。

第四，**支持多租户和权限控制**。

最后，**它的社区非常活跃，版本变化快，问题修复快。**

通过对 DolphinScheduler 架构和源代码的分析，我们认为其架构符合主流大数据框架设计，与国外优秀产品 Hbase、Kafka 等有相似的架构模式和设计。

# **基于 DolphinScheduler 的二次开发**

为了使 DolphinScheduler 更适合我们的应用场景，我们在 DolphinScheduler 的基础上做了第二次改造，它包括 6 个方面。

1.  **增加异步服务调用功能**
2.  **添加元数据库 Oracle 适配**
3.  **增加多环境配置能力**
4.  **添加日志和历史数据清理策略**
5.  **添加对纱线日志的访问**
6.  **添加服务安全策略**

## **01** 增加异步服务调用功能

![](img/466f59c728c9a09ebf016f0df7d2faaf.png)

首先增加**异步服务调用函数**，上图是 DolphinScheduler 2 . 0 . 5 版本的架构，大部分是原生 dolphin scheduler 的服务组件。红色标记的网关是基于 DolphinScheduler 添加的网关服务。实现了流量控制，黑白名单，也是用户访问业务开发的入口。通过优化流程的启动接口，返回流程的唯一代码，我们增加了**服务映射**的功能。

![](img/5855509225a68d99826205aa6def444b.png)

在经典的 DolphinScheduler 访问模式下，用户提交的工作流执行指令会进入原数据库中的命令表，获得 zk 锁后，主组件从元数据库中获取命令，进行 DAG 解析，生成实际的流程实例，通过 RPC 将分解后的任务交付给工作节点执行，然后同步等待执行结果。

在原生的 DolphinScheduler 请求中，用户提交指令后，执行工作流的返回代码缺失，因此，我们增加了一个唯一的返回 ID，用户可以通过这个 ID 查询后续的进程状态，下载日志，下载数据。

## **02** 添加元数据库 Oracle 适配

我们的第二个转变是让 DolphinScheduler 适应 Oracle 数据库。目前原生 DolphinScheduler 的元数据库是 MySQL，我们需要根据生产需要将原数据库转换成 Oracle 数据库。为此，需要完成数据初始化模块和数据操作模块的适配。

![](img/e77bc3ce20a133d64f14ae298ffd3f26.png)

首先，对于数据初始化模块，我们修改了 install_ config。Conf 配置文件，将其更改为 Oracle 的配置。

其次，Oracle 应用程序需要添加 Yml，我们在 dolphinscheduler-2.0*/应用程序中。apache-dolphinscheduler-2.0 中加入了 Oracle 的 yml。* — bin/conf/directory。

最后我们转换数据操作模块，修改 mapper 文件和 file，因为 Dolphinscheduler-dao 模块是一个数据库操作模块，其他模块会引用这个模块来实现数据库操作。它使用 Mybatis 进行数据库连接，因此您需要更改映射器文件，所有映射器文件都在 resources 目录中。

## **03** 多环境配置能力

原生 DolphinScheduler 版本的安装不能根据环境进行配置，一般需要根据实际环境调整相关参数。我们希望通过安装脚本来增强环境选择和配置，以减少手动在线修改、自动安装的成本。相信所有的伙伴都遇到过类似的困难。为了在开发环境、测试环境、联调环境、性能环境、准生产环境、生产环境中使用 DolphinScheduler，需要修改大量与环境相关的配置参数。

我们修改 install Sh.file，添加输入参数[dev|test|product]，并选择适当的 install_ config_$ {evn}。可以安装 Conf 来自动选择环境。

另外，DolphinScheduler 的工作流与环境的绑定很强，不同环境下的工作流无法共享。下图显示了由原生 DolphinScheduler 导出的工作流的 JSON 文件。灰色部分表示流程所依赖的资源。ID 是一个数字，由数据库自动递增生成。但是，如果将环境 a 生成的流程实例放在环境 b 中，可能会出现 ID 主键冲突。换句话说，不同环境下生成的工作流是不能共享的。

![](img/6bc7e39cae9f2872509998dd0eda58d2.png)

我们通过生成资源的绝对路径作为资源的唯一 ID 来解决这个问题。

## **04** 日志和历史数据清理策略

DolphinScheduler 生成大量数据。数据库将在实例表中生成实例数据，该数据将随着实例任务的运行而不断增长。我们的策略是通过定义 DolphinScheduler 的调度任务，按照约定的保存周期清理这些表的数据。

其次，DolphinScheduler 的数据主要包括日志数据和任务执行目录，包括 worker、master、API 的服务日志数据，以及 worker 执行的目录。这些数据不会在任务执行结束时自动删除，还需要通过计划任务删除。通过运行日志清理脚本，我们可以自动删除日志。

![](img/7dc47c5a8d76da4dd75e01de3b2e9089.png)![](img/4e9c2e1ac2a49197657adaf89d382244.png)

## **05** 增加对纱线原木的获取

原生 DolphinScheduler 可以获取 worker 节点上执行的日志信息，但对于 Yarn 上的任务，需要登录 Yarn 集群，通过命令或界面获取。我们通过分析日志中的 YARNID 标签获得 Yarn 任务 ID，并通过 yarnclient 获得任务日志。减少了手动查看日志的过程。

![](img/d5c93e3d461bd2bff42332ea34477fef.png)

<yarnid>1234567890<yarnid></yarnid></yarnid>

## **06** 服务安全策略

添加监视器组件监控

![](img/cf4913524caa8d8eadaee6e45d3b5333.png)

上图显示了 DolphinScheduler 的两个核心组件 master 和 worker 以及 Zookeeper 之间的交互。MasterServer 服务启动时会向 Zookeeper 注册一个临时节点，通过监听 Zookeeper 临时节点的变化进行容错处理。WorkerServer 主要负责任务执行。当 WorkerServer 服务启动时，它向 Zookeeper 注册一个临时节点并维护心跳。目前，Zookeeper 扮演着非常重要的角色，主要表现在服务注册和心跳检测方面。

当主服务器和工作服务器连接到 Zookeeper 时，可以看到相关的参数，包括连接超时、会话超时和最大重试次数。

由于网络抖动和其他因素，主节点和工作节点可能会失去与 zk 的连接。连接丢失后，由于 worker 和 master 在 zk 上注册的临时信息消失，将确定 zk 从 master 和 worker 丢失，影响任务执行。没有人的干预，任务会被延迟。我们添加了 monitor 组件来监视服务状态。通过调度任务 cron，我们每 5 分钟运行一次 monitor 程序，检查工作进程和主进程是否处于活动状态。如果它们停机，将会重新启动。

*   **使用 zk 为服务组件添加 Kerberos 认证链接**

第二个安全策略是使用 zk 为服务组件添加 Kerberos 身份验证链接。Kerberos 是一种网络认证协议，旨在通过密钥系统为客户机/服务器应用程序提供强大的认证服务。主服务组件、API 服务组件、工作者服务组件在启动时完成 Kerberos 认证，然后使用 zk 进行相关服务注册和心跳连接，保证服务安全。

# **基于 DolphinScheduler 的插件扩展**

此外，我们还扩展了基于 DolphinScheduler 的插件。我们扩展了四种类型的操作符，包括 Richshell、SparkSQL、Dataexport 和 GBase 操作符。

## 添加新的任务类型 Richshell

首先，新的任务类型 Richshell 增强了原生 shell 功能。主要是通过模板引擎实现脚本参数的动态替换。用户可以通过服务调用替换脚本参数，使用户在使用参数时更加灵活。它是对全局参数的补充。

![](img/433fa92ddf80c1f11b35ed1bfe3a940d.png)

**添加一个新的任务类型 SparkSQL**

添加的第二个操作符是 SparkSQL。用户可以通过编写 SQL 来执行 Spark 任务，这样就可以在 Yarn 上调度任务。DolphinScheduler 原生也支持 JDBC 模式下的 SparkSQL 执行，但是因为 JDBC 连接数有限，所以会出现资源争用的情况。纱线簇模式不能用于通过 SparkSQL/Spark beer 等工具执行。通过使用这种任务类型，SparkSQL 程序可以以集群模式在 Yarn 集群上运行，以最大限度地利用集群资源并减少客户端资源的使用。

**添加新的任务类型数据导出**

第三个增加的是 Dataexport，它也是一个数据导出操作符。用户可以通过选择不同的存储组件来导出存储在组件中的数据。组件包括 ES、Hive、Hbase 等。

![](img/b9a3bc3611386e3d143e42942d2896db.png)

大数据平台中的数据导出后可能用于 BI 展示、统计分析、机器学习等数据准备。这些场景大多需要数据导出，利用 Spark 的数据处理能力来实现不同数据源的导出功能。

**添加新的任务类型 GBase**

添加的第四个插件是 Gbase。GBase 8a MPP 集群是一个具有列存储和无共享架构的分布式并行数据库集群。它具有高性能、高可用性、高扩展性等特点。它适用于 OLAP 场景(查询场景)，可以为大规模数据管理提供高性价比的通用计算平台，广泛用于支持各种数据仓库系统、BI 系统、决策支持系统。

![](img/fd0b0b4284fb0695a362977ed38d09e9.png)

作为数据入湖的应用场景，我们增加了 GBase 操作符，支持 GBase 数据的导入、导出和执行。

# **计划与展望**

未来我们会增加云原生支持，在现有架构上进行云原生改造。DolphinScheduler 已经迭代到版本 3，我们将继续更新支持。第二，添加 AI 模型算子。AI 应用场景越来越多。我们需要抽象出更多的 AI 场景；第三，增加灰度发布功能，实现无感知发布；第四，添加基于用户优先级的调度策略。

我相信，随着 DolphinScheduler、Kylin 等开源社区在中国的蓬勃发展，国产软件必将迎来更加美好的未来。最后，我想和大家分享一句话:“没有比追逐梦想更令人激动的力量，也没有比梦想更有力的脚步。”！

📌📌欢迎填写[这份调查](https://www.surveymonkey.com/r/7CHHWGW)来反馈您的用户体验或您对 Apache DolphinScheduler 的想法:)

[https://www.surveymonkey.com/r/7CHHWGW](https://www.surveymonkey.com/r/7CHHWGW)