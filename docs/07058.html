<html>
<head>
<title>Bias and Fairness in Machine Learning, Part 2: building a baseline model and features</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中的偏见和公平，第 2 部分:建立基线模型和特征</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/bias-and-fairness-in-machine-learning-part-2-building-a-baseline-model-and-features-358d13b39f1a?source=collection_archive---------19-----------------------#2022-02-21">https://blog.devgenius.io/bias-and-fairness-in-machine-learning-part-2-building-a-baseline-model-and-features-358d13b39f1a?source=collection_archive---------19-----------------------#2022-02-21</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><h2 id="aca4" class="il im in bd b dl io ip iq ir is it dk iu translated" aria-label="kicker paragraph">文章</h2><div class=""/><div class=""><h2 id="f176" class="pw-subtitle-paragraph jt iw in bd b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk dk translated"><em class="kl">来自</em> <a class="ae km" href="https://www.manning.com/books/feature-engineering-bookcamp?utm_source=medium&amp;utm_medium=organic&amp;utm_campaign=book_ozdemir_feature_11_11_21" rel="noopener ugc nofollow" target="_blank"> <em class="kl">特色工程图书营</em> </a> <em class="kl">作者:思南·奥兹德米尔</em></h2></div><p id="8125" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated"><strong class="kp ix"> <em class="lj">本系列文章涵盖</em> </strong></p><p id="73d4" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated"><em class="lj"> ●识别并减少我们的数据和模型中的偏差</em></p><p id="e99b" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated"><em class="lj"> ●通过各种指标量化公平性</em></p><p id="12ce" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated"><em class="lj"> ●应用特征工程技术，在不牺牲模型性能的情况下消除模型偏差</em></p></div><div class="ab cl lk ll hr lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="ig ih ii ij ik"><p id="f6b2" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">在<a class="ae km" href="https://www.manning.com/?utm_source=medium&amp;utm_medium=organic&amp;utm_campaign=book_ozdemir_feature_11_11_21" rel="noopener ugc nofollow" target="_blank">manning.com</a>结账时，在折扣代码框中输入<strong class="kp ix"> fccozdemir </strong>即可享受 35%的折扣。</p></div><div class="ab cl lk ll hr lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="ig ih ii ij ik"><h2 id="b26b" class="lr ls in bd lt lu lv dn lw lx ly dp lz kw ma mb mc la md me mf le mg mh mi it bi translated"><strong class="ak">建立基线模型</strong></h2><p id="2c13" class="pw-post-body-paragraph kn ko in kp b kq mj jx ks kt mk ka kv kw ml ky kz la mm lc ld le mn lg lh li ig bi translated">请查看<a class="ae km" href="https://manningbooks.medium.com/bias-and-fairness-in-machine-learning-part-1-introducing-our-dataset-and-the-problem-24f5f15c4f23" rel="noopener">第 1 部分</a>了解数据集的介绍以及偏见如何影响机器学习模型，使得公平在处理数据时成为重要的考虑因素。</p><p id="1f4d" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">是时候建立我们的基线 ML 模型了。对于我们的模型的第一遍，我们将应用一点特征工程来确保我们的模型正确地解释我们的所有数据，并花时间分析我们的模型的公平性/性能结果。</p><h2 id="54a5" class="lr ls in bd lt lu lv dn lw lx ly dp lz kw ma mb mc la md me mf le mg mh mi it bi translated"><strong class="ak">特征构造</strong></h2><p id="573c" class="pw-post-body-paragraph kn ko in kp b kq mj jx ks kt mk ka kv kw ml ky kz la mm lc ld le mn lg lh li ig bi translated">正如我们在 EDA 中看到的那样，我们有三个特征，每个特征都可以计算相关人员的青少年犯罪数量。再来看看我们的三个少年特征。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="c11f" class="lr ls in mt b gy mx my l mz na">compas_df[["juv_fel_count", "juv_misd_count", "juv_other_count"]].describe()</span></pre><figure class="mo mp mq mr gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi nb"><img src="../Images/b0f67474f8e0f5cc5ae70dbb1f14c9ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*HQHhhA7QgGcwuf8E.png"/></div></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk translated">图一。我们有三个不同的特征，每一个都是少年犯罪的子集。我们的目标是将它们结合成一个功能</figcaption></figure><p id="a00b" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">让我们将这些都添加到一个名为 juv_count 的新列中，这样应该更容易理解一些。</p><p id="6157" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated"><strong class="kp ix">清单 1。构建新的青少年犯罪计数功能</strong></p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="f1c8" class="lr ls in mt b gy mx my l mz na"># feature construction, add up our three juv columns and remove the original features<br/> compas_df['juv_count'] = compas_df[["juv_fel_count", "juv_misd_count", "juv_other_count"]].sum(axis=1)  # A<br/> compas_df = compas_df.drop(["juv_fel_count", "juv_misd_count", "juv_other_count"], axis=1)  # B</span></pre><p id="774e" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated"><strong class="kp ix"> #A 构建我们新的青少年犯罪总数</strong></p><p id="a11a" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated"><strong class="kp ix"> #B 去掉原来的少年特征</strong></p><p id="3f30" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">我们现在有 1 个新功能，因此我们删除了 3 个功能。</p><figure class="mo mp mq mr gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi nn"><img src="../Images/b0ea2c8b2afb9ae18cea990c87605630.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2zvdiK0oo8W0ltrJ.png"/></div></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk translated">图二。我们的训练数据的当前状态和我们的青少年犯罪总数</figcaption></figure><h2 id="f8c4" class="lr ls in bd lt lu lv dn lw lx ly dp lz kw ma mb mc la md me mf le mg mh mi it bi translated"><strong class="ak">建立我们的基线管道</strong></h2><p id="1084" class="pw-post-body-paragraph kn ko in kp b kq mj jx ks kt mk ka kv kw ml ky kz la mm lc ld le mn lg lh li ig bi translated">让我们开始把我们的管道放在一起，创建我们的基线 ML 模型。首先，我们将数据分成训练集和测试集，并实例化一个静态随机森林分类器。我们在这里选择了随机森林模型，因为随机森林模型具有计算特征重要性的有用特性。这最终会对我们非常有用。我们可以选择决策树，甚至逻辑回归，因为它们都有特征重要性的表示，但现在，我们将选择随机森林。请记住，我们的目标是操纵我们的特征，而不是我们的模型，所以我们将在所有的迭代中使用相同的模型和相同的参数。除了分割我们的 X 和 y，我们还将分割 race 列，这样我们就有一个简单的方法来分割我们的测试集。</p><p id="7c88" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated"><strong class="kp ix">清单 2。将我们的数据分成训练集和测试集</strong></p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="7190" class="lr ls in mt b gy mx my l mz na">from sklearn.model_selection import train_test_split<br/> from sklearn.ensemble import RandomForestClassifier<br/>  <br/> # Split up our data<br/> X_train, X_test, y_train, y_test, race_train, race_test = train_test_split(compas_df.drop('two_year_recid', axis=1),<br/>                                                     compas_df['two_year_recid'],<br/>                                                     compas_df['race'],<br/>                                                     stratify=compas_df['two_year_recid'],<br/>                                                     test_size=0.3,<br/>                                                     random_state=0)<br/>  <br/> # our static classifier<br/> classifier = RandomForestClassifier(max_depth=10, n_estimators=20, random_state=0)</span></pre><p id="c2bb" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">现在我们已经把数据分割好了，分类器也准备好了，让我们像上一章一样开始创建我们的特征管道。首先是我们的分类数据。让我们创建一个管道，它将对我们的分类列进行热编码，并且如果分类特征是二进制的，则只删除第二个伪列。</p><p id="12ac" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated"><strong class="kp ix">清单 3。创建我们的定性渠道</strong></p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="ca52" class="lr ls in mt b gy mx my l mz na">from sklearn.compose import ColumnTransformer<br/> from sklearn.pipeline import Pipeline, FeatureUnion<br/> from sklearn.preprocessing import OneHotEncoder, StandardScaler<br/>  <br/> categorical_features = ['race', 'sex', 'c_charge_degree']<br/> categorical_transformer = Pipeline(steps=[<br/>     ('onehot', OneHotEncoder(drop='if_binary'))<br/> ])</span></pre><p id="19a5" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">对于我们的数字数据，我们将调整我们的数据，以降低我们在 EDA 中看到的异常值。</p><p id="1d26" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated"><strong class="kp ix">清单 4。创建我们的量化渠道</strong></p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="614f" class="lr ls in mt b gy mx my l mz na">numerical_features = ["age", "priors_count"]<br/> numerical_transformer = Pipeline(steps=[<br/>     ('scale', StandardScaler())<br/> ])</span></pre><p id="5f74" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">让我们介绍来自 scikit-learn 的 ColumnTransformer 对象，它将帮助我们用最少的代码快速地将我们的两个管道应用到我们的特定列。</p><p id="ad37" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated"><strong class="kp ix">清单 5。将我们的管道放在一起，创建我们的特征预处理器</strong></p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="3d71" class="lr ls in mt b gy mx my l mz na">preprocessor = ColumnTransformer(transformers=[<br/>         ('cat', categorical_transformer, categorical_features),<br/>         ('num', numerical_transformer, numerical_features)<br/> ])<br/>  <br/> clf_tree = Pipeline(steps=[<br/>     ('preprocessor', preprocessor),<br/>     ('classifier', classifier)<br/> ])</span></pre><p id="a705" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">随着管道的建立，我们可以在我们的训练集上训练它，并在我们的测试集上运行它。</p><p id="8c4b" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated"><strong class="kp ix">清单 6。在我们的测试集上运行我们的无偏见模型</strong></p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="60a2" class="lr ls in mt b gy mx my l mz na">clf_tree.fit(X_train, y_train)<br/> unaware_y_preds = clf_tree.predict(X_test)</span></pre><p id="c2df" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated"><em class="lj"> Unaware_y_preds </em>将是一个由 0 和 1 组成的数组，其中 0 表示我们的模型预测此人不会再次成为好友，1 表示我们的模型预测此人会再次成为好友。</p><p id="cb8e" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">现在我们已经在测试集上预测了我们的模型，是时候开始研究我们的 ML 模型到底有多公平了。</p><h2 id="da87" class="lr ls in bd lt lu lv dn lw lx ly dp lz kw ma mb mc la md me mf le mg mh mi it bi translated"><strong class="ak">基线模型中的测量偏差</strong></h2><p id="b32d" class="pw-post-body-paragraph kn ko in kp b kq mj jx ks kt mk ka kv kw ml ky kz la mm lc ld le mn lg lh li ig bi translated">为了帮助我们深入了解我们的公平指标，我们将使用一个名为<em class="lj"> dalex </em>的模块。Dalex 有一些优秀的特性，有助于可视化不同种类的偏见和公平指标。我们的基本对象是解释器对象，使用我们的解释器对象，我们可以获得一些基本的模型性能。</p><p id="e9b9" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated"><strong class="kp ix">清单 7。使用 Dalex 解释我们的模型</strong></p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="1392" class="lr ls in mt b gy mx my l mz na">import dalex as dx<br/>  <br/> exp_tree = dx.Explainer(clf_tree, X_test, y_test, label='Random Forest Bias Unaware', verbose=True)<br/> exp_tree.model_performance()</span></pre><figure class="mo mp mq mr gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi no"><img src="../Images/e14b880f588b8da1520f04b1dd250677.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*b3qEn1pkF8oLj_TB.png"/></div></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk translated">图 3。我们的无偏见模型的基线模型性能</figcaption></figure><p id="6823" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">我们的指标并不惊人，但我们关心性能和公平性，所以让我们深入了解一下公平性。我们的第一个问题是“我们的模型在多大程度上依赖种族作为预测累犯的方式？”这个问题与我们模型的不同处理方式密切相关。Dalex 有一个非常方便的绘图，可以与基于树的模型和线性模型一起使用，以帮助可视化我们的模型从中学习最多的功能。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="1873" class="lr ls in mt b gy mx my l mz na">exp_tree.model_parts().plot()</span></pre><figure class="mo mp mq mr gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi np"><img src="../Images/eb68326251eee08b152a136db467eabb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mkBcJ3lG__01susZ.png"/></div></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk translated">图 4。dalex 报道的无偏见模型的特征重要性。该可视化直接从随机森林的要素重要性属性中获取要素重要性，并显示 priors_count 和 age 是我们最重要的要素。</figcaption></figure><p id="be41" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">Dalex 根据<strong class="kp ix">退出损失</strong>来报告重要性，这意味着如果完全删除特征问题，我们模型的整体“适合度”会降低多少。根据这个图表，如果我们丢失了 priors_count，我们的模型将丢失很多信息，但是理论上，如果我们放弃 race，情况会更好。看起来我们的模型根本没有从比赛中学习！这说明了模型对敏感特征的不了解。</p><p id="1809" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">在我们开始无偏见的舞蹈之前，我们应该再看几个指标。Dalex 也有一个 model_fairness 对象，我们可以查看它，它将为我们的每个种族类别计算几个指标。</p><p id="898a" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated"><strong class="kp ix">清单 8。输出模型公平性</strong></p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="afd1" class="lr ls in mt b gy mx my l mz na">mf_tree = exp_tree.model_fairness(protected=race_test, privileged = "Caucasian")<br/> mf_tree.metric_scores</span></pre><figure class="mo mp mq mr gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi nq"><img src="../Images/e1bde8516b4a270bb560554d33d02f49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7y4wqjy6pn5KNgKI.png"/></div></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk translated">图 5。我们的无偏见模型的 10 个公平指标的分解</figcaption></figure><p id="1db8" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">默认情况下，该软件包在这里为我们提供了 10 个指标，让我们根据真阳性(TP)、假阳性(FP)、假阴性(FN)、实际阳性(AP)、实际阴性(AN)、预测阳性(PP)和预测阴性(PN)来分解如何计算每个指标。请记住，我们可以按种族计算这些指标:</p><ol class=""><li id="5771" class="nr ns in kp b kq kr kt ku kw nt la nu le nv li nw nx ny nz bi translated">TPR(r) = TP / AP(又称灵敏度)</li><li id="6d3f" class="nr ns in kp b kq oa kt ob kw oc la od le oe li nw nx ny nz bi translated">TNR = TN/AN(也称为特异性)</li><li id="e852" class="nr ns in kp b kq oa kt ob kw oc la od le oe li nw nx ny nz bi translated">PPV(r) = TP / (PP)(也称为精度)</li><li id="485f" class="nr ns in kp b kq oa kt ob kw oc la od le oe li nw nx ny nz bi translated">NPV(r) = TN / (PN)</li><li id="0bfc" class="nr ns in kp b kq oa kt ob kw oc la od le oe li nw nx ny nz bi translated">FNR(r) = FN / AP <strong class="kp ix">或</strong> 1 — TPR</li><li id="42e5" class="nr ns in kp b kq oa kt ob kw oc la od le oe li nw nx ny nz bi translated">FPR(r) = FP / AN <strong class="kp ix">或</strong> 1 — TNR</li><li id="8f29" class="nr ns in kp b kq oa kt ob kw oc la od le oe li nw nx ny nz bi translated">FDR(r) = FP / (PP) <strong class="kp ix">或</strong> 1 — PPV</li><li id="9ffa" class="nr ns in kp b kq oa kt ob kw oc la od le oe li nw nx ny nz bi translated">FOR(r) = FN / (PN) <strong class="kp ix">或</strong> 1 — NPV</li><li id="20fe" class="nr ns in kp b kq oa kt ob kw oc la od le oe li nw nx ny nz bi translated">ACC(r) = TP + TN / (TP + TN + FP + FN)(按种族划分的整体准确度)</li><li id="7b23" class="nr ns in kp b kq oa kt ob kw oc la od le oe li nw nx ny nz bi translated">STP(r) = TP + FP / (TP + FP + FP + FN)(又名 P[预测累犯| Race=r])</li></ol><p id="c7b6" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">这些数字本身不会有很大帮助，所以让我们通过将我们的价值观与特权人群(白种人)进行比较来进行“公平检查”。为什么我们选择白种人作为我们的特权群体？嗯，在许多其他原因中，如果我们看看我们的基线模型预测我们组之间累犯的频率，我们会注意到，与我们测试集中的实际比率相比，该模型大大低估了白人累犯率。</p><p id="cd2a" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">出于我们的目的，我们将重点关注<strong class="kp ix"> TPR、ACC、PPV、FPR、</strong>和<strong class="kp ix"> STP </strong>作为我们的主要指标。我们选择这些指标的原因是:</p><ol class=""><li id="4906" class="nr ns in kp b kq kr kt ku kw nt la nu le nv li nw nx ny nz bi translated">TPR 与我们的模型捕捉实际累犯的程度有关。在人们反复争吵的所有时间里，我们的模型预测他们是积极的吗？我们希望这个值更高。</li><li id="9bd6" class="nr ns in kp b kq oa kt ob kw oc la od le oe li nw nx ny nz bi translated">ACC 是我们的整体准确度。这是一个相当全面的方法来判断我们的模型，但不会在真空中被考虑。我们希望这个值更高。</li><li id="b74f" class="nr ns in kp b kq oa kt ob kw oc la od le oe li nw nx ny nz bi translated">PPV 是我们的精准。它衡量我们对模型的正面预测的信任程度。在我们的模型预测累犯的次数中，模型在积极预测中的正确率是多少？我们希望这个值更高。</li><li id="11cf" class="nr ns in kp b kq oa kt ob kw oc la od le oe li nw nx ny nz bi translated">FPR 涉及到我们的模型预测累犯率时，有人不会真的累犯。我们希望这个更低。</li><li id="7ad6" class="nr ns in kp b kq oa kt ob kw oc la od le oe li nw nx ny nz bi translated">STP 是每组的统计奇偶校验。。我们希望这在种族上大致相等，这意味着我们的模型应该能够基于非人口统计信息可靠地预测累犯。</li></ol><p id="a870" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated"><strong class="kp ix">清单 9。凸显白种人的特权</strong></p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="7df5" class="lr ls in mt b gy mx my l mz na"># Recidivism by race in our test set<br/> y_test.groupby(race_test).mean()<br/>  <br/> # Predicted Recidivism by race in our bias-unaware model<br/> pd.Series(unaware_y_preds, index=y_test.index).groupby(race_test).mean()</span></pre><figure class="mo mp mq mr gt nc gh gi paragraph-image"><div class="gh gi of"><img src="../Images/ac68c7767d7cac489b4240a6464d2e1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/format:webp/0*JT45FsayQ1bW9UWh.png"/></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk translated">图 6。左边是我们测试集中各组的实际累犯率，右边是我们基线无偏差模型预测的累犯率。我们的模型大大低估了白人惯犯。将近 41%的白种人会复发，而我们的模型认为只有 28%会复发。这意味着我们的模型漏掉了近 30%的白种人复发。</figcaption></figure><p id="2391" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">非洲裔美国人的累犯率预测非常相似，而白种人似乎只有不到 29%的时间得到累犯预测，即使实际比率几乎是 41%。事实上，我们的模型低估了白种人群体，这表明白种人在我们的模型中享有特权。发生这种情况的部分原因是这些数据代表了不公平的司法系统。回想一下这样一个事实，即非裔美国人有更高的既往数，既往数是我们模型中最重要的特征，但它仍然无法准确预测高加索人的累犯，我们的模型显然无法基于原始数据可靠地预测累犯。</p><p id="ac30" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">现在让我们运行公平性检查，看看我们的无偏见模型如何跨越我们的五个偏见指标。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="c22d" class="lr ls in mt b gy mx my l mz na">mf_tree = exp_tree.model_fairness(protected=race_test, privileged = "Caucasian")<br/> mf_tree.fairness_check()</span></pre><p id="10f6" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">我们的输出列在下表中，乍一看，很多！我们强调了需要关注的主要领域。我们希望每个值都在(0.8 和 1.25)之间，粗体值是超出该范围的值，因此被称为偏差的证据。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="b4f0" class="lr ls in mt b gy mx my l mz na">Bias detected in 4 metrics: TPR, PPV, FPR, STP<br/> Conclusion: your model is not fair because 2 or more criteria exceeded acceptable limits set by epsilon.<br/> Ratios of metrics, based on 'Caucasian'. Parameter 'epsilon' was set to 0.8 and therefore metrics should be within (0.8, 1.25)<br/>                        TPR       ACC       PPV       FPR       STP<br/> African-American  <strong class="mt ix">1.633907</strong>  1.035994  1.160069  <strong class="mt ix">1.701493  1.782456</strong><br/> Hispanic          0.874693  1.007825  <strong class="mt ix">0.769363</strong>  1.069652  0.915789<br/> Other             <strong class="mt ix">1.380835</strong>  1.035994  0.876076  <strong class="mt ix">1.422886</strong>  <strong class="mt ix">1.336842</strong></span></pre><p id="393e" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">上表中的每个值都是 metric_scores 表中的值除以白种人值(我们的特权群体)。例如，非裔美国人的 TPR 值 1.633907 等于 TPR(非裔美国人)/ TPR(高加索人)，计算结果为 0.665 / 0.407。</p><p id="2e40" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">然后对照五分之四的范围(0.8，1.25)检查这些比率，如果我们的指标超出该范围，我们认为该比率不公平。理想值是 1，表示该比赛的指定指标等于我们特权组的指标值。如果我们把超出这个范围的比率加起来，我们得到 7(它们是粗体的)。</p><p id="c4d3" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">我们也可以使用 dalex 绘制上表中的数字。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="c6db" class="lr ls in mt b gy mx my l mz na">mf_tree.plot()  # Same numbers from the fairness_check in a plot</span></pre><figure class="mo mp mq mr gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi og"><img src="../Images/a79288d0ac6121228eea7cd6ba59ef9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KjXITrEl-2diioHn.png"/></div></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk translated">图 7。Dalex 提供了我们将重点关注的 5 个主要比率的直观细分，并按小组进行细分。我们希望所有的蓝色柱线都在图表的黄色部分，红色部分的柱线被认为有偏差的危险。我们可以看到我们有一些工作要做！</figcaption></figure><p id="9415" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">为了使事情变得简单一点，让我们把重点放在公平性检查的五个指标的奇偶损失上。<em class="lj">均等损失</em>代表我们弱势群体的总分。Dalex 将指标的奇偶校验损失计算为我们的公平性检查中指标比率对数的绝对值之和。</p><figure class="mo mp mq mr gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi og"><img src="../Images/d4d99d42b83b77742102684afcf614f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*6QpYk9XTO8wfb1aH.png"/></div></div></figure></div><div class="ab cl lk ll hr lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="ig ih ii ij ik"><p id="72ab" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">例如，如果我们看一下我们组的统计平价(STP ),我们有:</p><p id="dea2" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">STP(非裔美国人)= 0.508</p><p id="e39a" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">西班牙裔 STP = 0.261</p><p id="75bf" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">STP(其他)= 0.381</p><p id="0754" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">STP(白种人)= 0.285</p><p id="8416" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">一个简短的代码片段显示，在我们的无偏见模型中，STP 的奇偶校验损失应该是 0.956</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="fd54" class="lr ls in mt b gy mx my l mz na"># STP metrics for unprivileged groups<br/> unpriv_stp = [0.508, 0.261, 0.381]<br/>  <br/> # STP metrics for privileged group<br/> caucasian_stp = 0.285<br/>  <br/> # 0.956 appears as light orange in the following figure<br/> sum([abs(np.log(u / caucasian_stp)) for u in unpriv_stp])</span></pre><p id="9742" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">我们看到 STP 的奇偶损失是 0.956。幸运的是，dalex 为我们提供了一种更简单的方法来计算所有五个指标的奇偶校验损失，并为我们将它们堆叠在一个图表中。下图是我们将用于跨模型进行比较的图，5 个堆栈代表了我们五个偏差指标中每一个的值。它们堆叠在一起代表模型的整体偏差。我们希望看到总堆叠长度到<strong class="kp ix">减少</strong>，因为我们变得更有偏差意识。我们将把这个堆叠奇偶校验损失图与经典的 ML 指标配对，如准确度、精确度和召回率。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="9f64" class="lr ls in mt b gy mx my l mz na"># Plot of parity loss of each metric<br/> mf_tree.plot(type = 'stacked')</span></pre><figure class="mo mp mq mr gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi oh"><img src="../Images/02a2541a338ec5f8ba83b0c9b5b412c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*OHVB6Ue7Ivn9h-Bb.png"/></div></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk translated">图 8。累积奇偶校验损失。在这种情况下，越小越好，意味着偏差越小。例如，右手边的浅橙色部分代表我们之前手工计算的 0.956。总的来说，我们的无偏见模型得分约为 3.5，这是我们在偏见方面要击败的数字。</figcaption></figure><p id="fc21" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">我们现在有了模型性能的基线(来自我们的模型性能总结)和由我们的堆叠奇偶损失图表给出的公平性基线。</p><p id="828f" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">现在让我们继续讨论如何积极利用特征工程来减少数据中的偏差。</p><h2 id="44b6" class="lr ls in bd lt lu lv dn lw lx ly dp lz kw ma mb mc la md me mf le mg mh mi it bi translated"><strong class="ak">减轻偏见</strong></h2><p id="b239" class="pw-post-body-paragraph kn ko in kp b kq mj jx ks kt mk ka kv kw ml ky kz la mm lc ld le mn lg lh li ig bi translated">当谈到在我们的模型中减少偏见和促进公平时，我们有三个主要的机会来做到这一点:</p><ol class=""><li id="0d15" class="nr ns in kp b kq kr kt ku kw nt la nu le nv li nw nx ny nz bi translated">预处理—应用于训练数据的偏差缓解，即在模型有机会对训练数据进行训练之前</li><li id="db01" class="nr ns in kp b kq oa kt ob kw oc la od le oe li nw nx ny nz bi translated">处理中-在训练阶段应用于模型的偏差缓解</li><li id="9147" class="nr ns in kp b kq oa kt ob kw oc la od le oe li nw nx ny nz bi translated">后处理-在模型拟合到训练数据后，应用于预测标注的偏差缓解</li></ol><p id="df69" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">偏差缓解的每个阶段都有优点和缺点，预处理直接涉及特征工程技术。</p><h2 id="1275" class="lr ls in bd lt lu lv dn lw lx ly dp lz kw ma mb mc la md me mf le mg mh mi it bi translated"><strong class="ak">预处理</strong></h2><p id="82d2" class="pw-post-body-paragraph kn ko in kp b kq mj jx ks kt mk ka kv kw ml ky kz la mm lc ld le mn lg lh li ig bi translated">在建模发生之前，预处理偏差减轻发生在训练数据中。当我们无法访问模型本身或下游预测，但可以访问初始训练数据时，预处理非常有用。</p><p id="33ab" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">我们将在本章中实现的预处理偏差缓解技术的两个示例是:</p><ol class=""><li id="6380" class="nr ns in kp b kq kr kt ku kw nt la nu le nv li nw nx ny nz bi translated"><strong class="kp ix">完全不同的影响消除</strong> —编辑特征值以提高组的公平性</li><li id="a759" class="nr ns in kp b kq oa kt ob kw oc la od le oe li nw nx ny nz bi translated"><strong class="kp ix">学习公平表示</strong> —通过混淆关于受保护属性的原始信息来提取新的特征集</li></ol><p id="baf8" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">通过实现这两种技术，我们希望减少我们的模型所表现出的整体偏差，同时也试图提高我们的 ML 管道在这个过程中的性能。</p><h2 id="b48a" class="lr ls in bd lt lu lv dn lw lx ly dp lz kw ma mb mc la md me mf le mg mh mi it bi translated"><strong class="ak">进行中</strong></h2><p id="9a16" class="pw-post-body-paragraph kn ko in kp b kq mj jx ks kt mk ka kv kw ml ky kz la mm lc ld le mn lg lh li ig bi translated">在训练期间应用处理中的技术。它们通常以某种正则项或替代目标函数的形式出现。只有当我们能够使用实际的学习算法时，内处理技术才是可能的。否则，我们将不得不依赖于预处理或后处理。</p><p id="29e3" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">处理中偏差缓解技术的一些例子包括:</p><ol class=""><li id="98bd" class="nr ns in kp b kq kr kt ku kw nt la nu le nv li nw nx ny nz bi translated">元公平分类器—使用公平性作为输入来优化分类器的公平性</li><li id="62f9" class="nr ns in kp b kq oa kt ob kw oc la od le oe li nw nx ny nz bi translated">偏见消除器——对我们的学习目标实施一个特权感知正则化术语</li></ol><h2 id="1c37" class="lr ls in bd lt lu lv dn lw lx ly dp lz kw ma mb mc la md me mf le mg mh mi it bi translated"><strong class="ak">后处理</strong></h2><p id="3ede" class="pw-post-body-paragraph kn ko in kp b kq mj jx ks kt mk ka kv kw ml ky kz la mm lc ld le mn lg lh li ig bi translated">顾名思义，后处理技术是在训练时间之后应用的，并且在我们需要将 ML 模型视为黑盒并且我们无法访问原始训练数据时最有用。</p><p id="7d40" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">后处理偏差减轻技术的一些例子包括:</p><ol class=""><li id="fff8" class="nr ns in kp b kq kr kt ku kw nt la nu le nv li nw nx ny nz bi translated">均等赔率-使用单独的优化目标修改预测的标注，以使预测更加公平。</li><li id="06dc" class="nr ns in kp b kq oa kt ob kw oc la od le oe li nw nx ny nz bi translated">校准均衡赔率-修改分类器的分数以获得更公平的结果。</li></ol><p id="7f23" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">目前就这些。在第 3 部分中，我们将了解如何构建一个偏差感知模型。</p><p id="054e" class="pw-post-body-paragraph kn ko in kp b kq kr jx ks kt ku ka kv kw kx ky kz la lb lc ld le lf lg lh li ig bi translated">如果你想了解这本书的更多信息，可以在曼宁的 liveBook 平台上查看<a class="ae km" href="https://livebook.manning.com/book/feature-engineering-bookcamp?origin=product-look-inside&amp;utm_source=medium&amp;utm_medium=organic&amp;utm_campaign=book_ozdemir_feature_11_11_21" rel="noopener ugc nofollow" target="_blank">这里</a>。</p></div></div>    
</body>
</html>