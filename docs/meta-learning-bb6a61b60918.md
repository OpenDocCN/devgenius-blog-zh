# 元学习

> 原文：<https://blog.devgenius.io/meta-learning-bb6a61b60918?source=collection_archive---------17----------------------->

![](img/3dcc099ef1ad100bcbd285964722f63f.png)

这是与自动创建机器学习模型、用于训练神经网络的数据集以及模型不可知元学习相关的系列博客文章的一部分。如果你对这个故事的背景感兴趣，你可以滚动到文章的底部，找到以前博客文章的链接。你也可以前往[使用 SERP 数据构建机器学习模型](https://serpapi.com/use-cases/machine-learning-and-artificial-intelligence)页面，清楚地了解你可以创建什么样的自动化机器学习模型，或者如何利用它们进行元学习。

在前几周，我展示了一个创建机器学习算法的表单示例。通过存储机器学习算法的超参数元数据，这是可能的。本周，我将解释如何存储每个机器学习训练和测试过程的元数据，为元学习算法铺平道路。

# 什么是元学习任务？

元学习是使用以前获得的和分类的学习过程的元数据来处理机器学习算法以前没有遇到的新的学习任务。元学习的任务是学会学习。

今天的深度学习模型无法完成各种不同的任务。例如，我在前几周展示了一个图像分类器。尽管超参数的调整对于特定的任务来说很容易，但我没有产生有效的图像分类模型。这花费了我很多时间，我只是展示了如何使这个过程更加自动化。即使我创建了具有良好优化的卷积神经网络，我仍然会面临要分类的对象范围有限的问题。我还会通过使用强化学习来解决这个问题，将模型暴露给持续的训练，并在我需要的时候获取它的迭代。但是它不能解决如何处理非常相似的物体的问题。我会使用深度学习训练过程的先前子集来获得关于该问题的知识，并在训练过程中应用该知识的公式。

这个清单还在继续。但这并没有解决一个问题。我如何花更少的时间调整模型？这就是元学习成为救世主的地方。学习问题等元学习方法可用于大幅减少创建模型所需的时间。

但是，怎么做呢？为了将它应用到元学习中，我们首先需要深入了解我们人类是如何看待这些问题的。比如说；我们如何知道机器学习训练过程已经变坏了？通过观察损失函数。我们关注损失函数的原因是，它是深度神经网络在特定任务中表现如何的衍生元数据。我们怎么能确定呢？结果会给我们统计上更高的预测率。通过观察优化对损失函数的有效性，这一知识本身就足以为我们提供基于优化的元学习技术应该如何操作的洞察力。

还必须存储深度学习训练过程，以及它随后的准确性结果，以便使用元学习方法进行交叉比较。

# 元学习需要什么？

以我的愚见，除了普遍的共识，我还看到了一些其他的必要条件，它们将被视为元学习的必要条件。

让我来分解三种常见的元学习方法，看看它们需要什么:

基于模型的元学习:提出的模型使用机器学习过程的内部或外部记忆，以实现更好的学习。也就是说，如果你有一只狗要分类，如果你已经对其他狗进行了分类，你可以使用你以前使用的模型来自动轻松地实现这个目标。这种集中的元学习方法的缺点是必须标记对象。

基于度量的元学习:提出的模型使用不同的度量来决定学习任务在过程中是否相似。如果您必须在人类和鸟类之间进行分类，您可以使用之前获得的哺乳动物和鸟类分类元数据来获得良好的结果。然而，这种元学习类型的缺点是包含了一个蝙蝠。看起来像鸟类的哺乳动物。

基于优化的元学习:提出的模型使用先前获得的深度学习训练的优化超参数的元数据来最大化元学习的结果。这种纯粹的元学习方法需要高度密集的机器学习过程。

现在，为了应对基于模型的元学习过程的弱点，我已经在我以前的一篇博文中提出了一个解决方案。我使用 [SerpApi 的 Google Images Scraper API](https://serpapi.com/images-results) 使用 chips 参数抓取带有特定标签的图像，以创建大规模数据集(也只有特定大小的图像才能自动预处理)。

我没有一个完整的解决方案来对抗基于度量的元学习的弱点。然而，我目睹了许多搜索引擎朝着丰富其知识图、答案框和相关搜索项(如相关问题、相关搜索等)的方向发展。这有助于模拟新任务之间的联系。但是，当然，这是一个模糊的想法。你可以看看带有例子的文档，比如 SerpApi 的 Google 知识图抓取器 API 、 [SerpApi 的 Google 答案框抓取器 API](https://serpapi.com/direct-answer-box-api) 以及其他相关文档，以便更好地了解如何在元学习中利用它们。您也可以[注册申请免费积分](https://serpapi.com/users/sign_up)。

我也没有解决基于优化的元学习的弱点的方法。然而，本周我将展示如何用异步调用存储机器学习训练过程，这对这种元学习方法至关重要。计算机科学中的异步处理指的是并行运行但不影响彼此进度的任务分配。它使我们不必等待培训过程结束，也不必在这种情况下运行多个调用。

拥有良好的机器学习框架至关重要，这种框架可以存储训练示例并在外部对象或数据点中进行比较，还可以存储训练数据的元数据以供将来使用。利用 SGD(随机梯度下降)、RNN(递归神经网络)、回归、少量学习等也是有用的。在一个地方用一个通用的语法来实现迁移学习与 MAML(模型不可知元学习)。这些博客文章系列的目的是实现这篇博客文章中提出的至少一部分内容。一旦在 [SerpApi 的 Github 页面](https://github.com/serpapi/)上开源，我希望我的错误(尤其是前端的)能在别人的帮助下被掩盖。就像现实世界中表现最好的程序员一样，我们的目标是在为特定问题训练模型时，最大限度地减少定制需求，并使训练好的模型能够执行多任务操作。当然，在初始化的时候，我并不指望一个可以做多个分类任务的监督学习模型能写一首诗。但是进行元训练的能力，至少是通过人的观察，交叉比较不同模型参数的基准，对于像我这样试图获得新技能的人来说是令人兴奋的一步。

# 存储机器学习模型

我已经创建了一个尝试项，存储在存储服务器的 models 范围下:

它容纳了在接下来的几周中用于调用训练过程的唯一 id、模型文件名的名称、作为我们用来触发训练的字典的训练命令、用于观察每次反向传播的训练状态的训练损失、用于创建实时可视图形的时期数、用于触发测试过程的字典的测试命令、用于存储模型准确性的准确性、用于观察其状态的状态以及测试过程中使用的限制的限制。

让我们初始化该类以与模型数据库通信:

主文件中还有一些助手端点:

让我们更新培训端点，以便在数据库中为我们创建一个模型对象:

让我们收集我们在训练过程中的损失(也是梯度步骤的 lr 调度器):

测试过程的另一个更新是异步的，并且与存储服务器进行通信:

以下是培训中得出的存储项目:

# 结论

我感谢读者的关注，也感谢 SerpApi 的聪明人让这篇博文成为可能。我想在这篇文章中分享另一个观点。我发现 ICLR、ICML 和 arxiv 的一些出版物很吸引人(我计划在接下来的几周内分享我对它们的看法)。但我也看到了对元学习开源项目的重要需求，以快速适应深度网络。在人工智能发展的这个阶段，我认为专业人士和爱好者之间没有矛盾。我相信，如果我们能在元学习上共同进步，我们就能在人类的成就上达到列文速度。无论是数据集的自动提供，还是深度学习的自动优化，元学习都有许多要点，每个人都可以做出贡献。撇开围绕元学习或学会学习这个词的炒作和概括不谈，这个主题非常有趣，本质上也很有逻辑性。我希望醒来时看到一个拥有多任务能力的模型仍在自己学习任务的世界。即使是这种成就的原始版本也是令人兴奋的。

*原载于 2022 年 8 月 12 日*[*【https://serpapi.com】*](https://serpapi.com/blog/meta-learning/)*。*