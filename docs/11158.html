<html>
<head>
<title>MLOps with MLFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">带 MLFlow 的 MLOps</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/mlops-with-mlflow-f6fd6069a527?source=collection_archive---------15-----------------------#2022-12-21">https://blog.devgenius.io/mlops-with-mlflow-f6fd6069a527?source=collection_archive---------15-----------------------#2022-12-21</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><div class=""><h2 id="848f" class="pw-subtitle-paragraph jk im in bd b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb dk translated">强大的机器学习工程。</h2></div><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi kc"><img src="../Images/b84129bc7a244d9e07eb9d2331f4b8ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*32ydz8f3c924sAp_XHgngA.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated"><strong class="bd ks">机器学习工作流</strong>:以 AWS 服务为例的典型 ML 工作流。</figcaption></figure><h1 id="51c1" class="kt ku in bd ks kv kw kx ky kz la lb lc jt ld ju le jw lf jx lg jz lh ka li lj bi translated">机器学习工程</h1><p id="e4a4" class="pw-post-body-paragraph lk ll in lm b ln lo jo lp lq lr jr ls lt lu lv lw lx ly lz ma mb mc md me mf ig bi translated">部署生产级软件比玩具项目和研究代码更不稳定。虽然机器学习可以解决复杂的问题，但它的脆弱性和复杂性需要合理的 MLOps 来确保快速开发/部署健壮的模型。</p><p id="e940" class="pw-post-body-paragraph lk ll in lm b ln mg jo lp lq mh jr ls lt mi lv lw lx mj lz ma mb mk md me mf ig bi translated">标准的机器学习架构如下:</p><ul class=""><li id="e768" class="ml mm in lm b ln mg lq mh lt mn lx mo mb mp mf mq mr ms mt bi translated"><strong class="lm io"> <em class="mu">特征工程</em> </strong>:处理原始数据，清理&amp;提取特征。</li><li id="be06" class="ml mm in lm b ln mv lq mw lt mx lx my mb mz mf mq mr ms mt bi translated"><strong class="lm io"> <em class="mu">训练模型</em> </strong>:建立并评估模型。</li><li id="db76" class="ml mm in lm b ln mv lq mw lt mx lx my mb mz mf mq mr ms mt bi translated"><strong class="lm io"> <em class="mu">在线服务预测</em> </strong>:通过一些产品/端点服务模型。</li></ul><p id="aa1b" class="pw-post-body-paragraph lk ll in lm b ln mg jo lp lq mh jr ls lt mi lv lw lx mj lz ma mb mk md me mf ig bi translated">自由(超)参数的数量是产品复杂性的指数。因此，成功的应用数据科学依赖于执行 3 个功能:</p><blockquote class="na nb nc"><p id="08ea" class="lk ll mu lm b ln mg jo lp lq mh jr ls nd mi lv lw ne mj lz ma nf mk md me mf ig bi translated">(1)构建健壮、高效、直观的<strong class="lm io">数据工程管道</strong>；(2)智能<strong class="lm io">特征工程</strong> &amp; (3) <strong class="lm io">超参数调谐</strong>。</p></blockquote><p id="8917" class="pw-post-body-paragraph lk ll in lm b ln mg jo lp lq mh jr ls lt mi lv lw lx mj lz ma mb mk md me mf ig bi translated">因此，生产培训循环包含:</p><pre class="kd ke kf kg gt ng nh ni bn nj nk bi"><span id="1bcd" class="nl ku in nh b be nm nn l no np">for hp in HyperParameter:<br/>  for f in featureSet:<br/>    for p in Parameters:<br/>      model.fit()<br/>      model.pkl()<br/>      config.store()</span></pre><p id="8e15" class="pw-post-body-paragraph lk ll in lm b ln mg jo lp lq mh jr ls lt mi lv lw lx mj lz ma mb mk md me mf ig bi translated">超参数搜索通常是通过一系列经过充分研究的优化程序完成的，如<code class="fe nq nr ns nh b"><em class="mu">Bayesian Optimisation</em></code>；特征工程是编码理论(特定领域)抽象和模型拟合/降维的结合；参数由标准优化协议拟合。</p><blockquote class="na nb nc"><p id="0f07" class="lk ll mu lm b ln mg jo lp lq mh jr ls nd mi lv lw ne mj lz ma nf mk md me mf ig bi translated">很容易看到自由参数/实验的空间是如何随着任何非平凡的 ML 应用程序而爆炸的。因此，有效的实验和配置记录系统对于在生产中提供健壮可靠的 ML 模型是必不可少的。</p></blockquote><p id="2f47" class="pw-post-body-paragraph lk ll in lm b ln mg jo lp lq mh jr ls lt mi lv lw lx mj lz ma mb mk md me mf ig bi translated"><em class="mu">理论注</em>:考虑可能模型的总空间:可能超参数的空间(<em class="mu">HP</em>)；特征集空间(<em class="mu">f</em>)；模型空间(<em class="mu"> m </em> ) &amp;参数空间<em class="mu"> (p) </em>。由此产生的 VC-dimension 爆炸，需要严格的规范和样本外性能检查<code class="fe nq nr ns nh b">D &lt;- f(hp,f,m,p)</code>。</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi nt"><img src="../Images/1d2f2bdb449615feeaafb2289ca95a2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WD4l7qbiAHJ80J512Xrotg.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">VC-dimension 在 D(近似自由度)中是指数的。</figcaption></figure></div><div class="ab cl nu nv hr nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="ig ih ii ij ik"><h2 id="ea50" class="ob ku in bd ks oc od dn ky oe of dp lc lt og oh le lx oi oj lg mb ok ol li om bi translated">数据摄取</h2><p id="3422" class="pw-post-body-paragraph lk ll in lm b ln lo jo lp lq lr jr ls lt lu lv lw lx ly lz ma mb mc md me mf ig bi translated">行业规范是 it 依赖第三方 API 进行数据摄取，像<strong class="lm io"> <em class="mu"> Kafka </em> </strong>(数据流)&amp;<strong class="lm io"><em class="mu">Apache Spark</em></strong>(大数据摄取)这样的工具可以轻松集成到任何云 ML 工作流中。虽然这些工具可以用来直接执行特征工程和 ML，但是假设我们使用 Apache 工具获取&amp;干净的原始数据，然后将数据转储到某个中央低延迟桶中，以供下游分析。</p><p id="7edb" class="pw-post-body-paragraph lk ll in lm b ln mg jo lp lq mh jr ls lt mi lv lw lx mj lz ma mb mk md me mf ig bi translated"><strong class="lm io"> <em class="mu">特征工程</em> </strong> &amp; <strong class="lm io"> <em class="mu">建模</em> </strong>可以解耦成独立的模块，两者遵循相同的流程，我们可以定义为:</p><blockquote class="na nb nc"><p id="dce2" class="lk ll mu lm b ln mg jo lp lq mh jr ls nd mi lv lw ne mj lz ma nf mk md me mf ig bi translated">有些集合的任意运算<strong class="lm io"> f() </strong> <em class="in"> </em>对输入数据<em class="in"> </em> <strong class="lm io"> X </strong> <em class="in"> </em>这样才能返回一些可取的<em class="in"> </em> <strong class="lm io"> y </strong> <em class="in">。</em>我们感兴趣的是上菜功能<em class="in"/><strong class="lm io">f()</strong><em class="in"/>的制作。</p></blockquote></div><div class="ab cl nu nv hr nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="ig ih ii ij ik"><h1 id="9554" class="kt ku in bd ks kv on kx ky kz oo lb lc jt op ju le jw oq jx lg jz or ka li lj bi translated">工作流程问题</h1><p id="5509" class="pw-post-body-paragraph lk ll in lm b ln lo jo lp lq lr jr ls lt lu lv lw lx ly lz ma mb mc md me mf ig bi translated">虽然理论上这很简单，但实际上我们会遇到很多问题:</p><h2 id="05f6" class="ob ku in bd ks oc od dn ky oe of dp lc lt og oh le lx oi oj lg mb ok ol li om bi translated">工作流程</h2><ul class=""><li id="fb55" class="ml mm in lm b ln lo lq lr lt os lx ot mb ou mf mq mr ms mt bi translated"><strong class="lm io"> <em class="mu">配置日志&amp;元分析</em> </strong>:当务之急是正确地跟踪和分析这一大套实验，以易于查询的方式进行。</li><li id="09c9" class="ml mm in lm b ln mv lq mw lt mx lx my mb mz mf mq mr ms mt bi translated"><strong class="lm io"> <em class="mu">计算成本</em> </strong>:拟合大型模型/处理大型数据需要计算成本高昂的作业，通常需要将作业拆分到本地和云实例上。</li><li id="5340" class="ml mm in lm b ln mv lq mw lt mx lx my mb mz mf mq mr ms mt bi translated"><strong class="lm io"> <em class="mu">算法复杂度:</em> </strong>鉴于参数空间的复杂度，应该通过检查记录的实验结果来彻底检查模型的鲁棒性。</li><li id="8750" class="ml mm in lm b ln mv lq mw lt mx lx my mb mz mf mq mr ms mt bi translated"><strong class="lm io"> <em class="mu">工作流复杂性</em> </strong>:贡献者、环境和外部依赖的数量增加了开发周期的复杂性。工程师需要无缝的机制来共享代码、测试和检查更新以及在代码库之间跳转。</li></ul><h2 id="80da" class="ob ku in bd ks oc od dn ky oe of dp lc lt og oh le lx oi oj lg mb ok ol li om bi translated">部署</h2><ul class=""><li id="23c9" class="ml mm in lm b ln lo lq lr lt os lx ot mb ou mf mq mr ms mt bi translated"><strong class="lm io"><em class="mu"/></strong>:版本控制&amp;依赖管理需要容器化来保证软件在生产中的可靠性。</li><li id="ad5b" class="ml mm in lm b ln mv lq mw lt mx lx my mb mz mf mq mr ms mt bi translated"><strong class="lm io"> <em class="mu">监控</em> </strong>:新模型应缓慢推出，并仔细注意监控数据分布偏离样本性能&amp;。</li></ul></div><div class="ab cl nu nv hr nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="ig ih ii ij ik"><h1 id="cdd7" class="kt ku in bd ks kv on kx ky kz oo lb lc jt op ju le jw oq jx lg jz or ka li lj bi translated">解决办法</h1><p id="0fd0" class="pw-post-body-paragraph lk ll in lm b ln lo jo lp lq lr jr ls lt lu lv lw lx ly lz ma mb mc md me mf ig bi translated">为了缓解上述问题，当部署机器学习模型时，必须<strong class="lm io"> <em class="mu">记录实验配置</em> </strong>和<strong class="lm io"> <em class="mu">容器</em> </strong>函数。</p><h2 id="d18f" class="ob ku in bd ks oc od dn ky oe of dp lc lt og oh le lx oi oj lg mb ok ol li om bi translated"><strong class="ak">集装箱化</strong></h2><p id="b6ba" class="pw-post-body-paragraph lk ll in lm b ln lo jo lp lq lr jr ls lt lu lv lw lx ly lz ma mb mc md me mf ig bi translated"><strong class="lm io"> <em class="mu"> Docker </em> </strong>是集装箱化的行业标准，ML 也不例外。它已经很好地通过了确保与所有云平台的生产集成所需的临界质量，因此现在是 ML 工作流的标准部分。希望利用可以与码头集装箱耦合的实验测井解决方案。</p><h2 id="81e1" class="ob ku in bd ks oc od dn ky oe of dp lc lt og oh le lx oi oj lg mb ok ol li om bi translated">实验测井</h2><p id="8bee" class="pw-post-body-paragraph lk ll in lm b ln lo jo lp lq lr jr ls lt lu lv lw lx ly lz ma mb mc md me mf ig bi translated">出于以下几个原因，记录实验是一种很好的做法:</p><ul class=""><li id="25ad" class="ml mm in lm b ln mg lq mh lt mn lx mo mb mp mf mq mr ms mt bi translated">找到最佳的模型配置。</li><li id="6716" class="ml mm in lm b ln mv lq mw lt mx lx my mb mz mf mq mr ms mt bi translated">分享、复制和建立实验。</li><li id="8bcd" class="ml mm in lm b ln mv lq mw lt mx lx my mb mz mf mq mr ms mt bi translated">检查点&amp;恢复大型计算任务。</li></ul><p id="34e8" class="pw-post-body-paragraph lk ll in lm b ln mg jo lp lq mh jr ls lt mi lv lw lx mj lz ma mb mk md me mf ig bi translated">为此，许多生产就绪的 ML 框架(Keras、pyTorch、TensorFlow 等)包括内置的检查点和日志协议，然而在现实中，ML 解决方案可能不仅仅包含模型，而是采取某种函数序列的形式(包括程序和模型)。因此，谨慎的做法可能是实现一种可以记录实验配置&amp;(超)参数的解决方案，这些参数是对程序序列的抽象:输入<strong class="lm io"> <em class="mu">权重&amp;偏差</em> </strong>和<strong class="lm io"> <em class="mu"> MLFlow </em> </strong>。</p><h1 id="34cd" class="kt ku in bd ks kv kw kx ky kz la lb lc jt ld ju le jw lf jx lg jz lh ka li lj bi translated">MLFlow</h1><p id="d192" class="pw-post-body-paragraph lk ll in lm b ln lo jo lp lq lr jr ls lt lu lv lw lx ly lz ma mb mc md me mf ig bi translated">我们使用 MLFlow 来保持实验、配置、参数和结果的整洁簿记。下面是一个简单的例子，说明在部署 Python (Keras)模块时如何集成 MLFLow。</p><pre class="kd ke kf kg gt ng nh ni bn nj nk bi"><span id="dd1f" class="nl ku in nh b be nm nn l no np">import mlflow<br/>import mlflow.sklearn<br/>...<br/><br/>with mlflow.start_run():<br/>  train_model()<br/>  mlflow.log_param("alpha", alpha)<br/>  ...<br/><br/>mlflow.sklearn.log_model(lr, "model")</span></pre><blockquote class="ov"><p id="84fa" class="ow ox in bd oy oz pa pb pc pd pe mf dk translated">瞧啊。</p></blockquote><p id="3f0b" class="pw-post-body-paragraph lk ll in lm b ln pf jo lp lq pg jr ls lt ph lv lw lx pi lz ma mb pj md me mf ig bi translated">就这么简单，MLFlow 现在会在一个自己创建的目录中记录实验。</p><p id="9096" class="pw-post-body-paragraph lk ll in lm b ln mg jo lp lq mh jr ls lt mi lv lw lx mj lz ma mb mk md me mf ig bi translated"><strong class="lm io">命令行界面(CLI) </strong>:通过多做一点设置工作，可以从 MLFlow 中获得更多。如果基本目录包含一个<code class="fe nq nr ns nh b">MLproject</code> ( <code class="fe nq nr ns nh b">yaml</code>文件)配置文件，用户可以明确指定运行时配置。</p><p id="03d1" class="pw-post-body-paragraph lk ll in lm b ln mg jo lp lq mh jr ls lt mi lv lw lx mj lz ma mb mk md me mf ig bi translated">例如，这里我们的<code class="fe nq nr ns nh b">MLproject</code>文件包含默认参数值、我们的 conda/pip yaml 文件的名称(<code class="fe nq nr ns nh b">conda.yaml</code>，以及要运行的 python 命令。</p><pre class="kd ke kf kg gt ng nh ni bn nj nk bi"><span id="8a8c" class="nl ku in nh b be nm nn l no np">name: mflow-example<br/>python_env: conda.yaml<br/><br/>entry_points:<br/>  main:<br/>    parameters:<br/>      alpha:  {type: float, default: 0.5}<br/>      beta:   {type: float, default: 0.2}<br/>    command: "python wine_model.py {alpha} {beta}"</span></pre><p id="d569" class="pw-post-body-paragraph lk ll in lm b ln mg jo lp lq mh jr ls lt mi lv lw lx mj lz ma mb mk md me mf ig bi translated">人们现在可以直接从命令行界面运行 T4。这将创建一个新的 conda 环境，并安装<code class="fe nq nr ns nh b">conda.yaml</code>中描述的所有依赖项，然后执行<code class="fe nq nr ns nh b">bash</code>命令。</p><p id="eeaf" class="pw-post-body-paragraph lk ll in lm b ln mg jo lp lq mh jr ls lt mi lv lw lx mj lz ma mb mk md me mf ig bi translated"><strong class="lm io">实验元分析:</strong>运行<code class="fe nq nr ns nh b">mlflow ui</code>将启动<em class="mu"> gunicorn </em>并在本地端口上提供一个 mlflow 仪表板，描述所有的实验运行。可以提取这些数据以找到最佳模型，执行模型敏感性分析并共享实验、配置和结果&amp;作业。</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi pk"><img src="../Images/1ea98c9d5b9043f3918020f6df74bfa3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oNkKz2F0dt511aEoeYuMBA.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk translated">MLFlow 指标和配置仪表板。</figcaption></figure><p id="3394" class="pw-post-body-paragraph lk ll in lm b ln mg jo lp lq mh jr ls lt mi lv lw lx mj lz ma mb mk md me mf ig bi translated"><strong class="lm io">装箱</strong>:最后，一个人可以装箱一个特定的配置，以便为生产中的模型服务。虽然 MLFlow 可以直接与 SageMaker (AWS ML)等工具集成，但是您可以简单地将配置写入 docker 映像，然后根据需要进行部署。只需提供所选实验<code class="fe nq nr ns nh b">$path</code>的路径并运行:</p><pre class="kd ke kf kg gt ng nh ni bn nj nk bi"><span id="bd4f" class="nl ku in nh b be nm nn l no np">mlflow models build-docker \<br/>  -m $path \<br/>  -n my-docker-image \<br/>  --enable-mlserver</span></pre><blockquote class="ov"><p id="abcf" class="ow ox in bd oy oz pa pb pc pd pe mf dk translated">瞧啊。高效、可审计、可共享、可复制、用户友好、生产就绪的机器学习:)。</p></blockquote></div></div>    
</body>
</html>