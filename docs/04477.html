<html>
<head>
<title>Data Science Hackathon Implementation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据科学黑客马拉松实施</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/data-science-hackathon-implementation-25d07d5e5d56?source=collection_archive---------6-----------------------#2021-03-21">https://blog.devgenius.io/data-science-hackathon-implementation-25d07d5e5d56?source=collection_archive---------6-----------------------#2021-03-21</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><p id="3b97" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi ki translated">2021年2月，我参加了由AnalyticsVidhya举办的数据科学黑客马拉松。成为如此有趣的挑战的一部分是一次令人惊奇的经历，我从我的第一次经历中学到了很多东西。</p><p id="62b6" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">这些挑战确实有助于激发疯狂的能量来封装所有已知的数据科学概念，通过多种功能组合来解决手头的问题，并破坏大脑和神经以获得绝对最重要的结果。</p><p id="6a3d" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">所以让我们开始吧！！！</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/d5f1a464e496c8cd03205b4a1cf5d6aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h1p71f7yFTzCatzzftF3yA.jpeg"/></div></div></figure><p id="7a94" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io">问题陈述:</strong>fin man a<strong class="jm io">T5】金融服务公司提供贷款、投资基金、保险等各种金融服务。给它的顾客。FinMan希望向现有客户交叉销售保单，这些客户可能持有该公司的保单，也可能不持有。</strong></p><p id="832a" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io">目标结果:</strong>该公司需要建立一个模型，在给定以下信息的情况下，预测该人是否会对其提议的健康计划/政策感兴趣:</p><ul class=""><li id="6036" class="ld le in jm b jn jo jr js jv lf jz lg kd lh kh li lj lk ll bi translated">人口统计(城市、年龄、地区等。)</li><li id="efe3" class="ld le in jm b jn lm jr ln jv lo jz lp kd lq kh li lj lk ll bi translated">关于客户持有政策的信息</li><li id="d1ce" class="ld le in jm b jn lm jr ln jv lo jz lp kd lq kh li lj lk ll bi translated">推荐的政策信息</li></ul><p id="d7b0" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">实现细节如下:</p><h1 id="bca8" class="lr ls in bd lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo bi translated"><strong class="ak"> A .数据探索</strong></h1><ol class=""><li id="c64a" class="ld le in jm b jn mp jr mq jv mr jz ms kd mt kh mu lj lk ll bi translated">使用的库:Pandas，Numpy，Seaborn，Matplotlib</li><li id="c5cf" class="ld le in jm b jn lm jr ln jv lo jz lp kd lq kh mu lj lk ll bi translated">使用info()、describe()和shape等函数分析数据</li><li id="a2fb" class="ld le in jm b jn lm jr ln jv lo jz lp kd lq kh mu lj lk ll bi translated">使用以下代码检查每个特性中缺失值的数量:</li></ol><pre class="ks kt ku kv gt mv mw mx my aw mz bi"><span id="09f6" class="na ls in mw b gy nb nc l nd ne">df.isnull().sum()</span></pre><p id="59fb" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">4.检查每个特征的<strong class="jm io"> <em class="nf">相关性</em> </strong>与目标变量</p><pre class="ks kt ku kv gt mv mw mx my aw mz bi"><span id="047d" class="na ls in mw b gy nb nc l nd ne">sns.heatmap(df.corr())</span></pre><p id="e01f" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">5.分离数字和分类特征</p><pre class="ks kt ku kv gt mv mw mx my aw mz bi"><span id="4e01" class="na ls in mw b gy nb nc l nd ne">#Numerical Features<br/>num_fields=[feature for feature in df.columns if df[feature].dtypes!=’O’ ]</span><span id="d3c8" class="na ls in mw b gy ng nc l nd ne">#Categorical features<br/>cat_feature=[feature for feature in df.columns if df[feature].dtypes=='O']</span></pre><p id="887a" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">6.对于每个数值特征，检查它是一个<strong class="jm io"> <em class="nf">离散</em> </strong>数值特征还是一个<strong class="jm io"> <em class="nf">连续</em> </strong>数值特征。这里，唯一值小于30的所有特征被视为离散的，否则被视为连续的特征</p><pre class="ks kt ku kv gt mv mw mx my aw mz bi"><span id="0be7" class="na ls in mw b gy nb nc l nd ne">#Number of unique values <br/>for feature in num_fields:<br/> print(‘{}: {} Unique values’.format(feature,df[feature].nunique()))</span><span id="0b04" class="na ls in mw b gy ng nc l nd ne">#Discrete Numerical Features<br/>discrete_feature=[feature for feature in num_fields if df[feature].nunique()&lt;30]</span><span id="3b42" class="na ls in mw b gy ng nc l nd ne">#Continuous Numerical Features<br/>continuous_feature=[feature for feature in num_fields if df[feature].nunique()&gt;30]</span></pre><p id="3f6e" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">7.检查离散特征与目标列的关系</p><p id="f260" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">a.这里的“响应”是目标(因变量),我们将“持有策略类型”计数分组到收到的相应响应中</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nh"><img src="../Images/cd4934b5a7e88fcb61d8fe3afc3f28e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZzlLVGYKZVKJT0zrhGQTBA.png"/></div></div></figure><pre class="ks kt ku kv gt mv mw mx my aw mz bi"><span id="4444" class="na ls in mw b gy nb nc l nd ne">for feature in discrete_feature:<br/> data.groupby(‘Response’)[feature].count().plot.bar()<br/> plt.xlabel(‘Response’)<br/> plt.ylabel(feature)<br/> plt.show()</span></pre><p id="4115" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">b.下面，我们将比较每个“Holding_Policy_Type”类别的回应数量</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/fde5e456228686cb9a1d2a41ad8dda08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/1*GLI6PlAj1RjiSPXXyTc_uw.png"/></div></figure><pre class="ks kt ku kv gt mv mw mx my aw mz bi"><span id="7d03" class="na ls in mw b gy nb nc l nd ne">sns.countplot(x=df[‘Holding_Policy_Type’],hue=df[‘Response’])</span></pre><p id="42c4" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">9.分析<strong class="jm io"> <em class="nf">数据的分布</em> </strong>为连续特征。它帮助我们了解数据是否有偏差，以及是否需要应用任何转换，如对数转换</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nj"><img src="../Images/d6ac642b89a3440a886d929e58a77fc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*hzK7u9xJ3fxv1-Opom7AiQ.png"/></div></div></figure><pre class="ks kt ku kv gt mv mw mx my aw mz bi"><span id="681e" class="na ls in mw b gy nb nc l nd ne">for feature in continuous_feature:<br/> sns.distplot(df[feature])<br/> plt.title(feature)<br/> plt.show()</span></pre><p id="caa4" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">10.对于分类特征，我们分析每个特征中唯一值的数量，以了解要实现的编码类型</p><h1 id="b167" class="lr ls in bd lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo bi translated"><strong class="ak"> B .特色工程</strong></h1><p id="5593" class="pw-post-body-paragraph jk jl in jm b jn mp jp jq jr mq jt ju jv nk jx jy jz nl kb kc kd nm kf kg kh ig bi translated"><strong class="jm io"> 1。通过删除基于</strong>的特征来执行特征选择</p><ul class=""><li id="3073" class="ld le in jm b jn jo jr js jv lf jz lg kd lh kh li lj lk ll bi translated">缺失值百分比高的要素</li><li id="edfe" class="ld le in jm b jn lm jr ln jv lo jz lp kd lq kh li lj lk ll bi translated">共线(高度相关)要素</li><li id="9226" class="ld le in jm b jn lm jr ln jv lo jz lp kd lq kh li lj lk ll bi translated">基于树的模型中重要性为零的特征</li><li id="4018" class="ld le in jm b jn lm jr ln jv lo jz lp kd lq kh li lj lk ll bi translated">具有单一唯一值的要素</li></ul><p id="4ae1" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io"> 2。插补</strong></p><ul class=""><li id="943d" class="ld le in jm b jn jo jr js jv lf jz lg kd lh kh li lj lk ll bi translated">插补是用替代值替换缺失数据的过程</li><li id="7bdd" class="ld le in jm b jn lm jr ln jv lo jz lp kd lq kh li lj lk ll bi translated"><em class="nf"> </em> <strong class="jm io"> <em class="nf">分类特征</em> </strong>中缺失值有多种处理方式。在这种情况下，每个分类特征中缺失的值被识别并替换为“新类别”</li></ul><pre class="ks kt ku kv gt mv mw mx my aw mz bi"><span id="4913" class="na ls in mw b gy nb nc l nd ne">df[‘Health Indicator’]=np.where(df[‘Health Indicator’].isnull(),’XN’,df[‘Health Indicator’])</span></pre><ul class=""><li id="936d" class="ld le in jm b jn jo jr js jv lf jz lg kd lh kh li lj lk ll bi translated">对于<strong class="jm io"> <em class="nf">数值特征</em> </strong>，缺失的数值被替换为0</li></ul><pre class="ks kt ku kv gt mv mw mx my aw mz bi"><span id="e05e" class="na ls in mw b gy nb nc l nd ne">df[‘Holding_Policy_Type’]=df[‘Holding_Policy_Type’].fillna(0)</span></pre><ul class=""><li id="393c" class="ld le in jm b jn jo jr js jv lf jz lg kd lh kh li lj lk ll bi translated">其中一个字符串类型的类别包含数值，因此特征值被转换为浮点型，缺少的值被替换为0</li></ul><pre class="ks kt ku kv gt mv mw mx my aw mz bi"><span id="56e3" class="na ls in mw b gy nb nc l nd ne">#Converting the string value into numeric value<br/>df[‘Holding_Policy_Duration’]=df[‘Holding_Policy_Duration’].apply<br/>(lambda x: float(x))</span><span id="a02d" class="na ls in mw b gy ng nc l nd ne">#Replacing the missing values by 0<br/>df['Holding_Policy_Duration']=df['Holding_Policy_Duration'].<br/>fillna(0)</span></pre><p id="313e" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io"> 3。编码</strong></p><ul class=""><li id="de9f" class="ld le in jm b jn jo jr js jv lf jz lg kd lh kh li lj lk ll bi translated">在处理分类数据以将值转换为数值类型时，编码是必需的预处理步骤</li><li id="d2e1" class="ld le in jm b jn lm jr ln jv lo jz lp kd lq kh li lj lk ll bi translated"><strong class="jm io">一键编码:</strong>包含较少类别值的分类特征使得应用一键编码更有效，以避免维数灾难</li></ul><pre class="ks kt ku kv gt mv mw mx my aw mz bi"><span id="0bbd" class="na ls in mw b gy nb nc l nd ne">pd.get_dummies(df[[‘Accomodation_Type’,’Reco_Insurance_Type’,’Is_Spouse’]],drop_first=True)</span></pre><ul class=""><li id="6f35" class="ld le in jm b jn jo jr js jv lf jz lg kd lh kh li lj lk ll bi translated"><strong class="jm io">目标编码:</strong>我们不能对包含更多类别的分类特征实施一键编码，因为这会增加维度的数量。为此，对这些特征实施了目标编码，其中评估了根据目标列的每个类别的平均值，并且每个标签被其各自的值替换</li></ul><pre class="ks kt ku kv gt mv mw mx my aw mz bi"><span id="781f" class="na ls in mw b gy nb nc l nd ne">values_city_code=round(df.groupby(‘City_Code’)[‘Response’].mean(),3)<br/>df[‘City_Code’]=df[‘City_Code’].map(values_city_code)</span></pre><p id="3bb3" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io"> 4。缩放比例</strong></p><ul class=""><li id="4f11" class="ld le in jm b jn jo jr js jv lf jz lg kd lh kh li lj lk ll bi translated">机器学习中的特征缩放是在创建机器学习模型之前的数据预处理期间最关键的步骤之一</li><li id="4fd0" class="ld le in jm b jn lm jr ln jv lo jz lp kd lq kh li lj lk ll bi translated">机器学习算法只看到数字——如果范围有很大的差异，比如几千范围内的差异和几十范围内的差异，它可能会做出潜在的假设，即更高范围内的数字具有某种优势。所以这些更重要的数字在训练模型时开始起更决定性的作用。因此，需要将所有的特征值都放在同一范围内</li><li id="39a8" class="ld le in jm b jn lm jr ln jv lo jz lp kd lq kh li lj lk ll bi translated">最常见的特征缩放技术是规范化和标准化</li><li id="693c" class="ld le in jm b jn lm jr ln jv lo jz lp kd lq kh li lj lk ll bi translated">为这个问题语句实现的特征缩放是使用MinMaxScaler库的标准化</li></ul><pre class="ks kt ku kv gt mv mw mx my aw mz bi"><span id="d6af" class="na ls in mw b gy nb nc l nd ne">from sklearn.preprocessing import MinMaxScaler<br/>minmax=MinMaxScaler()<br/>minmax.fit(df[features])</span></pre><p id="f98d" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated"><strong class="jm io"> 5。存储数据</strong></p><ul class=""><li id="41ec" class="ld le in jm b jn jo jr js jv lf jz lg kd lh kh li lj lk ll bi translated">遵循所有特征工程步骤后，我们以pickle格式或任何其他合适的格式保存数据，以避免每次使用相同数据运行代码时执行上述步骤</li></ul><h1 id="1d2d" class="lr ls in bd lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo bi translated">C.型号选择</h1><ol class=""><li id="287a" class="ld le in jm b jn mp jr mq jv mr jz ms kd mt kh mu lj lk ll bi translated">当应用模型时，我们需要分离独立特征和从属(目标)特征</li><li id="f152" class="ld le in jm b jn lm jr ln jv lo jz lp kd lq kh mu lj lk ll bi translated">这是一个分类问题陈述，实现了诸如DecisionTreeClassifier、XGBoostClassifier和RandomForestClassifier之类的算法，并且基于准确性分数和Roc Auc分数，相应地选择了XGBoostClassifier</li><li id="ca38" class="ld le in jm b jn lm jr ln jv lo jz lp kd lq kh mu lj lk ll bi translated">为了算法和参数的最佳选择，使用了超参数调谐</li><li id="8f80" class="ld le in jm b jn lm jr ln jv lo jz lp kd lq kh mu lj lk ll bi translated"><strong class="jm io">算法选择:</strong>实现TPOTClassifier库，以便了解数据集的最佳可能算法</li></ol><pre class="ks kt ku kv gt mv mw mx my aw mz bi"><span id="5fae" class="na ls in mw b gy nb nc l nd ne">from tpot import TPOTClassifier<br/>tpot=TPOTClassifier()<br/>tpot = TPOTClassifier(generations=5, population_size=20, cv=5,random_state=42, verbosity=2)<br/>tpot.fit(X_train, y_train)</span></pre><p id="3e98" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">5.<strong class="jm io">参数选择:</strong></p><ul class=""><li id="bc11" class="ld le in jm b jn jo jr js jv lf jz lg kd lh kh li lj lk ll bi translated">可以使用RandomSearchCV和GridSearchCV等超参数技术</li><li id="80f4" class="ld le in jm b jn lm jr ln jv lo jz lp kd lq kh li lj lk ll bi translated">RandomSearchCV可以通过以下方式实现，以了解算法中要使用的最佳参数组合:</li></ul><pre class="ks kt ku kv gt mv mw mx my aw mz bi"><span id="3589" class="na ls in mw b gy nb nc l nd ne">#Hyperparameter optimization<br/>params={<br/> “learning_rate” : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,<br/> “max_depth” : [ 3, 4, 5, 6, 8, 10, 12, 15],<br/> “min_child_weight” : [ 1, 3, 5, 7 ],<br/> #The value should be less than 1<br/> “gamma” : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],<br/> #The value should be less than 1<br/> “colsample_bytree” : [ 0.3, 0.4, 0.5 , 0.7 ]<br/>}</span><span id="6090" class="na ls in mw b gy ng nc l nd ne">#Implementing RandomSearchCV for hyperparameter tuning<br/>random_search=RandomizedSearchCV(classifier,param_distributions=params,n_iter=5,scoring='roc_auc',n_jobs=-1,cv=5,verbose=3)</span><span id="26e9" class="na ls in mw b gy ng nc l nd ne">random_search.fit(X_train,y_train)<br/>random_search.best_estimator_</span></pre><p id="bbc1" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">6.从随机搜索中获得的结果用作XGBoostClassifier中的参数值，然后执行fit方法</p><pre class="ks kt ku kv gt mv mw mx my aw mz bi"><span id="4b25" class="na ls in mw b gy nb nc l nd ne">import xgboost</span><span id="9c49" class="na ls in mw b gy ng nc l nd ne">classifier=xgboost.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,colsample_bynode=1, colsample_bytree=0.5, gamma=0.0, gpu_id=-1,importance_type='gain', interaction_constraints='', learning_rate=0.05, max_delta_step=0, max_depth=4,min_child_weight=3,  monotone_constraints='()', n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact', validate_parameters=1, verbosity=None)</span><span id="18cd" class="na ls in mw b gy ng nc l nd ne">classifier.fit(X_train,y_train)</span></pre><p id="e6ea" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">7.然后，我们检查在训练数据上实现的模型的准确性。这是一个分类问题，我们将使用准确性得分和ROC AUC得分来确定模型效率</p><pre class="ks kt ku kv gt mv mw mx my aw mz bi"><span id="c150" class="na ls in mw b gy nb nc l nd ne">from sklearn.metrics import accuracy_score,roc_auc_score<br/>y_pred=classifier.predict(X_train)</span><span id="87fb" class="na ls in mw b gy ng nc l nd ne">#Accuracy Score<br/>acc_score=accuracy_score(y_test,y_pred)<br/>print('Accuracy Score: ',acc_score)</span><span id="03c3" class="na ls in mw b gy ng nc l nd ne">#ROC AUC Score<br/>roc_auc_score=roc_auc_score(y_test,y_pred)<br/>print('ROC AUC Score: ',roc_auc_score)</span></pre><h1 id="9731" class="lr ls in bd lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo bi translated">D.预测测试数据的目标值</h1><ol class=""><li id="2291" class="ld le in jm b jn mp jr mq jv mr jz ms kd mt kh mu lj lk ll bi translated">在模型选择之后，我们将预测测试数据的目标值</li><li id="d1cb" class="ld le in jm b jn lm jr ln jv lo jz lp kd lq kh mu lj lk ll bi translated">为训练数据遵循的所有特征工程步骤也需要为测试数据实现</li><li id="1ea7" class="ld le in jm b jn lm jr ln jv lo jz lp kd lq kh mu lj lk ll bi translated">我们使用在训练阶段创建的模型对象的预测方法来评估分类问题输出</li></ol><pre class="ks kt ku kv gt mv mw mx my aw mz bi"><span id="5e07" class="na ls in mw b gy nb nc l nd ne">test_pred=classifier.predict(X_test)</span></pre></div><div class="ab cl nn no hr np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="ig ih ii ij ik"><p id="d31d" class="pw-post-body-paragraph jk jl in jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ig bi translated">希望这篇文章有深刻的见解，是一个有用的倡议，从解决数据科学问题开始。</p></div></div>    
</body>
</html>