<html>
<head>
<title>Is it worth writing a custom CNN for your classification task?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为你的分类任务写一个自定义 CNN 值得吗？</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/is-it-worth-writing-a-custom-cnn-for-your-classification-task-a5faacbe795b?source=collection_archive---------2-----------------------#2022-11-21">https://blog.devgenius.io/is-it-worth-writing-a-custom-cnn-for-your-classification-task-a5faacbe795b?source=collection_archive---------2-----------------------#2022-11-21</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><figure class="gl gn jl jm jn jo gh gi paragraph-image"><div class="gh gi jk"><img src="../Images/4a2f1fc2dedc95b927043ea28df869bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*N4w77tPfl1gc85zYE_a2Mg.png"/></div><figcaption class="jr js gj gh gi jt ju bd b be z dk translated">由稳定扩散产生</figcaption></figure><p id="68a1" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">分类是计算机视觉中一项基本而广泛的任务。幸运的是，对于分类问题有很多很好的架构，您可以在 PyTorch 和 TensorFlow 中找到它们，因此您可以轻松地选择模型并根据您的数据进行训练。这是一个可靠的解决方案，也是一个正确的起点。但是我有一个任务要做一个真正快速轻量级的神经网络，准备牺牲一些准确性。让我们看看进展如何。</p><h1 id="94a2" class="kt ku in bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">我想达到什么目标？</h1><p id="aff4" class="pw-post-body-paragraph jv jw in jx b jy lr ka kb kc ls ke kf kg lt ki kj kk lu km kn ko lv kq kr ks ig bi translated">因此，我需要一个轻量级和快速的卷积神经网络分类任务，相当小的图像(约 178x178)和 5 类预测。</p><p id="4ea1" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">我的分类模型将基于检测器模型的作物产量进行推理，这就是为什么我的数据集图像很小，但它们的大小不一样。基于大小统计和一些实验，我发现神经网络输入的最佳大小是 178x178，有 3 个通道(RGB)。因为我希望我的推断更快，所以输入越小越好。</p><h1 id="e606" class="kt ku in bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">我有什么选择？</h1><p id="3558" class="pw-post-body-paragraph jv jw in jx b jy lr ka kb kc ls ke kf kg lt ki kj kk lu km kn ko lv kq kr ks ig bi translated">我可以从<a class="ae lw" href="https://pytorch.org/vision/stable/models.html#classification" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>获取一个预训练的模型，然后用我的数据训练它。我应该得到很好的结果，但大多数模型是在 224x224 或更大的图像上进行预训练的。当然，我可以调整到推荐的大小，但是对于我的推理时间和数据来说，这不是最佳的。我可以用 178x178 的图像进行训练，但这似乎也不是最佳的，因为神经网络是在不同的大小上进行预训练的。</p><p id="6036" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">所以我的第二个想法是写一个简单的自定义 CNN。在这种情况下，我可以对我的数据采用一种架构，并对其进行调整，使其在我的情况下足够准确和快速地工作。这比编写一个伟大的通用架构(例如 EfficientNet)更容易，它在各种情况下都能很好地工作。有了两条不同的路，我开始工作。</p><h1 id="094b" class="kt ku in bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">如何为 PyTorch 准备我们的数据？</h1><p id="1908" class="pw-post-body-paragraph jv jw in jx b jy lr ka kb kc ls ke kf kg lt ki kj kk lu km kn ko lv kq kr ks ig bi translated">无论你选择什么道路，你都需要为训练准备数据。我假设您已经收集了数据并将其存储到文件夹中，这些文件夹显示了您的类:</p><pre class="lx ly lz ma gt mb mc md bn me mf bi"><span id="86d8" class="mg ku in mc b be mh mi l mj mk">-&gt; data_folder<br/>---&gt; class_1<br/>-----&gt; image_1.jpg<br/>-----&gt; image_2.jpg<br/>---&gt; class_2<br/>-----&gt; image_1.jpg<br/>-----&gt; image_2.jpg</span></pre><p id="fced" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">之后，我们需要:</p><ul class=""><li id="cee1" class="ml mm in jx b jy jz kc kd kg mn kk mo ko mp ks mq mr ms mt bi translated">将数据拆分到文件夹“训练”、“有效”、“测试”</li><li id="d5c7" class="ml mm in jx b jy mu kc mv kg mw kk mx ko my ks mq mr ms mt bi translated">加载和预处理数据</li></ul><p id="25f6" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">下面是如何做到这一点的示例(utils.py):</p><pre class="lx ly lz ma gt mb mc md bn me mf bi"><span id="dcd7" class="mg ku in mc b be mh mi l mz mk">import os<br/>import random<br/>import shutil<br/><br/>import torch<br/>from torchvision import datasets, transforms<br/><br/><br/># Count images for train valid test split<br/>def get_sets_amount(valid_x, test_x, path_to_folder):<br/>    count_images = 0<br/><br/>    folders = [x for x in os.listdir(path_to_folder) if not x.startswith(".")]<br/>    for folder in folders:<br/>        path = os.path.join(path_to_folder, folder)<br/>        for image in os.listdir(path):<br/>            image_path = os.path.join(path, image)<br/>            if os.path.isfile(image_path) and not image.startswith("."):<br/>                count_images += 1<br/><br/>    valid_amount = int(count_images * valid_x)<br/>    test_amount = int(count_images * test_x)<br/>    train_amount = count_images - valid_amount - test_amount<br/><br/>    return train_amount, valid_amount, test_amount<br/><br/><br/># Split images by folders<br/>def create_sets_folders(path_to_folder, valid_part, test_part, classes):<br/>    train_amount, valid_amount, test_amount = get_sets_amount(<br/>        valid_part, test_part, path_to_folder<br/>    )<br/>    print(<br/>        f"Train images: {train_amount}\nValid images: {valid_amount}\nTest images: {test_amount}"<br/>    )<br/><br/>    os.chdir(path_to_folder)<br/>    if os.path.isdir("train") is False:<br/><br/>        os.mkdir("valid")<br/>        os.mkdir("test")<br/><br/>        for name in classes:<br/>            shutil.copytree(f"{name}", f"train/{name}")<br/>            os.mkdir(f"valid/{name}")<br/>            os.mkdir(f"test/{name}")<br/><br/>            valid_samples = random.sample(<br/>                os.listdir(f"train/{name}"), round(valid_amount / len(classes))<br/>            )<br/>            for j in valid_samples:<br/>                shutil.move(f"train/{name}/{j}", f"valid/{name}")<br/><br/>            test_samples = random.sample(<br/>                os.listdir(f"train/{name}"), round(test_amount / len(classes))<br/>            )<br/>            for k in test_samples:<br/>                shutil.move(f"train/{name}/{k}", f"test/{name}")<br/><br/>        print("Created train, valid and test directories")<br/><br/><br/># Load images to Torch and preprocess them<br/>def load_data(path, im_size, batch_size):<br/>    transform = transforms.Compose([transforms.Resize(im_size), transforms.ToTensor()])<br/>    dataset = datasets.ImageFolder(path, transform=transform)<br/>    dataloader = torch.utils.data.DataLoader(<br/>        dataset, batch_size=batch_size, shuffle=True<br/>    )<br/><br/>    return dataloader<br/><br/><br/>def get_splited_data(<br/>    path_to_folder, valid_part, test_part, classes, im_size, batch_size<br/>):<br/>    create_sets_folders(path_to_folder, valid_part, test_part, classes)<br/><br/>    train_data = load_data(os.path.join(path_to_folder, "train"), im_size, batch_size)<br/>    valid_data = load_data(os.path.join(path_to_folder, "valid"), im_size, batch_size)<br/>    test_data = load_data(os.path.join(path_to_folder, "test"), im_size, batch_size)<br/><br/>    return train_data, valid_data, test_data</span></pre><h1 id="de09" class="kt ku in bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">如何在自定义数据集上轻松训练 PyTorch 模型？</h1><p id="7e9e" class="pw-post-body-paragraph jv jw in jx b jy lr ka kb kc ls ke kf kg lt ki kj kk lu km kn ko lv kq kr ks ig bi translated">在第一个解决方案中，我只需要一个预训练的模型，改变最后一层，以获得正确数量的类的输出。您可以修补架构或添加增强，但假设这是我们的基线模型。下面是一个如何训练你的模型的例子:</p><pre class="lx ly lz ma gt mb mc md bn me mf bi"><span id="f33f" class="mg ku in mc b be mh mi l mz mk">import os<br/>import time<br/>from pathlib import Path<br/><br/>import torch<br/>import torchvision.models as models<br/>from sklearn.metrics import accuracy_score, f1_score<br/>from torch import nn<br/>from tqdm import tqdm<br/><br/>from utils import get_splited_data<br/><br/><br/># get model predictions<br/>def get_preds(model, testing_data, device):<br/>    val_preds = []<br/>    val_labels = []<br/>    model.eval()  # set mode<br/><br/>    with torch.no_grad():<br/>        for data, target in testing_data:<br/>            images, labels = data.to(device), target.to(device)<br/>            outputs = model.forward(images)<br/>            val_preds.extend(torch.max(outputs.data, 1).indices.tolist())<br/>            val_labels.extend(labels.tolist())<br/><br/>    return val_preds, val_labels<br/><br/><br/>def build_model(num_classes, device):<br/>    model = models.efficientnet_b0(<br/>        weights=models.EfficientNet_B0_Weights.DEFAULT,<br/>    )<br/>    model.classifier[1] = nn.Linear(in_features=1280, out_features=num_classes)<br/>    return model.to(device)<br/><br/><br/>def train(<br/>    train_data, device, optimizer, model, loss_func, valid_data, epochs, path_to_save<br/>):<br/>    best_metric = 0<br/><br/>    for epoch in range(1, epochs + 1):<br/>        model.train()  # set mode<br/><br/>        with tqdm(train_data, unit="batch") as tepoch:<br/>            for data, target in tepoch:<br/>                tepoch.set_description(f"Epoch {epoch}/{epochs}")<br/><br/>                images, labels = data.to(device), target.to(device)<br/>                # zero the parameter gradients<br/>                optimizer.zero_grad()<br/>                # forward + loss + backward + optimize<br/>                outputs = model.forward(images)<br/>                loss = loss_func(outputs, labels)<br/>                loss.backward()<br/>                optimizer.step()<br/><br/>        # Get metrics after an epoch<br/>        preds, valid_labels = get_preds(model, valid_data, device)<br/>        f1 = f1_score(preds, valid_labels, average="weighted")<br/>        accuracy = accuracy_score(preds, valid_labels)<br/><br/>        print(f"Valid accuracy: {round(accuracy, 2)}, valid f1: {round(f1, 2)}")<br/><br/>        # Save best model<br/>        if f1 &gt; best_metric:<br/>            best_metric = f1<br/>            torch.save(model.state_dict(), os.path.join(path_to_save, "model.pt"))<br/><br/><br/>def infer(model_path, valid_data, test_data, device, classes):<br/>    model = build_model(len(classes), device)<br/>    checkpoint = torch.load(model_path)<br/>    model.load_state_dict(checkpoint)<br/><br/>    time_start = time.perf_counter()<br/><br/>    valid_accuracy = round(accuracy_score(*get_preds(model, valid_data, device)), 2)<br/>    test_accuracy = round(accuracy_score(*get_preds(model, test_data, device)), 2)<br/><br/>    print("time:", round(time.perf_counter() - time_start, 3))<br/>    print(f"valid_accuracy = {valid_accuracy}, test_accuracy = {test_accuracy}")<br/><br/><br/>def main():<br/>    path_to_folder = Path("path_to_folder")<br/>    path_to_save = Path("path_to_save")<br/>    device = torch.device("mps")  # 'cuda' if you use nvidia gpu<br/><br/>    classes = ["class_1", "class_2"]<br/>    im_size = 256, 256<br/>    valid_part = 0.15<br/>    test_part = 0.05<br/>    batch_size = 30<br/>    epochs = 15<br/><br/>    torch.manual_seed(42)<br/><br/>    train_data, valid_data, test_data = get_splited_data(<br/>        path_to_folder, valid_part, test_part, classes, im_size, batch_size<br/>    )<br/><br/>    model = build_model(len(classes), device)  # build the model<br/>    loss_func = (<br/>        nn.CrossEntropyLoss()<br/>    )  # init loss function (combined with final activation)<br/>    optimizer = torch.optim.Adam(model.parameters())<br/><br/>    train(<br/>        train_data,<br/>        device,<br/>        optimizer,<br/>        model,<br/>        loss_func,<br/>        valid_data,<br/>        epochs,<br/>        path_to_save,<br/>    )<br/>    infer(path_to_save / "model.pt", valid_data, test_data, device, classes)<br/><br/><br/>if __name__ == "__main__":<br/>    main()</span></pre><h1 id="b300" class="kt ku in bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">自定义 CNN 呢？</h1><p id="84eb" class="pw-post-body-paragraph jv jw in jx b jy lr ka kb kc ls ke kf kg lt ki kj kk lu km kn ko lv kq kr ks ig bi translated">第二条路径会稍微长一点。首先，我需要创建一个架构，这是我为这项任务带来的:</p><figure class="lx ly lz ma gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="nb nc di nd bf ne"><div class="gh gi na"><img src="../Images/f6004dfcfab96a396c9dfcaa6a1dc59f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jf-hn3i6cx0pMgEaYDrQAg.png"/></div></div><figcaption class="jr js gj gh gi jt ju bd b be z dk translated">定制分类器架构</figcaption></figure><p id="ce7c" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">这很简单，但应该行得通。训练代码类似于第一个，只需要用选择的架构编写你的自定义类。这里有一个例子:</p><pre class="lx ly lz ma gt mb mc md bn me mf bi"><span id="8dc6" class="mg ku in mc b be mh mi l mz mk">class Custom_classifier(nn.Module):<br/>    def __init__(self):<br/>        super(Custom_classifier, self).__init__()<br/><br/>        self.features = nn.Sequential(<br/>            # input channels, output channels, kernel size, padding<br/>            nn.Conv2d(3, 64, (3, 3), padding='same'),<br/>            nn.BatchNorm2d(64),<br/>            nn.ReLU(),<br/><br/>            nn.Conv2d(64, 128, (3, 3)),<br/>            nn.MaxPool2d((3, 3)),<br/>            nn.BatchNorm2d(128),<br/>            nn.ReLU(),<br/><br/>            nn.Conv2d(128, 128, (3, 3)),<br/>            nn.MaxPool2d((3, 3)),<br/>            nn.BatchNorm2d(128),<br/>            nn.ReLU(),<br/><br/>            nn.Conv2d(128, 256, (3, 3)),<br/>            nn.MaxPool2d((3, 3)),<br/>            nn.BatchNorm2d(256),<br/>            nn.ReLU(),<br/><br/>            nn.Conv2d(256, 256, (3, 3)),<br/>            nn.BatchNorm2d(256),<br/>            nn.ReLU(),<br/>        )<br/><br/>        self.glob_pool = nn.AdaptiveAvgPool2d((1, 1)) # Global average pooling<br/><br/>        self.classifier = nn.Sequential(<br/>            nn.Linear(256, 256),<br/>            nn.ReLU(),<br/><br/>            nn.Linear(256, 128),<br/>            nn.ReLU(),<br/><br/>            nn.Linear(128, 5), # n_classes<br/>        )<br/><br/><br/>    def forward(self, x):<br/>      x = self.features(x)<br/>      x = self.glob_pool(x).reshape(-1, 256)<br/>      x = self.classifier(x)<br/>      return x</span></pre><p id="f7ce" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">你可以写得更简洁，我只是在修改架构时发现它更容易使用。所以用这个片段作为例子。</p><h1 id="90ef" class="kt ku in bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">我的结果是什么？</h1><p id="df41" class="pw-post-body-paragraph jv jw in jx b jy lr ka kb kc ls ke kf kg lt ki kj kk lu km kn ko lv kq kr ks ig bi translated">最后说一下训练结果。我已经训练了 EfficientNetB0 和 MobileNetV3，并从头开始训练，我还尝试了 256x256 和 178x178 作为输入尺寸。当然还有 178x178 输入尺寸的自定义 CNN。以下是我得到的信息:</p><figure class="lx ly lz ma gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="nb nc di nd bf ne"><div class="gh gi nf"><img src="../Images/91909cbb1f39a1aebb9b6ffeafa8c007.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SDt1Nlrk_HBwWLuTgJKKvQ.png"/></div></div></figure><figure class="lx ly lz ma gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="nb nc di nd bf ne"><div class="gh gi ng"><img src="../Images/4f0af6a3ac510746d44319f34417c3fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0zE6v3BLUC_EnWgHk5YIXg.png"/></div></div></figure><figure class="lx ly lz ma gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="nb nc di nd bf ne"><div class="gh gi nh"><img src="../Images/d93ac03d41a5a5625d2367e6212d56f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ulqd690eEEEMB59IVUcjRQ.png"/></div></div></figure><p id="ad80" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">很容易看出，预训练的模型更准确(咄)，但有趣的是，在从头开始训练时，我得到了与定制模型同样好的结果，即使输入大小更低，而且它更快更小，所以架构很好。那给了我什么？不幸的是，没有太多，因为我每个班只有大约 3000 张图片，所以我不能得到更接近预训练模型的精度。</p><p id="5f04" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">以下是来自培训的所有数据:</p><figure class="lx ly lz ma gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="nb nc di nd bf ne"><div class="gh gi ni"><img src="../Images/4286962dd1346688f824bc0dc420af05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dXTxCk061AWH-7RsGWerNQ.png"/></div></div><figcaption class="jr js gj gh gi jt ju bd b be z dk translated">推理时间是用谷歌 colab 的 a100 对 4164 幅图像进行测量的</figcaption></figure><h1 id="4e13" class="kt ku in bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">那么值得吗？</h1><p id="7560" class="pw-post-body-paragraph jv jw in jx b jy lr ka kb kc ls ke kf kg lt ki kj kk lu km kn ko lv kq kr ks ig bi translated">如果你没有大量的数据，你可以利用预训练的模型——这是一个很好的解决方案(你也可以冻结一些层)。</p><p id="0f76" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">如果你有具体的数据而 ImageNet 或者 COCO 是不相关的，你就要从零开始训练模型。你也可以从现有的架构开始，看看你能得到多好的结果，这仍然是一个好的解决方案。</p><p id="ff6d" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">在极少数情况下，您可能需要一个定制的模型，因此您可以从头开始编写它或者定制现有的架构。</p><p id="4796" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">如果你有具体的数据而 ImageNet 或者 COCO 是不相关的，你就要从零开始训练模型。你也可以从现有的架构开始，看看你能得到多好的结果，这仍然是一个好的解决方案。在极少数情况下，您可能需要一个定制的模型，因此您可以从头开始编写它或者定制现有的架构。</p><p id="47a2" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">最后，这种情况下的答案是不，不值得。我可以采用一个预训练的模型，并获得 96%的准确性，模型大小略有增加，推理速度略有下降。是的，从一个快速的基线开始，然后试着增加它总是一个好主意。</p><p id="a17f" class="pw-post-body-paragraph jv jw in jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ig bi translated">感谢您的关注！</p></div></div>    
</body>
</html>