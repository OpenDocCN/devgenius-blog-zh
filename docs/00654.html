<html>
<head>
<title>Actually using Deep Neural Network Layers without learning what they even are!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">实际上使用深度神经网络层，甚至不知道它们是什么！</h1>
<blockquote>原文：<a href="https://blog.devgenius.io/actually-using-deep-neural-network-layers-without-learning-what-they-even-are-a63425c4470b?source=collection_archive---------18-----------------------#2020-06-13">https://blog.devgenius.io/actually-using-deep-neural-network-layers-without-learning-what-they-even-are-a63425c4470b?source=collection_archive---------18-----------------------#2020-06-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/4dfd14c149aedbdabbbc2945e86072df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fbgPH-KF9cIaWGvG"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated"><a class="ae kc" href="https://unsplash.com/@hansonluu?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">汉森卢</a>在<a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="fbf8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最近，我在<a class="ae kc" href="http://freecodecamp.org/" rel="noopener ugc nofollow" target="_blank"> Freecodecamp </a>上开始了一个深度学习课程，并偶然发现了 Jovian.ml，这就像是我第一次开始觉得即使是我也可以学习<a class="ae kc" href="https://www.youtube.com/watch?v=vo_fUOk-IKk&amp;t=543s" rel="noopener ugc nofollow" target="_blank">深度学习。通过这门课程，我将分享我的旅程，因为我每周都做作业和项目。这是为数不多的博客中的第三篇。</a></p><p id="3a29" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如我已经说过的，我真的不知道什么是神经网络，直到我在 4 层架构的帮助下完成了这个 CIFAR10 数据集预测模型的构建后两天。我看过 Pytorch 的第三次演讲:从零到甘斯课程。很明显，我被指向了几个资源，但很明显，我只是在完成实际任务后才查看它们。</p><p id="82b0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于作业，跳到这个博客的结尾。这里的大部分代码都是不言自明的，除了线性和逻辑回归模型之外，我真的不知道更多的东西，这是我在以前的博客中学习和讨论过的。事实上，我很惊讶地看到，添加一个非线性元素，并在选择的层中训练它，会给我带来实际的深度神经网络实践经验！</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><p id="279a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面是作业的问题陈述。</p><blockquote class="lj lk ll"><p id="9b38" class="kd ke li kf b kg kh ki kj kk kl km kn lm kp kq kr ln kt ku kv lo kx ky kz la ij bi translated">使用神经网络对日常物体的图像进行分类</p></blockquote><p id="e5f8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">尝试许多不同的神经网络架构来解决问题的能力是深度学习真正强大的原因，特别是与线性回归、逻辑回归等浅层学习技术相比。</p><p id="1963" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这项任务中，你将:</p><p id="2ffd" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">探索 CIFAR10 数据集:<a class="ae kc" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank">https://www.cs.toronto.edu/~kriz/cifar.html</a></p><p id="147c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">建立训练管道，在 GPU 上训练神经网络</p><p id="cb0b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">尝试不同的网络架构和超参数</p><blockquote class="lj lk ll"><p id="7fa4" class="kd ke li kf b kg kh ki kj kk kl km kn lm kp kq kr ln kt ku kv lo kx ky kz la ij bi translated">进口</p></blockquote><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="24c2" class="ly lz iq lu b gy ma mb l mc md"># Uncomment and run the commands below if imports fail</span><span id="6577" class="ly lz iq lu b gy me mb l mc md"># !conda install numpy pandas pytorch torchvision cpuonly -c pytorch -y</span><span id="9d75" class="ly lz iq lu b gy me mb l mc md"># !pip install matplotlib --upgrade --quiet</span><span id="8593" class="ly lz iq lu b gy me mb l mc md">import torch</span><span id="053d" class="ly lz iq lu b gy me mb l mc md">import torchvision</span><span id="6026" class="ly lz iq lu b gy me mb l mc md">import numpy as np</span><span id="52a0" class="ly lz iq lu b gy me mb l mc md">import matplotlib.pyplot as plt</span><span id="60ea" class="ly lz iq lu b gy me mb l mc md">import torch.nn as nn</span><span id="9340" class="ly lz iq lu b gy me mb l mc md">import torch.nn.functional as F</span><span id="536b" class="ly lz iq lu b gy me mb l mc md">from torchvision.datasets import CIFAR10</span><span id="f1ce" class="ly lz iq lu b gy me mb l mc md">from torchvision.transforms import ToTensor</span><span id="d136" class="ly lz iq lu b gy me mb l mc md">from torchvision.utils import make_grid</span><span id="4390" class="ly lz iq lu b gy me mb l mc md">from torch.utils.data.dataloader import DataLoader</span><span id="848f" class="ly lz iq lu b gy me mb l mc md">from torch.utils.data import random_split</span><span id="0a2d" class="ly lz iq lu b gy me mb l mc md">%matplotlib inline</span><span id="8b96" class="ly lz iq lu b gy me mb l mc md"># Project name used for jovian.commit</span><span id="bccc" class="ly lz iq lu b gy me mb l mc md">project_name = '03-cifar10-feedforward'</span></pre><blockquote class="lj lk ll"><p id="4d3c" class="kd ke li kf b kg kh ki kj kk kl km kn lm kp kq kr ln kt ku kv lo kx ky kz la ij bi translated">探索 CIFAR10 数据集</p></blockquote><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="fdb9" class="ly lz iq lu b gy ma mb l mc md">dataset = CIFAR10(root='data/', download=True, transform=ToTensor())</span><span id="eecf" class="ly lz iq lu b gy me mb l mc md">test_dataset = CIFAR10(root='data/', train=False, transform=ToTensor())</span><span id="052e" class="ly lz iq lu b gy me mb l mc md">Downloading <a class="ae kc" href="https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz" rel="noopener ugc nofollow" target="_blank">https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz</a> to data/cifar-10-python.tar.gz</span></pre><p id="e38a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">170500096/?[00:20 &lt;00:00, 80989446.23it/s]</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="b4eb" class="ly lz iq lu b gy ma mb l mc md">Extracting data/cifar-10-python.tar.gz to data/</span></pre><p id="73a4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">问:训练数据集包含多少幅图像？</strong></p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="694a" class="ly lz iq lu b gy ma mb l mc md">dataset_size = len(dataset)</span><span id="7b3f" class="ly lz iq lu b gy me mb l mc md">dataset_size</span><span id="388f" class="ly lz iq lu b gy me mb l mc md">50000</span></pre><p id="3a98" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">问:测试数据集包含多少幅图像？</strong></p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="26c4" class="ly lz iq lu b gy ma mb l mc md">test_dataset_size = len(test_dataset)</span><span id="5760" class="ly lz iq lu b gy me mb l mc md">test_dataset_size</span><span id="9751" class="ly lz iq lu b gy me mb l mc md">10000</span></pre><p id="aa1f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">问:数据集包含多少个输出类？你能列出它们吗？</strong></p><p id="b1d6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">提示:使用<code class="fe mf mg mh lu b">dataset.classes</code></p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="19ba" class="ly lz iq lu b gy ma mb l mc md">classes = dataset.classes</span><span id="29ef" class="ly lz iq lu b gy me mb l mc md">classes</span><span id="42d4" class="ly lz iq lu b gy me mb l mc md">['airplane',<br/> 'automobile',<br/> 'bird',<br/> 'cat',<br/> 'deer',<br/> 'dog',<br/> 'frog',<br/> 'horse',<br/> 'ship',<br/> 'truck']</span><span id="5426" class="ly lz iq lu b gy me mb l mc md">num_classes = len(dataset.classes)</span><span id="4907" class="ly lz iq lu b gy me mb l mc md">num_classes</span><span id="49cc" class="ly lz iq lu b gy me mb l mc md">10</span></pre><p id="fc2f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">问:来自数据集的图像张量的形状是什么？</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="8563" class="ly lz iq lu b gy ma mb l mc md">img, label = dataset[0]</span><span id="98d0" class="ly lz iq lu b gy me mb l mc md">img_shape = img.shape</span><span id="73df" class="ly lz iq lu b gy me mb l mc md">img_shape</span><span id="797d" class="ly lz iq lu b gy me mb l mc md">torch.Size([3, 32, 32])</span></pre><p id="4838" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi mi translated">注意，该数据集由三通道彩色图像(RGB)组成。让我们看一个来自数据集的样本图像。<code class="fe mf mg mh lu b">matplotlib</code>期望通道是图像张量的最后一个维度(而在 PyTorch 中它们是第一个维度)，所以我们将通过<code class="fe mf mg mh lu b">.permute</code>张量方法将通道转移到最后一个维度。让我们也为图像打印标签。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="cd0a" class="ly lz iq lu b gy ma mb l mc md">img, label = dataset[0]</span><span id="f3ca" class="ly lz iq lu b gy me mb l mc md">plt.imshow(img.permute((1, 2, 0)))</span><span id="68ea" class="ly lz iq lu b gy me mb l mc md">print('Label (numeric):', label)</span><span id="eb44" class="ly lz iq lu b gy me mb l mc md">print('Label (textual):', classes[label])</span><span id="8f3a" class="ly lz iq lu b gy me mb l mc md">Label (numeric): 6<br/>Label (textual): frog</span></pre><p id="21b7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">(可选)问:你能确定属于每一类的图像数量吗？</strong></p><p id="2f5c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">提示:遍历数据集。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="9f73" class="ly lz iq lu b gy ma mb l mc md">numb_of_image= np.zeros(len(dataset.classes), dtype= 'int64')</span><span id="e36a" class="ly lz iq lu b gy me mb l mc md">numb_of_image[0]</span><span id="3ad9" class="ly lz iq lu b gy me mb l mc md">​</span><span id="cf38" class="ly lz iq lu b gy me mb l mc md">for image,label in dataset:</span><span id="9d71" class="ly lz iq lu b gy me mb l mc md">numb_of_image[label]+=1</span><span id="7f6d" class="ly lz iq lu b gy me mb l mc md">for i in range(num_classes):</span><span id="3ff7" class="ly lz iq lu b gy me mb l mc md">print (" Class "+classes[i]+" : \t\t"+str(numb_of_image[i])+" images.")</span><span id="018d" class="ly lz iq lu b gy me mb l mc md">Class airplane : 		5000 images.<br/> Class automobile : 		5000 images.<br/> Class bird : 		5000 images.<br/> Class cat : 		5000 images.<br/> Class deer : 		5000 images.<br/> Class dog : 		5000 images.<br/> Class frog : 		5000 images.<br/> Class horse : 		5000 images.<br/> Class ship : 		5000 images.<br/> Class truck : 		5000 images.</span></pre><p id="1dad" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在继续之前，让我们把工作留给木星吧。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="77aa" class="ly lz iq lu b gy ma mb l mc md">!pip install jovian --upgrade --quiet</span><span id="ad37" class="ly lz iq lu b gy me mb l mc md">import jovian</span><span id="2b63" class="ly lz iq lu b gy me mb l mc md">jovian.commit(project=project_name, environment=None)</span><span id="58d6" class="ly lz iq lu b gy me mb l mc md">[jovian] Attempting to save notebook..<br/>[jovian] Detected Kaggle notebook...<br/>[jovian] Uploading notebook to <a class="ae kc" href="https://jovian.ml/aakashkrsingh1/03-cifar10-feedforward" rel="noopener ugc nofollow" target="_blank">https://jovian.ml/aakashkrsingh1/03-cifar10-feedforward</a></span></pre><p id="71b5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">提交成功:<a class="ae kc" href="https://jovian.ml/aakashkrsingh1/03-cifar10-feedforward" rel="noopener ugc nofollow" target="_blank">https://jovian.ml/aakashkrsingh1/03-cifar10-feedforward</a></p><blockquote class="lj lk ll"><p id="d1b6" class="kd ke li kf b kg kh ki kj kk kl km kn lm kp kq kr ln kt ku kv lo kx ky kz la ij bi translated"><strong class="kf ir">准备培训数据</strong></p><p id="636d" class="kd ke li kf b kg kh ki kj kk kl km kn lm kp kq kr ln kt ku kv lo kx ky kz la ij bi translated">我们将使用包含 5000 张图像(数据集的 10%)的验证集。为了确保每次都得到相同的验证集，我们将 PyTorch 的随机数生成器设置为种子值 43。</p></blockquote><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="0979" class="ly lz iq lu b gy ma mb l mc md">torch.manual_seed(43)</span><span id="bf57" class="ly lz iq lu b gy me mb l mc md">val_size = 5000</span><span id="394a" class="ly lz iq lu b gy me mb l mc md">train_size = len(dataset) - val_size</span></pre><p id="a7c2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们使用<code class="fe mf mg mh lu b">random_split</code>方法来创建训练&amp;验证集</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="e0a7" class="ly lz iq lu b gy ma mb l mc md">train_ds, val_ds = random_split(dataset, [train_size, val_size])</span><span id="4253" class="ly lz iq lu b gy me mb l mc md">len(train_ds), len(val_ds)</span><span id="ca71" class="ly lz iq lu b gy me mb l mc md">(45000, 5000)</span></pre><p id="e07d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在可以创建数据加载器来批量加载数据。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="4293" class="ly lz iq lu b gy ma mb l mc md">batch_size=128</span><span id="6e11" class="ly lz iq lu b gy me mb l mc md">train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)</span><span id="bd4b" class="ly lz iq lu b gy me mb l mc md">val_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)</span><span id="a3bb" class="ly lz iq lu b gy me mb l mc md">test_loader = DataLoader(test_dataset, batch_size*2, num_workers=4, pin_memory=True)</span></pre><p id="fea0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们使用 Torchvision 的<code class="fe mf mg mh lu b">make_grid</code>助手函数来可视化一批数据。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="870c" class="ly lz iq lu b gy ma mb l mc md">for images, _ in train_loader:</span><span id="a02a" class="ly lz iq lu b gy me mb l mc md">print('images.shape:', images.shape)</span><span id="6916" class="ly lz iq lu b gy me mb l mc md">plt.figure(figsize=(16,8))</span><span id="27f2" class="ly lz iq lu b gy me mb l mc md">plt.axis('off')</span><span id="05dc" class="ly lz iq lu b gy me mb l mc md">plt.imshow(make_grid(images, nrow=16).permute((1, 2, 0)))</span><span id="8051" class="ly lz iq lu b gy me mb l mc md">break</span><span id="15a8" class="ly lz iq lu b gy me mb l mc md">images.shape: torch.Size([128, 3, 32, 32])</span></pre><p id="e8f8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你能通过观察给所有的图片贴上标签吗？尝试手动标记数据的随机样本是估计问题难度和识别标记中的错误(如果有的话)的好方法。</p><blockquote class="lj lk ll"><p id="bc1f" class="kd ke li kf b kg kh ki kj kk kl km kn lm kp kq kr ln kt ku kv lo kx ky kz la ij bi translated">GPU 基础模型课程和培训</p></blockquote><p id="5ebc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们创建一个基础模型类，它包含除模型架构之外的所有内容，也就是说，它不包含<code class="fe mf mg mh lu b">__init__</code>和<code class="fe mf mg mh lu b">__forward__</code>方法。稍后我们将扩展这个类来尝试不同的架构。事实上，您可以扩展这个模型来解决任何图像分类问题。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="0811" class="ly lz iq lu b gy ma mb l mc md">def accuracy(outputs, labels):</span><span id="7921" class="ly lz iq lu b gy me mb l mc md">_, preds = torch.max(outputs, dim=1)</span><span id="509f" class="ly lz iq lu b gy me mb l mc md">return torch.tensor(torch.sum(preds == labels).item() / len(preds))</span><span id="6661" class="ly lz iq lu b gy me mb l mc md">class ImageClassificationBase(nn.Module):</span><span id="aef0" class="ly lz iq lu b gy me mb l mc md">def training_step(self, batch):</span><span id="8fd3" class="ly lz iq lu b gy me mb l mc md">images, labels = batch</span><span id="8298" class="ly lz iq lu b gy me mb l mc md">out = self(images)                  # Generate predictions</span><span id="7272" class="ly lz iq lu b gy me mb l mc md">loss = F.cross_entropy(out, labels) # Calculate loss</span><span id="1dbf" class="ly lz iq lu b gy me mb l mc md">return loss</span><span id="9a5c" class="ly lz iq lu b gy me mb l mc md">def validation_step(self, batch):</span><span id="095b" class="ly lz iq lu b gy me mb l mc md">images, labels = batch</span><span id="1e03" class="ly lz iq lu b gy me mb l mc md">out = self(images)                    # Generate predictions</span><span id="a082" class="ly lz iq lu b gy me mb l mc md">loss = F.cross_entropy(out, labels)   # Calculate loss</span><span id="67dc" class="ly lz iq lu b gy me mb l mc md">acc = accuracy(out, labels)           # Calculate accuracy</span><span id="00e6" class="ly lz iq lu b gy me mb l mc md">return {'val_loss': loss.detach(), 'val_acc': acc}</span><span id="b6f1" class="ly lz iq lu b gy me mb l mc md">def validation_epoch_end(self, outputs):</span><span id="3552" class="ly lz iq lu b gy me mb l mc md">batch_losses = [x['val_loss'] for x in outputs]</span><span id="8b35" class="ly lz iq lu b gy me mb l mc md">epoch_loss = torch.stack(batch_losses).mean()   # Combine losses</span><span id="f1bc" class="ly lz iq lu b gy me mb l mc md">batch_accs = [x['val_acc'] for x in outputs]</span><span id="7d7f" class="ly lz iq lu b gy me mb l mc md">epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies</span><span id="1e90" class="ly lz iq lu b gy me mb l mc md">return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}</span><span id="75b6" class="ly lz iq lu b gy me mb l mc md">def epoch_end(self, epoch, result):</span><span id="1b2f" class="ly lz iq lu b gy me mb l mc md">print("Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}".format(epoch, result['val_loss'], result['val_acc']))</span></pre><p id="0a49" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们也可以使用与之前完全相同的训练循环。我希望您开始看到将我们的代码重构为可重用函数的好处。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="470e" class="ly lz iq lu b gy ma mb l mc md">def evaluate(model, val_loader):</span><span id="ae5b" class="ly lz iq lu b gy me mb l mc md">outputs = [model.validation_step(batch) for batch in val_loader]</span><span id="489c" class="ly lz iq lu b gy me mb l mc md">return model.validation_epoch_end(outputs)</span><span id="95ab" class="ly lz iq lu b gy me mb l mc md">​</span><span id="112b" class="ly lz iq lu b gy me mb l mc md">def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):</span><span id="bca5" class="ly lz iq lu b gy me mb l mc md">history = []</span><span id="f4de" class="ly lz iq lu b gy me mb l mc md">optimizer = opt_func(model.parameters(), lr)</span><span id="bd7a" class="ly lz iq lu b gy me mb l mc md">for epoch in range(epochs):</span><span id="f7ee" class="ly lz iq lu b gy me mb l mc md"># Training Phase</span><span id="3f6e" class="ly lz iq lu b gy me mb l mc md">for batch in train_loader:</span><span id="804b" class="ly lz iq lu b gy me mb l mc md">loss = model.training_step(batch)</span><span id="1e7c" class="ly lz iq lu b gy me mb l mc md">loss.backward()</span><span id="3591" class="ly lz iq lu b gy me mb l mc md">optimizer.step()</span><span id="9034" class="ly lz iq lu b gy me mb l mc md">optimizer.zero_grad()</span><span id="cde2" class="ly lz iq lu b gy me mb l mc md"># Validation phase</span><span id="e94b" class="ly lz iq lu b gy me mb l mc md">result = evaluate(model, val_loader)</span><span id="5944" class="ly lz iq lu b gy me mb l mc md">model.epoch_end(epoch, result)</span><span id="a26d" class="ly lz iq lu b gy me mb l mc md">history.append(result)</span><span id="6ca6" class="ly lz iq lu b gy me mb l mc md">return history</span></pre><p id="acc0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，让我们定义一些将数据和标签转移到 GPU 的工具，如果有的话。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="6b36" class="ly lz iq lu b gy ma mb l mc md">torch.cuda.is_available()</span><span id="8d85" class="ly lz iq lu b gy me mb l mc md">True</span><span id="41db" class="ly lz iq lu b gy me mb l mc md">def get_default_device():</span><span id="aa29" class="ly lz iq lu b gy me mb l mc md">"""Pick GPU if available, else CPU"""</span><span id="2baf" class="ly lz iq lu b gy me mb l mc md">if torch.cuda.is_available():</span><span id="3ccb" class="ly lz iq lu b gy me mb l mc md">return torch.device('cuda')</span><span id="3814" class="ly lz iq lu b gy me mb l mc md">else:</span><span id="67b8" class="ly lz iq lu b gy me mb l mc md">return torch.device('cpu')</span><span id="a699" class="ly lz iq lu b gy me mb l mc md">device = get_default_device()</span><span id="2750" class="ly lz iq lu b gy me mb l mc md">device</span><span id="6fd5" class="ly lz iq lu b gy me mb l mc md">device(type='cuda')</span><span id="be72" class="ly lz iq lu b gy me mb l mc md">def to_device(data, device):</span><span id="4b93" class="ly lz iq lu b gy me mb l mc md">"""Move tensor(s) to chosen device"""</span><span id="c48f" class="ly lz iq lu b gy me mb l mc md">if isinstance(data, (list,tuple)):</span><span id="82b1" class="ly lz iq lu b gy me mb l mc md">return [to_device(x, device) for x in data]</span><span id="33dc" class="ly lz iq lu b gy me mb l mc md">return data.to(device, non_blocking=True)</span><span id="3bb8" class="ly lz iq lu b gy me mb l mc md">​</span><span id="aa78" class="ly lz iq lu b gy me mb l mc md">class DeviceDataLoader():</span><span id="e5fc" class="ly lz iq lu b gy me mb l mc md">"""Wrap a dataloader to move data to a device"""</span><span id="a5c5" class="ly lz iq lu b gy me mb l mc md">def __init__(self, dl, device):</span><span id="93f4" class="ly lz iq lu b gy me mb l mc md">self.dl = dl</span><span id="8669" class="ly lz iq lu b gy me mb l mc md">self.device = device</span><span id="91ee" class="ly lz iq lu b gy me mb l mc md">def __iter__(self):</span><span id="b034" class="ly lz iq lu b gy me mb l mc md">"""Yield a batch of data after moving it to device"""</span><span id="8daa" class="ly lz iq lu b gy me mb l mc md">for b in self.dl:</span><span id="306f" class="ly lz iq lu b gy me mb l mc md">yield to_device(b, self.device)</span><span id="2cad" class="ly lz iq lu b gy me mb l mc md">​</span><span id="f553" class="ly lz iq lu b gy me mb l mc md">def __len__(self):</span><span id="6188" class="ly lz iq lu b gy me mb l mc md">"""Number of batches"""</span><span id="aa10" class="ly lz iq lu b gy me mb l mc md">return len(self.dl)</span></pre><p id="e091" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们也定义几个辅助函数来绘制损耗和精度。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="4044" class="ly lz iq lu b gy ma mb l mc md">def plot_losses(history):</span><span id="9781" class="ly lz iq lu b gy me mb l mc md">losses = [x['val_loss'] for x in history]</span><span id="0269" class="ly lz iq lu b gy me mb l mc md">plt.plot(losses, '-x')</span><span id="5900" class="ly lz iq lu b gy me mb l mc md">plt.xlabel('epoch')</span><span id="8c12" class="ly lz iq lu b gy me mb l mc md">plt.ylabel('loss')</span><span id="c8f6" class="ly lz iq lu b gy me mb l mc md">plt.title('Loss vs. No. of epochs');</span><span id="8831" class="ly lz iq lu b gy me mb l mc md">def plot_accuracies(history):</span><span id="4a1c" class="ly lz iq lu b gy me mb l mc md">accuracies = [x['val_acc'] for x in history]</span><span id="3576" class="ly lz iq lu b gy me mb l mc md">plt.plot(accuracies, '-x')</span><span id="b3a0" class="ly lz iq lu b gy me mb l mc md">plt.xlabel('epoch')</span><span id="5267" class="ly lz iq lu b gy me mb l mc md">plt.ylabel('accuracy')</span><span id="0251" class="ly lz iq lu b gy me mb l mc md">plt.title('Accuracy vs. No. of epochs');</span></pre><p id="2dc4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们将数据加载器移动到适当的设备上。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="0ec2" class="ly lz iq lu b gy ma mb l mc md">train_loader = DeviceDataLoader(train_loader, device)</span><span id="4437" class="ly lz iq lu b gy me mb l mc md">val_loader = DeviceDataLoader(val_loader, device)</span><span id="7b0e" class="ly lz iq lu b gy me mb l mc md">test_loader = DeviceDataLoader(test_loader, device)</span></pre><blockquote class="lj lk ll"><p id="2436" class="kd ke li kf b kg kh ki kj kk kl km kn lm kp kq kr ln kt ku kv lo kx ky kz la ij bi translated"><strong class="kf ir">训练模型</strong></p><p id="9569" class="kd ke li kf b kg kh ki kj kk kl km kn lm kp kq kr ln kt ku kv lo kx ky kz la ij bi translated">我们将多次尝试训练该模型。每次，尝试不同的架构和不同的学习速率。以下是一些可以尝试的想法:</p></blockquote><ul class=""><li id="4834" class="mr ms iq kf b kg kh kk kl ko mt ks mu kw mv la mw mx my mz bi translated">增加或减少隐藏层的数量</li><li id="93db" class="mr ms iq kf b kg na kk nb ko nc ks nd kw ne la mw mx my mz bi translated">增加或减少每个隐藏层的大小</li><li id="48ed" class="mr ms iq kf b kg na kk nb ko nc ks nd kw ne la mw mx my mz bi translated">尝试不同的激活功能</li><li id="7ffa" class="mr ms iq kf b kg na kk nb ko nc ks nd kw ne la mw mx my mz bi translated">尝试不同次数的训练</li><li id="6e19" class="mr ms iq kf b kg na kk nb ko nc ks nd kw ne la mw mx my mz bi translated">在每个时期尝试不同的学习速度</li></ul><p id="4e0d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你能达到的最高验证准确度是多少？</p><blockquote class="lj lk ll"><p id="c1bd" class="kd ke li kf b kg kh ki kj kk kl km kn lm kp kq kr ln kt ku kv lo kx ky kz la ij bi translated">你能达到 50%的准确率吗？60%呢？</p></blockquote><p id="f663" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae kc" href="https://jovian.ml/aakashkrsingh1/03-cifar10-feedforward" rel="noopener ugc nofollow" target="_blank"> <strong class="kf ir"> <em class="li">剧透预警:我达到了 56%的准确率！</em> </strong> </a></p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="4660" class="ly lz iq lu b gy ma mb l mc md">input_size = 3*32*32</span><span id="4b3e" class="ly lz iq lu b gy me mb l mc md">output_size = 10</span></pre><p id="8378" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">问:扩展</strong> <code class="fe mf mg mh lu b"><strong class="kf ir">ImageClassificationBase</strong></code> <strong class="kf ir">类完成模型定义。</strong></p><p id="64d1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">提示:定义<code class="fe mf mg mh lu b">__init__</code>和<code class="fe mf mg mh lu b">forward</code>方法。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="2350" class="ly lz iq lu b gy ma mb l mc md">class CIFAR10Model(ImageClassificationBase):</span><span id="ea69" class="ly lz iq lu b gy me mb l mc md">def __init__(self):</span><span id="b32e" class="ly lz iq lu b gy me mb l mc md">super().__init__()</span><span id="80c1" class="ly lz iq lu b gy me mb l mc md">self.layer1 = nn.Linear(input_size,2048)</span><span id="44fa" class="ly lz iq lu b gy me mb l mc md">self.layer2 = nn.Linear(2048, 1024)</span><span id="e3d7" class="ly lz iq lu b gy me mb l mc md">self.layer3 = nn.Linear(1024, 64)</span><span id="908d" class="ly lz iq lu b gy me mb l mc md">self.layer4 = nn.Linear(64, output_size)</span><span id="3b38" class="ly lz iq lu b gy me mb l mc md">def forward(self, xb):</span><span id="1d6d" class="ly lz iq lu b gy me mb l mc md"># Flatten images into vectors</span><span id="443f" class="ly lz iq lu b gy me mb l mc md">out = xb.view(xb.size(0), -1)</span><span id="89cf" class="ly lz iq lu b gy me mb l mc md"># Apply layers &amp; activation functions</span><span id="6dfb" class="ly lz iq lu b gy me mb l mc md">out = F.relu(self.layer1(out))</span><span id="ea31" class="ly lz iq lu b gy me mb l mc md">out = F.relu(self.layer2(out))</span><span id="1e54" class="ly lz iq lu b gy me mb l mc md">out = F.relu(self.layer3(out))</span><span id="b182" class="ly lz iq lu b gy me mb l mc md">out = self.layer4(out)</span><span id="bbbb" class="ly lz iq lu b gy me mb l mc md">return out</span></pre><p id="b678" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您现在可以实例化该模型，并将其移动到适当的设备上。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="3df1" class="ly lz iq lu b gy ma mb l mc md">model = to_device(CIFAR10Model(), device)</span></pre><p id="8e42" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在训练模型之前，最好使用初始权重集来检查验证损失和准确性。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="834e" class="ly lz iq lu b gy ma mb l mc md">history = [evaluate(model, val_loader)]</span><span id="e470" class="ly lz iq lu b gy me mb l mc md">history</span><span id="385b" class="ly lz iq lu b gy me mb l mc md">[{'val_loss': 2.3046696186065674, 'val_acc': 0.09804687649011612}]</span></pre><p id="d5e3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">问:使用</strong> <code class="fe mf mg mh lu b"><strong class="kf ir">fit</strong></code> <strong class="kf ir">函数训练模型，减少验证损失&amp;提高精度。</strong></p><p id="288a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">利用 Jupyter 的交互特性在多个阶段中训练模型，每次都根据前一个训练阶段的结果调整时期数和学习率。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="f2c5" class="ly lz iq lu b gy ma mb l mc md">history += fit(20, 1e-1, model, train_loader, val_loader)</span><span id="d315" class="ly lz iq lu b gy me mb l mc md">Epoch [0], val_loss: 1.9074, val_acc: 0.3133<br/>Epoch [1], val_loss: 1.9483, val_acc: 0.3256<br/>Epoch [2], val_loss: 1.7978, val_acc: 0.3590<br/>Epoch [3], val_loss: 1.8224, val_acc: 0.3625<br/>Epoch [4], val_loss: 1.6472, val_acc: 0.4050<br/>Epoch [5], val_loss: 1.6542, val_acc: 0.3990<br/>Epoch [6], val_loss: 1.6782, val_acc: 0.3990<br/>Epoch [7], val_loss: 1.6896, val_acc: 0.4114<br/>Epoch [8], val_loss: 1.5654, val_acc: 0.4446<br/>Epoch [9], val_loss: 1.8320, val_acc: 0.4041<br/>Epoch [10], val_loss: 1.5664, val_acc: 0.4380<br/>Epoch [11], val_loss: 1.4741, val_acc: 0.4813<br/>Epoch [12], val_loss: 1.4432, val_acc: 0.4832<br/>Epoch [13], val_loss: 1.4054, val_acc: 0.4977<br/>Epoch [14], val_loss: 1.4874, val_acc: 0.4856<br/>Epoch [15], val_loss: 1.5399, val_acc: 0.4665<br/>Epoch [16], val_loss: 1.5237, val_acc: 0.4644<br/>Epoch [17], val_loss: 1.3979, val_acc: 0.5097<br/>Epoch [18], val_loss: 1.6656, val_acc: 0.4508<br/>Epoch [19], val_loss: 1.4789, val_acc: 0.4879</span><span id="c5bb" class="ly lz iq lu b gy me mb l mc md">history += fit(10, 1e-3, model, train_loader, val_loader)</span><span id="9d10" class="ly lz iq lu b gy me mb l mc md">Epoch [0], val_loss: 1.3157, val_acc: 0.5477<br/>Epoch [1], val_loss: 1.3072, val_acc: 0.5530<br/>Epoch [2], val_loss: 1.3045, val_acc: 0.5524<br/>Epoch [3], val_loss: 1.3043, val_acc: 0.5542<br/>Epoch [4], val_loss: 1.3032, val_acc: 0.5545<br/>Epoch [5], val_loss: 1.3038, val_acc: 0.5549<br/>Epoch [6], val_loss: 1.3032, val_acc: 0.5545<br/>Epoch [7], val_loss: 1.3030, val_acc: 0.5561<br/>Epoch [8], val_loss: 1.3032, val_acc: 0.5543<br/>Epoch [9], val_loss: 1.3033, val_acc: 0.5530</span><span id="6edc" class="ly lz iq lu b gy me mb l mc md">history += fit(10, 1e-5, model, train_loader, val_loader)</span><span id="292a" class="ly lz iq lu b gy me mb l mc md">Epoch [0], val_loss: 1.3033, val_acc: 0.5534<br/>Epoch [1], val_loss: 1.3032, val_acc: 0.5534<br/>Epoch [2], val_loss: 1.3032, val_acc: 0.5532<br/>Epoch [3], val_loss: 1.3032, val_acc: 0.5537<br/>Epoch [4], val_loss: 1.3032, val_acc: 0.5537<br/>Epoch [5], val_loss: 1.3032, val_acc: 0.5537<br/>Epoch [6], val_loss: 1.3032, val_acc: 0.5539<br/>Epoch [7], val_loss: 1.3032, val_acc: 0.5541<br/>Epoch [8], val_loss: 1.3032, val_acc: 0.5545<br/>Epoch [9], val_loss: 1.3032, val_acc: 0.5547</span><span id="72f5" class="ly lz iq lu b gy me mb l mc md">history += fit(10, 2e-6, model, train_loader, val_loader)</span><span id="ffe0" class="ly lz iq lu b gy me mb l mc md">Epoch [0], val_loss: 1.3032, val_acc: 0.5547<br/>Epoch [1], val_loss: 1.3032, val_acc: 0.5547<br/>Epoch [2], val_loss: 1.3032, val_acc: 0.5547<br/>Epoch [3], val_loss: 1.3032, val_acc: 0.5547<br/>Epoch [4], val_loss: 1.3032, val_acc: 0.5547<br/>Epoch [5], val_loss: 1.3032, val_acc: 0.5547<br/>Epoch [6], val_loss: 1.3032, val_acc: 0.5549<br/>Epoch [7], val_loss: 1.3032, val_acc: 0.5549<br/>Epoch [8], val_loss: 1.3032, val_acc: 0.5549<br/>Epoch [9], val_loss: 1.3032, val_acc: 0.5549</span><span id="d1a7" class="ly lz iq lu b gy me mb l mc md">history += fit(10, 5e-8, model, train_loader, val_loader)</span><span id="7b57" class="ly lz iq lu b gy me mb l mc md">Epoch [0], val_loss: 1.3032, val_acc: 0.5549<br/>Epoch [1], val_loss: 1.3032, val_acc: 0.5549<br/>Epoch [2], val_loss: 1.3032, val_acc: 0.5549<br/>Epoch [3], val_loss: 1.3032, val_acc: 0.5549<br/>Epoch [4], val_loss: 1.3032, val_acc: 0.5549<br/>Epoch [5], val_loss: 1.3032, val_acc: 0.5549<br/>Epoch [6], val_loss: 1.3032, val_acc: 0.5549<br/>Epoch [7], val_loss: 1.3032, val_acc: 0.5549<br/>Epoch [8], val_loss: 1.3032, val_acc: 0.5549<br/>Epoch [9], val_loss: 1.3032, val_acc: 0.5549</span><span id="b3af" class="ly lz iq lu b gy me mb l mc md">epoch_list=[ (20,1e-1),(10,1e-3),(10,2e-6),(10,5e-8) ]</span></pre><p id="ba06" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">绘制损失和精度，以检查您是否开始触及模型在该数据集上的性能极限。如果你能看到进一步提高的空间，你可以多训练一些。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="3b7d" class="ly lz iq lu b gy ma mb l mc md">plot_losses(history)</span><span id="d636" class="ly lz iq lu b gy me mb l mc md">plot_accuracies(history)</span></pre><p id="e1a2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，在测试数据集上评估模型并报告其最终性能。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="98cd" class="ly lz iq lu b gy ma mb l mc md">eval=evaluate(model, test_loader)</span><span id="e4d5" class="ly lz iq lu b gy me mb l mc md">eval</span><span id="f92b" class="ly lz iq lu b gy me mb l mc md">{'val_loss': 1.2519348859786987, 'val_acc': 0.564453125}</span></pre><p id="b08a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你对准确性满意吗？通过完成下面的部分来记录您的结果，然后您可以回来尝试不同的架构&amp;超参数。</p><blockquote class="lj lk ll"><p id="e1ac" class="kd ke li kf b kg kh ki kj kk kl km kn lm kp kq kr ln kt ku kv lo kx ky kz la ij bi translated"><strong class="kf ir">记录结果</strong></p></blockquote><p id="5e24" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当您执行多个实验时，以系统的方式记录结果是很重要的，以便您可以在以后查看它们，并确定您可能希望在以后重现或建立的最佳方法。</p><p id="045e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">问:用简短的总结描述一下模型的架构。</p><p id="4988" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如<code class="fe mf mg mh lu b">"3 layers (16,32,10)"</code> (16，32，10 代表每层的输出大小)</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="2bb0" class="ly lz iq lu b gy ma mb l mc md">arch = "4 layers (2048,1024,64,10)"</span></pre><p id="49c0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">问:提供培训时使用的学习率列表。</strong></p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="b0ab" class="ly lz iq lu b gy ma mb l mc md">lrs = [i for _, i in epoch_list]</span><span id="5816" class="ly lz iq lu b gy me mb l mc md">lrs</span><span id="7dfb" class="ly lz iq lu b gy me mb l mc md">[0.1, 0.001, 2e-06, 5e-08]</span></pre><p id="331a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">问:提供训练时使用的历元数列表。</strong></p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="4a5e" class="ly lz iq lu b gy ma mb l mc md">epochs = [j for j, _ in epoch_list]</span><span id="e3d4" class="ly lz iq lu b gy me mb l mc md">epochs</span><span id="1c66" class="ly lz iq lu b gy me mb l mc md">[20, 10, 10, 10]</span></pre><p id="64d0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">问:最终测试精度&amp;测试损失是多少？</strong></p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="7ec8" class="ly lz iq lu b gy ma mb l mc md">test_acc = eval['val_acc']</span><span id="4df7" class="ly lz iq lu b gy me mb l mc md">test_loss = eval['val_loss']</span><span id="e0b0" class="ly lz iq lu b gy me mb l mc md">test_loss, test_acc</span><span id="85cf" class="ly lz iq lu b gy me mb l mc md">(1.2519348859786987, 0.564453125)</span></pre><p id="7152" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，让我们将训练好的模型权重保存到磁盘，这样我们可以在以后使用这个模型。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="5b13" class="ly lz iq lu b gy ma mb l mc md">torch.save(model.state_dict(), 'cifar10-feedforward.pth')</span></pre><p id="d216" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe mf mg mh lu b">jovian</code>库提供了一些实用功能，让你的工作有条不紊。对于你的 notebok 的每一个版本，你都可以从你的实验中附加一些超参数和指标。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="9836" class="ly lz iq lu b gy ma mb l mc md"># Clear previously recorded hyperparams &amp; metrics</span><span id="8bbb" class="ly lz iq lu b gy me mb l mc md">jovian.reset()</span><span id="2916" class="ly lz iq lu b gy me mb l mc md">jovian.log_hyperparams(arch=arch,</span><span id="36ea" class="ly lz iq lu b gy me mb l mc md">lrs=lrs,</span><span id="29b6" class="ly lz iq lu b gy me mb l mc md">epochs=epochs)</span><span id="c7bc" class="ly lz iq lu b gy me mb l mc md">[jovian] Hyperparams logged.</span><span id="c91c" class="ly lz iq lu b gy me mb l mc md">jovian.log_metrics(test_loss=test_loss, test_acc=test_acc)</span><span id="ea7a" class="ly lz iq lu b gy me mb l mc md">[jovian] Metrics logged.</span></pre><p id="9587" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，我们可以将笔记本提交给 Jovian，附上超参数、度量和训练好的模型权重。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="57b1" class="ly lz iq lu b gy ma mb l mc md">jovian.commit(project=project_name, outputs=['cifar10-feedforward.pth'], environment=None)</span><span id="1e17" class="ly lz iq lu b gy me mb l mc md">[jovian] Attempting to save notebook..<br/>[jovian] Detected Kaggle notebook...<br/>[jovian] Uploading notebook to <a class="ae kc" href="https://jovian.ml/aakashkrsingh1/03-cifar10-feedforward" rel="noopener ugc nofollow" target="_blank">https://jovian.ml/aakashkrsingh1/03-cifar10-feedforward</a></span></pre><p id="265b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">提交成功:<a class="ae kc" href="https://jovian.ml/aakashkrsingh1/03-cifar10-feedforward" rel="noopener ugc nofollow" target="_blank">https://jovian.ml/aakashkrsingh1/03-cifar10-feedforward</a></p><p id="96cd" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">提交后，您可以在 Jovian 的“记录”选项卡中找到记录的指标和超参数。您可以在“文件”选项卡中找到保存的模型权重。</p><blockquote class="lj lk ll"><p id="24b4" class="kd ke li kf b kg kh ki kj kk kl km kn lm kp kq kr ln kt ku kv lo kx ky kz la ij bi translated"><a class="ae kc" href="https://jovian.ml/aakashkrsingh1/03-cifar10-feedforward" rel="noopener ugc nofollow" target="_blank"> <strong class="kf ir">继续实验</strong> </a></p></blockquote><p id="ccb7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，在我的笔记本分叉后，回到<strong class="kf ir">“训练模型”</strong>部分，尝试另一个具有不同超参数集的网络架构。随着您尝试不同的实验，您将开始了解不同架构&amp;超参数如何影响最终结果。如果你不能达到非常高的精度，不要担心，我们将在下一讲中对我们的模型做一些基本的改变。</p><p id="5a0e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦你尝试了多个实验，你可以使用 Jovian 上的<strong class="kf ir">“比较”</strong>按钮来比较你的结果。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><figure class="lp lq lr ls gt jr"><div class="bz fp l di"><div class="nf ng l"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">这是我的 Jupyter 笔记本，用于<a class="ae kc" href="https://jovian.ml/forum/c/pytorch-zero-to-gans/18" rel="noopener ugc nofollow" target="_blank">课程</a>的第三次作业。</figcaption></figure></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><p id="e932" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我</p></div></div>    
</body>
</html>